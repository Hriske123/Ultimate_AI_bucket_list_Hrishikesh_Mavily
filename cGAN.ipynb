{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize images to the range [-1, 1]\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "x_test = (x_test.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "# Reshape images to (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "x_train = x_train[:8000]\n",
        "y_train = y_train[:8000]\n",
        "x_test = x_test[:2000]\n",
        "y_test = y_test[:2000]\n",
        "# One-hot encode the labels\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "metadata": {
        "id": "Mgac4I--TaBL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, ReLU, BatchNormalization, Embedding, multiply, Concatenate, UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def build_generator():\n",
        "    noise_shape = (100,)\n",
        "    label_shape = (num_classes,)\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    label = Input(shape=label_shape)\n",
        "\n",
        "    # Concatenate noise and label\n",
        "    model_input = Concatenate()([noise, label])\n",
        "\n",
        "    x = Dense(256 * 7 * 7, activation='relu')(model_input)\n",
        "    x = Reshape((7, 7, 256))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = Dropout(0.4)(x)  # Adding dropout after Conv2D\n",
        "    x = UpSampling2D()(x)\n",
        "    x = Conv2D(64, kernel_size=3, padding='same', activation='relu')(x) # Adding dropout after Conv2D\n",
        "    x = BatchNormalization()(x)\n",
        "    #x = Dropout(0.4)(x)  # Adding dropout after Conv2D\n",
        "    generated_image = Conv2D(1, kernel_size=3, padding='same', activation='tanh')(x)\n",
        "\n",
        "    model = Model([noise, label], generated_image)\n",
        "    return model\n",
        "    generator = build_generator()\n"
      ],
      "metadata": {
        "id": "aHeYTSt9Vqhm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    img_shape = (28, 28, 1)\n",
        "    label_shape = (num_classes,)\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    label = Input(shape=label_shape)\n",
        "\n",
        "    flat_img = Flatten()(img)\n",
        "\n",
        "    # Concatenate the flattened image and label\n",
        "    model_input = Concatenate()([flat_img, label])\n",
        "\n",
        "    x = Dense(512)(model_input)\n",
        "    x = ReLU()(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = ReLU()(x)\n",
        "    x = Dense(512)(x)\n",
        "    x = ReLU()(x)\n",
        "    validity = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model([img, label], validity)\n",
        "    return model\n",
        "\n",
        "# Instantiate the discriminator\n",
        "discriminator = build_discriminator()\n"
      ],
      "metadata": {
        "id": "F3kPn-KTVs-g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import legacy as optimizers\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "# Use legacy Adam optimizer\n",
        "optimizer = optimizers.Adam(0.0001, 0.5)\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "z = Input(shape=(100,))\n",
        "label = Input(shape=(num_classes,))\n",
        "img = generator([z, label])\n",
        "\n",
        "discriminator.trainable = False\n",
        "valid = discriminator([img, label])\n",
        "\n",
        "combined = Model([z, label], valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "def train(epochs, batch_size=128, sample_interval=200):\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train Discriminator\n",
        "        idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
        "        imgs, labels = x_train[idx], y_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "        gen_imgs = generator.predict([noise, labels])\n",
        "\n",
        "        valid = np.ones((half_batch, 1))\n",
        "        fake = np.zeros((half_batch, 1))\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], valid)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        labels = np.eye(num_classes)[np.random.choice(num_classes, batch_size)]\n",
        "\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        g_loss = combined.train_on_batch([noise, labels], valid)\n",
        "\n",
        "        # Print the progress\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
        "\n",
        "        # If at save interval, save generated image samples\n",
        "        if epoch % sample_interval == 0:\n",
        "            sample_images(epoch)\n",
        "\n",
        "def sample_images(epoch):\n",
        "    r, c = 2, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    sampled_labels = np.eye(num_classes)[np.arange(0, num_classes).reshape(-1)]\n",
        "\n",
        "    gen_imgs = generator.predict([noise, sampled_labels])\n",
        "\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].set_title(f\"Class: {cnt}\")\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    plt.show()\n",
        "\n",
        "# Train the GAN for 10,000 epochs with a batch size of 64\n",
        "train(epochs=10000, batch_size=64, sample_interval=1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VnQRHO9sWHm0",
        "outputId": "c89c096c-7418-4aa5-bb4e-b40407e9afdb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n",
            "0 [D loss: 0.5068666934967041 | D accuracy: 50.0] [G loss: 0.35378801822662354]\n",
            "1/1 [==============================] - 0s 114ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "1 [D loss: 0.4375421702861786 | D accuracy: 50.0] [G loss: 0.3069705665111542]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2 [D loss: 0.4066477045416832 | D accuracy: 50.0] [G loss: 0.28439074754714966]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3 [D loss: 0.3834370616823435 | D accuracy: 50.0] [G loss: 0.30340564250946045]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4 [D loss: 0.37486447021365166 | D accuracy: 57.8125] [G loss: 0.2484697550535202]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5 [D loss: 0.35787686333060265 | D accuracy: 89.0625] [G loss: 0.2830338478088379]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6 [D loss: 0.3557088263332844 | D accuracy: 98.4375] [G loss: 0.2733996510505676]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7 [D loss: 0.3410911560058594 | D accuracy: 96.875] [G loss: 0.2695883512496948]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8 [D loss: 0.35689476504921913 | D accuracy: 76.5625] [G loss: 0.2493588924407959]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9 [D loss: 0.37570562213659286 | D accuracy: 53.125] [G loss: 0.2793693542480469]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "10 [D loss: 0.4072529748082161 | D accuracy: 50.0] [G loss: 0.2838916778564453]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "11 [D loss: 0.4391773883253336 | D accuracy: 50.0] [G loss: 0.263505756855011]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "12 [D loss: 0.457914624363184 | D accuracy: 50.0] [G loss: 0.3009636104106903]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "13 [D loss: 0.4386432785540819 | D accuracy: 50.0] [G loss: 0.2625875174999237]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "14 [D loss: 0.4468909054994583 | D accuracy: 50.0] [G loss: 0.20033855736255646]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "15 [D loss: 0.41043951362371445 | D accuracy: 71.875] [G loss: 0.15623679757118225]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "16 [D loss: 0.413185179233551 | D accuracy: 90.625] [G loss: 0.07815737277269363]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "17 [D loss: 0.369277685880661 | D accuracy: 93.75] [G loss: 0.05522232502698898]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "18 [D loss: 0.2984802834689617 | D accuracy: 98.4375] [G loss: 0.02700134739279747]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "19 [D loss: 0.25295431911945343 | D accuracy: 96.875] [G loss: 0.021651532500982285]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "20 [D loss: 0.24248069524765015 | D accuracy: 93.75] [G loss: 0.009124267846345901]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "21 [D loss: 0.1592615507543087 | D accuracy: 98.4375] [G loss: 0.005525821819901466]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "22 [D loss: 0.15087435394525528 | D accuracy: 95.3125] [G loss: 0.005135015584528446]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "23 [D loss: 0.14056188613176346 | D accuracy: 98.4375] [G loss: 0.002838387619704008]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "24 [D loss: 0.049534921534359455 | D accuracy: 100.0] [G loss: 0.002246080432087183]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "25 [D loss: 0.14690254628658295 | D accuracy: 95.3125] [G loss: 0.0011195021215826273]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "26 [D loss: 0.061831130646169186 | D accuracy: 100.0] [G loss: 0.0006558108143508434]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "27 [D loss: 0.06438140384852886 | D accuracy: 100.0] [G loss: 0.0008252100087702274]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "28 [D loss: 0.03128911554813385 | D accuracy: 100.0] [G loss: 0.0006067676586098969]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "29 [D loss: 0.043726978823542595 | D accuracy: 98.4375] [G loss: 0.0006294195191003382]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "30 [D loss: 0.1299942322075367 | D accuracy: 98.4375] [G loss: 0.0005347850383259356]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "31 [D loss: 0.03810192085802555 | D accuracy: 98.4375] [G loss: 0.00028024567291140556]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "32 [D loss: 0.08563468605279922 | D accuracy: 96.875] [G loss: 0.00029037875356152654]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "33 [D loss: 0.01777855074033141 | D accuracy: 100.0] [G loss: 0.00032411888241767883]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "34 [D loss: 0.06603656895458698 | D accuracy: 98.4375] [G loss: 0.00020065950229763985]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "35 [D loss: 0.027593256905674934 | D accuracy: 100.0] [G loss: 0.0001833572896430269]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "36 [D loss: 0.015143424272537231 | D accuracy: 100.0] [G loss: 0.00028556081815622747]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "37 [D loss: 0.009586187545210123 | D accuracy: 100.0] [G loss: 0.00015676827752031386]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "38 [D loss: 0.008580372203141451 | D accuracy: 100.0] [G loss: 0.0001967177086044103]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "39 [D loss: 0.00376935611711815 | D accuracy: 100.0] [G loss: 0.00018240392091684043]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "40 [D loss: 0.007993652019649744 | D accuracy: 100.0] [G loss: 0.00012609244731720537]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "41 [D loss: 0.009623617632314563 | D accuracy: 100.0] [G loss: 0.00013239355757832527]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "42 [D loss: 0.011686916463077068 | D accuracy: 100.0] [G loss: 9.492166282143444e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "43 [D loss: 0.06818896159529686 | D accuracy: 98.4375] [G loss: 0.000152565015014261]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "44 [D loss: 0.002280277607496828 | D accuracy: 100.0] [G loss: 0.0002039283572230488]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "45 [D loss: 0.0188093448523432 | D accuracy: 100.0] [G loss: 7.062669465085492e-05]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "46 [D loss: 0.003350490878801793 | D accuracy: 100.0] [G loss: 8.707516826689243e-05]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "47 [D loss: 0.013970660977065563 | D accuracy: 100.0] [G loss: 5.3352356189861894e-05]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "48 [D loss: 0.004375504708150402 | D accuracy: 100.0] [G loss: 6.28064080956392e-05]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "49 [D loss: 0.0022587116836803034 | D accuracy: 100.0] [G loss: 6.329266761895269e-05]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "50 [D loss: 0.003896888578310609 | D accuracy: 100.0] [G loss: 0.00010477103933226317]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "51 [D loss: 0.009845380671322346 | D accuracy: 100.0] [G loss: 4.074498428963125e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "52 [D loss: 0.003240722930058837 | D accuracy: 100.0] [G loss: 5.596278060693294e-05]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "53 [D loss: 0.0026442769449204206 | D accuracy: 100.0] [G loss: 6.052003664080985e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "54 [D loss: 0.0034554892918094993 | D accuracy: 100.0] [G loss: 6.857827247586101e-05]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "55 [D loss: 0.001590628846315667 | D accuracy: 100.0] [G loss: 5.739851258113049e-05]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "56 [D loss: 0.001100057823350653 | D accuracy: 100.0] [G loss: 4.98239096486941e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "57 [D loss: 0.0008533438667654991 | D accuracy: 100.0] [G loss: 3.55589363607578e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "58 [D loss: 0.001955163839738816 | D accuracy: 100.0] [G loss: 6.841673166491091e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "59 [D loss: 0.003790648654103279 | D accuracy: 100.0] [G loss: 4.094888208783232e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "60 [D loss: 0.0020998832769691944 | D accuracy: 100.0] [G loss: 3.9817183278501034e-05]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "61 [D loss: 0.0023278282023966312 | D accuracy: 100.0] [G loss: 3.861296136165038e-05]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "62 [D loss: 0.0012292246974539012 | D accuracy: 100.0] [G loss: 4.300940781831741e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "63 [D loss: 0.0009623859659768641 | D accuracy: 100.0] [G loss: 3.376196400495246e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "64 [D loss: 0.004438958945684135 | D accuracy: 100.0] [G loss: 3.3455726224929094e-05]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "65 [D loss: 0.004141777520999312 | D accuracy: 100.0] [G loss: 4.894735320704058e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "66 [D loss: 0.0016860938194440678 | D accuracy: 100.0] [G loss: 3.060455492231995e-05]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "67 [D loss: 0.0011996700777672231 | D accuracy: 100.0] [G loss: 3.859884600387886e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "68 [D loss: 0.004953005583956838 | D accuracy: 100.0] [G loss: 2.5194189220201224e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "69 [D loss: 0.0011925417711609043 | D accuracy: 100.0] [G loss: 4.2985924665117636e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "70 [D loss: 0.0008701585611561313 | D accuracy: 100.0] [G loss: 3.486099012661725e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "71 [D loss: 0.0008398348290938884 | D accuracy: 100.0] [G loss: 2.1568877855315804e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "72 [D loss: 0.006527307792566717 | D accuracy: 100.0] [G loss: 1.7854650650406256e-05]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "73 [D loss: 0.0018282459204783663 | D accuracy: 100.0] [G loss: 1.5551944670733064e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "74 [D loss: 0.001065053409547545 | D accuracy: 100.0] [G loss: 3.8885271351318806e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "75 [D loss: 0.007752049481496215 | D accuracy: 100.0] [G loss: 1.546094790683128e-05]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "76 [D loss: 0.0026875156036112458 | D accuracy: 100.0] [G loss: 1.524005983810639e-05]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "77 [D loss: 0.002047735149972141 | D accuracy: 100.0] [G loss: 1.5610658010700718e-05]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "78 [D loss: 0.0022006880026310682 | D accuracy: 100.0] [G loss: 1.473833981435746e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "79 [D loss: 0.0011753903236240149 | D accuracy: 100.0] [G loss: 1.522129969089292e-05]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "80 [D loss: 0.002092701499350369 | D accuracy: 100.0] [G loss: 1.1305609405098949e-05]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "81 [D loss: 0.0009782561974134296 | D accuracy: 100.0] [G loss: 4.383155464893207e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "82 [D loss: 0.0018470209324732423 | D accuracy: 100.0] [G loss: 1.4798237316426821e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "83 [D loss: 0.0012176698655821383 | D accuracy: 100.0] [G loss: 1.63072891155025e-05]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "84 [D loss: 0.0005715514125768095 | D accuracy: 100.0] [G loss: 1.4568469850928523e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "85 [D loss: 0.001851083361543715 | D accuracy: 100.0] [G loss: 1.952131060534157e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "86 [D loss: 0.0008066642039921135 | D accuracy: 100.0] [G loss: 1.891114516183734e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "87 [D loss: 0.0013496208703145385 | D accuracy: 100.0] [G loss: 3.116205698461272e-05]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "88 [D loss: 0.01318952301517129 | D accuracy: 100.0] [G loss: 2.7508713174029253e-05]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "89 [D loss: 0.0017180760787596228 | D accuracy: 100.0] [G loss: 1.2085432899766602e-05]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "90 [D loss: 0.0007215161167550832 | D accuracy: 100.0] [G loss: 1.0182306141359732e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "91 [D loss: 0.0034272955963388085 | D accuracy: 100.0] [G loss: 1.2837232134188525e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "92 [D loss: 0.0009245157416444272 | D accuracy: 100.0] [G loss: 1.2419319318723865e-05]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "93 [D loss: 0.0058018394047394395 | D accuracy: 100.0] [G loss: 1.0340263543184847e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "94 [D loss: 0.0014576737085008062 | D accuracy: 100.0] [G loss: 9.24343112274073e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "95 [D loss: 0.0031671024626120925 | D accuracy: 100.0] [G loss: 2.2829744921182282e-05]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "96 [D loss: 0.0023628947092220187 | D accuracy: 100.0] [G loss: 8.687971785548143e-06]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "97 [D loss: 0.0026807222748175263 | D accuracy: 100.0] [G loss: 1.401589088345645e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "98 [D loss: 0.0013312504743225873 | D accuracy: 100.0] [G loss: 9.814153600018471e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "99 [D loss: 0.0005684421666956041 | D accuracy: 100.0] [G loss: 5.717874046240468e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "100 [D loss: 0.00038242776827246416 | D accuracy: 100.0] [G loss: 8.636000529804733e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "101 [D loss: 0.012208183761686087 | D accuracy: 100.0] [G loss: 5.450096523418324e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "102 [D loss: 0.0020287863590056077 | D accuracy: 100.0] [G loss: 6.553405000886414e-06]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "103 [D loss: 0.0005652919498970732 | D accuracy: 100.0] [G loss: 2.0160339772701263e-05]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "104 [D loss: 0.0005005805869586766 | D accuracy: 100.0] [G loss: 6.328577910608146e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "105 [D loss: 0.0004991663154214621 | D accuracy: 100.0] [G loss: 6.51800655759871e-06]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "106 [D loss: 0.004375091928523034 | D accuracy: 100.0] [G loss: 6.764185854990501e-06]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "107 [D loss: 0.0009127938683377579 | D accuracy: 100.0] [G loss: 5.257218163023936e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "108 [D loss: 0.0013577243080362678 | D accuracy: 100.0] [G loss: 1.1264161003055051e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "109 [D loss: 0.0006427154294215143 | D accuracy: 100.0] [G loss: 5.176058493816527e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "110 [D loss: 0.0013562890817411244 | D accuracy: 100.0] [G loss: 5.910608706471976e-06]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "111 [D loss: 0.0005348311824491248 | D accuracy: 100.0] [G loss: 1.015112047753064e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "112 [D loss: 0.0023066450376063585 | D accuracy: 100.0] [G loss: 7.154038030421361e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "113 [D loss: 0.0008400315418839455 | D accuracy: 100.0] [G loss: 4.419054675963707e-06]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "114 [D loss: 0.0837849173694849 | D accuracy: 98.4375] [G loss: 1.3807381947117392e-05]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "115 [D loss: 0.12305153162014904 | D accuracy: 96.875] [G loss: 1.3940929420641623e-05]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "116 [D loss: 0.0594388407189399 | D accuracy: 96.875] [G loss: 2.5011904654093087e-06]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "117 [D loss: 0.05266531265806407 | D accuracy: 100.0] [G loss: 4.3189129428355955e-06]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "118 [D loss: 0.03374248631007504 | D accuracy: 98.4375] [G loss: 3.4184561172878603e-06]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "119 [D loss: 0.04898270603735 | D accuracy: 96.875] [G loss: 2.2298872863757424e-06]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "120 [D loss: 0.001382813323289156 | D accuracy: 100.0] [G loss: 1.1157064818689832e-06]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "121 [D loss: 0.002411540597677231 | D accuracy: 100.0] [G loss: 9.638480378271197e-07]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "122 [D loss: 0.0014678971929242834 | D accuracy: 100.0] [G loss: 9.232650768353778e-07]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "123 [D loss: 0.0008963286090875044 | D accuracy: 100.0] [G loss: 1.2571957768159336e-06]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "124 [D loss: 0.0006864627757749986 | D accuracy: 100.0] [G loss: 8.364703489860403e-07]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "125 [D loss: 0.0016503099468536675 | D accuracy: 100.0] [G loss: 6.20174546384078e-07]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "126 [D loss: 0.0014784119557589293 | D accuracy: 100.0] [G loss: 8.030224876165448e-07]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "127 [D loss: 0.0007015938899712637 | D accuracy: 100.0] [G loss: 1.350100774288876e-06]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "128 [D loss: 0.006235314882360399 | D accuracy: 100.0] [G loss: 3.3231499401153997e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "129 [D loss: 0.0012107307047699578 | D accuracy: 100.0] [G loss: 7.310321734621539e-07]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "130 [D loss: 0.0015400430420413613 | D accuracy: 100.0] [G loss: 1.920688418977079e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "131 [D loss: 0.011060943827033043 | D accuracy: 100.0] [G loss: 4.413863052832312e-07]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "132 [D loss: 0.002959081110020634 | D accuracy: 100.0] [G loss: 4.0785585042613093e-07]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "133 [D loss: 0.0011654581903712824 | D accuracy: 100.0] [G loss: 1.0331727935408708e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "134 [D loss: 0.0006870780998724513 | D accuracy: 100.0] [G loss: 7.767660008539679e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "135 [D loss: 0.001326406025327742 | D accuracy: 100.0] [G loss: 4.469315513233596e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "136 [D loss: 0.0004752986533276271 | D accuracy: 100.0] [G loss: 1.15366356112645e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "137 [D loss: 0.0004298458898119861 | D accuracy: 100.0] [G loss: 7.925859222268627e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "138 [D loss: 0.0012918774737045169 | D accuracy: 100.0] [G loss: 5.856432494510955e-07]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "139 [D loss: 0.0004298511739762034 | D accuracy: 100.0] [G loss: 3.4519388236731174e-07]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "140 [D loss: 0.0012744123814627528 | D accuracy: 100.0] [G loss: 9.241566658602096e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "141 [D loss: 0.00043448869837448 | D accuracy: 100.0] [G loss: 6.149030582491832e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "142 [D loss: 0.0004472831424209289 | D accuracy: 100.0] [G loss: 9.613836482458282e-07]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "143 [D loss: 0.0071941104251891375 | D accuracy: 100.0] [G loss: 5.582437552220654e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "144 [D loss: 0.001330677081568865 | D accuracy: 100.0] [G loss: 2.923088686657138e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "145 [D loss: 0.0008788878367340658 | D accuracy: 100.0] [G loss: 2.2908650976205536e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "146 [D loss: 0.0006146022824395914 | D accuracy: 100.0] [G loss: 3.275831943483354e-07]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "147 [D loss: 0.0007959541981108487 | D accuracy: 100.0] [G loss: 4.6898841787879064e-07]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "148 [D loss: 0.0004009163658338366 | D accuracy: 100.0] [G loss: 1.5332519751609652e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "149 [D loss: 0.003525897685904056 | D accuracy: 100.0] [G loss: 3.760413562758913e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "150 [D loss: 0.0006949274429643992 | D accuracy: 100.0] [G loss: 3.8931511880946346e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "151 [D loss: 0.0005299320265521601 | D accuracy: 100.0] [G loss: 1.5845314464968396e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "152 [D loss: 0.00493234395980835 | D accuracy: 100.0] [G loss: 2.64951523831769e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "153 [D loss: 0.0016025611839722842 | D accuracy: 100.0] [G loss: 2.4891281213967886e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "154 [D loss: 0.000795283071056474 | D accuracy: 100.0] [G loss: 1.8017984757534578e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "155 [D loss: 0.00055763097043382 | D accuracy: 100.0] [G loss: 1.0430622978674364e-06]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "156 [D loss: 0.0004073970048921183 | D accuracy: 100.0] [G loss: 3.8647058886454033e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "157 [D loss: 0.0005953852087259293 | D accuracy: 100.0] [G loss: 1.1827193020508275e-06]\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "158 [D loss: 0.014333725906908512 | D accuracy: 98.4375] [G loss: 4.7532620328638586e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "159 [D loss: 0.004610305164533202 | D accuracy: 100.0] [G loss: 2.0984640514143393e-07]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "160 [D loss: 0.0005690221296390519 | D accuracy: 100.0] [G loss: 3.8315346273520845e-07]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "161 [D loss: 0.0005566580512095243 | D accuracy: 100.0] [G loss: 1.902849078305735e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "162 [D loss: 0.0044538904912769794 | D accuracy: 100.0] [G loss: 1.8588316663681326e-07]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "163 [D loss: 0.0008905061986297369 | D accuracy: 100.0] [G loss: 1.505786428879219e-07]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "164 [D loss: 0.0018273693276569247 | D accuracy: 100.0] [G loss: 1.3067958661849843e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "165 [D loss: 0.0007595449569635093 | D accuracy: 100.0] [G loss: 6.336327942335629e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "166 [D loss: 0.00047902544065436814 | D accuracy: 100.0] [G loss: 2.054819674413011e-07]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "167 [D loss: 0.0003874558988172794 | D accuracy: 100.0] [G loss: 6.234430998119933e-07]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "168 [D loss: 0.00042557304550427943 | D accuracy: 100.0] [G loss: 1.9271497819772776e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "169 [D loss: 0.006514086853712797 | D accuracy: 100.0] [G loss: 3.016718324033718e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "170 [D loss: 0.0019495489614200778 | D accuracy: 100.0] [G loss: 1.3273714216666122e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "171 [D loss: 0.0008742567151784897 | D accuracy: 100.0] [G loss: 1.3508218899005442e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "172 [D loss: 0.014449034817516804 | D accuracy: 100.0] [G loss: 1.9320573585446255e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "173 [D loss: 0.0017708176924315921 | D accuracy: 100.0] [G loss: 1.8757245356937347e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "174 [D loss: 0.000525354338606121 | D accuracy: 100.0] [G loss: 2.1054954402188741e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "175 [D loss: 0.001204934756970033 | D accuracy: 100.0] [G loss: 1.54052287371087e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "176 [D loss: 0.30987973883748055 | D accuracy: 93.75] [G loss: 3.4323024920013268e-06]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "177 [D loss: 0.3635827631663382 | D accuracy: 93.75] [G loss: 2.6244422770105302e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "178 [D loss: 0.6046299840945721 | D accuracy: 87.5] [G loss: 4.23799610871356e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "179 [D loss: 0.13867555372416973 | D accuracy: 93.75] [G loss: 1.1095339687017258e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "180 [D loss: 0.22823001071810722 | D accuracy: 98.4375] [G loss: 2.9330269626370864e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "181 [D loss: 0.0059852493495782255 | D accuracy: 100.0] [G loss: 6.318432497209869e-06]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "182 [D loss: 0.27172349725151435 | D accuracy: 92.1875] [G loss: 6.162294994283002e-07]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "183 [D loss: 0.2174159036949277 | D accuracy: 93.75] [G loss: 3.431255208852235e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "184 [D loss: 0.02142781810835004 | D accuracy: 100.0] [G loss: 3.886090098603745e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "185 [D loss: 0.10297872871160507 | D accuracy: 96.875] [G loss: 5.059824275122082e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "186 [D loss: 0.0038318318547680974 | D accuracy: 100.0] [G loss: 1.676362444413826e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "187 [D loss: 0.004103721585124731 | D accuracy: 100.0] [G loss: 1.1139245970070988e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "188 [D loss: 0.01732331793755293 | D accuracy: 98.4375] [G loss: 1.1315789834043244e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "189 [D loss: 0.017612369963899255 | D accuracy: 98.4375] [G loss: 2.110712529201919e-07]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "190 [D loss: 0.01674625091254711 | D accuracy: 100.0] [G loss: 1.5421217369748774e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "191 [D loss: 0.023899482563138008 | D accuracy: 98.4375] [G loss: 6.239389449547161e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "192 [D loss: 0.005513151525519788 | D accuracy: 100.0] [G loss: 1.0125368987701222e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "193 [D loss: 0.009127577999606729 | D accuracy: 100.0] [G loss: 1.1334404348417593e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "194 [D loss: 0.004398444201797247 | D accuracy: 100.0] [G loss: 5.954900217375325e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "195 [D loss: 0.0023045550915412605 | D accuracy: 100.0] [G loss: 2.4709981616410914e-08]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "196 [D loss: 0.0038880130741745234 | D accuracy: 100.0] [G loss: 4.069724468536151e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "197 [D loss: 0.0030839269747957587 | D accuracy: 100.0] [G loss: 2.2586273473734764e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "198 [D loss: 0.002699358039535582 | D accuracy: 100.0] [G loss: 5.091543897606243e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "199 [D loss: 0.006581209367141128 | D accuracy: 100.0] [G loss: 2.2180891789957968e-08]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "200 [D loss: 0.015934429597109556 | D accuracy: 100.0] [G loss: 1.7898607040933712e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "201 [D loss: 0.0059604308335110545 | D accuracy: 100.0] [G loss: 2.5804022030229135e-08]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "202 [D loss: 0.002584514455520548 | D accuracy: 100.0] [G loss: 3.9363786896728925e-08]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "203 [D loss: 0.001957110333023593 | D accuracy: 100.0] [G loss: 3.594607633772284e-08]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "204 [D loss: 0.03866512421518564 | D accuracy: 98.4375] [G loss: 5.347879437067604e-07]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "205 [D loss: 0.0061113537376513705 | D accuracy: 100.0] [G loss: 6.599898227932499e-08]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "206 [D loss: 0.004370824317447841 | D accuracy: 100.0] [G loss: 1.5680360831993312e-07]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "207 [D loss: 0.002715662238188088 | D accuracy: 100.0] [G loss: 8.654453154122166e-08]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "208 [D loss: 0.058475716039538383 | D accuracy: 96.875] [G loss: 9.380686449844688e-09]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "209 [D loss: 0.006111768074333668 | D accuracy: 100.0] [G loss: 3.984702701131937e-08]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "210 [D loss: 0.006497109308838844 | D accuracy: 100.0] [G loss: 3.319859587236351e-08]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "211 [D loss: 0.0019196528010070324 | D accuracy: 100.0] [G loss: 2.5667159064823863e-08]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "212 [D loss: 0.015322760445997119 | D accuracy: 98.4375] [G loss: 7.404790114406978e-09]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "213 [D loss: 0.014999224804341793 | D accuracy: 100.0] [G loss: 3.849199003980175e-08]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "214 [D loss: 0.006070844130590558 | D accuracy: 100.0] [G loss: 1.517745751300481e-08]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "215 [D loss: 0.0017292790134888492 | D accuracy: 100.0] [G loss: 7.74006458925669e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "216 [D loss: 0.0012981312029296532 | D accuracy: 100.0] [G loss: 3.086675093300073e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "217 [D loss: 0.000999630425212672 | D accuracy: 100.0] [G loss: 3.81922138359414e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "218 [D loss: 0.0031814175890758634 | D accuracy: 100.0] [G loss: 1.2613296185293166e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "219 [D loss: 0.001100135108572431 | D accuracy: 100.0] [G loss: 7.632701581883339e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "220 [D loss: 0.0010423994099255651 | D accuracy: 100.0] [G loss: 1.4020839600448198e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "221 [D loss: 0.001430937903933227 | D accuracy: 100.0] [G loss: 4.380350748789397e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "222 [D loss: 0.0007275004409166286 | D accuracy: 100.0] [G loss: 1.223428647278979e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "223 [D loss: 0.004901818989310414 | D accuracy: 100.0] [G loss: 1.1151163548106524e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "224 [D loss: 0.000981328393208969 | D accuracy: 100.0] [G loss: 2.9361357789525755e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "225 [D loss: 0.0013838160666637123 | D accuracy: 100.0] [G loss: 5.515055967464377e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "226 [D loss: 0.0008496330337948166 | D accuracy: 100.0] [G loss: 1.4280984395043106e-08]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "227 [D loss: 0.0007150313249439932 | D accuracy: 100.0] [G loss: 7.95272470099917e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "228 [D loss: 0.002179945004172623 | D accuracy: 100.0] [G loss: 1.178948050295503e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "229 [D loss: 0.0006878272979520261 | D accuracy: 100.0] [G loss: 1.4175437712538042e-08]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "230 [D loss: 0.0021486710757017136 | D accuracy: 100.0] [G loss: 7.386856903934813e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "231 [D loss: 0.014585128054022789 | D accuracy: 98.4375] [G loss: 2.7920570744299766e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "232 [D loss: 0.0038885401299921796 | D accuracy: 100.0] [G loss: 1.1595671978170685e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "233 [D loss: 0.0015579568134853616 | D accuracy: 100.0] [G loss: 8.373389981386481e-09]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "234 [D loss: 0.0017689045635052025 | D accuracy: 100.0] [G loss: 2.6621552251526737e-07]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "235 [D loss: 0.020303445402532816 | D accuracy: 98.4375] [G loss: 6.454347722950615e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "236 [D loss: 0.0036813855986110866 | D accuracy: 100.0] [G loss: 2.6189269419774064e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "237 [D loss: 0.0014096441082074307 | D accuracy: 100.0] [G loss: 1.3908652007899036e-08]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "238 [D loss: 0.0007949908413138473 | D accuracy: 100.0] [G loss: 3.74754538512434e-09]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "239 [D loss: 0.0006891499069752172 | D accuracy: 100.0] [G loss: 9.077941953705704e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "240 [D loss: 0.0005655807749462838 | D accuracy: 100.0] [G loss: 1.7307232980101617e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "241 [D loss: 0.0005941404670011252 | D accuracy: 100.0] [G loss: 1.5997395408362536e-08]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "242 [D loss: 0.0005053542245150311 | D accuracy: 100.0] [G loss: 5.69883029655216e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "243 [D loss: 0.00595477968454361 | D accuracy: 100.0] [G loss: 2.5888347465752304e-08]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "244 [D loss: 0.0014289403916336596 | D accuracy: 100.0] [G loss: 5.571457961650594e-09]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "245 [D loss: 0.04588983487337828 | D accuracy: 98.4375] [G loss: 4.096772698858331e-09]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "246 [D loss: 0.0016615857093711384 | D accuracy: 100.0] [G loss: 3.362166989262505e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "247 [D loss: 0.0007559830792160938 | D accuracy: 100.0] [G loss: 3.4257863212872053e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "248 [D loss: 0.001041383104166016 | D accuracy: 100.0] [G loss: 3.658332747846771e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "249 [D loss: 0.0022080273483879864 | D accuracy: 100.0] [G loss: 4.620134497201889e-09]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "250 [D loss: 0.000582815273446613 | D accuracy: 100.0] [G loss: 3.441307683260675e-09]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "251 [D loss: 0.0015932144597172737 | D accuracy: 100.0] [G loss: 5.419573678722145e-09]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "252 [D loss: 0.0008947536116465926 | D accuracy: 100.0] [G loss: 1.0150408513709408e-08]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "253 [D loss: 0.028302942868322134 | D accuracy: 98.4375] [G loss: 3.1464346683662825e-09]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "254 [D loss: 0.005805472212159657 | D accuracy: 100.0] [G loss: 1.3972460521927133e-08]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "255 [D loss: 0.0017324475920759141 | D accuracy: 100.0] [G loss: 3.553448202353593e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "256 [D loss: 0.0006981576734688133 | D accuracy: 100.0] [G loss: 1.701795704356357e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "257 [D loss: 0.0008759154297877103 | D accuracy: 100.0] [G loss: 4.2669991984212174e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "258 [D loss: 0.0005698164532077499 | D accuracy: 100.0] [G loss: 3.790840530371042e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "259 [D loss: 0.0006288438016781583 | D accuracy: 100.0] [G loss: 6.182380829500289e-09]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "260 [D loss: 0.00044047296432836447 | D accuracy: 100.0] [G loss: 4.967787958776171e-08]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "261 [D loss: 0.003590463660657406 | D accuracy: 100.0] [G loss: 2.4328734582468314e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "262 [D loss: 0.01459607481956482 | D accuracy: 98.4375] [G loss: 9.405756173919144e-09]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "263 [D loss: 0.0033010791667038575 | D accuracy: 100.0] [G loss: 7.1316881289362755e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "264 [D loss: 0.0011297585142528987 | D accuracy: 100.0] [G loss: 5.460049079530904e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "265 [D loss: 0.0006443435072469583 | D accuracy: 100.0] [G loss: 4.509260520535463e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "266 [D loss: 0.0007892620924394578 | D accuracy: 100.0] [G loss: 1.4590495478472576e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "267 [D loss: 0.0004627105518011376 | D accuracy: 100.0] [G loss: 1.4880705556663543e-09]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "268 [D loss: 0.0005669608945026994 | D accuracy: 100.0] [G loss: 2.374144214556395e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "269 [D loss: 0.0005581503501161933 | D accuracy: 100.0] [G loss: 6.94131774281459e-09]\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "270 [D loss: 0.010316081112250686 | D accuracy: 100.0] [G loss: 1.2735050791690128e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "271 [D loss: 0.002166250355401189 | D accuracy: 100.0] [G loss: 5.7887850068993885e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "272 [D loss: 0.0016246752929873765 | D accuracy: 100.0] [G loss: 2.177509017542434e-08]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "273 [D loss: 0.0007158875832828926 | D accuracy: 100.0] [G loss: 2.6332149793972803e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "274 [D loss: 0.0006318209852906875 | D accuracy: 100.0] [G loss: 1.1930504584256596e-08]\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "275 [D loss: 0.0004483500042624655 | D accuracy: 100.0] [G loss: 3.658561098518476e-08]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "276 [D loss: 0.0005657804140355438 | D accuracy: 100.0] [G loss: 8.98548568883939e-10]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "277 [D loss: 0.0003815919772023335 | D accuracy: 100.0] [G loss: 2.4543460597215017e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "278 [D loss: 0.0005713349091820419 | D accuracy: 100.0] [G loss: 1.8087307207537151e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "279 [D loss: 0.00680599722545594 | D accuracy: 100.0] [G loss: 4.519404572800312e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "280 [D loss: 0.00129031783899336 | D accuracy: 100.0] [G loss: 5.311648010319914e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "281 [D loss: 0.0009564367410348495 | D accuracy: 100.0] [G loss: 1.4571741591140608e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "282 [D loss: 0.03250405378639698 | D accuracy: 98.4375] [G loss: 4.873299985774793e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "283 [D loss: 0.0005044906974944752 | D accuracy: 100.0] [G loss: 2.6163584632143966e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "284 [D loss: 0.000330526105244644 | D accuracy: 100.0] [G loss: 8.08544431407654e-09]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "285 [D loss: 0.006144862883957103 | D accuracy: 100.0] [G loss: 8.502153647782507e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "286 [D loss: 0.0006927669721150664 | D accuracy: 100.0] [G loss: 1.5016865528849621e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "287 [D loss: 0.004225628450512886 | D accuracy: 100.0] [G loss: 4.177826085083325e-09]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "288 [D loss: 0.0012545995850814506 | D accuracy: 100.0] [G loss: 2.8258961837224206e-09]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "289 [D loss: 0.0007691254932069569 | D accuracy: 100.0] [G loss: 6.739009350553715e-09]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "290 [D loss: 0.006549787009134889 | D accuracy: 100.0] [G loss: 5.219717991167272e-10]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "291 [D loss: 0.0016974481623037718 | D accuracy: 100.0] [G loss: 8.906443360601202e-10]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "292 [D loss: 0.003298397408798337 | D accuracy: 100.0] [G loss: 3.5536713571815426e-09]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "293 [D loss: 0.0009398375477758236 | D accuracy: 100.0] [G loss: 2.5465658470835706e-09]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "294 [D loss: 0.0006347875441861106 | D accuracy: 100.0] [G loss: 2.5315225471445046e-09]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "295 [D loss: 0.0005244839449005667 | D accuracy: 100.0] [G loss: 2.6312174661313747e-09]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "296 [D loss: 0.000481773347928538 | D accuracy: 100.0] [G loss: 2.5775468426303405e-09]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "297 [D loss: 0.0006596006278414279 | D accuracy: 100.0] [G loss: 2.239340268772594e-09]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "298 [D loss: 0.00045921105629531667 | D accuracy: 100.0] [G loss: 1.4970410688874836e-08]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "299 [D loss: 0.00046898986329324543 | D accuracy: 100.0] [G loss: 5.184277451775188e-10]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "300 [D loss: 0.00033869276956011163 | D accuracy: 100.0] [G loss: 8.671181106478798e-09]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "301 [D loss: 0.00036475248998613097 | D accuracy: 100.0] [G loss: 4.138157816413468e-09]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "302 [D loss: 0.0003065144210268045 | D accuracy: 100.0] [G loss: 4.829493693847553e-09]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "303 [D loss: 0.004751610686071217 | D accuracy: 100.0] [G loss: 1.0047821241698784e-08]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "304 [D loss: 0.0009718773253553081 | D accuracy: 100.0] [G loss: 5.255264001746696e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "305 [D loss: 0.0007120989866962191 | D accuracy: 100.0] [G loss: 1.111210901072468e-09]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "306 [D loss: 0.0006196413887664676 | D accuracy: 100.0] [G loss: 2.0908061948432533e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "307 [D loss: 0.0006318924424704164 | D accuracy: 100.0] [G loss: 1.1513578979105432e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "308 [D loss: 0.0015381400589831173 | D accuracy: 100.0] [G loss: 3.3290348255832214e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "309 [D loss: 0.0004489137552354805 | D accuracy: 100.0] [G loss: 1.9642145687726043e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "310 [D loss: 0.0004296201550459955 | D accuracy: 100.0] [G loss: 3.6341387676941395e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "311 [D loss: 0.0005568325505009852 | D accuracy: 100.0] [G loss: 5.201651109842942e-09]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "312 [D loss: 0.0014778177428524941 | D accuracy: 100.0] [G loss: 1.108337643884738e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "313 [D loss: 0.002722376899328083 | D accuracy: 100.0] [G loss: 8.872320655939347e-10]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "314 [D loss: 0.00099071155909769 | D accuracy: 100.0] [G loss: 1.3083718108930498e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "315 [D loss: 0.0005462540830194484 | D accuracy: 100.0] [G loss: 3.3692655332373533e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "316 [D loss: 0.00045964206947246566 | D accuracy: 100.0] [G loss: 8.70932437280203e-10]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "317 [D loss: 0.0003991975436292705 | D accuracy: 100.0] [G loss: 1.296070362144519e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "318 [D loss: 0.0003085183307121042 | D accuracy: 100.0] [G loss: 2.5017836691176853e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "319 [D loss: 0.0006261199014261365 | D accuracy: 100.0] [G loss: 4.58046434115289e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "320 [D loss: 0.0005912826998155651 | D accuracy: 100.0] [G loss: 6.249069040009658e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "321 [D loss: 0.007825215114280581 | D accuracy: 100.0] [G loss: 7.928231404719099e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "322 [D loss: 0.0023809031442851847 | D accuracy: 100.0] [G loss: 3.1350606555236027e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "323 [D loss: 0.0005133537296160284 | D accuracy: 100.0] [G loss: 1.0204264100366345e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "324 [D loss: 0.030499553307890892 | D accuracy: 98.4375] [G loss: 4.327991853791957e-10]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "325 [D loss: 0.0004240052676323103 | D accuracy: 100.0] [G loss: 1.7452034262177563e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "326 [D loss: 0.00037097818858455867 | D accuracy: 100.0] [G loss: 4.2054562610083224e-10]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "327 [D loss: 0.0002883821798604913 | D accuracy: 100.0] [G loss: 4.748750281891034e-10]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "328 [D loss: 0.0002782993310574966 | D accuracy: 100.0] [G loss: 6.735872415397637e-10]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "329 [D loss: 0.007357190712355077 | D accuracy: 100.0] [G loss: 2.4699371437009177e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "330 [D loss: 0.002479260612744838 | D accuracy: 100.0] [G loss: 1.5983868395519352e-10]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "331 [D loss: 0.0011581686703721061 | D accuracy: 100.0] [G loss: 3.433118789253342e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "332 [D loss: 0.0005932431486144196 | D accuracy: 100.0] [G loss: 6.013697317897027e-10]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "333 [D loss: 0.0004450150881893933 | D accuracy: 100.0] [G loss: 1.089790924169165e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "334 [D loss: 0.00042396943536004983 | D accuracy: 100.0] [G loss: 2.8045049615954554e-10]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "335 [D loss: 0.0005290925473673269 | D accuracy: 100.0] [G loss: 1.0274820994027323e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "336 [D loss: 0.003267853579018265 | D accuracy: 100.0] [G loss: 1.2102348012632547e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "337 [D loss: 0.005400401074439287 | D accuracy: 100.0] [G loss: 3.784721869237728e-09]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "338 [D loss: 0.0008756107999943197 | D accuracy: 100.0] [G loss: 4.0785730348602556e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "339 [D loss: 0.0007335195259656757 | D accuracy: 100.0] [G loss: 1.1295402113642439e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "340 [D loss: 0.0006248297431739047 | D accuracy: 100.0] [G loss: 1.4927223346283824e-10]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "341 [D loss: 0.00027443151111583575 | D accuracy: 100.0] [G loss: 9.187159366597086e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "342 [D loss: 0.0005203973929042149 | D accuracy: 100.0] [G loss: 7.868636991981148e-11]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "343 [D loss: 0.00023689000312288044 | D accuracy: 100.0] [G loss: 2.2976447411338086e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "344 [D loss: 0.001301003134358325 | D accuracy: 100.0] [G loss: 1.2037431051936665e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "345 [D loss: 0.0009892004891298711 | D accuracy: 100.0] [G loss: 3.3699179557977743e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "346 [D loss: 0.008558946105495124 | D accuracy: 100.0] [G loss: 7.707149501934296e-11]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "347 [D loss: 0.0002798085333779454 | D accuracy: 100.0] [G loss: 5.663964852686831e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "348 [D loss: 0.17107167094945908 | D accuracy: 96.875] [G loss: 1.097568702590479e-09]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "349 [D loss: 0.00019480921764625236 | D accuracy: 100.0] [G loss: 3.25783622301401e-10]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "350 [D loss: 0.0019821777823381126 | D accuracy: 100.0] [G loss: 2.4483456928514613e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "351 [D loss: 0.0035036486297030933 | D accuracy: 100.0] [G loss: 5.601723529480296e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "352 [D loss: 0.0002766222751233727 | D accuracy: 100.0] [G loss: 4.261954122952716e-10]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "353 [D loss: 0.03945819986984134 | D accuracy: 96.875] [G loss: 1.8914221577848167e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "354 [D loss: 0.024832583954776055 | D accuracy: 98.4375] [G loss: 8.319490651942374e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "355 [D loss: 0.012105115049052984 | D accuracy: 98.4375] [G loss: 7.69211361273392e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "356 [D loss: 0.001330373139353469 | D accuracy: 100.0] [G loss: 4.5380194046984457e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "357 [D loss: 0.0015176574961515144 | D accuracy: 100.0] [G loss: 4.0065950557277574e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "358 [D loss: 0.0019940308993682265 | D accuracy: 100.0] [G loss: 3.834638440114446e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "359 [D loss: 0.0006958065623621223 | D accuracy: 100.0] [G loss: 1.6624888132810156e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "360 [D loss: 0.10873708501458168 | D accuracy: 93.75] [G loss: 2.690770939395293e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "361 [D loss: 0.0022331317713906174 | D accuracy: 100.0] [G loss: 2.450186054048231e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "362 [D loss: 0.1820383830126957 | D accuracy: 95.3125] [G loss: 4.1093642266787356e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "363 [D loss: 0.13006535917520523 | D accuracy: 96.875] [G loss: 1.0783398479707884e-10]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "364 [D loss: 0.19187224404595327 | D accuracy: 93.75] [G loss: 2.4695761879911515e-08]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "365 [D loss: 0.0934467578326803 | D accuracy: 96.875] [G loss: 4.317808333098583e-08]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "366 [D loss: 0.321475939512311 | D accuracy: 93.75] [G loss: 5.209642717218799e-10]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "367 [D loss: 0.07869640458375216 | D accuracy: 96.875] [G loss: 4.2153999735283776e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "368 [D loss: 0.005238024517893791 | D accuracy: 100.0] [G loss: 2.698633982944898e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "369 [D loss: 0.005168934918401646 | D accuracy: 100.0] [G loss: 1.6190071505661763e-10]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "370 [D loss: 0.0730644790455699 | D accuracy: 96.875] [G loss: 6.773258065528864e-10]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "371 [D loss: 0.007599849486723542 | D accuracy: 100.0] [G loss: 6.850251477175107e-10]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "372 [D loss: 0.004694684175774455 | D accuracy: 100.0] [G loss: 3.5463849634709277e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "373 [D loss: 0.002224854426458478 | D accuracy: 100.0] [G loss: 1.945262617653043e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "374 [D loss: 0.003757221275009215 | D accuracy: 100.0] [G loss: 1.2079544031706746e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "375 [D loss: 0.001691582496277988 | D accuracy: 100.0] [G loss: 2.3013928263093675e-10]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "376 [D loss: 0.062212271615862846 | D accuracy: 96.875] [G loss: 1.1729726079323655e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "377 [D loss: 0.006440937053412199 | D accuracy: 100.0] [G loss: 1.6644783329411439e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "378 [D loss: 0.010167836910113692 | D accuracy: 100.0] [G loss: 3.4244829194562953e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "379 [D loss: 0.0021926238096057205 | D accuracy: 100.0] [G loss: 2.825886191715199e-09]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "380 [D loss: 0.10826162621378899 | D accuracy: 96.875] [G loss: 5.094091815038837e-10]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "381 [D loss: 0.006735870614647865 | D accuracy: 100.0] [G loss: 1.0577758668972592e-09]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "382 [D loss: 0.044143610866740346 | D accuracy: 98.4375] [G loss: 1.2838464735764887e-09]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "383 [D loss: 0.018428436131216586 | D accuracy: 98.4375] [G loss: 9.171657877615758e-10]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "384 [D loss: 0.03879343532025814 | D accuracy: 98.4375] [G loss: 6.525025519898975e-10]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "385 [D loss: 0.023465580408810638 | D accuracy: 98.4375] [G loss: 3.5707230949810764e-08]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "386 [D loss: 0.004278844299733464 | D accuracy: 100.0] [G loss: 2.0979677994859003e-09]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "387 [D loss: 0.006054320489056408 | D accuracy: 100.0] [G loss: 3.386503966140708e-09]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "388 [D loss: 0.006010698270983994 | D accuracy: 100.0] [G loss: 5.713797213147132e-10]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "389 [D loss: 0.0012704695691354573 | D accuracy: 100.0] [G loss: 4.074359738481803e-10]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "390 [D loss: 0.033170933835208416 | D accuracy: 98.4375] [G loss: 6.351045023222923e-09]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "391 [D loss: 0.003768502429011278 | D accuracy: 100.0] [G loss: 2.1165114105770044e-09]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "392 [D loss: 0.006573428399860859 | D accuracy: 100.0] [G loss: 8.650576366342477e-10]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "393 [D loss: 0.0011307186214253306 | D accuracy: 100.0] [G loss: 6.174936117986363e-10]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "394 [D loss: 0.17816637828946114 | D accuracy: 93.75] [G loss: 2.2388442211251913e-09]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "395 [D loss: 0.03210618288721889 | D accuracy: 98.4375] [G loss: 1.3284656041889775e-08]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "396 [D loss: 0.1283953608945012 | D accuracy: 95.3125] [G loss: 3.2185587528488213e-09]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "397 [D loss: 0.09250234067440033 | D accuracy: 96.875] [G loss: 3.949362614719121e-09]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "398 [D loss: 0.03983311168849468 | D accuracy: 96.875] [G loss: 3.731232212089708e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "399 [D loss: 0.02580003277398646 | D accuracy: 98.4375] [G loss: 6.906744620671645e-10]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "400 [D loss: 0.030773703008890152 | D accuracy: 98.4375] [G loss: 1.5398282648959594e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "401 [D loss: 0.016358723398298025 | D accuracy: 100.0] [G loss: 2.7286152004535325e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "402 [D loss: 0.021355005097575486 | D accuracy: 100.0] [G loss: 1.1549832379387226e-07]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "403 [D loss: 0.010868173230846878 | D accuracy: 100.0] [G loss: 8.172778898085653e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "404 [D loss: 0.06628632172942162 | D accuracy: 96.875] [G loss: 6.033648247694146e-08]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "405 [D loss: 0.011884346371516585 | D accuracy: 100.0] [G loss: 4.3345231404146034e-08]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "406 [D loss: 0.035346940625458956 | D accuracy: 98.4375] [G loss: 6.82192657919245e-09]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "407 [D loss: 0.04262128844857216 | D accuracy: 98.4375] [G loss: 4.434575728851087e-08]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "408 [D loss: 0.03268585912883282 | D accuracy: 98.4375] [G loss: 6.713377409539589e-09]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "409 [D loss: 0.2664962448179722 | D accuracy: 89.0625] [G loss: 6.867903579177437e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "410 [D loss: 0.06314230698626488 | D accuracy: 98.4375] [G loss: 3.621531874387074e-08]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "411 [D loss: 0.1718554114922881 | D accuracy: 96.875] [G loss: 1.1773883201726676e-08]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "412 [D loss: 0.179085411131382 | D accuracy: 95.3125] [G loss: 6.318524725656971e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "413 [D loss: 0.0641965614631772 | D accuracy: 98.4375] [G loss: 1.1087185214364581e-07]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "414 [D loss: 0.05033466778695583 | D accuracy: 98.4375] [G loss: 7.136605972846155e-08]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "415 [D loss: 0.17347873747348785 | D accuracy: 95.3125] [G loss: 9.77811183133781e-08]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "416 [D loss: 0.06032313033938408 | D accuracy: 96.875] [G loss: 1.847058257453682e-07]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "417 [D loss: 0.016888451762497425 | D accuracy: 100.0] [G loss: 4.2985408299500705e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "418 [D loss: 0.06056499108672142 | D accuracy: 98.4375] [G loss: 4.071209787070984e-07]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "419 [D loss: 0.22286494821310043 | D accuracy: 92.1875] [G loss: 9.372081422043266e-08]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "420 [D loss: 0.03459588438272476 | D accuracy: 98.4375] [G loss: 2.131484734491096e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "421 [D loss: 0.04784076754003763 | D accuracy: 98.4375] [G loss: 3.046335450562765e-08]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "422 [D loss: 0.1080482229590416 | D accuracy: 96.875] [G loss: 2.245286481183939e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "423 [D loss: 0.015343548730015755 | D accuracy: 100.0] [G loss: 2.0994244209759927e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "424 [D loss: 0.11608906090259552 | D accuracy: 96.875] [G loss: 5.964525939816667e-07]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "425 [D loss: 0.0510148610919714 | D accuracy: 96.875] [G loss: 3.344671881677641e-07]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "426 [D loss: 0.15976877324283123 | D accuracy: 95.3125] [G loss: 1.1608919976424659e-06]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "427 [D loss: 0.04743714118376374 | D accuracy: 100.0] [G loss: 5.837977710143605e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "428 [D loss: 0.009927215316565707 | D accuracy: 100.0] [G loss: 9.779955689737108e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "429 [D loss: 0.12472236901521683 | D accuracy: 95.3125] [G loss: 2.472260689501127e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "430 [D loss: 0.08041982725262642 | D accuracy: 96.875] [G loss: 2.887354185077129e-06]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "431 [D loss: 0.11865974217653275 | D accuracy: 96.875] [G loss: 1.3832893728249473e-06]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "432 [D loss: 0.08170653134584427 | D accuracy: 96.875] [G loss: 6.36352979199728e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "433 [D loss: 0.03063574619591236 | D accuracy: 100.0] [G loss: 1.4384593214344932e-06]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "434 [D loss: 0.07147418335080147 | D accuracy: 98.4375] [G loss: 2.2490721676149406e-06]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "435 [D loss: 0.045324115082621574 | D accuracy: 98.4375] [G loss: 1.4106927892498788e-06]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "436 [D loss: 0.15876946598291397 | D accuracy: 95.3125] [G loss: 1.1580049203985254e-06]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "437 [D loss: 0.11149095743894577 | D accuracy: 95.3125] [G loss: 8.501081083522877e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "438 [D loss: 0.11229469627141953 | D accuracy: 96.875] [G loss: 5.810223910884815e-07]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "439 [D loss: 0.09369589760899544 | D accuracy: 96.875] [G loss: 6.736203772561566e-07]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "440 [D loss: 0.0454558115452528 | D accuracy: 98.4375] [G loss: 2.456814399920404e-06]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "441 [D loss: 0.1734047383069992 | D accuracy: 92.1875] [G loss: 2.242625123471953e-05]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "442 [D loss: 0.0663788067176938 | D accuracy: 98.4375] [G loss: 1.4029512840352254e-06]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "443 [D loss: 0.2556556388735771 | D accuracy: 93.75] [G loss: 1.9073842850048095e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "444 [D loss: 0.0495632141828537 | D accuracy: 98.4375] [G loss: 5.800466169603169e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "445 [D loss: 0.06255095079541206 | D accuracy: 98.4375] [G loss: 2.001835309783928e-05]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "446 [D loss: 0.19698305428028107 | D accuracy: 93.75] [G loss: 6.0539819969562814e-05]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "447 [D loss: 0.09551434591412544 | D accuracy: 95.3125] [G loss: 7.709997589699924e-05]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "448 [D loss: 0.06404215563088655 | D accuracy: 98.4375] [G loss: 0.00010873425344470888]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "449 [D loss: 0.24838627129793167 | D accuracy: 92.1875] [G loss: 2.3894755941000767e-05]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "450 [D loss: 0.0785373980179429 | D accuracy: 96.875] [G loss: 0.0008392833406105638]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "451 [D loss: 0.052523654885590076 | D accuracy: 98.4375] [G loss: 0.0002981367870233953]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "452 [D loss: 0.06804724782705307 | D accuracy: 98.4375] [G loss: 0.00014835789625067264]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "453 [D loss: 0.06449492275714874 | D accuracy: 98.4375] [G loss: 0.0010461498750373721]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "454 [D loss: 0.06735629960894585 | D accuracy: 98.4375] [G loss: 0.00023955840151757002]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "455 [D loss: 0.13032469898462296 | D accuracy: 95.3125] [G loss: 0.00016783169121481478]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "456 [D loss: 0.03841225430369377 | D accuracy: 100.0] [G loss: 0.0008437400683760643]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "457 [D loss: 0.07656276598572731 | D accuracy: 96.875] [G loss: 0.00043170934077352285]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "458 [D loss: 0.03580877743661404 | D accuracy: 98.4375] [G loss: 0.0004141494573559612]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "459 [D loss: 0.07457438856363297 | D accuracy: 96.875] [G loss: 5.8675424952525645e-05]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "460 [D loss: 0.2044716626405716 | D accuracy: 92.1875] [G loss: 0.007982943207025528]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "461 [D loss: 0.279304139316082 | D accuracy: 89.0625] [G loss: 0.026799269020557404]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "462 [D loss: 0.28466371446847916 | D accuracy: 87.5] [G loss: 0.32844480872154236]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "463 [D loss: 0.6340901106595993 | D accuracy: 81.25] [G loss: 0.053419068455696106]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "464 [D loss: 0.9392369389533997 | D accuracy: 67.1875] [G loss: 0.16131216287612915]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "465 [D loss: 0.4566754996776581 | D accuracy: 84.375] [G loss: 0.41805779933929443]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "466 [D loss: 0.7209544032812119 | D accuracy: 67.1875] [G loss: 0.014988375827670097]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "467 [D loss: 0.3615550994873047 | D accuracy: 79.6875] [G loss: 0.005411649588495493]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "468 [D loss: 0.3089694529771805 | D accuracy: 87.5] [G loss: 0.027791030704975128]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "469 [D loss: 0.26961682736873627 | D accuracy: 90.625] [G loss: 0.045349229127168655]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "470 [D loss: 0.5119476914405823 | D accuracy: 84.375] [G loss: 0.04195113480091095]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "471 [D loss: 0.2747737765312195 | D accuracy: 93.75] [G loss: 0.04194704070687294]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "472 [D loss: 0.3365757167339325 | D accuracy: 85.9375] [G loss: 0.03802201896905899]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "473 [D loss: 0.51340252161026 | D accuracy: 76.5625] [G loss: 0.05341695621609688]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "474 [D loss: 0.39659518003463745 | D accuracy: 85.9375] [G loss: 0.10382665693759918]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "475 [D loss: 0.6138335764408112 | D accuracy: 68.75] [G loss: 0.260907918214798]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "476 [D loss: 0.558797687292099 | D accuracy: 76.5625] [G loss: 0.16068731248378754]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "477 [D loss: 0.652029812335968 | D accuracy: 64.0625] [G loss: 0.29204627871513367]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "478 [D loss: 0.5789273679256439 | D accuracy: 76.5625] [G loss: 0.9932504892349243]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "479 [D loss: 0.6947396099567413 | D accuracy: 64.0625] [G loss: 0.3133670687675476]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "480 [D loss: 0.36561091244220734 | D accuracy: 81.25] [G loss: 0.2053484171628952]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "481 [D loss: 0.4597935378551483 | D accuracy: 75.0] [G loss: 0.07566151022911072]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "482 [D loss: 0.36283253133296967 | D accuracy: 81.25] [G loss: 0.08381970226764679]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "483 [D loss: 0.32840433716773987 | D accuracy: 79.6875] [G loss: 0.1471579521894455]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "484 [D loss: 0.5515523254871368 | D accuracy: 73.4375] [G loss: 0.06920190155506134]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "485 [D loss: 0.27718445658683777 | D accuracy: 93.75] [G loss: 0.11655053496360779]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "486 [D loss: 0.4326671063899994 | D accuracy: 76.5625] [G loss: 0.14309930801391602]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "487 [D loss: 0.45348402857780457 | D accuracy: 79.6875] [G loss: 0.10290944576263428]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "488 [D loss: 0.3892631530761719 | D accuracy: 78.125] [G loss: 0.21076714992523193]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "489 [D loss: 0.32975175976753235 | D accuracy: 85.9375] [G loss: 0.1431044042110443]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "490 [D loss: 0.34522396326065063 | D accuracy: 89.0625] [G loss: 0.3138839900493622]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "491 [D loss: 0.5506952106952667 | D accuracy: 73.4375] [G loss: 0.002653201576322317]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "492 [D loss: 0.28219088912010193 | D accuracy: 89.0625] [G loss: 0.004289230331778526]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "493 [D loss: 0.3472239598631859 | D accuracy: 89.0625] [G loss: 0.0020175252575427294]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "494 [D loss: 0.4114595800638199 | D accuracy: 79.6875] [G loss: 0.002310873009264469]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "495 [D loss: 0.2640291899442673 | D accuracy: 92.1875] [G loss: 0.0011190344812348485]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "496 [D loss: 0.2748434618115425 | D accuracy: 87.5] [G loss: 0.002133391099050641]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "497 [D loss: 0.11965721100568771 | D accuracy: 96.875] [G loss: 0.004410503897815943]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "498 [D loss: 0.16532662510871887 | D accuracy: 95.3125] [G loss: 0.0027741841040551662]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "499 [D loss: 0.15292569249868393 | D accuracy: 95.3125] [G loss: 0.008926153182983398]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "500 [D loss: 0.14968474209308624 | D accuracy: 93.75] [G loss: 0.01030879095196724]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "501 [D loss: 0.19600751996040344 | D accuracy: 92.1875] [G loss: 0.005276207346469164]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "502 [D loss: 0.2417834848165512 | D accuracy: 85.9375] [G loss: 0.003924901597201824]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "503 [D loss: 0.14932166785001755 | D accuracy: 95.3125] [G loss: 0.012947211042046547]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "504 [D loss: 0.11647668853402138 | D accuracy: 98.4375] [G loss: 0.0028216468635946512]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "505 [D loss: 0.2655060142278671 | D accuracy: 89.0625] [G loss: 0.0014340245397761464]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "506 [D loss: 0.09572245180606842 | D accuracy: 98.4375] [G loss: 0.008896008133888245]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "507 [D loss: 0.12368518859148026 | D accuracy: 98.4375] [G loss: 0.0017801973735913634]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "508 [D loss: 0.23813766986131668 | D accuracy: 92.1875] [G loss: 0.002826516516506672]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "509 [D loss: 0.15399790555238724 | D accuracy: 92.1875] [G loss: 0.013099506497383118]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "510 [D loss: 0.09357981011271477 | D accuracy: 100.0] [G loss: 0.010448542423546314]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "511 [D loss: 0.06599843502044678 | D accuracy: 96.875] [G loss: 0.009491019882261753]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "512 [D loss: 0.058359578251838684 | D accuracy: 100.0] [G loss: 0.005845004692673683]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "513 [D loss: 0.22863569855690002 | D accuracy: 90.625] [G loss: 0.014661906287074089]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "514 [D loss: 0.163035586476326 | D accuracy: 93.75] [G loss: 0.14287720620632172]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "515 [D loss: 0.1249568946659565 | D accuracy: 96.875] [G loss: 0.03589007630944252]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "516 [D loss: 0.12362270429730415 | D accuracy: 96.875] [G loss: 0.029961388558149338]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "517 [D loss: 0.13617835193872452 | D accuracy: 96.875] [G loss: 0.00888109765946865]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "518 [D loss: 0.08965297043323517 | D accuracy: 96.875] [G loss: 0.47731995582580566]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "519 [D loss: 0.6822278797626495 | D accuracy: 71.875] [G loss: 0.09889867156744003]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "520 [D loss: 0.13609013706445694 | D accuracy: 93.75] [G loss: 0.09332576394081116]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "521 [D loss: 0.16831029951572418 | D accuracy: 95.3125] [G loss: 0.28835219144821167]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "522 [D loss: 0.4555104672908783 | D accuracy: 75.0] [G loss: 0.7331644296646118]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "523 [D loss: 0.28113797307014465 | D accuracy: 87.5] [G loss: 0.4043947458267212]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "524 [D loss: 0.2935885637998581 | D accuracy: 89.0625] [G loss: 2.0856571197509766]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "525 [D loss: 0.7955324649810791 | D accuracy: 68.75] [G loss: 1.1905996799468994]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "526 [D loss: 1.4082754850387573 | D accuracy: 48.4375] [G loss: 3.081005573272705]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "527 [D loss: 0.2798846773803234 | D accuracy: 85.9375] [G loss: 4.537398815155029]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "528 [D loss: 0.26997022330760956 | D accuracy: 89.0625] [G loss: 3.8394312858581543]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "529 [D loss: 0.3800079673528671 | D accuracy: 84.375] [G loss: 3.91686749458313]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "530 [D loss: 0.5848081111907959 | D accuracy: 75.0] [G loss: 6.4557342529296875]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "531 [D loss: 0.3793508782982826 | D accuracy: 87.5] [G loss: 6.1932573318481445]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "532 [D loss: 0.46437692642211914 | D accuracy: 79.6875] [G loss: 4.069267272949219]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "533 [D loss: 0.24019750207662582 | D accuracy: 93.75] [G loss: 2.4256367683410645]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "534 [D loss: 0.2657731622457504 | D accuracy: 89.0625] [G loss: 2.1707401275634766]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "535 [D loss: 0.25544146448373795 | D accuracy: 87.5] [G loss: 2.131155252456665]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "536 [D loss: 0.3616073280572891 | D accuracy: 87.5] [G loss: 1.348905086517334]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "537 [D loss: 0.07106583938002586 | D accuracy: 98.4375] [G loss: 1.360039234161377]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "538 [D loss: 0.2593413442373276 | D accuracy: 87.5] [G loss: 2.086482048034668]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "539 [D loss: 0.07588321715593338 | D accuracy: 98.4375] [G loss: 2.2080583572387695]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "540 [D loss: 0.07202877663075924 | D accuracy: 100.0] [G loss: 1.977684736251831]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "541 [D loss: 0.14680366963148117 | D accuracy: 95.3125] [G loss: 1.605060338973999]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "542 [D loss: 0.2171003669500351 | D accuracy: 93.75] [G loss: 1.7090060710906982]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "543 [D loss: 0.15923535451292992 | D accuracy: 93.75] [G loss: 1.5964415073394775]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "544 [D loss: 0.1438450887799263 | D accuracy: 96.875] [G loss: 1.6355113983154297]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "545 [D loss: 0.14190159738063812 | D accuracy: 95.3125] [G loss: 2.0388972759246826]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "546 [D loss: 0.2962324917316437 | D accuracy: 85.9375] [G loss: 2.163292169570923]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "547 [D loss: 0.43725477159023285 | D accuracy: 85.9375] [G loss: 1.0629863739013672]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "548 [D loss: 0.3800939470529556 | D accuracy: 78.125] [G loss: 1.1654331684112549]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "549 [D loss: 0.3510499894618988 | D accuracy: 81.25] [G loss: 2.2343811988830566]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "550 [D loss: 0.8149383366107941 | D accuracy: 59.375] [G loss: 2.2201292514801025]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "551 [D loss: 0.3744065463542938 | D accuracy: 79.6875] [G loss: 1.783036708831787]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "552 [D loss: 0.3660922646522522 | D accuracy: 87.5] [G loss: 1.6817848682403564]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "553 [D loss: 0.2811792194843292 | D accuracy: 90.625] [G loss: 1.9688830375671387]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "554 [D loss: 0.40494781732559204 | D accuracy: 82.8125] [G loss: 1.7039945125579834]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "555 [D loss: 0.34511682391166687 | D accuracy: 84.375] [G loss: 1.806898593902588]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "556 [D loss: 0.3038783669471741 | D accuracy: 92.1875] [G loss: 1.959808588027954]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "557 [D loss: 0.28947775065898895 | D accuracy: 90.625] [G loss: 1.9874706268310547]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "558 [D loss: 0.35112684965133667 | D accuracy: 84.375] [G loss: 2.0080838203430176]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "559 [D loss: 0.297081857919693 | D accuracy: 85.9375] [G loss: 1.9839973449707031]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "560 [D loss: 0.5184709429740906 | D accuracy: 73.4375] [G loss: 1.680452823638916]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "561 [D loss: 0.31865403056144714 | D accuracy: 89.0625] [G loss: 2.1751084327697754]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "562 [D loss: 0.42843347787857056 | D accuracy: 78.125] [G loss: 1.7729647159576416]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "563 [D loss: 0.32720211148262024 | D accuracy: 89.0625] [G loss: 1.6865853071212769]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "564 [D loss: 0.3735923320055008 | D accuracy: 87.5] [G loss: 1.7852555513381958]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "565 [D loss: 0.42376604676246643 | D accuracy: 87.5] [G loss: 1.7437607049942017]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "566 [D loss: 0.33811481297016144 | D accuracy: 93.75] [G loss: 1.7909808158874512]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "567 [D loss: 0.4677828699350357 | D accuracy: 82.8125] [G loss: 1.7384454011917114]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "568 [D loss: 0.5853155553340912 | D accuracy: 76.5625] [G loss: 1.576127290725708]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "569 [D loss: 0.18557961285114288 | D accuracy: 96.875] [G loss: 2.2294740676879883]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "570 [D loss: 0.36628078669309616 | D accuracy: 87.5] [G loss: 1.8253496885299683]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "571 [D loss: 0.2946201115846634 | D accuracy: 89.0625] [G loss: 1.585550308227539]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "572 [D loss: 0.1675366833806038 | D accuracy: 95.3125] [G loss: 1.9141184091567993]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "573 [D loss: 0.22158144414424896 | D accuracy: 90.625] [G loss: 1.80806565284729]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "574 [D loss: 0.4144297242164612 | D accuracy: 82.8125] [G loss: 0.995707631111145]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "575 [D loss: 0.22586975991725922 | D accuracy: 93.75] [G loss: 1.2922405004501343]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "576 [D loss: 0.15709778293967247 | D accuracy: 95.3125] [G loss: 2.0167598724365234]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "577 [D loss: 0.1427932344377041 | D accuracy: 93.75] [G loss: 2.678114414215088]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "578 [D loss: 0.3338780403137207 | D accuracy: 87.5] [G loss: 2.3332042694091797]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "579 [D loss: 0.37491801381111145 | D accuracy: 82.8125] [G loss: 2.1457889080047607]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "580 [D loss: 0.4284578561782837 | D accuracy: 78.125] [G loss: 1.7532458305358887]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "581 [D loss: 0.9158976674079895 | D accuracy: 62.5] [G loss: 1.4675366878509521]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "582 [D loss: 0.5076667070388794 | D accuracy: 73.4375] [G loss: 2.248091220855713]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "583 [D loss: 0.5551728308200836 | D accuracy: 71.875] [G loss: 2.3700432777404785]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "584 [D loss: 0.5550230145454407 | D accuracy: 62.5] [G loss: 1.524372935295105]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "585 [D loss: 0.3928396701812744 | D accuracy: 81.25] [G loss: 1.804442048072815]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "586 [D loss: 0.32909439504146576 | D accuracy: 87.5] [G loss: 2.1356682777404785]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "587 [D loss: 0.48646581172943115 | D accuracy: 78.125] [G loss: 1.9470423460006714]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "588 [D loss: 0.3831573724746704 | D accuracy: 84.375] [G loss: 1.8471856117248535]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "589 [D loss: 0.35558754205703735 | D accuracy: 82.8125] [G loss: 2.206716537475586]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "590 [D loss: 0.41665054857730865 | D accuracy: 78.125] [G loss: 1.7784862518310547]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "591 [D loss: 0.49107423424720764 | D accuracy: 78.125] [G loss: 1.587334156036377]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "592 [D loss: 0.3977956771850586 | D accuracy: 78.125] [G loss: 1.9537851810455322]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "593 [D loss: 0.44258221983909607 | D accuracy: 79.6875] [G loss: 1.930357575416565]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "594 [D loss: 0.36720114946365356 | D accuracy: 82.8125] [G loss: 1.6730422973632812]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "595 [D loss: 0.39933378994464874 | D accuracy: 79.6875] [G loss: 1.5158041715621948]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "596 [D loss: 0.36072884500026703 | D accuracy: 85.9375] [G loss: 1.6926956176757812]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "597 [D loss: 0.27469906210899353 | D accuracy: 90.625] [G loss: 2.023602247238159]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "598 [D loss: 0.4865942448377609 | D accuracy: 79.6875] [G loss: 1.7094457149505615]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "599 [D loss: 0.4032284915447235 | D accuracy: 81.25] [G loss: 2.0021748542785645]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "600 [D loss: 0.37632451951503754 | D accuracy: 84.375] [G loss: 2.327005386352539]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "601 [D loss: 0.4043516367673874 | D accuracy: 82.8125] [G loss: 2.2254300117492676]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "602 [D loss: 0.376640260219574 | D accuracy: 84.375] [G loss: 2.2472925186157227]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "603 [D loss: 0.4917164444923401 | D accuracy: 76.5625] [G loss: 1.6321580410003662]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "604 [D loss: 0.4451943635940552 | D accuracy: 85.9375] [G loss: 1.7650450468063354]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "605 [D loss: 0.21722626686096191 | D accuracy: 96.875] [G loss: 2.1320834159851074]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "606 [D loss: 0.2600000724196434 | D accuracy: 89.0625] [G loss: 2.23073148727417]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "607 [D loss: 0.33940260112285614 | D accuracy: 89.0625] [G loss: 2.189174175262451]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "608 [D loss: 0.308023601770401 | D accuracy: 90.625] [G loss: 1.9600797891616821]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "609 [D loss: 0.2688907980918884 | D accuracy: 92.1875] [G loss: 1.8540010452270508]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "610 [D loss: 0.2899776101112366 | D accuracy: 85.9375] [G loss: 1.8964287042617798]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "611 [D loss: 0.3171086013317108 | D accuracy: 84.375] [G loss: 1.7866268157958984]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "612 [D loss: 0.25777779519557953 | D accuracy: 92.1875] [G loss: 2.1462271213531494]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "613 [D loss: 0.4378049969673157 | D accuracy: 79.6875] [G loss: 1.6984639167785645]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "614 [D loss: 0.4041356146335602 | D accuracy: 76.5625] [G loss: 1.6133079528808594]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "615 [D loss: 0.4401039779186249 | D accuracy: 81.25] [G loss: 1.5082391500473022]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "616 [D loss: 0.6718504130840302 | D accuracy: 67.1875] [G loss: 1.33180832862854]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "617 [D loss: 0.390069417655468 | D accuracy: 78.125] [G loss: 1.558013677597046]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "618 [D loss: 0.40622784197330475 | D accuracy: 79.6875] [G loss: 1.5761854648590088]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "619 [D loss: 0.7657026052474976 | D accuracy: 56.25] [G loss: 1.5761561393737793]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "620 [D loss: 0.6062203347682953 | D accuracy: 78.125] [G loss: 1.6918258666992188]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "621 [D loss: 0.6267977356910706 | D accuracy: 67.1875] [G loss: 1.5140122175216675]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "622 [D loss: 0.5696836113929749 | D accuracy: 67.1875] [G loss: 1.4289178848266602]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "623 [D loss: 0.4587601125240326 | D accuracy: 75.0] [G loss: 1.5046743154525757]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "624 [D loss: 0.49212706089019775 | D accuracy: 73.4375] [G loss: 1.6849792003631592]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "625 [D loss: 0.4801517277956009 | D accuracy: 78.125] [G loss: 1.712714433670044]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "626 [D loss: 0.4110209792852402 | D accuracy: 78.125] [G loss: 1.595201015472412]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "627 [D loss: 0.42520931363105774 | D accuracy: 82.8125] [G loss: 1.7336851358413696]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "628 [D loss: 0.43612660467624664 | D accuracy: 84.375] [G loss: 1.6298102140426636]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "629 [D loss: 0.4153822958469391 | D accuracy: 82.8125] [G loss: 1.7383430004119873]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "630 [D loss: 0.5593793988227844 | D accuracy: 73.4375] [G loss: 1.6113625764846802]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "631 [D loss: 0.4712955951690674 | D accuracy: 76.5625] [G loss: 1.5472264289855957]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "632 [D loss: 0.4566826671361923 | D accuracy: 76.5625] [G loss: 1.5980401039123535]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "633 [D loss: 0.4359258711338043 | D accuracy: 78.125] [G loss: 1.4589767456054688]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "634 [D loss: 0.4511687606573105 | D accuracy: 82.8125] [G loss: 1.5631030797958374]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "635 [D loss: 0.5094605088233948 | D accuracy: 81.25] [G loss: 1.3182467222213745]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "636 [D loss: 0.6664398312568665 | D accuracy: 67.1875] [G loss: 1.5826022624969482]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "637 [D loss: 0.5401743948459625 | D accuracy: 76.5625] [G loss: 1.7896783351898193]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "638 [D loss: 0.5060949623584747 | D accuracy: 73.4375] [G loss: 1.5759212970733643]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "639 [D loss: 0.5540510714054108 | D accuracy: 78.125] [G loss: 1.569289207458496]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "640 [D loss: 0.5262523889541626 | D accuracy: 76.5625] [G loss: 1.3450524806976318]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "641 [D loss: 0.6151854693889618 | D accuracy: 71.875] [G loss: 1.6494405269622803]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "642 [D loss: 0.6174945831298828 | D accuracy: 60.9375] [G loss: 1.411765217781067]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "643 [D loss: 0.4450047165155411 | D accuracy: 79.6875] [G loss: 1.3789608478546143]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "644 [D loss: 0.5596017837524414 | D accuracy: 71.875] [G loss: 1.452857255935669]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "645 [D loss: 0.5636359453201294 | D accuracy: 76.5625] [G loss: 1.4477627277374268]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "646 [D loss: 0.45153817534446716 | D accuracy: 81.25] [G loss: 1.357520341873169]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "647 [D loss: 0.40998780727386475 | D accuracy: 82.8125] [G loss: 1.444998025894165]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "648 [D loss: 0.4738026261329651 | D accuracy: 78.125] [G loss: 1.4499742984771729]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "649 [D loss: 0.4586992859840393 | D accuracy: 76.5625] [G loss: 1.5879428386688232]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "650 [D loss: 0.5997786819934845 | D accuracy: 65.625] [G loss: 1.287280797958374]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "651 [D loss: 0.522800087928772 | D accuracy: 73.4375] [G loss: 1.3023760318756104]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "652 [D loss: 0.4165959656238556 | D accuracy: 87.5] [G loss: 1.4241342544555664]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "653 [D loss: 0.5230703800916672 | D accuracy: 68.75] [G loss: 1.4813847541809082]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "654 [D loss: 0.5410497188568115 | D accuracy: 68.75] [G loss: 1.4428067207336426]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "655 [D loss: 0.5234101563692093 | D accuracy: 76.5625] [G loss: 1.1643011569976807]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "656 [D loss: 0.6968425214290619 | D accuracy: 59.375] [G loss: 1.230377197265625]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "657 [D loss: 0.3915519118309021 | D accuracy: 84.375] [G loss: 1.5881733894348145]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "658 [D loss: 0.5993073433637619 | D accuracy: 71.875] [G loss: 1.252390742301941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "659 [D loss: 0.5275005847215652 | D accuracy: 71.875] [G loss: 1.299924373626709]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "660 [D loss: 0.5670618414878845 | D accuracy: 73.4375] [G loss: 1.6196448802947998]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "661 [D loss: 0.5125788450241089 | D accuracy: 76.5625] [G loss: 1.4825055599212646]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "662 [D loss: 0.5674861669540405 | D accuracy: 67.1875] [G loss: 1.4262456893920898]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "663 [D loss: 0.49044322967529297 | D accuracy: 75.0] [G loss: 1.5233901739120483]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "664 [D loss: 0.4987937957048416 | D accuracy: 78.125] [G loss: 1.6038818359375]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "665 [D loss: 0.5169605314731598 | D accuracy: 75.0] [G loss: 1.40435791015625]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "666 [D loss: 0.6428984701633453 | D accuracy: 64.0625] [G loss: 1.2820188999176025]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "667 [D loss: 0.5778855085372925 | D accuracy: 71.875] [G loss: 1.1483808755874634]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "668 [D loss: 0.44467319548130035 | D accuracy: 81.25] [G loss: 1.2111175060272217]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "669 [D loss: 0.5336394011974335 | D accuracy: 76.5625] [G loss: 1.0610592365264893]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "670 [D loss: 0.5766644477844238 | D accuracy: 65.625] [G loss: 1.0739681720733643]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "671 [D loss: 0.5042048394680023 | D accuracy: 78.125] [G loss: 1.2105133533477783]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "672 [D loss: 0.6450572311878204 | D accuracy: 71.875] [G loss: 1.2799150943756104]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "673 [D loss: 0.4947430491447449 | D accuracy: 84.375] [G loss: 1.3063862323760986]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "674 [D loss: 0.47790876030921936 | D accuracy: 78.125] [G loss: 1.3251904249191284]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "675 [D loss: 0.5608747452497482 | D accuracy: 67.1875] [G loss: 1.3377816677093506]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "676 [D loss: 0.4406675100326538 | D accuracy: 82.8125] [G loss: 1.2468016147613525]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "677 [D loss: 0.4968968331813812 | D accuracy: 78.125] [G loss: 1.2246463298797607]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "678 [D loss: 0.5366290062665939 | D accuracy: 75.0] [G loss: 1.12235426902771]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "679 [D loss: 0.41503433883190155 | D accuracy: 85.9375] [G loss: 1.1231417655944824]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "680 [D loss: 0.5701562762260437 | D accuracy: 75.0] [G loss: 1.2623865604400635]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "681 [D loss: 0.45449098944664 | D accuracy: 82.8125] [G loss: 1.4346550703048706]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "682 [D loss: 0.5855709612369537 | D accuracy: 65.625] [G loss: 1.1582192182540894]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "683 [D loss: 0.49518047273159027 | D accuracy: 68.75] [G loss: 1.080042839050293]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "684 [D loss: 0.5801021605730057 | D accuracy: 65.625] [G loss: 1.3401126861572266]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "685 [D loss: 0.4805730730295181 | D accuracy: 75.0] [G loss: 1.372499704360962]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "686 [D loss: 0.6181361675262451 | D accuracy: 64.0625] [G loss: 1.1403419971466064]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "687 [D loss: 0.5307961702346802 | D accuracy: 76.5625] [G loss: 1.2287590503692627]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "688 [D loss: 0.4556510001420975 | D accuracy: 73.4375] [G loss: 1.222991704940796]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "689 [D loss: 0.5420264005661011 | D accuracy: 78.125] [G loss: 1.1345429420471191]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "690 [D loss: 0.5930254459381104 | D accuracy: 65.625] [G loss: 1.4122052192687988]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "691 [D loss: 0.4827715903520584 | D accuracy: 76.5625] [G loss: 1.2046443223953247]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "692 [D loss: 0.42416128516197205 | D accuracy: 84.375] [G loss: 1.4892702102661133]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "693 [D loss: 0.4871990382671356 | D accuracy: 79.6875] [G loss: 1.2191035747528076]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "694 [D loss: 0.5472872108221054 | D accuracy: 68.75] [G loss: 1.0435914993286133]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "695 [D loss: 0.4371797889471054 | D accuracy: 79.6875] [G loss: 1.1495492458343506]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "696 [D loss: 0.4247826635837555 | D accuracy: 87.5] [G loss: 1.0817445516586304]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "697 [D loss: 0.3466968238353729 | D accuracy: 85.9375] [G loss: 1.1051218509674072]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "698 [D loss: 0.5755157470703125 | D accuracy: 62.5] [G loss: 0.9678836464881897]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "699 [D loss: 0.4940653592348099 | D accuracy: 73.4375] [G loss: 0.9576172232627869]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "700 [D loss: 0.43978598713874817 | D accuracy: 81.25] [G loss: 1.0109450817108154]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "701 [D loss: 0.3943501114845276 | D accuracy: 82.8125] [G loss: 1.0539350509643555]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "702 [D loss: 0.47941145300865173 | D accuracy: 76.5625] [G loss: 1.1167187690734863]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "703 [D loss: 0.5544964522123337 | D accuracy: 70.3125] [G loss: 1.1056764125823975]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "704 [D loss: 0.5460561811923981 | D accuracy: 70.3125] [G loss: 1.052513599395752]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "705 [D loss: 0.47476939857006073 | D accuracy: 81.25] [G loss: 1.1584811210632324]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "706 [D loss: 0.5583533346652985 | D accuracy: 70.3125] [G loss: 1.0233834981918335]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "707 [D loss: 0.5268713682889938 | D accuracy: 71.875] [G loss: 0.9742114543914795]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "708 [D loss: 0.5004358738660812 | D accuracy: 75.0] [G loss: 1.4419225454330444]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "709 [D loss: 0.5933869183063507 | D accuracy: 70.3125] [G loss: 1.181020736694336]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "710 [D loss: 0.5594924539327621 | D accuracy: 73.4375] [G loss: 1.4210716485977173]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "711 [D loss: 0.37051090598106384 | D accuracy: 87.5] [G loss: 1.3450207710266113]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "712 [D loss: 0.533970445394516 | D accuracy: 78.125] [G loss: 1.2552540302276611]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "713 [D loss: 0.5112855732440948 | D accuracy: 76.5625] [G loss: 1.0427157878875732]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "714 [D loss: 0.4782605916261673 | D accuracy: 78.125] [G loss: 1.0971689224243164]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "715 [D loss: 0.43624378740787506 | D accuracy: 79.6875] [G loss: 0.9402899742126465]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "716 [D loss: 0.4779423177242279 | D accuracy: 78.125] [G loss: 1.0980037450790405]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "717 [D loss: 0.5495182275772095 | D accuracy: 73.4375] [G loss: 1.2769062519073486]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "718 [D loss: 0.5150655508041382 | D accuracy: 75.0] [G loss: 1.075554609298706]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "719 [D loss: 0.5373983085155487 | D accuracy: 76.5625] [G loss: 1.0444495677947998]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "720 [D loss: 0.4538329094648361 | D accuracy: 78.125] [G loss: 1.1035547256469727]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "721 [D loss: 0.5386374890804291 | D accuracy: 65.625] [G loss: 1.1588542461395264]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "722 [D loss: 0.49772027134895325 | D accuracy: 79.6875] [G loss: 0.9675136208534241]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "723 [D loss: 0.5465924143791199 | D accuracy: 73.4375] [G loss: 1.119214415550232]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "724 [D loss: 0.4117462784051895 | D accuracy: 79.6875] [G loss: 1.0874228477478027]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "725 [D loss: 0.4723197817802429 | D accuracy: 79.6875] [G loss: 1.276057481765747]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "726 [D loss: 0.4378870278596878 | D accuracy: 79.6875] [G loss: 1.417402744293213]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "727 [D loss: 0.4432138651609421 | D accuracy: 81.25] [G loss: 1.377848744392395]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "728 [D loss: 0.4565444588661194 | D accuracy: 85.9375] [G loss: 1.2266515493392944]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "729 [D loss: 0.5421262979507446 | D accuracy: 68.75] [G loss: 1.0971877574920654]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "730 [D loss: 0.412869855761528 | D accuracy: 85.9375] [G loss: 1.1946067810058594]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "731 [D loss: 0.488642156124115 | D accuracy: 81.25] [G loss: 1.1234426498413086]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "732 [D loss: 0.3703502416610718 | D accuracy: 85.9375] [G loss: 0.9823888540267944]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "733 [D loss: 0.5357616543769836 | D accuracy: 70.3125] [G loss: 1.0554143190383911]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "734 [D loss: 0.4115256518125534 | D accuracy: 85.9375] [G loss: 1.1406793594360352]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "735 [D loss: 0.4915026128292084 | D accuracy: 79.6875] [G loss: 1.1794596910476685]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "736 [D loss: 0.41493943333625793 | D accuracy: 84.375] [G loss: 1.1499204635620117]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "737 [D loss: 0.394171804189682 | D accuracy: 81.25] [G loss: 1.178526759147644]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "738 [D loss: 0.4936090111732483 | D accuracy: 78.125] [G loss: 1.1982955932617188]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "739 [D loss: 0.471820205450058 | D accuracy: 79.6875] [G loss: 1.2191798686981201]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "740 [D loss: 0.520018681883812 | D accuracy: 73.4375] [G loss: 1.1286048889160156]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "741 [D loss: 0.528779610991478 | D accuracy: 68.75] [G loss: 1.2103737592697144]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "742 [D loss: 0.4037974774837494 | D accuracy: 85.9375] [G loss: 1.1031041145324707]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "743 [D loss: 0.44137321412563324 | D accuracy: 81.25] [G loss: 1.123705506324768]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "744 [D loss: 0.5465278029441833 | D accuracy: 76.5625] [G loss: 0.8698461055755615]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "745 [D loss: 0.47879642248153687 | D accuracy: 75.0] [G loss: 1.1665563583374023]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "746 [D loss: 0.4228380024433136 | D accuracy: 78.125] [G loss: 1.1999632120132446]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "747 [D loss: 0.5833373367786407 | D accuracy: 70.3125] [G loss: 1.1846036911010742]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "748 [D loss: 0.5310570597648621 | D accuracy: 79.6875] [G loss: 1.0852208137512207]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "749 [D loss: 0.4839363396167755 | D accuracy: 78.125] [G loss: 0.9138047695159912]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "750 [D loss: 0.4155755639076233 | D accuracy: 87.5] [G loss: 0.9652335047721863]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "751 [D loss: 0.4391990602016449 | D accuracy: 84.375] [G loss: 0.9952143430709839]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "752 [D loss: 0.43496519327163696 | D accuracy: 73.4375] [G loss: 1.0206029415130615]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "753 [D loss: 0.6799974739551544 | D accuracy: 65.625] [G loss: 1.0075401067733765]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "754 [D loss: 0.5231960713863373 | D accuracy: 68.75] [G loss: 1.0845861434936523]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "755 [D loss: 0.552537590265274 | D accuracy: 70.3125] [G loss: 1.3479280471801758]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "756 [D loss: 0.508488804101944 | D accuracy: 71.875] [G loss: 1.3782823085784912]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "757 [D loss: 0.40714767575263977 | D accuracy: 82.8125] [G loss: 1.1445412635803223]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "758 [D loss: 0.377148762345314 | D accuracy: 82.8125] [G loss: 1.1318838596343994]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "759 [D loss: 0.6342435479164124 | D accuracy: 64.0625] [G loss: 1.042708396911621]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "760 [D loss: 0.44788260757923126 | D accuracy: 82.8125] [G loss: 1.1060627698898315]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "761 [D loss: 0.4881446063518524 | D accuracy: 76.5625] [G loss: 1.280961275100708]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "762 [D loss: 0.5658811628818512 | D accuracy: 68.75] [G loss: 1.3143072128295898]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "763 [D loss: 0.4936428666114807 | D accuracy: 81.25] [G loss: 1.2817597389221191]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "764 [D loss: 0.5027733147144318 | D accuracy: 78.125] [G loss: 1.211338996887207]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "765 [D loss: 0.44400978088378906 | D accuracy: 75.0] [G loss: 1.1568126678466797]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "766 [D loss: 0.4737800359725952 | D accuracy: 73.4375] [G loss: 1.3178269863128662]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "767 [D loss: 0.4991956502199173 | D accuracy: 73.4375] [G loss: 1.1076037883758545]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "768 [D loss: 0.5594449937343597 | D accuracy: 71.875] [G loss: 0.8757678270339966]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "769 [D loss: 0.4685211181640625 | D accuracy: 75.0] [G loss: 0.9271105527877808]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "770 [D loss: 0.4821825176477432 | D accuracy: 73.4375] [G loss: 1.10487699508667]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "771 [D loss: 0.47318509221076965 | D accuracy: 76.5625] [G loss: 1.322340965270996]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "772 [D loss: 0.5153828859329224 | D accuracy: 67.1875] [G loss: 1.1547960042953491]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "773 [D loss: 0.5294369608163834 | D accuracy: 76.5625] [G loss: 1.1437034606933594]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "774 [D loss: 0.4452393651008606 | D accuracy: 78.125] [G loss: 1.054072618484497]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "775 [D loss: 0.3981530964374542 | D accuracy: 87.5] [G loss: 1.0281492471694946]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "776 [D loss: 0.49450966715812683 | D accuracy: 71.875] [G loss: 1.0571188926696777]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "777 [D loss: 0.4158015698194504 | D accuracy: 79.6875] [G loss: 1.0873568058013916]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "778 [D loss: 0.5115754157304764 | D accuracy: 78.125] [G loss: 1.0372618436813354]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "779 [D loss: 0.4218084067106247 | D accuracy: 73.4375] [G loss: 1.1399922370910645]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "780 [D loss: 0.4923264682292938 | D accuracy: 81.25] [G loss: 1.2970311641693115]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "781 [D loss: 0.5188213884830475 | D accuracy: 79.6875] [G loss: 1.2119708061218262]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "782 [D loss: 0.5796579420566559 | D accuracy: 70.3125] [G loss: 1.1137380599975586]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "783 [D loss: 0.4292934089899063 | D accuracy: 78.125] [G loss: 1.117406964302063]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "784 [D loss: 0.5017063915729523 | D accuracy: 73.4375] [G loss: 1.1187851428985596]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "785 [D loss: 0.5999869108200073 | D accuracy: 67.1875] [G loss: 1.040926456451416]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "786 [D loss: 0.47896625101566315 | D accuracy: 78.125] [G loss: 1.212688684463501]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "787 [D loss: 0.45345330238342285 | D accuracy: 78.125] [G loss: 1.1445465087890625]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "788 [D loss: 0.452383428812027 | D accuracy: 78.125] [G loss: 0.9901654720306396]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "789 [D loss: 0.5624910742044449 | D accuracy: 62.5] [G loss: 1.0119047164916992]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "790 [D loss: 0.47230926156044006 | D accuracy: 73.4375] [G loss: 1.1844435930252075]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "791 [D loss: 0.5427213311195374 | D accuracy: 73.4375] [G loss: 1.0265603065490723]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "792 [D loss: 0.4971536695957184 | D accuracy: 75.0] [G loss: 1.0951619148254395]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "793 [D loss: 0.47242338955402374 | D accuracy: 76.5625] [G loss: 1.0575206279754639]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "794 [D loss: 0.5119847655296326 | D accuracy: 73.4375] [G loss: 1.0849653482437134]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "795 [D loss: 0.6099766194820404 | D accuracy: 57.8125] [G loss: 1.0660364627838135]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "796 [D loss: 0.5495721101760864 | D accuracy: 75.0] [G loss: 1.0417709350585938]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "797 [D loss: 0.4932247996330261 | D accuracy: 79.6875] [G loss: 0.8868986368179321]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "798 [D loss: 0.471735879778862 | D accuracy: 76.5625] [G loss: 1.0689631700515747]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "799 [D loss: 0.41337233781814575 | D accuracy: 84.375] [G loss: 1.1273218393325806]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "800 [D loss: 0.4503019452095032 | D accuracy: 81.25] [G loss: 1.1367554664611816]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "801 [D loss: 0.6089611947536469 | D accuracy: 70.3125] [G loss: 1.1158897876739502]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "802 [D loss: 0.3947981595993042 | D accuracy: 78.125] [G loss: 1.071698546409607]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "803 [D loss: 0.4987228661775589 | D accuracy: 73.4375] [G loss: 1.0367395877838135]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "804 [D loss: 0.40670645236968994 | D accuracy: 84.375] [G loss: 1.0368797779083252]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "805 [D loss: 0.6175792217254639 | D accuracy: 65.625] [G loss: 1.1300818920135498]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "806 [D loss: 0.4979282021522522 | D accuracy: 78.125] [G loss: 1.0596306324005127]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "807 [D loss: 0.5621173977851868 | D accuracy: 70.3125] [G loss: 0.997071385383606]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "808 [D loss: 0.4915889799594879 | D accuracy: 76.5625] [G loss: 1.0415979623794556]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "809 [D loss: 0.4823615550994873 | D accuracy: 76.5625] [G loss: 0.983120858669281]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "810 [D loss: 0.4490308314561844 | D accuracy: 81.25] [G loss: 1.0668022632598877]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "811 [D loss: 0.5111986249685287 | D accuracy: 75.0] [G loss: 1.0814578533172607]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "812 [D loss: 0.5563393831253052 | D accuracy: 73.4375] [G loss: 1.1161967515945435]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "813 [D loss: 0.539095550775528 | D accuracy: 65.625] [G loss: 1.0726815462112427]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "814 [D loss: 0.5454290211200714 | D accuracy: 75.0] [G loss: 1.0653023719787598]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "815 [D loss: 0.46496474742889404 | D accuracy: 79.6875] [G loss: 1.0323741436004639]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "816 [D loss: 0.45866043865680695 | D accuracy: 78.125] [G loss: 1.0897557735443115]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "817 [D loss: 0.37007373571395874 | D accuracy: 82.8125] [G loss: 1.0370758771896362]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "818 [D loss: 0.4585718661546707 | D accuracy: 78.125] [G loss: 1.1390252113342285]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "819 [D loss: 0.5566155910491943 | D accuracy: 70.3125] [G loss: 1.0306730270385742]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "820 [D loss: 0.45206934213638306 | D accuracy: 81.25] [G loss: 1.0965020656585693]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "821 [D loss: 0.46638061106204987 | D accuracy: 75.0] [G loss: 1.0674173831939697]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "822 [D loss: 0.5850964486598969 | D accuracy: 73.4375] [G loss: 1.0728455781936646]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "823 [D loss: 0.4793969988822937 | D accuracy: 82.8125] [G loss: 1.0326422452926636]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "824 [D loss: 0.4583141356706619 | D accuracy: 82.8125] [G loss: 1.1197843551635742]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "825 [D loss: 0.48030275106430054 | D accuracy: 79.6875] [G loss: 0.9630728363990784]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "826 [D loss: 0.5353871583938599 | D accuracy: 64.0625] [G loss: 0.9244436621665955]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "827 [D loss: 0.44394300878047943 | D accuracy: 81.25] [G loss: 1.0284591913223267]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "828 [D loss: 0.42464689165353775 | D accuracy: 84.375] [G loss: 1.251307487487793]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "829 [D loss: 0.5645572543144226 | D accuracy: 70.3125] [G loss: 1.1883950233459473]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "830 [D loss: 0.46016253530979156 | D accuracy: 82.8125] [G loss: 1.0716040134429932]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "831 [D loss: 0.5831298530101776 | D accuracy: 70.3125] [G loss: 1.006333827972412]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "832 [D loss: 0.47355416417121887 | D accuracy: 71.875] [G loss: 0.8379605412483215]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "833 [D loss: 0.46229246258735657 | D accuracy: 78.125] [G loss: 0.9981154203414917]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "834 [D loss: 0.5715154558420181 | D accuracy: 71.875] [G loss: 1.0274343490600586]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "835 [D loss: 0.4312649518251419 | D accuracy: 81.25] [G loss: 1.0848418474197388]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "836 [D loss: 0.4501146823167801 | D accuracy: 78.125] [G loss: 1.1930214166641235]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "837 [D loss: 0.5355770587921143 | D accuracy: 76.5625] [G loss: 1.1324139833450317]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "838 [D loss: 0.5132955610752106 | D accuracy: 73.4375] [G loss: 1.110306978225708]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "839 [D loss: 0.4580532908439636 | D accuracy: 81.25] [G loss: 0.961289644241333]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "840 [D loss: 0.524755209684372 | D accuracy: 68.75] [G loss: 0.9992351531982422]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "841 [D loss: 0.427472360432148 | D accuracy: 82.8125] [G loss: 1.0820317268371582]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "842 [D loss: 0.3962142914533615 | D accuracy: 81.25] [G loss: 1.2063910961151123]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "843 [D loss: 0.46005018055438995 | D accuracy: 78.125] [G loss: 1.3088397979736328]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "844 [D loss: 0.509372279047966 | D accuracy: 76.5625] [G loss: 1.163961410522461]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "845 [D loss: 0.5519392788410187 | D accuracy: 68.75] [G loss: 1.00581693649292]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "846 [D loss: 0.53365558385849 | D accuracy: 64.0625] [G loss: 0.9430745244026184]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "847 [D loss: 0.48005862534046173 | D accuracy: 76.5625] [G loss: 0.9989949464797974]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "848 [D loss: 0.5089703798294067 | D accuracy: 78.125] [G loss: 1.1492722034454346]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "849 [D loss: 0.46579186618328094 | D accuracy: 81.25] [G loss: 1.2066516876220703]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "850 [D loss: 0.5677281320095062 | D accuracy: 78.125] [G loss: 1.0501512289047241]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "851 [D loss: 0.5673775672912598 | D accuracy: 70.3125] [G loss: 1.0875022411346436]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "852 [D loss: 0.6289298832416534 | D accuracy: 65.625] [G loss: 1.0763475894927979]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "853 [D loss: 0.39899176359176636 | D accuracy: 85.9375] [G loss: 1.0353341102600098]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "854 [D loss: 0.5089799761772156 | D accuracy: 76.5625] [G loss: 1.0769907236099243]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "855 [D loss: 0.3818313479423523 | D accuracy: 82.8125] [G loss: 1.1356842517852783]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "856 [D loss: 0.5144810676574707 | D accuracy: 76.5625] [G loss: 1.0688719749450684]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "857 [D loss: 0.45842352509498596 | D accuracy: 79.6875] [G loss: 1.1608086824417114]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "858 [D loss: 0.507845550775528 | D accuracy: 81.25] [G loss: 1.103773832321167]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "859 [D loss: 0.5060853064060211 | D accuracy: 71.875] [G loss: 1.1526308059692383]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "860 [D loss: 0.4702834188938141 | D accuracy: 78.125] [G loss: 1.0589700937271118]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "861 [D loss: 0.5282022356987 | D accuracy: 76.5625] [G loss: 1.048390507698059]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "862 [D loss: 0.472112774848938 | D accuracy: 84.375] [G loss: 1.0596460103988647]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "863 [D loss: 0.5236535668373108 | D accuracy: 73.4375] [G loss: 1.028153896331787]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "864 [D loss: 0.3992329388856888 | D accuracy: 87.5] [G loss: 1.0182591676712036]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "865 [D loss: 0.48892131447792053 | D accuracy: 81.25] [G loss: 1.1217715740203857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "866 [D loss: 0.42476746439933777 | D accuracy: 84.375] [G loss: 1.1199418306350708]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "867 [D loss: 0.42513641715049744 | D accuracy: 84.375] [G loss: 1.08620023727417]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "868 [D loss: 0.6042455732822418 | D accuracy: 65.625] [G loss: 1.0593136548995972]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "869 [D loss: 0.4622972309589386 | D accuracy: 81.25] [G loss: 1.2139636278152466]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "870 [D loss: 0.5323282778263092 | D accuracy: 78.125] [G loss: 1.146877408027649]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "871 [D loss: 0.38967034220695496 | D accuracy: 84.375] [G loss: 1.2076337337493896]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "872 [D loss: 0.5175930857658386 | D accuracy: 76.5625] [G loss: 1.118593692779541]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "873 [D loss: 0.4971041679382324 | D accuracy: 78.125] [G loss: 1.0722850561141968]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "874 [D loss: 0.41696079075336456 | D accuracy: 84.375] [G loss: 1.0666553974151611]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "875 [D loss: 0.3843770921230316 | D accuracy: 82.8125] [G loss: 1.126291036605835]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "876 [D loss: 0.4511931538581848 | D accuracy: 82.8125] [G loss: 1.0841411352157593]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "877 [D loss: 0.5051142424345016 | D accuracy: 67.1875] [G loss: 1.1720685958862305]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "878 [D loss: 0.5705016851425171 | D accuracy: 71.875] [G loss: 1.1828761100769043]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "879 [D loss: 0.4736532121896744 | D accuracy: 81.25] [G loss: 1.1503565311431885]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "880 [D loss: 0.5014783442020416 | D accuracy: 79.6875] [G loss: 1.059129238128662]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "881 [D loss: 0.4580617845058441 | D accuracy: 79.6875] [G loss: 1.0762312412261963]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "882 [D loss: 0.540803998708725 | D accuracy: 68.75] [G loss: 1.032126784324646]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "883 [D loss: 0.4411071091890335 | D accuracy: 82.8125] [G loss: 1.1234416961669922]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "884 [D loss: 0.5218058228492737 | D accuracy: 71.875] [G loss: 1.0857329368591309]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "885 [D loss: 0.49903950095176697 | D accuracy: 73.4375] [G loss: 0.9591005444526672]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "886 [D loss: 0.4822714626789093 | D accuracy: 78.125] [G loss: 0.997282862663269]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "887 [D loss: 0.5180639773607254 | D accuracy: 76.5625] [G loss: 1.0428931713104248]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "888 [D loss: 0.41548797488212585 | D accuracy: 85.9375] [G loss: 1.093009114265442]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "889 [D loss: 0.3724161386489868 | D accuracy: 87.5] [G loss: 1.2551593780517578]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "890 [D loss: 0.41732458770275116 | D accuracy: 82.8125] [G loss: 1.148998737335205]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "891 [D loss: 0.5277440249919891 | D accuracy: 79.6875] [G loss: 1.2001945972442627]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "892 [D loss: 0.6270832419395447 | D accuracy: 68.75] [G loss: 1.0467592477798462]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "893 [D loss: 0.47143690288066864 | D accuracy: 75.0] [G loss: 1.083827018737793]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "894 [D loss: 0.42628034949302673 | D accuracy: 82.8125] [G loss: 1.0688048601150513]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "895 [D loss: 0.2985662892460823 | D accuracy: 92.1875] [G loss: 1.1801645755767822]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "896 [D loss: 0.5358765721321106 | D accuracy: 73.4375] [G loss: 0.9814522862434387]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "897 [D loss: 0.48005181550979614 | D accuracy: 81.25] [G loss: 0.9704877138137817]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "898 [D loss: 0.4666039049625397 | D accuracy: 76.5625] [G loss: 1.1345255374908447]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "899 [D loss: 0.4943074584007263 | D accuracy: 78.125] [G loss: 1.106261968612671]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "900 [D loss: 0.5340060740709305 | D accuracy: 67.1875] [G loss: 1.1050398349761963]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "901 [D loss: 0.48075199127197266 | D accuracy: 73.4375] [G loss: 1.1217647790908813]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "902 [D loss: 0.44084620475769043 | D accuracy: 79.6875] [G loss: 1.066053867340088]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "903 [D loss: 0.45664364099502563 | D accuracy: 76.5625] [G loss: 1.0809448957443237]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "904 [D loss: 0.44054771959781647 | D accuracy: 81.25] [G loss: 1.0387585163116455]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "905 [D loss: 0.5531213730573654 | D accuracy: 68.75] [G loss: 0.9994809627532959]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "906 [D loss: 0.4212936460971832 | D accuracy: 82.8125] [G loss: 1.1382784843444824]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "907 [D loss: 0.4361433982849121 | D accuracy: 82.8125] [G loss: 1.1363065242767334]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "908 [D loss: 0.5544925183057785 | D accuracy: 73.4375] [G loss: 1.0456840991973877]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "909 [D loss: 0.42815010249614716 | D accuracy: 84.375] [G loss: 1.0878314971923828]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "910 [D loss: 0.422619491815567 | D accuracy: 84.375] [G loss: 1.1651464700698853]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "911 [D loss: 0.43581296503543854 | D accuracy: 82.8125] [G loss: 1.0401923656463623]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "912 [D loss: 0.6049381196498871 | D accuracy: 64.0625] [G loss: 0.9740896224975586]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "913 [D loss: 0.5271013826131821 | D accuracy: 75.0] [G loss: 1.044621467590332]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "914 [D loss: 0.421606108546257 | D accuracy: 84.375] [G loss: 1.152832269668579]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "915 [D loss: 0.5780714005231857 | D accuracy: 75.0] [G loss: 1.1441230773925781]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "916 [D loss: 0.5554928779602051 | D accuracy: 67.1875] [G loss: 1.2092318534851074]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "917 [D loss: 0.5078025162220001 | D accuracy: 73.4375] [G loss: 1.106274962425232]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "918 [D loss: 0.5009848922491074 | D accuracy: 73.4375] [G loss: 1.184563398361206]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "919 [D loss: 0.5272879302501678 | D accuracy: 75.0] [G loss: 0.9937158226966858]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "920 [D loss: 0.4597834497690201 | D accuracy: 78.125] [G loss: 1.0726178884506226]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "921 [D loss: 0.4807257056236267 | D accuracy: 81.25] [G loss: 1.043994665145874]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "922 [D loss: 0.4683977961540222 | D accuracy: 82.8125] [G loss: 1.0129961967468262]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "923 [D loss: 0.4593929350376129 | D accuracy: 82.8125] [G loss: 1.0083757638931274]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "924 [D loss: 0.4615398347377777 | D accuracy: 75.0] [G loss: 1.0208358764648438]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "925 [D loss: 0.5555935800075531 | D accuracy: 75.0] [G loss: 1.0737602710723877]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "926 [D loss: 0.5111522376537323 | D accuracy: 76.5625] [G loss: 1.1656724214553833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "927 [D loss: 0.5275735855102539 | D accuracy: 73.4375] [G loss: 1.0544830560684204]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "928 [D loss: 0.519164651632309 | D accuracy: 76.5625] [G loss: 1.1114418506622314]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "929 [D loss: 0.5358528643846512 | D accuracy: 81.25] [G loss: 0.9379238486289978]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "930 [D loss: 0.5768385529518127 | D accuracy: 71.875] [G loss: 0.9320798516273499]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "931 [D loss: 0.515457347035408 | D accuracy: 75.0] [G loss: 0.9848358035087585]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "932 [D loss: 0.510759100317955 | D accuracy: 75.0] [G loss: 0.9419797658920288]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "933 [D loss: 0.464521199464798 | D accuracy: 75.0] [G loss: 1.1095155477523804]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "934 [D loss: 0.45780208706855774 | D accuracy: 76.5625] [G loss: 1.0251704454421997]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "935 [D loss: 0.40228357911109924 | D accuracy: 90.625] [G loss: 1.0832771062850952]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "936 [D loss: 0.46098849177360535 | D accuracy: 71.875] [G loss: 1.1628239154815674]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "937 [D loss: 0.5510017275810242 | D accuracy: 70.3125] [G loss: 1.0999813079833984]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "938 [D loss: 0.5539733469486237 | D accuracy: 73.4375] [G loss: 1.0707473754882812]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "939 [D loss: 0.47810743749141693 | D accuracy: 70.3125] [G loss: 1.0438145399093628]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "940 [D loss: 0.40146106481552124 | D accuracy: 84.375] [G loss: 1.211247205734253]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "941 [D loss: 0.5245063602924347 | D accuracy: 73.4375] [G loss: 1.146040916442871]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "942 [D loss: 0.4617917835712433 | D accuracy: 76.5625] [G loss: 1.1098456382751465]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "943 [D loss: 0.44135311245918274 | D accuracy: 81.25] [G loss: 1.1834298372268677]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "944 [D loss: 0.4898730367422104 | D accuracy: 76.5625] [G loss: 1.028186321258545]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "945 [D loss: 0.5245369225740433 | D accuracy: 76.5625] [G loss: 1.0145530700683594]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "946 [D loss: 0.5930273234844208 | D accuracy: 67.1875] [G loss: 0.9519655704498291]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "947 [D loss: 0.4819190502166748 | D accuracy: 76.5625] [G loss: 0.9629371166229248]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "948 [D loss: 0.4642893821001053 | D accuracy: 78.125] [G loss: 1.0732024908065796]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "949 [D loss: 0.4030805975198746 | D accuracy: 84.375] [G loss: 1.1768288612365723]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "950 [D loss: 0.48711103200912476 | D accuracy: 75.0] [G loss: 1.1987844705581665]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "951 [D loss: 0.42689190804958344 | D accuracy: 81.25] [G loss: 1.1644492149353027]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "952 [D loss: 0.44124773144721985 | D accuracy: 81.25] [G loss: 1.0661797523498535]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "953 [D loss: 0.4130426198244095 | D accuracy: 81.25] [G loss: 1.045857310295105]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "954 [D loss: 0.46368978917598724 | D accuracy: 78.125] [G loss: 1.1000349521636963]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "955 [D loss: 0.4738858491182327 | D accuracy: 73.4375] [G loss: 1.11090087890625]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "956 [D loss: 0.4174916446208954 | D accuracy: 81.25] [G loss: 1.0645129680633545]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "957 [D loss: 0.47600264847278595 | D accuracy: 79.6875] [G loss: 1.0600941181182861]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "958 [D loss: 0.3586067631840706 | D accuracy: 87.5] [G loss: 1.1799086332321167]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "959 [D loss: 0.46977049112319946 | D accuracy: 82.8125] [G loss: 1.2817091941833496]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "960 [D loss: 0.5015984773635864 | D accuracy: 71.875] [G loss: 1.0576224327087402]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "961 [D loss: 0.5246755480766296 | D accuracy: 76.5625] [G loss: 1.096895456314087]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "962 [D loss: 0.3699180632829666 | D accuracy: 84.375] [G loss: 1.1378939151763916]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "963 [D loss: 0.4081861227750778 | D accuracy: 79.6875] [G loss: 1.09083092212677]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "964 [D loss: 0.46109843254089355 | D accuracy: 82.8125] [G loss: 1.1068992614746094]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "965 [D loss: 0.3869907259941101 | D accuracy: 82.8125] [G loss: 1.0974981784820557]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "966 [D loss: 0.5192250609397888 | D accuracy: 75.0] [G loss: 0.9780609011650085]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "967 [D loss: 0.4189510941505432 | D accuracy: 81.25] [G loss: 1.097337245941162]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "968 [D loss: 0.4444761872291565 | D accuracy: 79.6875] [G loss: 1.1314001083374023]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "969 [D loss: 0.49758225679397583 | D accuracy: 76.5625] [G loss: 1.105466365814209]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "970 [D loss: 0.528880700469017 | D accuracy: 70.3125] [G loss: 1.034332513809204]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "971 [D loss: 0.4652442932128906 | D accuracy: 81.25] [G loss: 1.049358606338501]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "972 [D loss: 0.36467380821704865 | D accuracy: 84.375] [G loss: 1.210249423980713]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "973 [D loss: 0.447563499212265 | D accuracy: 76.5625] [G loss: 1.0239589214324951]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "974 [D loss: 0.45269346237182617 | D accuracy: 75.0] [G loss: 1.145499587059021]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "975 [D loss: 0.47693993151187897 | D accuracy: 81.25] [G loss: 1.1034985780715942]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "976 [D loss: 0.4643700420856476 | D accuracy: 79.6875] [G loss: 1.1823101043701172]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "977 [D loss: 0.4840823709964752 | D accuracy: 75.0] [G loss: 1.107558012008667]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "978 [D loss: 0.48033425211906433 | D accuracy: 79.6875] [G loss: 1.1029282808303833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "979 [D loss: 0.42293238639831543 | D accuracy: 84.375] [G loss: 1.035714864730835]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "980 [D loss: 0.48892074823379517 | D accuracy: 68.75] [G loss: 1.043210744857788]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "981 [D loss: 0.45734912157058716 | D accuracy: 81.25] [G loss: 1.0937395095825195]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "982 [D loss: 0.4801662862300873 | D accuracy: 75.0] [G loss: 1.0566896200180054]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "983 [D loss: 0.4364130198955536 | D accuracy: 78.125] [G loss: 1.2228186130523682]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "984 [D loss: 0.48818668723106384 | D accuracy: 73.4375] [G loss: 1.0839574337005615]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "985 [D loss: 0.5628361701965332 | D accuracy: 75.0] [G loss: 1.1441632509231567]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "986 [D loss: 0.4612705260515213 | D accuracy: 82.8125] [G loss: 1.0712140798568726]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "987 [D loss: 0.41779346764087677 | D accuracy: 84.375] [G loss: 1.1401886940002441]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "988 [D loss: 0.48011626303195953 | D accuracy: 79.6875] [G loss: 1.1560112237930298]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "989 [D loss: 0.48689331114292145 | D accuracy: 76.5625] [G loss: 1.1917816400527954]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "990 [D loss: 0.45711323618888855 | D accuracy: 75.0] [G loss: 1.0770013332366943]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "991 [D loss: 0.542210042476654 | D accuracy: 70.3125] [G loss: 1.045988917350769]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "992 [D loss: 0.4215068370103836 | D accuracy: 84.375] [G loss: 1.0676782131195068]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "993 [D loss: 0.38458251953125 | D accuracy: 82.8125] [G loss: 1.1136785745620728]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "994 [D loss: 0.4894983768463135 | D accuracy: 75.0] [G loss: 1.058109164237976]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "995 [D loss: 0.4119321256875992 | D accuracy: 84.375] [G loss: 1.1400494575500488]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "996 [D loss: 0.491498202085495 | D accuracy: 81.25] [G loss: 1.1934611797332764]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "997 [D loss: 0.5451980531215668 | D accuracy: 73.4375] [G loss: 1.0687263011932373]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "998 [D loss: 0.47401162981987 | D accuracy: 79.6875] [G loss: 1.1015151739120483]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "999 [D loss: 0.45619185268878937 | D accuracy: 78.125] [G loss: 1.0129756927490234]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1000 [D loss: 0.4166809171438217 | D accuracy: 85.9375] [G loss: 1.0278420448303223]\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFJCAYAAADkLDW5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABliUlEQVR4nO2deZRVxbX/NzI0Qze2EQTBCIKINCAYoRlaBUQGA4pRlJgQxWgc83TlIRqzTFCS955mwCEqiT6TlZegGFSIKAmDoIIgIEMYZBKQBImKRkBUEJv6/ZFfVz6nuNX0HZrG6/ezlmttL+eeU1W7qu7p767aVcs550wIIYQQX2iOqukCCCGEEKLm0QuBEEIIIfRCIIQQQgi9EAghhBDC9EIghBBCCNMLgRBCCCFMLwRCCCGEML0QCCGEEML0QiCEEEIIO0JeCFq3bm2jRo2q6WKIFMg3Rybyy5GLfHPkIt9UTrW+EGzatMmuvfZaa9OmjdWvX98aN25sZWVldv/999snn3xSnY+uVt566y279NJLrbi42Bo3bmzDhg2zzZs313Sx0iIffbN+/Xr73ve+Z71797b69etbrVq17M0336zpYqVFPvrlmWeesREjRlibNm2sYcOG1r59exs9erTt3LmzpouWFvnomylTptigQYOsRYsWVlBQYCeccIINHz7cVq9eXdNFS4t89E3IgAEDrFatWvbd73632p5Rp7pu/Pzzz9sll1xiBQUFdvnll1unTp3s008/tfnz59uYMWNszZo19sgjj1TX46uNPXv2WL9+/WzXrl32gx/8wOrWrWv33nuv9enTx1asWGHHHntsTRfxkOSrbxYuXGgPPPCAlZSUWIcOHWzFihU1XaS0yFe/XHPNNdaiRQsbOXKknXjiibZq1Sp78MEHbfr06bZs2TJr0KBBTRfxkOSrb1atWmXHHHOM3XzzzdakSRN7++237Te/+Y2VlpbawoULrUuXLjVdxEOSr74hzzzzjC1cuLD6H+Sqgc2bN7vCwkJ36qmnuu3btx/07xs3bnT33Xef//9WrVq5K664ojqKknPuueceZ2Zu8eLF/rO1a9e62rVru9tvv70GS1Y18tk377//vtu9e7dzzrmf/exnzszcli1barZQVSSf/TJ37tyDPvvd737nzMw9+uijh79AaZLPvknF22+/7erUqeOuvfbami7KIfki+OaTTz5xrVu3duPGjXNm5m688cZqe1a1vBBcd911zszcK6+8UqXrQye9//77bvTo0a5Tp06uUaNGrqioyA0ePNitWLHioO8+8MADrqSkxDVo0MAVFxe7M844w02cONH/++7du93NN9/sWrVq5erVq+eaNm3qzj33XLd06VJ/zUcffeTWrl3rduzYcciydu/e3XXv3v2gzwcOHOjatm1bpfrWJPnsG/J5eyH4oviFzzAz95//+Z8Zff9w8kXzzYEDB1zjxo3diBEjMvr+4eSL4Ju77rrLnXjiie7jjz+u9heCallDMG3aNGvTpo317t07o+9v3rzZpk6dakOHDrXx48fbmDFjbNWqVdanTx/bvn27v+7RRx+1m266yUpKSuy+++6zu+66y7p27WqLFi3y11x33XU2YcIEu/jii+3hhx+2W265xRo0aGBr16711yxevNg6dOhgDz74YKXlOnDggK1cudK6det20L+Vlpbapk2b7MMPP8yozoeLfPXN550vml/efvttMzNr0qRJRt8/nHwRfLNz507bsWOHrVq1yq6++mrbvXu39e/fP6P6Hk7y3Td/+9vf7O6777Z77rnn8ITWcv2GsWvXLmdmbtiwYVX+TvjWtnfvXldeXp64ZsuWLa6goMCNGzfOfzZs2DDXsWPHSu999NFHH/KNau7cuc7M3NixYyu9bseOHc7MEmWo4KGHHnJm5tatW1fpPWqSfPZNyOdJIfgi+aWCq666ytWuXdtt2LAho+8fLr4ovmnfvr0zM2dmrrCw0N1xxx0HlflI44vgm+HDh7vevXv7/7dqVghyvqhw9+7dZmZWVFSU8T0KCgq8XV5ebjt37rTCwkJr3769LVu2zP9bcXGxbdu2zZYsWWLdu3dPea/i4mJbtGiRbd++3Vq0aJHymr59+9q/2rpyKlarsnwV1K9fP3HNkUg+++bzzBfNL48//rg99thjduutt1q7du0yusfh4ovim9/+9re2e/du27x5s/32t7+1Tz75xMrLy+2oo46InekpyXffzJ07155++umEClHd5NzbjRs3NjPLSjo/cOCA3XvvvdauXTsrKCiwJk2aWNOmTW3lypW2a9cuf91tt91mhYWFVlpaau3atbMbb7zRXnnllcS9fvrTn9rq1avty1/+spWWltqdd96Z8RbBCslm3759B/3b3r17E9ccieSzbz7PfJH8Mm/ePLvqqqts0KBB9l//9V85uWd18kXxTa9evWzQoEF2/fXX24wZM+wPf/iD3X777VnftzrJZ9989tlndtNNN9m3vvWt6AtItVAdskOLFi3SWmAXyjg//vGPnZm5b3/72+6JJ55wM2bMcLNmzXIdO3Z0ffr0SXx3z549btKkSW7UqFGuWbNmzszcj370o8Q127dvdw899JAbNmyYa9iwoatfv76bPn162vUqLy93BQUF7vrrrz/o3+644w5nZn6V+5FKvvom5PMUMnDui+GXFStWuOLiYtetWzf34YcfZnWvw8kXwTchl112mWvevHlO71kd5KtvHnvsMVe3bl33yiuvuC1btvj/zMxdfvnlbsuWLe6jjz5K+76HolpeCK655hpnZm7BggVVuj50UpcuXVy/fv0Ouq5ly5YHOYns27fPDRkyxNWuXdt98sknKa955513XMuWLV1ZWVmVyhbSrVu3lLsMBgwY4Nq0aZPRPQ8n+ewb8nl7Ich3v7zxxhuuefPm7pRTTnHvvvtuxvepCfLdN6m48MILXYMGDXJ6z+ogX30zduxYv6Yj9t+UKVPSvu+hqJYA0a233mqNGjWyq6++2t55552D/n3Tpk12//33R79fu3btg+IskydPtrfeeivx2fvvv5/4/3r16llJSYk552z//v1WXl6ekH3MzI477jhr0aJFQvb/+OOPbd26dfbee+8dsm7Dhw+3JUuW2GuvveY/W79+vc2ZM8cuueSSQ36/psln33yeyWe/vP322zZw4EA76qijbMaMGda0adNDfudIIp998+677x702ZtvvmkvvPBCyt1URxr56puvf/3rNmXKlIP+MzP76le/alOmTLEePXpUeo9MqJZMhW3btrXHH3/cRowYYR06dEhkj1qwYIFNnjy50nzSQ4cOtXHjxtmVV15pvXv3tlWrVtnEiROtTZs2iesGDhxozZs3t7KyMmvWrJmtXbvWHnzwQRsyZIgVFRXZzp07fSrOLl26WGFhoc2ePduWLFliv/jFL/x9Fi9ebP369bOxY8fanXfeWWndbrjhBnv00UdtyJAhdsstt1jdunVt/Pjx1qxZMxs9enQ2zXZYyGff7Nq1y375y1+amfn43oMPPmjFxcVWXFxcrSk/syWf/TJ48GDbvHmz3XrrrTZ//nybP3++/7dmzZrZgAEDMmqzw0U++6Zz587Wv39/69q1qx1zzDG2ceNGe+yxx2z//v129913Z9Nsh4V89c2pp55qp556asp/O+mkk+zCCy9Mp5mqTs41B7Bhwwb3ne98x7Vu3drVq1fPFRUVubKyMvfLX/7S7d2711+XaivI6NGj3fHHH+8aNGjgysrK3MKFC12fPn0SMs6vf/1rd/bZZ7tjjz3WFRQUuLZt27oxY8a4Xbt2Oef+JeuMGTPGdenSxRUVFblGjRq5Ll26uIcffjhRznS3gvz97393w4cPd40bN3aFhYVu6NChbuPGjRm3U02Qj76piLGl+q9Vq1bZNNdhIx/9EvOJmVUqyx5p5KNvxo4d67p16+aOOeYYV6dOHdeiRQv39a9/3a1cuTKrtjrc5KNvUmHVvO2w1v9/iBBCCCG+wBy5m0yFEEIIcdjQC4EQQggh9EIghBBCCL0QCCGEEML0QiCEEEII0wuBEEIIIUwvBEIIIYSwNDIVNm/e3Nuffvqpt3ncL6+pOJrS7N9HA5v963SpCoqLixPPOOmkk7xdWFiY8vsffPCBtytOGDRLnjLI68nWrVu9feyxx3p77dq13q5du7a3P/74Y2+zzmbJIzf3799/SLusrMzbCxcu9HYuUvLyqE22O9ua6SY+++wzb/P4T9rhsbRM3cnr2A516vy7OzVq1MjbDRs2TGlXnFZmZrZu3bqU5WYblpeXe5tpQsMjp+nDPXv2ePuYY47xdq1atVI+Y+fOnd7O1jcnnHBCyufVq1cvZfnoI7b/l7/8ZW8fffTRiWfwNDWmoWXfpb9btmzpbaZUbdasmbdZb15Df3G88foTTzwxZdnM/pXKtQL6YsOGDd7m+OaYY3/auHGjZcsFF1zg7TVr1nibY6lz587e5sl2nOfatm3rbfYjM7O6det6e/ny5d4+77zzvM2+y7rTZ9u3b/c2T/bjd5nVjuOH43PmzJneDudezqXskxxz5Pjjj/f2P//5T29v2bIl5fVVhVkr2Z+3bdvmbdbpo48+8jbrzd+S8PeAcwfHGfsVn81+Sx/TR2y/2DzIOYA2ffePf/wjUVbOFSwT+wHnrNh3d+zYkfKaECkEQgghhKi6QsC3QL4ZEb558Y2Jf+3zrWXIkCGJ7/OvHx6A8sYbb3ibb+38K4jP4Ntrhw4dvM2/nvlXDd+8+FfNggULvL1+/fpEWXkv/rVEYm+ysfbLFN6vdevW3ma9+NcWfcC/APkmHf4lesopp3i7SZMm3j777LO9zb8y+QZLVYBvzHwe/wqizTq8+eab3j755JO9PW/evERZFy1a5G36hm/JbLMvfelL3mbbZAv/YmH7sW1ff/11b7NP8S+zF1980dv868MsqR7wL0w+g2OXB8AcddS//x6gOsG/iM466yxvcwzwLzD6i/4N/3L529/+5m2qTFTu+BcYffGVr3zFcgkVQo4N9rGVK1d6m3+NUy3jITjhYUClpaXepp86duyY8hn8q5HzE8cYy8G/8nv16uVt/pXO69u3b+9ttrmZ2dKlS73NPsY+QsWD44qKQrZwLHLsU7lh23AuYrn5W0RlK/wOFa2///3v3uZ44DzF3yW2bcwv7CtULgcOHOhtqh9h4uDYbxbHN+cKzsHhYUtVQQqBEEIIIfRCIIQQQog0QgaUfSlRUKKmDMeFQrFrLr744sQzKJfwGVy4Q1mH9+JxlZR4KA+xDpTwKUdSIqN8xUWBZmaTJk3yNuVPylaUcLlwKdchA8q0DNVQbmJbUYqjLEspk1KamVmXLl28TUmM0v2KFSu8TXmeUiplZC5w4/1ZJoaF2A9YnzD0RGmOISBK+AxpsD6pzlTPFPqZ/Zb9k4uaGD5gKIf+Yn82S9aVvqC8y+9QlmY56G9KwJQ82U5sSy6eZJ8Lj2/lvdgPYgtHWZ9Q4s4W1p19idI0pXfOCwyp8LvhAjyOeYYPGQJ6++23vU0ZmHMPQ6Dsn5zDuOiR0jLLSpk/XFTYu3dvb3PMcLEvpW3OpWyDbGHog/VjyIV9mIsQ2Qacf8J+yOvYD/gMhoI4H/G3jOEeti1DaxwnbGP+ZpxzzjneZt8wS7Y/x3qsH7AcChkIIYQQIiP0QiCEEEKIqocMKH9SGqNETRmDKzu7du3q7ZKSEm+HshXlLcoglKooP1Mqj8lWDEPE9msS7o+mLEYJzywZZqC0yHJTjqKEG8uTkCn0B6Uy7peO7YPnanFKZpTwzZLhBK4Wp2xGn/MaSt6Ul/k5JVl+zv7C8vF6hhXMkn31nnvu8XZMGmb7UcrLFpaXO2Uo67G/0V+UiQl3DJjFZUGGq1i/0047zduUINmevJ47CBh6YN0YCmCog/cP78vyEc4nrGu4uyJbGJ7h+GW/5TMpZZ977rne5rimPGyWnD/YvnwGQwm8hu3L+YJzJMNQvE8sVMW2Dfs5y86xvmrVKm9zvuYckok0HWPZsmXe5nzds2dPb3McM8wSm9cGDRqUeAb7JX9PYuEbhjbZhiwfxzR3rcR279AvLE+4Y43zJevEPsQcFxxjmYwZKQRCCCGE0AuBEEIIIdIIGVByphRBWYwhA642poxIKSZMB8zrKLUwGURVVrRylXQsfS/lL8rHlCmZmCiUcJkAgrBtmAqT0ivrmQu4Yp7tE5OEKcPzmmHDhnmbCZ3Mku1FWYpyGj+n7M9wC+VFlpVyHWUzSmYsK30Zyp+U4dkXKFNTkuUK+6qm+KwKlPUY1qC/2F9YP4YYYqm/zZJ+YptQEucY5TOYTIX9g/2T45jjkDtKeD0l1TDFMHcTcD6hjzn+OC5zvTMnDL1UwDmJZaTcy/bkinUmRzNLJiainM3dE/Qz/cfr2V82bdqU0uaz6RuODZab3zVLzm+Uszl2OS4XL17sbYaEs4X9lsm8uJOI7cFkSyzrnDlzvM2wpllyDDz77LPepo+HDh3qbYaFOE8NHjzY2xw/TPLEMcOdcAxTcYyFqYv5m0ofMUEf59pWrVp5uyoh8hApBEIIIYTQC4EQQggh0ggZUEqLrZilpMQVyVw9TfklXJ1KyYbJMSi7cEUzZURKwNx9QDkzJosSrjqlTP6b3/wmcR0TV1AmpZzFzxliyETKqQxKsbGV/rHVp/QNJfxwBwilR0q5lFXpmyVLlng7FqJgH+GzeR/KZOw77B/haYe8F5OBzJ0719uUs9l+4Y6FbGA7s+wsL/shn035k3077DuUlul7SoeUF9kn+V0mU2GYhbtmYqetcdzz8zDJU+zURcqkvIYr57mSOhfETmnluGa/ZT9k/+KcQtss2dZcrc+wD9uXoROGVnm+An3DtmYIhCGJ2I6w8MwOhitoMxTBvhc7RyZbWF7udOLY/cY3vpGyHJz3eR9K8mbJ8vL7nKM5B7F/sk/GTlXlbyV/4xgeisn84S4D7izgTheOdc6FLEcmfpFCIIQQQgi9EAghhBAiByEDSnxcDU1JitJ17EwEs6SEzJzOZ555prcp6VOOoQRIyYvSDK+hrMZVtcx7TcklPA6YZxv86Ec/8jYldIY6mIud1+QC1pd+oqRF+Tq2cviZZ57x9vnnn594Br/DdqTMxnqx3dlHuNKfUi2lO96fsihztPPzcMcH5VPKpCwH+3CuE0VVwP5MKY/l5a4G+oI2d0Ew9GAWDz+xf7NPUD6l7BjbtcExwHHCnRyxHSJhMi/6hWOD556wf7D/0o+5gNIvfUOZmhItJWtK+Aw3MeRZGUwOxXpxPmT/ZiiBYyYWzuEcyzFJP4W7Njg/sE6UrBkC4ljMpW9435deeillmRgyYH/mzgmu9A9leO5YoM/YJzlGuSOA/Z7PZp/gfTh+GHaizXEYyvzcacFQLfsBw4733nuvZYMUAiGEEELohUAIIYQQaYQMKFVSyqM8demll3qbCSYoOzGRBKWV8F6UySgjUk6OJVmhlEY5hc/jSl8eacl6sgyXXXZZoqx//vOfvR1LBsSV7HxeKGFlC+tIyS2WeIbyImVRylVhGfl93perxSm90+ds09gOEMq2hJ9TXuc9KwvBUFqjTEqbkmcu5U/K+awHw0fsq+yfsVXLHCNmyTakRM9EWOx7lO0pi1JCZ4iPOxwoY7OsbDP2/3AlO0N8LDfLwT4Yu28uYDsykQ9Dhnwmxwz7Hvs/5zyzpP+5ap11ZKiGY45hG/Zv9gX6mPXhfMZrKHEz/BN+n2OGZ7b86U9/slT0798/5eeZwNAAd3xcfPHF3mbb8Eh0+ovyehhW4/fZR/k89m/OWbFEd7E5jv2J4Qn2J4YEw2R9rAcTXT399NPepl95lHKYfKoqSCEQQgghhF4IhBBCCKEXAiGEEEJYGmsISCx2/9xzz3mbcShmvWMcOMwKxxgo4y2MXTHWyW06nTp18jbj3dz6xRg3n814JuN4jO8uXLgwUVbGC7nGgfE+xqdY1jC2mi28N222A2NczIzFs90ZiwoPDGKcizGy2CFG3B7KLZtclxHbusQ6sNyM67EPhltCueUutlWHMV3Gttm/soXl4LYurjlhnI+Z8RhL5VoUxvHNknFM+o/jYdu2bd5mG7Bt+F36MbYWhFulunfv7m2OhXBdCJ/BccLr2E5cy8C2yQXcQsdx8te//tXb69at8zb7C+eInj17epvlNUvGpGMZ67itLLauiZny2NdZB45prhPhGOO8E8aqOf64LoJZLjkH3Hbbbd7u0aOH5QrOxSwj5w36gusDOBex7cOstGvXrvU225bfYRtwHPN3g32V60I4Ntiu9AXhfdjeZskxynrE1uNwzU94UFJVkEIghBBCCL0QCCGEECKNkAHlplh2OsoVDBMw0xO3t4QZ4ih7UarkvSh5UlZl6ILSJmUTSiuUaWLbEbk1h1m+zJLSImVSSu2U9xh+CA/byBbK59xOR+md7c7y8tCY008/3dthRrzYYVBsL0q/se2l9Dn9R3mW54bzGkq7lBDpy7DslBQp1dOu7CCUbIhlVmSbxQ4gYb9liCbcdsj2pNTPrY3MotauXTtvM9xAeB+2LSVcthmvjx2SY5aUYTlvsH6U45nBMJeHTpklpfpY2Is25yD2z1hWVLPkuIyFQ5mxbs2aNd5mW7PulIo519BP4aFSqT4Pt9d27drV2/TBokWLvM0xyvABQ8UDBw5M+eyqEjtYiRkCKeGzPXg9/cu52szs+eef9za3LXL7JMcu25lzC31HX7N/cD6hjzgfcCyE2XvpJ45pzl/83WU4JQwLVQUpBEIIIYTQC4EQQggh0ggZUBLhKkpKK5SaKHlS3mXoIQwZcHUs/y1ceVkB5SXKNNzJQGmLcgylJkr7vCfrHGZK48pt1il2aAplUT47F8RCBpSVKFNTuqIcxpANd2eYJaV7lp9SKusYCx8RhgAYCmL5KPdxNTO/G668Zz9kpjbCPhzLKJktlHoZpmEfo5RMuY8H4DBMEIYMWA+GuChDsh/Qx+z3DK0wJLhs2TJvU7aN7YIIDzQiLDv9yjAG+wrLRGk3F7BeHD/sw5RoOY8w/MdrwhAJ5V7OBbEdUfQlfcC+QzjXsK/xPiwf52o+1ywZcmWIl/MDQ0887Inze7YwvNi7d29vs18wlMRV+JTzGd5g+NnMbM6cOd7u2LGjtzn2582b521m4OVY4m8Uf394GB9DLuxbHEvMesvPzZJtwN9H9lmODYa2GYKqKlIIhBBCCKEXAiGEEEKkETKgREhZgvLxggULvE0ZgzILJaHwAB1K/TG5m7Iov0+5leXjylPKqJQ2KQFScud9wsRElLAo88RWk3O1abiSNJdQbo+tlOWBG5TW+vXr5+3wwCDWl/IkQyd8NuVhSqkxiZRhF8phPFyFfYL3Cc92p1TL73N1N2VYSpCUTrOFdaIszjHDsrNMHAuUmMMDwWJ9j5JzLIRGHzMRDsvEOpxxxhne5nijFEoJlglgzJL9gDsOuMKd4Qf2J943F3B+4tjgXMD6sk0ow3fo0MHbbBOzpM9ZX85JDM1xXLEPs98yFMvPOR54H4aFeM8w8diLL77oba6e51wRSx6WywPBGH7gqn/ucmJiJ9Z19erV3o4dNmSWDCHQFwwBcJxxnuL13LXBBGN89iuvvOJt9iHuxuBcGc5lHKP0Pcc0+xDDPbGdYZUhhUAIIYQQeiEQQgghRBohA8ogsRXTDCtQPuPZzZR9KYWamZWVlXmbUldMvmGCCpaPSXHWr1+fsky8niviKRtRvgyTfbAcvFcskUtsRXAuoA8oeVNuohS6ePFib3fp0sXblKvCxESUuVl+SqH0f2xXAmFogKEHyp8M7XClNqXy8CwDJohhWelDrpim/Ml2yhZKlbwv5XyGvSiXsh8yyUpYV4a12J5sAz571apV3mYfpgRJqZESKfszZVeOK/qF51mYJecNrsTmGQD0C32X6zDbzTff7G2u8ub4oeQ/depUb1PipUzNXPhmScmbMjz7BSVe7qqgDM/5j+OSIYOYlM35KLZS3yw5P9FPLBP7EefM2E6eTGAIhonSYnMI5yz2W46fF154IfEdnj/Blfucazh3MkzNOYhjhnMwv8tdPRw/DMWxDoMHD06Ulfdiv+M8MGnSJG/TF+GOpKoghUAIIYQQeiEQQgghRIZnGVAOjuU3p5RJWZQSVJiwhuEEyoWUdSiZUTahRETpiAlvKNXyGt6TuwEoAVIeMktKOZS4KSnFclRTqs0FlAUpP3GXA+VkStAM2/A+oUTH8rPt2Bdi5zWwTJROKYVSpmQ/4H3oY0q7YVkZfuDq35g0Tf/H8vtnAvt9eBRwBZSG+ezYca9hEhj271jIgSud2SfYv9lX+TxKyZQg2VfYB1jPMJc6JVlKm/w+fc+2yUT+rIzx48d7+3vf+563uYPg5ZdfTlkWjnf2tdA39AHbnWOAK+Y5L8T6N/3N+Y9l4lil3M06hCvQY/MWE+5w/mTYkaGLbGG9WXael8DfEP4usS0ZNgmPNGff478x/MN5h79TsTak73h/3oe7uDgWGL4Jz1LhvMj+yBARdw5xrGcSmpZCIIQQQgi9EAghhBAijZABkx9Q1qF0QamKMiClM0o8s2bNSjxjwIAB3maO6tgqW8r4lOQon1GO4arhWBKd2KrOMMc05eBwdXEFTP7BNsu1/EnoDyaqoTTGla+vv/66ty+44AJvhzI8V0bHwi2sF59H6Zi7Eii/UWajNEkJjTIgk8ZQZjZLhgMGDRrkbbZHLGQQnlmRDaw3pV4mjOKzKf2xjSlFh7tdmFAolpSEbR47t4HXcIxyNTmlYdaNcwPHZJjkiTsfKPtyfghz7FfABFq5gGERJlRjn2RojXI0/cQ+zzqZJduXSWV4jgLnSUrWbHc+j+3DcB+lZfq+tLTU248//ri32f/Nkj4/77zzvM2wROwsmDBZVjZwhxjrwX7FMA37Dud07p7ib4lZ/Ojzl156ydsMlbDfcl7jXMExHTsXhH0rdnRyeG4FzzLgThe2E+cEloP9t6pIIRBCCCGEXgiEEEIIkeFZBrQpd1Bup3wTy30fQkmFK9P5OSVxylaxxB+UMym38Z6U81gfrlAPV6pyVS7vyxWpsWNI2X65gKEJ3pthDspHlAdjyTjCHSAMkcR8znagbEZ5ljtGYomi2LZsNz6XdQ7zslMGZMiB4RFeEzvjIlvY/mwbJuyhX5jTP1yhXwF3SpglwyD0UaydKSmyH3CM0qYfKdszjMGyVnZ8NMc0w1aUSVlWysHMqZ8LOC9Qwv/5z3/ubR7RPHPmTG8z/MOQZBjOodS/cuXKlOVgP2T/5jzH+YnyN/st+zklfM7D7P9hznxK2zz/g3UoKSnx9owZM7zNBELZwr6wYsUKb7N+sSRAnKPZ/8NdEGxzjkv2SY5Lzkfs32wz9lX6i2dmsG9zrNKn4c4A+o91ZSiHIQ3Wm2GFqiKFQAghhBB6IRBCCCFEGiEDyiZcWRvLnU8Zl59TqgtlQEqPlP0pn1EW4ueUPynrUMphOSjN8HMmVGKdw0QelF4ZfmAdKH9RDsx1XnbKT7EEQpTAKCXFzgcId0JQpuN9KWlRxmI7sO5cPU3Zkj6gTMnQBeVx9rswBMNn8778PuvAvpPLpFHsq5SZeQYHr4mdr8C+RgnSLOk/3qt79+7eZoIXrp6mXErfbd682dscD9zREEskFTtHwiye+IphGo5XzgHLly+3XMI6cnfT5MmTvc1wCUNaDNvw88rCiqwLd9RwPMR2hnB+4ViipM55lf4m7FMcC2bJcfLkk096m/2Fsj3HTHjMdTbMmTPH25ynWHb2w1hSOfqOfTi8VywMyTmVoQFeM3ToUG9zBwDHEv0SCwPS7+FZKhyjTGzE/hHb2cN5o6pIIRBCCCGEXgiEEEIIkUbIgHIYZQ3K87yGMi4TplACoeRvllzFSsmGclZshXvM5vWxpCeUpSlfUkoME6M8//zz3qacTsmZkiHbI5TrsoX15QpjSraUOZmHnMdt0h+Ud82SchdDC7GQDEMOlPWWLl3qba66pTxIOZKSG6U1fjfcGcCyx5IoUfqLrVrOFvqfEh/DN9x1w0QzlPu4ipvtbZaUa1lvjh/6lfelHEz/ctUzdxPQp5SxCeXwcMdB7Nn0BduACYMYisgFXElP3/Tq1cvbsdAj88VX1ibcIcM5JjZfUGqm5M0xwDJxTmHbcucD68b+EZ7ZwX7PlepM5sa5lPWJ7aDIBI59htY4f3E3DutN6Zz+CkM5/H+GbDhfvvrqq96mH88+++yUNkNo7KtMaMUxOXfu3JTlCXcG0N+x8CfHSWy3VlWRQiCEEEIIvRAIIYQQIgeJibhSnJ/HEtZQ3g1XXXL1J2Ur3pcSDyWsmOxLO3Y08Jo1a1I+i1IMV/SaJaVoSjOUnSiFsg1yKUubJduBsiXlN64+ZT77b33rW96mpBj6hrIzn0ebq3wpm9GvXEkfO+OCfortGOA9wx0RDJvEdq7QT/x+mLAlG/gMtj8lZ0rD7MP8biyEYpZMgsJ6x1ZSx8ImvA/LGjuG96KLLvI2+xP7APPomyXHEOvHxDFsD4ZDKM/mAvZD+pztwx0dvIar3NknKXGbJUOlPFODEjT9RP+xT3KVO3dHxHaGMORDmTp2JL1Zct6jnylNT5w40dvsU9zRki0MOVGGZxtwPLAcrDev79+/f+IZ3MXEMAN3OHBsXHXVVd7u27evt9mHTzvtNG/36NHD27EdNKwn+9ySJUsSZeWY4RgdPny4t3kGDcsU/mZVBSkEQgghhNALgRBCCCHSCBlQ7qBURVmHkiclNsrNlMJCqZe5w/k8SkFMgsLVmZTuGA5gOVhWyvyUoPgs7jKoLPkGn8HQAOVq1ieXR+yG96MEyZXA3BnCsAuPCaV0FR6PytXKlN5joST2Ee5KoAzL/kIf0E+x5FOVnYlBOY752yl/sr/wvmECqmyIJVChj9hXuXOC5WOimfCIXUqehD5mGIkrwtkn+WyufOcqc47PVatWeZs7cHgUeHjuAvsEy02Jmqu7OX5iuxoyheEx7njgEbgMJVJuZ7uxT5100kmJZ9D/9DPDMBwD7CP8nGOXY49zDa/nvMq+EzvLxSzZ1gz7sK8y1MH2C3eLZQPve+6553p74cKF3o7t2OI8fNZZZ3mbZxSYJecj7sigv7gLhf2W7U+/MNzDcDdlfrYxd1tdeOGF3uax7mbJJFGxY7DZZuGOinSRQiCEEEIIvRAIIYQQIo2QAWUkyouUYyj9UU6h/EmpMFwxTamSUi/lLUrXlHcpW8Xy7rN8sZXNLDclvHBnAKU0SjaUBmNnDFR2RGwmxOpL6Z3PZHtSUqRkFub0Z1tQYqc8xiQhlO2ZbIYyMsMHlGG5UjYmM1O6C0NP/D6lXspsrAN9HuYSzwau/KaPKAuy79FfHTt29Dbbhj4yS+5Y4BjgDhnelz6ibEm5lavl+Tn7OfsQJViGcsKQAduf/ZQSOleHc57JZMV0ZVBqnj59urc7d+7s7ViSF/Zt9i+2s1my/LyO8jL9zyPc6UuORc5/7F/c0cCV7QzhUHIOdxHRz/QBz5vhziEe9ZxJApwYHO8c10ygxr7DehPWO9z9wTHA0AB/H/jbNG/ePG8zDMs5nWOAcxNDBrE5i/dkmMosmRiM/YN9gj5iyI0JnKqKFAIhhBBC6IVACCGEEGmEDCiJUCKiFE15g/ISpQtKVWFyDIYJKAvNmjXL25TDmOOdIY3YSktKeCwr5VzKgVyBGp4/QPmHkielt9h5DPxuLoidmUDpnDIgJSpKf9xhQTnSLClh0jesL+vF59FnlLpioRNKtVzNTvkttoLfLClts0yU+OgP9u1c7wCpgKEZ7liJjR+2E+vHXSFmZsuWLfM2+xvbnEcvs3+fd9553ub5FuvXr/d27CwQ3odwfFOCNYvLqmyD2Mpt7i7KBez3DM+wXuzD4e6OCmL1CO9FYom9WEf6j30n1lYdOnRI+Tl9wHki3GUQO8ac45vzJ58RHsmdDZT6KZ8z8Q/DR0wgxPHDkFm3bt0Sz2C/Yr1Zj9gxwmeeeaa32T/4+8BwJHfp8PeN8xf9e/fddyfKSp/xOwzNMWz44osvejuTHQdSCIQQQgihFwIhhBBC6IVACCGEEJbGGgLGoxnHimW/YoyJ248YE2FM0SwZz2GmNcYlGXPjdizGuGOH4DCmwjrQ5tYcxtqZpcvMbP78+Sm/zzowrsT4INsyFzDexefTjh2iwvgY46phzJRrQhhr4+f0AZ/HdQ0sE33Ja7hWgHFLbgVinJNbH82S/mDGRfZJxvnYv8KtY9nAurI9aTMGyr7H7H+MjYZ+2bRpk7e5BZhjg2N04MCB3r788su9zS2d7J9cf8CycrsX47X0UdjP6TNuvVy0aJG3me2Payf+/Oc/Wy5hWTjOuT2Qa2UY2+ZaDfbbMC7P9R70Bz/nmGNmPq4/eOGFF7w9cuRIbzN7H+cn9hGuIYitEzBLrqOiz3lfjkXObeyD2cItgoy/c55iW3KtBevNePspp5ySeAa/wzahv/lbwXHJ2D3XrbHfsKyx7Lt8FrcNhlskue6A/Y4ZRzmv0XeVZXONIYVACCGEEHohEEIIIUQaIQNusaCsyu1R7du39zYlEcpfsS1oZklphrIxpUd+n+ewx7YlcVsWtwjxPpQmKR8z9BBukaRMz+/HQitsM8pUuYBbg1hmSmgMwcydO9fblDwpo1MiNUu2F0MOsUNnYmeqM0zEtma7UfpmvyOx0IxZst0ZTqDkzedRLqe8ni3s95QX6RfKhfw8dpgOt8KaJf1HuZ5bSDnOeK9HHnnE2/Q325PjmNI6x3pMTqfEHP4bYZ9leITSK/tfLmD/ZFiJZYyVl2OfsM3Nkv2Ybcd5iJ+zr7If9uzZ09tvvPGGt+knjkOOY/Y7+p4hvbAczIjHeYvfZxvkMrsn+zO3HHOO5dhgn+fBVBzT3JJplvQLQ1+sK9uDbcv253ZGzsHcwks4/3ArfjjXEv6uMQTAuYJzGT/PZHu7FAIhhBBC6IVACCGEEGmEDChFxKSjGFxNHjsQwiy52rhHjx7ejp23zfvysAiumKWcEpODY9+NnWUdEjsAhuWjZF+dhxtRLmRbM/NgLLsaZTlKxWZJ6ZG7Rriqlf2CUJ6lDMsdCpRtefAUfcZncWVzuJqWUjP7WGx3B0MgudwBwhAYyz5lyhRvx3bm0C/c1RHK2FxNPWrUKG8znFZaWupt+oh+6d69u7f/53/+x9uUZwnbLCaHM7tc+DzK49xZEDsMJjzTPls4TlhOhqgYamE7sOyUrBnuMEvK0XwGfcB279evn7cZbqHkvWTJEm9zJ0ps5wLnbc5TYRZJzlvcNcL+xoOVOFeE83g28HlsJ8rtvIbzGucE9qmXX3458QweVsQx2rdvX28z4x/7Hv3N8N3y5cu9zQOGSkpKUl5Dv9BfYZiNdaKP+JvF3ybOJwoZCCGEECIj9EIghBBCiKqHDJhQiNIm5ULKLJREuHKU8jalYbP4WdiU3ikpcuVx7ICimTNnerusrMzbTPjAVZ6U1SpbSRtLbMTvxw4aqkqYJR0oqzNMQPmIshLlPq6spXQVhgwYtonJVbEkVew7lJpjB2bxnryGq9EpX4YyemzVM+9LnzF0kcvDjehntjNlR67ojiUT4orp8MASSpIME/A7s2fP9jbHJcNAY8aM8fYll1zibUrLXPHMPsQ+x74RhpBYPoY6KPtyXHJ85zL5jVnSzwyB8XNKzQxL8RrOYZ07d048g75lOIG7Efj51KlTvc0kRWz32O4Izn8sB8c0yx2OEY4BjkX6maE49iMmEMoWjhmOa8r8HMesH8MKDAnRv+F92Q7333+/tzk/8DeH4QPOQewrHHsMQTHUFDuwj3UwS867rDfLzd0mbdq0Sfl5VZFCIIQQQgi9EAghhBAijZABZSGubuWqyFiSGso3lBEpqZklJf2Y7EvpnfIzk1isXr3a21zpy5XelNi4mpiSJ1f0hok8WA+GOtgGlIlZHz47F3A1Kduaz6QEzXaLJTLimePhd3ivWP5wynRsE8rlvIYyG/N5U4qjXMdyU4o2S54vzraJha5iIY1sYR9Zv369t2NnJzDURTjGmBjFLNmeXIXM0AJlWCalYr//9a9/7W2G0M466yxvs80po/J61iHcsUF5nGfds3z0XSj15hKuQqcUzjmJ4dBYyI9hF+atN0v2PY4NSsQMidFmiIK5+HkNk0NRBudqdvZ5hhvCfsS5gmGC2DkpHNNsv2xhX2dfoPzN8AbHEq+JJXAKv8MdPKwffc+wHOtKH9G/vCa2a4b1ZH8I+3wsVM/fI36f4bcwUVZVkEIghBBCCL0QCCGEECKNkAFXSFImi+XQpqRB6ZQSViixER7vyMQclCcpeTKkwfLxmFXKakuXLvU2palYkiGuZjWL58WnxBYLDVB6zQWU+GKJhlgvSv483pRSXBj+eeaZZ7wdy2/fsWNHb1O25DVPPfVUymfHjqxmu3PFbqdOnbwd7trgamr2SUp29BmfzXbKFkp8bE+GPvg8+ovXcMxUltSK53awfly5zxAPZUtKk5QgeU9Kziwrw2zcDRCGDOgLhvhi0jzHa6535vA57G98JsMxbCuWlxJ+GFZkmZl0jf6kvMxV6+zrv//9773Nsy+4y4DyNfszE++wfGFZmWSH8ydh3+F9c3lkeCyBV2wHE/sexwbDuOEuJP4e8XeDEjulex4zzbmP9WY52D9oM9ke+x/HUhgyYF05r/E7HFdsv0zGjBQCIYQQQuiFQAghhBBmtVyul7wLIYQQ4nOHFAIhhBBC6IVACCGEEHohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEKYXAiGEEEKYXgiEEEIIYXohEEIIIYTphUAIIYQQphcCIYQQQpheCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGFHyAtB69atbdSoUTVdDJEC+ebIRH45cpFvjlzkm8qp1heCTZs22bXXXmtt2rSx+vXrW+PGja2srMzuv/9+++STT6rz0dXGnXfeabVq1Trov/r169d00dIiH31TwZNPPmm9evWyRo0aWXFxsfXu3dvmzJlT08WqEvnol9atW6ccM7Vq1bJ27drVdPGqTD76xsxs9uzZ1q9fP2vSpIkVFxdbaWmp/f73v6/pYqVFvvpm0qRJ9pWvfMXq169vTZs2tauuusree++9anteneq68fPPP2+XXHKJFRQU2OWXX26dOnWyTz/91ObPn29jxoyxNWvW2COPPFJdj692JkyYYIWFhf7/a9euXYOlSY989s2dd95p48aNs+HDh9uoUaNs//79tnr1anvrrbdqumiHJF/9ct9999mePXsSn23dutXuuOMOGzhwYA2VKj3y1TfPPvusXXjhhdarVy//x84f//hHu/zyy+29996z733vezVdxEOSr76ZMGGC3XDDDda/f38bP368bdu2ze6//3577bXXbNGiRdXzR6irBjZv3uwKCwvdqaee6rZv337Qv2/cuNHdd999/v9btWrlrrjiiuooSs4ZO3asMzO3Y8eOmi5KRuSzbxYuXOhq1arlxo8fX9NFSZt89ksqfvzjHzszc6+88kpNF+WQ5LNvBgwY4Fq0aOH27t3rP9u/f79r27atO+2002qwZFUjX32zb98+V1xc7M4++2x34MAB//m0adOcmbkHHnigWp5bLS8E1113XVqDPXTS+++/70aPHu06derkGjVq5IqKitzgwYPdihUrDvruAw884EpKSlyDBg1ccXGxO+OMM9zEiRP9v+/evdvdfPPNrlWrVq5evXquadOm7txzz3VLly7113z00Udu7dq1VfqRr3ghePfdd92uXbsSzvo8kM++GTFihDv++ONdeXm5O3DggPvwww+rVMcjgXz2Syo6dOjgTjrppIy+e7jJZ9/06NHDdezYMeXnPXr0qFJ9a5J89c3SpUudmbmHHnrooH8rLCx0vXv3rlJ906Va1hBMmzbN2rRpY717987o+5s3b7apU6fa0KFDbfz48TZmzBhbtWqV9enTx7Zv3+6ve/TRR+2mm26ykpISu+++++yuu+6yrl272qJFi/w11113nU2YMMEuvvhie/jhh+2WW26xBg0a2Nq1a/01ixcvtg4dOtiDDz5Y5TK2adPGjj76aCsqKrKRI0faO++8k1FdDzf57JsXXnjBunfvbg888IA1bdrUioqK7Pjjj0/LrzVFPvslZPny5bZ27Vr7xje+kVFdDzf57Ju+ffvamjVr7Ic//KG98cYbtmnTJvvxj39sr732mt16660Z1fdwkq++2bdvn5mZNWjQ4KB/a9CggS1fvtwOHDiQUZ0rJddvGLt27XJm5oYNG1bl74RvbXv37nXl5eWJa7Zs2eIKCgrcuHHj/GfDhg1L+XZLjj76aHfjjTdWes3cuXOdmbmxY8cesqz33Xef++53v+smTpzonnrqKXfzzTe7OnXquHbt2rldu3Yd8vs1ST775p///KczM3fssce6wsJC97Of/cw9+eSTbvDgwc7M3K9+9atKv1+T5LNfUjF69GhnZu71119P+7uHm3z3zZ49e9yll17qatWq5czMmZlr2LChmzp16iG/W9Pks2927NjhatWq5a666qrE5+vWrfN+eu+99yq9RybkfFHh7t27zcysqKgo43sUFBR4u7y83Hbu3GmFhYXWvn17W7Zsmf+34uJi27Ztmy1ZssS6d++e8l7FxcW2aNEi2759u7Vo0SLlNX379jXnXJXKdvPNNyf+/+KLL7bS0lL75je/aQ8//LB9//vfr9J9aoJ89k3ForX333/fJk2aZCNGjDAzs+HDh1vnzp3tJz/5iV177bVVrufhJJ/9EnLgwAGbNGmSnX766dahQ4e0v3+4yXffFBQU2CmnnGLDhw+3iy66yMrLy+2RRx6xkSNH2qxZs6xnz55p1PTwks++adKkiV166aX2u9/9zjp06GBf+9rX7K233rL/+I//sLp169r+/furZ/dErt8wcvHWVl5e7saPH+9OPvlkV7t2bf9GZGauX79+/rrXX3/dtWzZ0pmZO/nkk90NN9zg5s+fn7j3k08+6erXr++OOuoo1717dzd27Fi3adOmbKt5EM2bN3f9+/fP+X1zST77ZseOHc7MXN26dd1nn32W+Le77rrLmZnbunVrRveubvLZLyFz5sxxZuZ+/vOf5+R+1U2+++baa691Xbp0SfyV/Omnn7p27dq50tLSjO97OMh33+zcudNdcMEFiTKNHDnSXXTRRc7M3AcffJDxvWNUy6LCFi1auLZt21b5+tBJFSuQv/3tb7snnnjCzZgxw82aNct17NjR9enTJ/HdPXv2uEmTJrlRo0a5Zs2aOTNzP/rRjxLXbN++3T300ENu2LBhrmHDhq5+/fpu+vTp2VTxILp37+5OP/30nN6zOshX35SXl7v69eu75s2bH/RvEyZMcGaWcqHQkUK++iXkqquuckcddZR76623sr7X4SJffbNv3z5Xp04d94Mf/OCgf7vpppvcUUcd5fbt25f2fQ8n+eobsnXrVvfSSy+5N9980znnXK9evVzTpk2zumeMankhuOaaa5yZuQULFlTp+tBJXbp0SbydVdCyZcuDnET27dvnhgwZ4mrXru0++eSTlNe88847rmXLlq6srKxKZasKBw4ccE2bNnUDBw7M2T2ri3z2Tc+ePV3t2rUPmsR++MMfOjM7on+E8tkvFezdu9cVFxe7c845J6v7HG7y1Tfbt293ZuZuu+22g/7t+uuvd2bmPv7447TvezjJV9/E+OCDD1y9evXcZZddlrN7kmrZZXDrrbdao0aN7Oqrr065+n7Tpk12//33R79fu3btg+IskydPPii5zPvvv5/4/3r16llJSYk552z//v1WXl5uu3btSlxz3HHHWYsWLfwqTjOzjz/+2NatW1elDFA7duw46LMJEybYjh07bPDgwYf8fk2Tz74ZMWKElZeX2+9+9zv/2d69e23ixIlWUlISjesdCeSzXyqYPn267dy50775zW9W+TtHAvnqm+OOO86Ki4ttypQp9umnn/rP9+zZY9OmTbNTTz015Sr3I4l89U2M22+/3T777LNqSxhVLZkK27Zta48//riNGDHCOnTokMgetWDBAps8eXKl+aSHDh1q48aNsyuvvNJ69+5tq1atsokTJ1qbNm0S1w0cONCaN29uZWVl1qxZM1u7dq09+OCDNmTIECsqKrKdO3faCSecYMOHD7cuXbpYYWGhzZ4925YsWWK/+MUv/H0WL15s/fr1s7Fjx9qdd95Zad1atWplI0aMsM6dO1v9+vVt/vz5NmnSJOvatesRu2iN5LNvrr32Wvvf//1fu/HGG23Dhg124okn2u9//3vbunWrTZs2LZtmq3by2S8VTJw40QoKCuziiy/OpIlqjHz1Te3ate2WW26xO+64w3r27GmXX365lZeX22OPPWbbtm2zP/zhD9k2XbWTr74xM7v77rtt9erV1qNHD6tTp45NnTrVZs6caT/5yU+iCxuzplp0h//Phg0b3He+8x3XunVrV69ePVdUVOTKysrcL3/5y0RmrFRbQUaPHu2OP/5416BBA1dWVuYWLlzo+vTpk5Bxfv3rX7uzzz7bHXvssa6goMC1bdvWjRkzxm//27dvnxszZozr0qWLKyoqco0aNXJdunRxDz/8cKKc6WzTufrqq11JSYkrKipydevWdSeffLK77bbb3O7du7Nqq8NNPvrGuX/JdFdccYX70pe+5AoKClyPHj3cX/7yl4zb6XCTr37ZtWuXq1+/vrvooosybpuaJl99M3HiRFdaWuqKi4tdgwYNXI8ePdxTTz2VcTvVBPnom+eee86Vlpa6oqIi17BhQ9ezZ0/3xz/+Mat2OhS1nMtg75AQQggh8ooj4vhjIYQQQtQseiEQQgghhF4IhBBCCKEXAiGEEEKYXgiEEEIIYXohEEIIIYSlkZiorKzM28uXL/f2UUf9+53i6KOPTvl5YWGht5kRq1u3bolnvPnmm95+4403vH3SSSd5+6OPPvJ2vXr1vF1SUuLt1157LWUdPv7445Tl+Oyzz7zdrFkzb5922mneXrJkSeJeJ554Ysp7bdmyxdtsg9q1a3v7ww8/9PbOnTtTljUd2rVr5+13333X29xRevzxx6csY8uWLb3NLIxskxCeLta+fXtvV5w4aJY8x/uYY47xNtuE/vvggw+8vXfv3pSfFxcXe5tZwcJT81gPtgf9z/uyTLVq1Ur5jEw4+eSTvc0+Qr+wndkvmjZt6u3GjRt7+8tf/nLiGSzjscce622e4sYkK1/60pe8/de//tXbFSfHmSXbqVGjRilt1qG8vNzbbO8wGxuv+8c//pHyXuwT9AX7BMuaKZxT6tT59zRIfxx33HHe5tnzzHi5detWb7OfmyXLzLbo0aOHtzn+6VuOn+3bt3ubfuX9mQ2Pz2Lf2bhxo7ebN2+eKGvdunW9zbmK99qwYYO3ORbpP5Y1E7p06eJt9lWe7Eeb9eBcxvFz5plnJp7BJGX8nTnllFNSPoP34tzHscf+zPHDPrFo0SJvs/3o0/r16yfKescdd3ibGRdff/11b3P+Yntwnmc9K0MKgRBCCCH0QiCEEEKINEIGlI4oUVAeoZzfsGFDb1PaorTfunXrxDMok3Xu3NnblF146ARle8pZlPpKS0u9vXbtWm9T5qI0RcmSEik/N0tKwCwTJS/WZ9OmTd6mRJkLKNOxXCzztm3bvM36Uh7kd+k/s6RUxhAF7RNOOMHb9B+laZaJUjbbh7Izy8Sy/v3vf095T7Ok/Bnrh5QX2bf5vGxhCIVQIuRY4ueUFNn/Bw0alLgX5Uw+j99nyI4hnj59+nibYUBKp5TKGRKkbL5gwYKU1y9btixRVh4Q89xzz3mbfuEcwvFDn+YCjkFK9ZRZY2GKTp06eXv+/Pne5hgzS/qGIQo+j/3wiiuu8DZ9zmdccMEF3uZZAy+++KK3f/jDH3qb7XzDDTd4OxwzU6dO9TbH7t133+1tttm5557r7dmzZ1uu4NzN0B/7NtuGBxpRbl+1apW3n3nmmcQz2Hd5X4ZVOdfwd4rjr0mTJt5muPuf//yntyntMzzEe5566qnefuWVVxJlZR9kqOmpp57yNvsjQwZheLEqSCEQQgghhF4IhBBCCJFGyCBclVrB22+/7W1K7LFVvF/5yle8fc011yTu9be//c3bXB1L+YZSCSUYypmUcihjU87cvHmztynfUJpkGUaOHJko64wZM7z9q1/9ytsMXTCcQomOZc0FLD/9QfmbK7ZjUiwlN0rLZklpjnWhjEXpnVIcn80+wvbl55S7GaqgrE2/htI8d4pw9TX7IaV6ru6nRJctvFcsdMG2pC/o0969e3ub8qJZUpZm6IhtSyh9Ux5nKI/jh2OSUihh6I59gOEzM7M//elP3qZUzjHDvsL2yKVfzJL9jeEn1oX9iPXq2rWrt+fMmeNtznlmSV/R5jzEXQqzZs1K+ezVq1d7m/2ZoTjK6ywTwzacR8PjfTnm1q1b5236PBay4/jJFkrv//3f/+3t9evXe5vtwXAt5zuWj3OImdmwYcO8TX9zPHAXEu/FMA3DpXwGy8oQGMvH9mboLgzljB07NuX3GQZk3+TvI8dYVZFCIIQQQgi9EAghhBAijZABpUZKeZSfKXP16tXL25RHKJ0x+YNZMrEKJV3yta99zduU27iikqteKXNRHqLE1rFjR29T2mWYhDKqmdnpp5/u7QEDBnibq+X5DEqhsdXnmULJjhIVZWO2LVfKMsTAdujfv3/iGVwhTj/TT/QzdwpwVwOlNbbp/v37U5aVn1NOY7/js8yS7cvwDOtA+S0WYsgWtg3rQbma5WPiHoZsuCMmlD+5Kpv1o+TJBCpsw549e3qb4SKWlX2In4flSFVujk+z5NigrMoxSimU7RfueskWthVDe5RvKeGzLPwu+/ZFF12UeAZXmLOPMTEOwwecD9km9BllbY77WHItjknK/9x9ZZacq1gn7jjhLi3uiMklnBOYiIehAfZ59kPOG/ydCeduhhxYb4agOb/w2QwTMKy3cOFCb9MXvD/De+xzS5cu9TbrFpa1b9++3uYcxz7BZGjsQ1VFCoEQQggh9EIghBBCiDRCBpQluMqWMmcsAVEs3zQlSLOkDMV/i62uZIIJym1cQcsyUaqlhEebkgult1B+oZRGCZ6yHCXTp59+2tuUjnIBJUXKYwwfMEf7Sy+95G3Wne0ZSsIxn7PdWQ6uzCVctU45kzIsfU+pOFzFXUGYQ57yN6Vz7jJgEhK2U1VzflcF9j2G2difKRnTFyx39+7dvR2u9I+thGcogvWjHNyqVStvcwcAy8QxwNAM/c4ysP24E8Qs2adiZ2WwfvQjy5QL2Ic5ZhgyYt9jaO3xxx/3Nus0efLkxDN4xgYTBzH8SumeOwJYDt6H4QaOH4ZD6UvOTZyT6Vez5Op++pbtxPFDKTyX4Rz2C8r+3GlDOZ9SPXc8sa5hiHbNmjXeZr0ZAqDNuZ5JgBimprTP+Z1zAH9DGJ5lGTg+zZIhCo7vM844w9tsM84bI0aMsHSRQiCEEEIIvRAIIYQQIo2QAWUJysGUl5iIhPIxQwaUanlkpFlSYqQ8wvzOlLUZAuB9WSauHKV0RCmMSYr4OSWr8CjcWK75559/3tuU/ShL8hm5hitcuTqdbcvVwoTHhPKoVLOkLEzZn3IhwzmURSn38XquCmZZKaGxrSghU7Lkit3w3+gDyvb0GfsIy5QtlAi5ephJnhg+YL+lRE6pNjz6l3WNJbzheOWYYQiAbcOxyzbnqnYeB86j0SsrK2VSyuAsN/td7KjsXMCyMRzA/skxy/HOcAy/G668Z1uw7Wizf8fO0eB96W/en/0rtsuG45ZJjcyS0jbDw2wD9h3uGMn2mHDC0CTneia0Y1/lDgCGD9jGYYIethXDaWwrhq5YbybRih1RznHM8Cf7NsMeDAPx3AqzZHswYRTrRB9x9054LkJVkEIghBBCCL0QCCGEECKNkAFlWcodlIu4cpUSChN0UAZ89tlnE88YOnSotylbMUc7pTuuqIwluWECIcrHPKqUq60pkbKeoRxIWZuy4ahRo7xNKZp1ZXvkAvqA0h/bmjIijy6NnQcREsudzVBCLJkKJTRKtVwZzbLSZqiKfmJZw1XOlPgojfLZXGnMvpPLvOxsA7Yzy8s+Rh9RyqS0z8/Nkv6mzEm59bTTTvM2Vy0zbNKtWzdvP/LII96mVEuJlO1HX3CMUb40S8qtDGNw3qCd650FhCEq+oP9mXMBdwCwXOxrYTI1SttsOz6DYQKuWme/j82xseRK3I3DuZDjh/3RLLlbgjL19OnTvc05nfJ8Lo+m/ta3vuXtr3/9696mzM++zf7PPsyyhonL+LvBMBZ3E3BscIwy/MnfJfqXY4BhWO4MYAiXYaMwVMt+8P3vf9/bd911l7cZOmKysbZt21q6SCEQQgghhF4IhBBCCJFGyICyBKGUTImUCUq4opjSFqUfs6TsQlmH+cUpiy5atMjbTCTBslKSo2RGuTp2zkAsKYdZchV3bFX2c889l/K+uVyVG5aNz6e8zFXBDHcwFMJ6DBkyJPEMyv4sP3PXx0Iy3GVCiW/FihXeprTJZzFRB6V99g+GkcL7MkzAvkeZmKv+KQFnC+vKvkQZkP5iXWnz+jBxycqVK71NCZNjjm1AWZrtQX8Ryq3sw5TNY6vSQ1mabfDtb3/b2z/96U+9zbqy/WKJjDKF/Z5yOSXb888/39s81yB2DkYYzmESm5jP+TnPRGFb009MnMZkOIRlevXVV73N8Gm4A4ShMvqc8xx9y/Bg7KjtTFi8eLG32Ve5k4UhipkzZ3qb7cFQQJiYiPMFy855gLvW2L/5W8Hj2Nm2DKfwPhwz3NlGf3EMmyV/E/n9Cy64wNsM4f7qV7/yNhOaVRUpBEIIIYTQC4EQQggh9EIghBBCCEtjDQG31DA7FLc2MC7FeDTXCjCuyNiJWTIGzbUJjJ3w4CLG1hhr4TNYjtgWrfCgj1TfZdnCcjCezfgi41O5zrRG2A70AWNljJnGso/RT2EsK3aIFbeScRtULHsWt6hxa88LL7zgbW6L5HoF2lxzEB6SxZgh42tcN0B/VlemQvbb2BY6loO+4LYkbvHjegyz5JYowhgl6z1jxgxv83x11ptbEwnXi4RbuSrgPBG2JccGr2NcPHYYVSyLX6Zwixkz+HEdwNy5c73N8csscWyTcC0L25FjlFsuuZ2O/ZBbk9kX2Cacw9gveE+OGa7rCtuT8XdmkGUMnOsM6NtYH8wExuLvueceb3MMcC5jXdnn2R7hGgLOX7FD1bg2h+vT+NvHrau0uQ6FPuV8x6yD7HPhoXIsO7dQc3s7D7MiXDdWVaQQCCGEEEIvBEIIIYRII2TArTKUsC655BJvUxJhRifKpZRrwu0qlAtj2xMpqbAclMr5PEpj4WFKFVCqjR20wi2LZkmZk9tguHXlyiuv9DYPraA8ngsom3HLHutOyZ/yJ7Oase5hiIRhFfqDEiZ9Q/mNz6bcR3/TN9zixbpRquXBU+GWNG4TWrVqlbfZ35hdkluoKAnmErYt25LP5lZBbkGbMmWKt8ODWig/c5sWQzbMNjhnzhxvsx+WlpZ6m/5lO/H+/fr18zYlT4aawrATD+bhPMDwIPsj+wel3VzAejG724svvpiyjGwTyuXcBhrOEbFD0zhmGM5h+I3zLT9nCIzEwqT0AdswDOfE5lXea+nSpd6OhSazheEbthN/D9hf2Cc5rjiWwkN+YqFHhkS41Z0hA9rz5s3zNg+MYyiHfuncubO3OWfxUMBBgwYlysrv83m33nqrt9kn2M/CObwqSCEQQgghhF4IhBBCCJFGyIByK2UTymLf/OY3vc1seJSguCqXkqBZMnsg5UWuUufKXa505urU2Gp5yl+UnSgNUvLn9czYFV7HlaBcPcpMVgwrhNnmsoVyNOtFOZrSGOVkhhUo/VGyNEvWl23Kg1B4L/YLhlcoCcYyGFJyY4iBh/TQx8xuFt6L0iFDQAwTUSoMD7HKBq6k530pf1I65MryP//5z96m78KDnPhvlE/pP/YDytq8F1egM+zEcnBMcocQQ4XsfwxnmCX7F8MMLDc/j63ozgWUz7minGOTUi77Nq9h3+H8ZZasC9uFK/oZ0uLcRkmesjGzH8aezayTlKk5n02bNi1RVl7HuZ7jleOS/o/tOMkEhgvZZmwDyuLsFxzTnAPClfvc6cTvsH/zedzhwN81/i7FdpuEhxVVwN8M1pPZd83MRo4c6W2GDplJlr+jDB+EmTOrghQCIYQQQuiFQAghhBBphAxi589TjqFEStmJEhbl7fBAFT6DK0YpYVJKoxxMmYYriPldlptyJpMaUY7iCvdwJTslKUqmvI6rQl977TVvh8llcgmThDA0QFmK1/AMcUrLYX3Z7qx7bIUx+wXla8qcXFHONqGEzOQ5XDVLOSxMPMK6UqpnvWOrljNZmRuDz6a0z74dOxiLIReG6NifzZL9lUlkGNah7ygvshyUgymPU7bnmKHEzNDYWWed5e0wNEZJlqvcKc+yfqwbQ265gP2bfYlhKSbIolQc8w3b3yw5nmLte+aZZ3q7V69e3p4+fbq3Od7oD0r17M8cexzfbM/wEC+2O8ME3LHDcca+w3k7WxhCoY/YXzhvMGTAenNnQZg4iX7hDg7K/mxPhrwZmqE8z77N3xnOARwP7DcMx/K5ZsnkQgw/8PeVuyaYKDDckVQVpBAIIYQQQi8EQgghhEgjZEDJhrIjpUmGDChBUV4aPHhwys/NkpIPZdwnnnjC25R/YjIs5TnuDqB8RvmL5ebqWZYnPNudkg3L+tvf/tbbsVzXTLiRCyix895ctUz5jb6h3EdfUpYzS7Yj5X32C0px9BOvZznYJpROKbNRKuaqXsql4bnflLYpw8bOr2CYgCGNbGF7xBJDxcIplA4pR4YrhylnUk5mP4gle2E5+DmTrNBfHDOxXRPLli3z9quvvpooKyVP9g/Wj3MLd5Lk0i9myTAfd8ow4dWIESO8fe+993qbUjFzyjNUaZYcG0xMxv7JtuMY41ikX1luStM9evTwNvs5+/a4ceO8He4MYAiIEjZDBpxv2Q9zGc7h/MvnMTzM3R88k4J9mCGDcL5l2JohT55Pw/meu0IY7uF8xLHOsBPbhmOVY4l9gGFes2TIgHMkk4oxTEDox6oihUAIIYQQeiEQQgghRBohA8q7zDvPFY5MesLVmJQXKdVyFb9ZUoai1MXENpSLKOtQeuVqTsptlGko+VM254peSkthyIDJKigLcfUuJaglS5Z4O9xdkS1sX64spfxG2ZiSVkza51kUZslV1vQN67Jw4UJv089sd7YV5VnKaZTNYjns2f7h8ceU75goisTCNgwfZQvbic9j/SgBxxKMsEyhdM5wVUy6ZYiIcjKv57PZV2IJeehThmXY9pRazZJ9hc/jvehL9olc+sUsGWZjiIRSPX3z9NNPe5tzzZNPPuntMAQ6fPhwbzMcQKmf8yrnTIYV6Ce2A/sXxzrnLc6dHEvhuOJ8yPYgLDfDkQwrZAt/TzgfsU4rVqxIWabYvBQmJuJuEIalGHpkEiCG1vg7wL4e21nA0Ov555/vbYaQGFoKd23x94shCo7LWOiPvz9VRQqBEEIIIfRCIIQQQog0QgZcbcyQAeUYJkCh7MjVkbyeR42aJSVJyjFcRRk7SpmyGvOy06bcSrmaqzwZtqBkFSasieUdp+T50ksveZtSEK/PBZSBmTSFsuhll13mbcpeDBkwMUcYIqFExaN52V5nnHGGt+lnyncMV1Bmo/TN/sX7cwU7ZblwxTT7TliPCth32LfDhEzZQGmZ7UGbRxM/88wz3maCFq6C52prs6QkyTFAqZFtS8mZITu2JyVjypmUVFk3nsHAMRyGctjXuOuCZeJYzGWSqBD2Me4OoGzPPs++zSRj/G64M4f/xvalPM95hJIwwygMQ1Ke57HNbDfWgX1twoQJ3mZiHDOz//u///M2xxz9HztfgYndsoX3Zftx/ozNMxwzDLmwvc3MOnbs6G2GctkmDCUw5MYwEm3OJxw/HA88c4UhA85XYRid7cH5kmEChnMZJsgkAZ4UAiGEEELohUAIIYQQaYQMKBdxJShlDMr5lL8oXb/88sveHjp0aOIZXFnNRBth/vYKKI1RwmSIgeWmdETJhRIZwwrcNRHmmOZ3KAWVlJR4u0+fPt6mhBtKWNnClaX0AcM2lAQpO5eVlXmbkllYX0pZlKXYDpR+Y+cGUB7jal/K2pTi6L/YTge2uVlydTtXWYerwCugtB3K3NnA5zGsQf8z3BM7E4M7JcLEREy2Rb/Sl88//7y36aO//OUv3r7wwgu9zTBG7LhqJn6h/E9/hTsDYglzKM3zc67AD6XUbGFCIa4opyTPfss5hTI15xHOF2bJ0AKTxHA+47zABE0M/3AXFNuEfZs+4P0pj3OnQ3hUM3ftUP5mYhyWj2GCXB7nzmN9uZuAZYrtzOA4Oeecc7wdSudsN4YZ+PvD3zjuiOG4ZF/lMzhm2OYMD9Ff/DxMMsTrCEMiDFWxP2YScpNCIIQQQgi9EAghhBAijZABJU/KGFyty1WvXAlKiYarzLmq3SwpQ1EWogzOBByUZClP0mYSGN6H3+U1/C4lpJAZM2Z4e+XKld7mamKGTWhT1skFLCdleEpGXCHOUA1zgZMwyU1paam3KTXzc8q6lFWZJ53XMKxAaZLfpczMduPn4a4NStCU4Sm9MsTEPpzLo1xZXvZnlp39javJY0d+M0RnlpSi2fdiR/Qy4dTMmTNTloMhKPatv/71r97m6nPu2OFOCcqaYdkpx7OdYmdM5HL3h1lS1mVf4Mp2tglX/XPXDH0ZHrPLOZNzzOmnn+5thijZ1rT5PPbtxx9/3Nuc2xhGog+4cp6SuFkyHMB2Z5+inM0wXWwnTyYsWrTI22x/PoP2n/70J28zdMExHSZh4vzCUAT7N+vK3yX2e96HoUb2FfqFidtYh1iyKbPkbyTnZPpv4MCBKZ9d2e9XDCkEQgghhNALgRBCCCHSCBlQ7qNUQglr6dKl3j7rrLO8vXz5cm8zv3coz1JWpaTIzykdxlbXE0qvlGQpDc6ePdvbsfzP4VGSDIkw+dHUqVO9TcmQUhBDK7mAsmMs+RLDPJT8GcKhXEtJ1SxZf65qjeX2pgxMSYwSPiVWJt+Jyejz5s1LeX2YZIVhidgOBybFYt+mL7OF50pw9TrHTCz0EctVzt0YZsmzPWLnA7CvU2amxMokWgzfcPzE5gBKrSTcqUJ5lmOXdeL45vfDemcL2yomqzMZDvPQc+U4JfWwjAxFnHfeed6mnxkO4HzB+3KejCW44nfZd7iLgf0o7OccQwwfcMyw3rEj5rOFz6PsHzvPgW15wQUXeJs7a7jLzSzp11ibc8xwjuNOEs5fDEvwDA5K+7FdNjzKOAwJ0i+cd+kj9jv6m2O6qkghEEIIIYReCIQQQgiRRsiAyVQoR1KeolRCKKdQKuSKeLOkXEi5lfIKJSXaDBnE8vPzaFNKMUzewSQRlMmnTZuWKCsla0rzGzdu9DZX4FO+iR3JmymU4SkLcrUxia3ip5/CpDIMkdAfDLEwLEE/U/aPrcrmNbwPZWZKfUw+RPnMLBmSoRzMHOPsq+zb3DGSLZQLY6vkKSszSRRDNmyD0C/cTcCV35Q/GRbieRDstwwNsD2ZpIj9ZsGCBd5mezM8SF+bJccow4CUfel7Xs85JxdwtTj7IaViwmOO2edph6u6uYOHcw/Ditw1xX5ImZqhHY5vJtWJ7Whh/2I7h0mUWA7OYZMnT/Y2+x5DHblM5kX5m+Ebwv7JxESU27mTI6wrxyJDbgwfMFET24ZhrNhx4BxXDKOzrExkxL7BsWqW9CvDAZzzmRiP18R+jytDCoEQQggh9EIghBBCiAxDBpRmePQppTfKZ5RCKQOFOwMojfIZlD8ph1GW5udcLU8Jivdksgkma6EcTiksTL4xd+5cb/ft29fbDHVw9TUl8XD1dbawjtxlwCM2zz777JRlieWUpzwcfoeyLlcYM4RDmY3lYx+JhXwotfNZ9DGlOIYzzJLyHWXSDRs2eJvyJ1fv5jIxEevN+zJJFducYQK2Ta9evbxNiTN8BiVP7mpgUiq2B6VKytvsE+zPrAPHDGVKtnE4ZuhjyrYMBcV2GsVyumcK+w/PyOA8x7Ag5znK8JxrOE+ZJX3FcRLbPUHfMCTGHQ70QUweZn3Yj9jPeWaAWbLvMdQTS8rD0ErsrJlMYL0ZruJ4Zd+hbM++wzM/wh1T7G+xY7h5DeV9Xs/QBW32Id6HY5114G4KhgLMkmEGzsGXXHJJymcwtJXJGRNSCIQQQgihFwIhhBBCpBEyiB13GTsKlKslKbFRDg5XkfJelLpiubVjEiTLwfuEMngFlGwoCXEFd7hKnOWgZEPZL7bzIcy9ny1MssK24i4HSpv0JaU1+omriM2SclVMBmNbU76jPxgWiiWbYaiGbRg7yjU8/pgSJp9ByfPVV1/1NuXPWIKrTKBkzjAGQwAx2ZG+YBKZ8OwJyqoME3AXDfsx682+zpXRlEjZV2LHM7MPMDQV7v6InV9AYglXcrmS3SyZ6IZjk7sGKP1y91HsaGKGV8ySCZ44/jg22PfoM86N7LdsQ+7S4rPpD/YjzlnsK2bJsctyM8kXn8ExFp4VkA0cf/QFw1s85ptjqVOnTt7mOAnP1OD358yZ422GXTgGOF+zf/I+HOv072WXXeZttiv7P+fvMOzEEDC/w7HIeseOJa8qUgiEEEIIoRcCIYQQQqQRMqDUG5OPKX1QquIqZ67k5PXhfSmdxI5HpWwZk6tjq4BpMwRC+YvfDVdMsz2YN5tHC1NypOTF7+YCypaUiXjkKuV27gCg/7gzJNwJQR/wOq5cpqxLm7tBuAKaEiT9QYmcMiplPMqolHPNkqukuRKb7U65lf0oPBY2G9gGlPUoTVKOZPkoY/PzMNkPobxPOZPJgq6++mpvcyyyD3E3DpPUUMJlOegLhqzY/82SY4vzQywcQFmaz8gFDBPGEuCwjLGzDzjXhOM6tpuH45JjgPI8v8uwHneS8Khg+p4y89e+9jVvc2cFd7qE3+eYYb3ZL5i0LZfhHM4DnDc4TxGeU8B+HgsPhnBOYaiFO0yeffbZlOXgbw59xHbifMc5lddzPg7PXSD0K8fS9OnTvc35n0c4VxUpBEIIIYTQC4EQQggh9EIghBBCCEtjDQHjIsz8xG0zjG8xrvvyyy97m3HL66+/PvEMHvrDQ4n4bG5L4fYfxvJihyExDs4YTnhgTAWM7zEGbJaMczO2w+yECxcu9DZj07Htj5nCeChjcHw+10kwbhbLLsj4qVmyfRk/jG3NZCyMsVXGG3lPtiGfzfaMxWuZRc4sGX9nHJIxWtaBsepMsnvF4NYgxntZXsb8YjF2HtTCDIFmyTbnd3j4ENcBMDbKw3HOPPNMb3MLIscGY99cT8Byc+x17tw5UVaWg2OAWzI51jm+cz1mWC/OW/QHs+Zxnjv33HO9zbU5rLtZcq7ivbimirF8+pLbtrnmhGOgR48e3mZb8xp+l32Q8XKz5Dhjv+W45JY7XsM1B9nCeZbrALhmhbF4Hr7EdV4DBgzwNtdvhdexfpwLuQZn9uzZ3uZaG/bJ2KF9vCd9xPUcnK84N5sl12t95zvf8TbXrfHwJvqIB5lVFSkEQgghhNALgRBCCCHSCBnwfGhuNaOsw60rvIbyLqXaMFMdt/9Q0uPWLMr+scONKJtTAuT1lAm5XYWyKMvKLYhmSSmIW3Mon8UOZaIsmgvYVpQpY9uBKG1SimM9GBIxMzv55JO9zTalPEYpPLblkvA+LCtle4aRuN2LfSo8h559j+VgO7EvUAYMpdRs4PPYf9ifKREyjBXLthjK0rEwGPsB+xvbiofvUP6MhYGeeuopb/NAKYbWGBoL/cKysp3pI/qF38/1tkNuH2OohTbnPIZqOEdw7ujZs2fiGQylsPyce9gv2L/5OecUhi4437KsDI2tXbvW2/Rl6BuGbWJb/2jHMpxmC8c1swiyv8S2yHbr1s3bHHuce83iWXBj27Ep6fPzK6+80tsMh/Xp08fbDG8w+yvLxPHNspnFQ54M2TDcx5BBJhkkpRAIIYQQQi8EQgghhEgjZECZi7IG5Y7YIQ2UlLjaNlydSimVUgmfF1utTzmMciklIa4upURNqYhSHVeFhge18HAQrlSNhToohVHyygWUsSjlse5czczycgU7d4+EvmHGQIYZKPdS0qLPKXNy9W4s615stwJXZ8+aNcvbYUiCbc3QB9uG9aZvY+GNTGC9KZdTLmQohvIixxVDMeHKfbbzypUrvc1QBFchMwzGfk8Jklnypk2b5m3Ks2wz3ocydhgSjIVjOFfQd+zXlOlzAX3A8divXz9v/+Uvf/H2ihUrvM3QJtt/7ty5iWewXTgvsC/wGs6x7DuE2ecYWmNIg+OHfYLSNyVus6TfYuHNMGxaQSyLYCZQbucumJhsz9X6ZWVl3mb9wrrGDuTj/DdhwgRvMxzDOf3nP/+5tynPM/TD3T7cecffNI7JEM4J3DXGUBV3ZvB3LdaHKkMKgRBCCCH0QiCEEEKINEIGlOEpj1CGp0RNSYOSIOWecMU0pWxK0ZRUKPvGknEQylxM4MOV1Fwpz9W2lPnCQ28omVKmoexEuY1yaS6T35glpXdKf5SMeMgGk8pQUmcylHBVN6Ur1peSHesVe3bswBrWgX2NoRmuimfSmnCVcyykFesLlFhjSaqyhVI4y8dwAMNkMYmc48osuaOC/Y1jiTJzbDU6xyIl1fPPP9/b7AOx0ACvYbuG/08fx0JQ7E+VyaqZwJ0RXP3NuYrzHJM1/eQnP/H2+PHjvc0wlJnZKaec4m2eUx877IvtznJs3brV2wyhMazH3TiUkNmelKxD33A8se/EEmcxtDJv3jzLFZxXFy9e7G36i9fwcx7ktGnTJm+H8wPnEYawOZex/ekXPpt9gr9rDL9xHMfmPoagOAebJfvHOeec4+3YjiSO9ccee8zSRQqBEEIIIfRCIIQQQog0QgaUOLgylhIhV2xSCqU8SAnr9ttvTzzjtttu83bsXHpKMJSAKXkRSqGUwhhi4MpRlo+5oLni1SwpLXMFLFcKU3biM8J7ZQvbNyZ/UiLkynaWZebMmd4OpXOGPHgvrmCnhMbrGaJgCIAr+inh0wd8FsMxtCmfmSX7DmVVStOUuVmO8F7Z8NWvftXblLy56pnjitewDpQjw5AB/cSdIKwfzwXh7gO2OUMALB/lT4aXKKPyucyXz/z4ZskxSumV/Zf1qa4zJsyS0jvb+tFHH/V2LLHXoEGDvM15jlK0WVL+PfHEE73NVeixBD/0Df3POY9hT4Z/WCb2eYYqOMbCctAHDAlzrqdveE22sFwcG9zBxr4wZMgQb3MVPkMBPPPBzOy1117zdiwpHedFhvsYomAoh+E6lo/+4vhm+IXzTzhm2A8YFuJ9+Z2+fftaNkghEEIIIYReCIQQQgiRYWIiyhWUpWlTHqT0RmmL8raZ2RNPPOFtrlJn4hBKfZQaecwnZWlKpJSBKEdRNuIqTYYbwoQ1TN4SS4TEHQuU63KZLz+E8hbDIpTOKTUylEGZjavXzZLSFUMvbBe244YNG7zNNmEf4eeUSxmGYDiGK4cpuYU7TPgdypwxyZoSXy7zsr/66qveZl8gDInQF5TqKefSv2Zm8+fPT2mzDTl2KWtTTqZMzPH64osvepthCMrsTHr1wgsveJvjwiy5Yj12rgH7FsdYrP0yhX2EkjfnNoZaKPOzjFy5Hybzip0zwXtxhTnbnZI8607/cxcD+21s5wL7RxgyiB0tHts1wvBRLhMTUYbneQvsb2wPnq/Bo735OxEeKbxkyRJvc4cZ+xvntfB8gQoYtuTvBucmfpfjgc9i+cIwFRO58d9iydQeeeQRb3OurSpSCIQQQgihFwIhhBBCmNVysYw+QgghhPjCIIVACCGEEHohEEIIIYReCIQQQghheiEQQgghhOmFQAghhBCmFwIhhBBCmF4IhBBCCGF6IRBCCCGE6YVACCGEEGb2/wBevTi0AxJCWAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1001 [D loss: 0.43198224902153015 | D accuracy: 79.6875] [G loss: 1.183971643447876]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1002 [D loss: 0.4431234896183014 | D accuracy: 78.125] [G loss: 1.0920939445495605]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1003 [D loss: 0.4091625511646271 | D accuracy: 78.125] [G loss: 1.2056851387023926]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1004 [D loss: 0.5044400840997696 | D accuracy: 81.25] [G loss: 1.1389164924621582]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1005 [D loss: 0.4098550081253052 | D accuracy: 87.5] [G loss: 1.0883309841156006]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1006 [D loss: 0.5655824095010757 | D accuracy: 73.4375] [G loss: 1.1765029430389404]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1007 [D loss: 0.5137266516685486 | D accuracy: 75.0] [G loss: 1.202211618423462]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1008 [D loss: 0.5086343288421631 | D accuracy: 79.6875] [G loss: 1.1450315713882446]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1009 [D loss: 0.4451344460248947 | D accuracy: 82.8125] [G loss: 1.1816234588623047]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1010 [D loss: 0.36547981202602386 | D accuracy: 87.5] [G loss: 1.0022794008255005]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1011 [D loss: 0.5239258408546448 | D accuracy: 75.0] [G loss: 1.0235975980758667]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1012 [D loss: 0.5868210941553116 | D accuracy: 70.3125] [G loss: 1.059220790863037]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1013 [D loss: 0.3079652786254883 | D accuracy: 92.1875] [G loss: 1.330564022064209]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1014 [D loss: 0.4815644472837448 | D accuracy: 75.0] [G loss: 1.154038906097412]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1015 [D loss: 0.5299922525882721 | D accuracy: 78.125] [G loss: 1.0405232906341553]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1016 [D loss: 0.505542665719986 | D accuracy: 75.0] [G loss: 1.0401194095611572]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1017 [D loss: 0.4660753756761551 | D accuracy: 73.4375] [G loss: 1.0532984733581543]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1018 [D loss: 0.4270448386669159 | D accuracy: 78.125] [G loss: 1.171343445777893]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1019 [D loss: 0.4691743552684784 | D accuracy: 78.125] [G loss: 1.1754956245422363]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1020 [D loss: 0.522955447435379 | D accuracy: 73.4375] [G loss: 1.0403494834899902]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1021 [D loss: 0.42852501571178436 | D accuracy: 82.8125] [G loss: 1.1129505634307861]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1022 [D loss: 0.5340111553668976 | D accuracy: 76.5625] [G loss: 1.179100513458252]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1023 [D loss: 0.4813311696052551 | D accuracy: 79.6875] [G loss: 1.1487295627593994]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1024 [D loss: 0.4477275311946869 | D accuracy: 79.6875] [G loss: 1.115746021270752]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1025 [D loss: 0.3588877469301224 | D accuracy: 87.5] [G loss: 1.0808768272399902]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1026 [D loss: 0.5638361275196075 | D accuracy: 68.75] [G loss: 1.166707158088684]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1027 [D loss: 0.3704409599304199 | D accuracy: 82.8125] [G loss: 1.290341854095459]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1028 [D loss: 0.5143039226531982 | D accuracy: 76.5625] [G loss: 1.304592251777649]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1029 [D loss: 0.5169627517461777 | D accuracy: 76.5625] [G loss: 1.2766367197036743]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1030 [D loss: 0.37247422337532043 | D accuracy: 85.9375] [G loss: 1.1658576726913452]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1031 [D loss: 0.4546141177415848 | D accuracy: 78.125] [G loss: 1.1428354978561401]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1032 [D loss: 0.5623998492956161 | D accuracy: 73.4375] [G loss: 1.1046291589736938]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1033 [D loss: 0.44927069544792175 | D accuracy: 79.6875] [G loss: 1.0613031387329102]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1034 [D loss: 0.4828875809907913 | D accuracy: 76.5625] [G loss: 1.1297550201416016]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1035 [D loss: 0.38121555745601654 | D accuracy: 89.0625] [G loss: 1.236989974975586]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1036 [D loss: 0.5740668177604675 | D accuracy: 67.1875] [G loss: 1.0986839532852173]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1037 [D loss: 0.32624028623104095 | D accuracy: 89.0625] [G loss: 1.1998584270477295]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1038 [D loss: 0.46105457842350006 | D accuracy: 78.125] [G loss: 1.052152156829834]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1039 [D loss: 0.4583761692047119 | D accuracy: 79.6875] [G loss: 1.0924160480499268]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1040 [D loss: 0.4666118174791336 | D accuracy: 79.6875] [G loss: 1.2565548419952393]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1041 [D loss: 0.4510264992713928 | D accuracy: 84.375] [G loss: 1.2674105167388916]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1042 [D loss: 0.44832706451416016 | D accuracy: 79.6875] [G loss: 1.2421822547912598]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1043 [D loss: 0.32948165386915207 | D accuracy: 90.625] [G loss: 1.2731091976165771]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1044 [D loss: 0.42135587334632874 | D accuracy: 84.375] [G loss: 1.250793218612671]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1045 [D loss: 0.4228484034538269 | D accuracy: 82.8125] [G loss: 1.2336257696151733]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1046 [D loss: 0.3880437910556793 | D accuracy: 84.375] [G loss: 1.204027533531189]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1047 [D loss: 0.4783303737640381 | D accuracy: 78.125] [G loss: 1.215646743774414]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1048 [D loss: 0.39717599749565125 | D accuracy: 81.25] [G loss: 1.3060753345489502]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1049 [D loss: 0.48770835995674133 | D accuracy: 71.875] [G loss: 1.339695692062378]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1050 [D loss: 0.578379213809967 | D accuracy: 70.3125] [G loss: 1.223705530166626]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1051 [D loss: 0.5431609451770782 | D accuracy: 65.625] [G loss: 1.1939256191253662]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1052 [D loss: 0.49326449632644653 | D accuracy: 79.6875] [G loss: 1.188597559928894]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1053 [D loss: 0.5008858442306519 | D accuracy: 76.5625] [G loss: 1.194143295288086]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1054 [D loss: 0.4290684759616852 | D accuracy: 78.125] [G loss: 1.109535813331604]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1055 [D loss: 0.5464730262756348 | D accuracy: 73.4375] [G loss: 1.0162055492401123]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1056 [D loss: 0.5250310599803925 | D accuracy: 75.0] [G loss: 1.102159023284912]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1057 [D loss: 0.4297073781490326 | D accuracy: 82.8125] [G loss: 1.0571863651275635]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1058 [D loss: 0.5025950223207474 | D accuracy: 78.125] [G loss: 1.1844053268432617]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1059 [D loss: 0.4719962030649185 | D accuracy: 81.25] [G loss: 1.1850316524505615]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1060 [D loss: 0.5211285501718521 | D accuracy: 75.0] [G loss: 1.176469326019287]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1061 [D loss: 0.42126840353012085 | D accuracy: 84.375] [G loss: 1.183286428451538]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1062 [D loss: 0.453893780708313 | D accuracy: 84.375] [G loss: 1.0380139350891113]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1063 [D loss: 0.5581629276275635 | D accuracy: 70.3125] [G loss: 1.040253758430481]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1064 [D loss: 0.5157755315303802 | D accuracy: 78.125] [G loss: 1.1225630044937134]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1065 [D loss: 0.4965522587299347 | D accuracy: 81.25] [G loss: 1.0500175952911377]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1066 [D loss: 0.5257970988750458 | D accuracy: 81.25] [G loss: 1.0040442943572998]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1067 [D loss: 0.4645339995622635 | D accuracy: 78.125] [G loss: 1.0272958278656006]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1068 [D loss: 0.5915173888206482 | D accuracy: 68.75] [G loss: 1.059462070465088]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1069 [D loss: 0.4835372269153595 | D accuracy: 73.4375] [G loss: 1.0979021787643433]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1070 [D loss: 0.4112226068973541 | D accuracy: 81.25] [G loss: 1.2608695030212402]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1071 [D loss: 0.49514853954315186 | D accuracy: 79.6875] [G loss: 1.1406590938568115]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1072 [D loss: 0.6093558371067047 | D accuracy: 70.3125] [G loss: 0.9764240384101868]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1073 [D loss: 0.4781721234321594 | D accuracy: 79.6875] [G loss: 1.110098123550415]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1074 [D loss: 0.386340394616127 | D accuracy: 85.9375] [G loss: 1.2395572662353516]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1075 [D loss: 0.42381446063518524 | D accuracy: 84.375] [G loss: 1.274442434310913]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1076 [D loss: 0.5600230991840363 | D accuracy: 70.3125] [G loss: 1.2060348987579346]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1077 [D loss: 0.36337070167064667 | D accuracy: 85.9375] [G loss: 1.2182635068893433]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1078 [D loss: 0.420976847410202 | D accuracy: 78.125] [G loss: 1.2315337657928467]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1079 [D loss: 0.4970592260360718 | D accuracy: 82.8125] [G loss: 1.0479907989501953]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1080 [D loss: 0.5262279510498047 | D accuracy: 73.4375] [G loss: 1.0763330459594727]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1081 [D loss: 0.41884103417396545 | D accuracy: 82.8125] [G loss: 1.318796157836914]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1082 [D loss: 0.39669162034988403 | D accuracy: 84.375] [G loss: 1.3408770561218262]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1083 [D loss: 0.4311635196208954 | D accuracy: 76.5625] [G loss: 1.288779854774475]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1084 [D loss: 0.42131128907203674 | D accuracy: 82.8125] [G loss: 1.1365656852722168]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1085 [D loss: 0.4743667095899582 | D accuracy: 79.6875] [G loss: 1.243351936340332]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1086 [D loss: 0.3699541240930557 | D accuracy: 84.375] [G loss: 1.1601377725601196]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1087 [D loss: 0.4818129241466522 | D accuracy: 73.4375] [G loss: 1.2610464096069336]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1088 [D loss: 0.4288516044616699 | D accuracy: 85.9375] [G loss: 1.2862868309020996]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1089 [D loss: 0.45255404710769653 | D accuracy: 78.125] [G loss: 1.3448753356933594]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1090 [D loss: 0.4368310123682022 | D accuracy: 82.8125] [G loss: 1.2591410875320435]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1091 [D loss: 0.41699986159801483 | D accuracy: 79.6875] [G loss: 1.1604111194610596]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1092 [D loss: 0.5104874819517136 | D accuracy: 79.6875] [G loss: 1.2807598114013672]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1093 [D loss: 0.513308197259903 | D accuracy: 76.5625] [G loss: 1.4111108779907227]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1094 [D loss: 0.5018099546432495 | D accuracy: 76.5625] [G loss: 1.3578852415084839]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1095 [D loss: 0.5034855604171753 | D accuracy: 73.4375] [G loss: 1.2371199131011963]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1096 [D loss: 0.44139575958251953 | D accuracy: 84.375] [G loss: 1.120693325996399]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1097 [D loss: 0.4452063739299774 | D accuracy: 78.125] [G loss: 1.2191698551177979]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1098 [D loss: 0.39048637449741364 | D accuracy: 89.0625] [G loss: 1.1743887662887573]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1099 [D loss: 0.4880550801753998 | D accuracy: 81.25] [G loss: 1.2257792949676514]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1100 [D loss: 0.34498150646686554 | D accuracy: 90.625] [G loss: 1.275496006011963]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1101 [D loss: 0.49408653378486633 | D accuracy: 78.125] [G loss: 1.1752452850341797]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1102 [D loss: 0.4897511899471283 | D accuracy: 76.5625] [G loss: 1.0659117698669434]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1103 [D loss: 0.43457046151161194 | D accuracy: 79.6875] [G loss: 1.2723331451416016]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1104 [D loss: 0.6100042760372162 | D accuracy: 71.875] [G loss: 1.1088387966156006]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1105 [D loss: 0.44971849024295807 | D accuracy: 81.25] [G loss: 1.1945253610610962]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1106 [D loss: 0.4469141364097595 | D accuracy: 82.8125] [G loss: 1.1783206462860107]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1107 [D loss: 0.44288893043994904 | D accuracy: 79.6875] [G loss: 1.1466197967529297]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1108 [D loss: 0.5961458384990692 | D accuracy: 65.625] [G loss: 1.2510547637939453]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1109 [D loss: 0.5146227478981018 | D accuracy: 70.3125] [G loss: 1.2523573637008667]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1110 [D loss: 0.44449134171009064 | D accuracy: 81.25] [G loss: 1.137895107269287]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1111 [D loss: 0.5051736831665039 | D accuracy: 75.0] [G loss: 1.2429571151733398]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1112 [D loss: 0.4419652968645096 | D accuracy: 87.5] [G loss: 1.2032742500305176]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1113 [D loss: 0.39334826171398163 | D accuracy: 82.8125] [G loss: 1.1161160469055176]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1114 [D loss: 0.393669068813324 | D accuracy: 85.9375] [G loss: 1.1710946559906006]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1115 [D loss: 0.3269239068031311 | D accuracy: 89.0625] [G loss: 1.2762675285339355]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1116 [D loss: 0.44025246798992157 | D accuracy: 87.5] [G loss: 1.140604019165039]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1117 [D loss: 0.43553777039051056 | D accuracy: 81.25] [G loss: 1.1381794214248657]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1118 [D loss: 0.4239994287490845 | D accuracy: 82.8125] [G loss: 1.147632360458374]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1119 [D loss: 0.4681406021118164 | D accuracy: 84.375] [G loss: 1.2394158840179443]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1120 [D loss: 0.5172934532165527 | D accuracy: 78.125] [G loss: 1.2362923622131348]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1121 [D loss: 0.4916083812713623 | D accuracy: 68.75] [G loss: 0.9483367204666138]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1122 [D loss: 0.390888050198555 | D accuracy: 85.9375] [G loss: 1.342585802078247]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1123 [D loss: 0.4010844826698303 | D accuracy: 87.5] [G loss: 1.3625293970108032]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1124 [D loss: 0.4749792069196701 | D accuracy: 79.6875] [G loss: 1.3955262899398804]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1125 [D loss: 0.45103001594543457 | D accuracy: 81.25] [G loss: 1.1455533504486084]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1126 [D loss: 0.5199469923973083 | D accuracy: 67.1875] [G loss: 1.2186309099197388]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1127 [D loss: 0.5037520229816437 | D accuracy: 75.0] [G loss: 1.3014891147613525]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1128 [D loss: 0.4019268751144409 | D accuracy: 87.5] [G loss: 1.2559707164764404]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1129 [D loss: 0.5023512691259384 | D accuracy: 79.6875] [G loss: 1.2742085456848145]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1130 [D loss: 0.5382542312145233 | D accuracy: 71.875] [G loss: 1.1090110540390015]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1131 [D loss: 0.510633796453476 | D accuracy: 76.5625] [G loss: 1.2266364097595215]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1132 [D loss: 0.5151877105236053 | D accuracy: 78.125] [G loss: 1.1673450469970703]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1133 [D loss: 0.36868607997894287 | D accuracy: 87.5] [G loss: 1.3462144136428833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1134 [D loss: 0.48095718026161194 | D accuracy: 81.25] [G loss: 1.194413423538208]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1135 [D loss: 0.4660555571317673 | D accuracy: 75.0] [G loss: 1.3298839330673218]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1136 [D loss: 0.4400918334722519 | D accuracy: 76.5625] [G loss: 1.2900595664978027]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1137 [D loss: 0.5141939371824265 | D accuracy: 71.875] [G loss: 1.1854749917984009]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1138 [D loss: 0.3920368105173111 | D accuracy: 82.8125] [G loss: 1.2061066627502441]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1139 [D loss: 0.3763120397925377 | D accuracy: 87.5] [G loss: 1.270099401473999]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1140 [D loss: 0.44948025047779083 | D accuracy: 79.6875] [G loss: 1.3139967918395996]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1141 [D loss: 0.45493701100349426 | D accuracy: 82.8125] [G loss: 1.2780961990356445]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1142 [D loss: 0.4554500877857208 | D accuracy: 78.125] [G loss: 1.3095557689666748]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1143 [D loss: 0.46636398136615753 | D accuracy: 78.125] [G loss: 1.2417244911193848]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1144 [D loss: 0.47526173293590546 | D accuracy: 73.4375] [G loss: 1.13334059715271]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1145 [D loss: 0.569044291973114 | D accuracy: 73.4375] [G loss: 1.1901432275772095]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1146 [D loss: 0.3660368174314499 | D accuracy: 85.9375] [G loss: 1.1615190505981445]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1147 [D loss: 0.4001535624265671 | D accuracy: 84.375] [G loss: 1.119221568107605]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1148 [D loss: 0.5669989883899689 | D accuracy: 70.3125] [G loss: 1.3103926181793213]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1149 [D loss: 0.4409720152616501 | D accuracy: 85.9375] [G loss: 1.239054560661316]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1150 [D loss: 0.39655887335538864 | D accuracy: 81.25] [G loss: 1.3076601028442383]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1151 [D loss: 0.5110179036855698 | D accuracy: 76.5625] [G loss: 1.1937212944030762]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1152 [D loss: 0.4353698641061783 | D accuracy: 78.125] [G loss: 1.1192668676376343]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1153 [D loss: 0.5406045168638229 | D accuracy: 71.875] [G loss: 1.1891413927078247]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1154 [D loss: 0.6397739946842194 | D accuracy: 65.625] [G loss: 1.2778762578964233]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1155 [D loss: 0.48657262325286865 | D accuracy: 76.5625] [G loss: 1.221961498260498]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1156 [D loss: 0.5462123155593872 | D accuracy: 76.5625] [G loss: 1.0656065940856934]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1157 [D loss: 0.5270707756280899 | D accuracy: 73.4375] [G loss: 1.1150414943695068]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1158 [D loss: 0.5701265633106232 | D accuracy: 70.3125] [G loss: 1.0670950412750244]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1159 [D loss: 0.4887400269508362 | D accuracy: 75.0] [G loss: 1.1188685894012451]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1160 [D loss: 0.4967763125896454 | D accuracy: 78.125] [G loss: 1.1332687139511108]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1161 [D loss: 0.5109104812145233 | D accuracy: 78.125] [G loss: 1.2540690898895264]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1162 [D loss: 0.45949050784111023 | D accuracy: 78.125] [G loss: 1.1794204711914062]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1163 [D loss: 0.5042153000831604 | D accuracy: 73.4375] [G loss: 1.038973093032837]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1164 [D loss: 0.47792017459869385 | D accuracy: 81.25] [G loss: 1.17865788936615]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1165 [D loss: 0.5692048370838165 | D accuracy: 76.5625] [G loss: 1.1059819459915161]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1166 [D loss: 0.4866514056921005 | D accuracy: 76.5625] [G loss: 1.117255449295044]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1167 [D loss: 0.5343768000602722 | D accuracy: 75.0] [G loss: 1.2936348915100098]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1168 [D loss: 0.5505865812301636 | D accuracy: 71.875] [G loss: 1.1686928272247314]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1169 [D loss: 0.5053383409976959 | D accuracy: 73.4375] [G loss: 1.1381099224090576]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1170 [D loss: 0.6001226603984833 | D accuracy: 70.3125] [G loss: 1.1072688102722168]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1171 [D loss: 0.4576370120048523 | D accuracy: 79.6875] [G loss: 1.1461472511291504]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1172 [D loss: 0.42529192566871643 | D accuracy: 85.9375] [G loss: 1.2229716777801514]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1173 [D loss: 0.503487840294838 | D accuracy: 81.25] [G loss: 1.2636809349060059]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1174 [D loss: 0.43194377422332764 | D accuracy: 89.0625] [G loss: 1.127087116241455]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1175 [D loss: 0.3909946233034134 | D accuracy: 87.5] [G loss: 1.1537022590637207]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1176 [D loss: 0.5041617900133133 | D accuracy: 73.4375] [G loss: 1.2112106084823608]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1177 [D loss: 0.5154707133769989 | D accuracy: 76.5625] [G loss: 1.1276029348373413]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1178 [D loss: 0.4602877348661423 | D accuracy: 81.25] [G loss: 1.1809589862823486]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1179 [D loss: 0.4536140561103821 | D accuracy: 85.9375] [G loss: 1.2533559799194336]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1180 [D loss: 0.5006688237190247 | D accuracy: 79.6875] [G loss: 1.1690245866775513]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1181 [D loss: 0.46526288986206055 | D accuracy: 76.5625] [G loss: 1.2057673931121826]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1182 [D loss: 0.5468180477619171 | D accuracy: 71.875] [G loss: 1.1395325660705566]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1183 [D loss: 0.4455636441707611 | D accuracy: 81.25] [G loss: 1.279050588607788]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1184 [D loss: 0.4224156588315964 | D accuracy: 82.8125] [G loss: 1.186029076576233]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1185 [D loss: 0.4653179794549942 | D accuracy: 84.375] [G loss: 1.1935477256774902]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1186 [D loss: 0.45333465933799744 | D accuracy: 75.0] [G loss: 1.330609917640686]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1187 [D loss: 0.35846683382987976 | D accuracy: 89.0625] [G loss: 1.2352800369262695]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1188 [D loss: 0.36685942113399506 | D accuracy: 85.9375] [G loss: 1.1955496072769165]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1189 [D loss: 0.485043540596962 | D accuracy: 81.25] [G loss: 1.2260222434997559]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1190 [D loss: 0.38071444630622864 | D accuracy: 76.5625] [G loss: 1.3632657527923584]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1191 [D loss: 0.4773920029401779 | D accuracy: 81.25] [G loss: 1.197251796722412]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1192 [D loss: 0.44068966805934906 | D accuracy: 82.8125] [G loss: 1.1361017227172852]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1193 [D loss: 0.4629105031490326 | D accuracy: 75.0] [G loss: 1.296994686126709]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1194 [D loss: 0.47802142798900604 | D accuracy: 81.25] [G loss: 1.2349016666412354]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1195 [D loss: 0.45776069164276123 | D accuracy: 79.6875] [G loss: 1.366016149520874]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1196 [D loss: 0.39173051714897156 | D accuracy: 79.6875] [G loss: 1.3129910230636597]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1197 [D loss: 0.4891856759786606 | D accuracy: 81.25] [G loss: 1.3669193983078003]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1198 [D loss: 0.4887560158967972 | D accuracy: 75.0] [G loss: 1.1917197704315186]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1199 [D loss: 0.48355570435523987 | D accuracy: 85.9375] [G loss: 1.1788101196289062]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1200 [D loss: 0.4590449333190918 | D accuracy: 79.6875] [G loss: 1.1459100246429443]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1201 [D loss: 0.4561527967453003 | D accuracy: 76.5625] [G loss: 1.207533359527588]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1202 [D loss: 0.5707980394363403 | D accuracy: 76.5625] [G loss: 1.165950059890747]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1203 [D loss: 0.5450212061405182 | D accuracy: 70.3125] [G loss: 1.1317081451416016]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1204 [D loss: 0.5390570759773254 | D accuracy: 76.5625] [G loss: 1.2147871255874634]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1205 [D loss: 0.5774565637111664 | D accuracy: 71.875] [G loss: 1.0547051429748535]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1206 [D loss: 0.540641114115715 | D accuracy: 71.875] [G loss: 1.0520195960998535]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1207 [D loss: 0.3902111202478409 | D accuracy: 90.625] [G loss: 1.0518444776535034]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1208 [D loss: 0.47495993971824646 | D accuracy: 79.6875] [G loss: 1.249030590057373]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1209 [D loss: 0.5118727385997772 | D accuracy: 79.6875] [G loss: 1.2384452819824219]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1210 [D loss: 0.3913504630327225 | D accuracy: 82.8125] [G loss: 1.2923109531402588]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1211 [D loss: 0.4681680351495743 | D accuracy: 79.6875] [G loss: 1.0916731357574463]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1212 [D loss: 0.4279756397008896 | D accuracy: 87.5] [G loss: 1.0097942352294922]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1213 [D loss: 0.5317911207675934 | D accuracy: 71.875] [G loss: 1.1655514240264893]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1214 [D loss: 0.48578009009361267 | D accuracy: 76.5625] [G loss: 1.2131296396255493]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1215 [D loss: 0.440715491771698 | D accuracy: 81.25] [G loss: 1.3147830963134766]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1216 [D loss: 0.5984929203987122 | D accuracy: 75.0] [G loss: 1.1256988048553467]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1217 [D loss: 0.4967288374900818 | D accuracy: 79.6875] [G loss: 1.1867361068725586]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1218 [D loss: 0.4599762558937073 | D accuracy: 82.8125] [G loss: 1.2512338161468506]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1219 [D loss: 0.5576340109109879 | D accuracy: 71.875] [G loss: 1.0857455730438232]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1220 [D loss: 0.5036090165376663 | D accuracy: 75.0] [G loss: 1.2264070510864258]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1221 [D loss: 0.4636368006467819 | D accuracy: 79.6875] [G loss: 1.1370313167572021]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1222 [D loss: 0.45571762323379517 | D accuracy: 76.5625] [G loss: 1.1700633764266968]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1223 [D loss: 0.5413280576467514 | D accuracy: 71.875] [G loss: 1.2344746589660645]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1224 [D loss: 0.5186344534158707 | D accuracy: 75.0] [G loss: 1.2295867204666138]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1225 [D loss: 0.34791185706853867 | D accuracy: 87.5] [G loss: 1.3205848932266235]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1226 [D loss: 0.5713841021060944 | D accuracy: 71.875] [G loss: 1.0427205562591553]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1227 [D loss: 0.5080945193767548 | D accuracy: 75.0] [G loss: 1.1960395574569702]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1228 [D loss: 0.4969980716705322 | D accuracy: 75.0] [G loss: 1.194939374923706]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1229 [D loss: 0.4391496330499649 | D accuracy: 82.8125] [G loss: 1.1929901838302612]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1230 [D loss: 0.4230939894914627 | D accuracy: 85.9375] [G loss: 1.2436983585357666]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1231 [D loss: 0.529308408498764 | D accuracy: 73.4375] [G loss: 1.2175137996673584]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1232 [D loss: 0.5364492386579514 | D accuracy: 71.875] [G loss: 1.09810471534729]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1233 [D loss: 0.5087817162275314 | D accuracy: 75.0] [G loss: 1.3405191898345947]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1234 [D loss: 0.4405253082513809 | D accuracy: 85.9375] [G loss: 1.2380707263946533]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1235 [D loss: 0.40420614182949066 | D accuracy: 82.8125] [G loss: 1.2154642343521118]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1236 [D loss: 0.42149704694747925 | D accuracy: 84.375] [G loss: 1.2470273971557617]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1237 [D loss: 0.3686056435108185 | D accuracy: 89.0625] [G loss: 1.357959270477295]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1238 [D loss: 0.4967552125453949 | D accuracy: 73.4375] [G loss: 1.1587634086608887]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1239 [D loss: 0.4001063406467438 | D accuracy: 84.375] [G loss: 1.1339507102966309]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1240 [D loss: 0.3571788966655731 | D accuracy: 89.0625] [G loss: 1.2779147624969482]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1241 [D loss: 0.38998542726039886 | D accuracy: 81.25] [G loss: 1.327243447303772]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1242 [D loss: 0.4240081459283829 | D accuracy: 81.25] [G loss: 1.2062060832977295]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1243 [D loss: 0.3848641812801361 | D accuracy: 84.375] [G loss: 1.1966049671173096]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1244 [D loss: 0.62337726354599 | D accuracy: 64.0625] [G loss: 1.2494843006134033]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1245 [D loss: 0.4959256649017334 | D accuracy: 79.6875] [G loss: 1.2557495832443237]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1246 [D loss: 0.4144972860813141 | D accuracy: 78.125] [G loss: 1.2517096996307373]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1247 [D loss: 0.48324257135391235 | D accuracy: 71.875] [G loss: 1.3220751285552979]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1248 [D loss: 0.5427455902099609 | D accuracy: 71.875] [G loss: 1.337526798248291]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1249 [D loss: 0.49357667565345764 | D accuracy: 75.0] [G loss: 1.2985725402832031]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1250 [D loss: 0.42016828060150146 | D accuracy: 85.9375] [G loss: 1.222559928894043]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1251 [D loss: 0.4477059990167618 | D accuracy: 81.25] [G loss: 1.252178430557251]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1252 [D loss: 0.43068861961364746 | D accuracy: 82.8125] [G loss: 1.2156739234924316]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1253 [D loss: 0.48898956179618835 | D accuracy: 73.4375] [G loss: 1.1765724420547485]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1254 [D loss: 0.48056381940841675 | D accuracy: 76.5625] [G loss: 1.4944732189178467]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1255 [D loss: 0.39360328018665314 | D accuracy: 82.8125] [G loss: 1.3388562202453613]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1256 [D loss: 0.717494934797287 | D accuracy: 60.9375] [G loss: 1.1461162567138672]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1257 [D loss: 0.6146262288093567 | D accuracy: 62.5] [G loss: 1.116860032081604]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1258 [D loss: 0.3821749687194824 | D accuracy: 81.25] [G loss: 1.1969513893127441]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1259 [D loss: 0.6473565697669983 | D accuracy: 60.9375] [G loss: 1.285287618637085]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1260 [D loss: 0.43215787410736084 | D accuracy: 81.25] [G loss: 1.337245225906372]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1261 [D loss: 0.4691675156354904 | D accuracy: 76.5625] [G loss: 1.1844205856323242]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1262 [D loss: 0.5052278339862823 | D accuracy: 79.6875] [G loss: 1.1653425693511963]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1263 [D loss: 0.5256772637367249 | D accuracy: 73.4375] [G loss: 0.9728142023086548]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1264 [D loss: 0.4935789257287979 | D accuracy: 75.0] [G loss: 1.122057318687439]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1265 [D loss: 0.4103184640407562 | D accuracy: 82.8125] [G loss: 1.2080206871032715]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1266 [D loss: 0.4166584610939026 | D accuracy: 82.8125] [G loss: 1.3645581007003784]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1267 [D loss: 0.42856958508491516 | D accuracy: 82.8125] [G loss: 1.4023864269256592]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1268 [D loss: 0.609068363904953 | D accuracy: 67.1875] [G loss: 1.2569663524627686]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1269 [D loss: 0.5582440793514252 | D accuracy: 79.6875] [G loss: 1.2562487125396729]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1270 [D loss: 0.49779312312602997 | D accuracy: 79.6875] [G loss: 1.1908116340637207]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1271 [D loss: 0.35290367901325226 | D accuracy: 84.375] [G loss: 1.2711198329925537]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1272 [D loss: 0.5721050649881363 | D accuracy: 70.3125] [G loss: 1.3415180444717407]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1273 [D loss: 0.5559816360473633 | D accuracy: 76.5625] [G loss: 1.2732282876968384]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1274 [D loss: 0.3973754495382309 | D accuracy: 82.8125] [G loss: 1.3200281858444214]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1275 [D loss: 0.6310081779956818 | D accuracy: 64.0625] [G loss: 1.2723968029022217]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1276 [D loss: 0.379952609539032 | D accuracy: 82.8125] [G loss: 1.2194072008132935]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1277 [D loss: 0.4316115081310272 | D accuracy: 81.25] [G loss: 1.3341560363769531]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1278 [D loss: 0.40315040946006775 | D accuracy: 84.375] [G loss: 1.299381971359253]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1279 [D loss: 0.5635787844657898 | D accuracy: 71.875] [G loss: 1.3585281372070312]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1280 [D loss: 0.5529261827468872 | D accuracy: 70.3125] [G loss: 1.3015382289886475]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1281 [D loss: 0.4638693630695343 | D accuracy: 81.25] [G loss: 1.2415664196014404]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1282 [D loss: 0.49914994835853577 | D accuracy: 71.875] [G loss: 1.211371898651123]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1283 [D loss: 0.5036908835172653 | D accuracy: 78.125] [G loss: 1.1032850742340088]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1284 [D loss: 0.5918949544429779 | D accuracy: 64.0625] [G loss: 1.2422581911087036]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1285 [D loss: 0.4533328115940094 | D accuracy: 79.6875] [G loss: 1.2213058471679688]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1286 [D loss: 0.4136507362127304 | D accuracy: 82.8125] [G loss: 1.2703150510787964]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1287 [D loss: 0.4206705391407013 | D accuracy: 78.125] [G loss: 1.3865190744400024]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1288 [D loss: 0.49436983466148376 | D accuracy: 78.125] [G loss: 1.3933055400848389]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1289 [D loss: 0.4560135453939438 | D accuracy: 84.375] [G loss: 1.3054537773132324]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1290 [D loss: 0.4269374907016754 | D accuracy: 78.125] [G loss: 1.4624539613723755]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1291 [D loss: 0.45647621154785156 | D accuracy: 79.6875] [G loss: 1.495873212814331]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1292 [D loss: 0.5550322830677032 | D accuracy: 78.125] [G loss: 1.3232389688491821]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1293 [D loss: 0.4305068254470825 | D accuracy: 78.125] [G loss: 1.2213307619094849]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1294 [D loss: 0.5378062278032303 | D accuracy: 78.125] [G loss: 1.1219042539596558]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1295 [D loss: 0.49762360751628876 | D accuracy: 78.125] [G loss: 1.2555359601974487]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1296 [D loss: 0.46898844838142395 | D accuracy: 73.4375] [G loss: 1.3248299360275269]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1297 [D loss: 0.5006862878799438 | D accuracy: 73.4375] [G loss: 1.3753118515014648]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1298 [D loss: 0.38371022045612335 | D accuracy: 84.375] [G loss: 1.2456719875335693]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1299 [D loss: 0.5678691864013672 | D accuracy: 75.0] [G loss: 1.3243165016174316]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1300 [D loss: 0.5811412334442139 | D accuracy: 68.75] [G loss: 1.1871135234832764]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1301 [D loss: 0.46534815430641174 | D accuracy: 78.125] [G loss: 1.250999093055725]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1302 [D loss: 0.47843536734580994 | D accuracy: 76.5625] [G loss: 1.30470609664917]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1303 [D loss: 0.6133380234241486 | D accuracy: 70.3125] [G loss: 1.1167445182800293]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1304 [D loss: 0.46395134925842285 | D accuracy: 82.8125] [G loss: 1.1433260440826416]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1305 [D loss: 0.42566172778606415 | D accuracy: 82.8125] [G loss: 1.2222273349761963]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1306 [D loss: 0.5303884744644165 | D accuracy: 76.5625] [G loss: 1.2616887092590332]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1307 [D loss: 0.43877990543842316 | D accuracy: 84.375] [G loss: 1.2408573627471924]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1308 [D loss: 0.414022833108902 | D accuracy: 79.6875] [G loss: 1.3578687906265259]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1309 [D loss: 0.4994116276502609 | D accuracy: 78.125] [G loss: 1.1167880296707153]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1310 [D loss: 0.38344067335128784 | D accuracy: 85.9375] [G loss: 1.2930495738983154]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1311 [D loss: 0.5084919184446335 | D accuracy: 73.4375] [G loss: 1.256746530532837]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1312 [D loss: 0.46214576065540314 | D accuracy: 78.125] [G loss: 1.225303292274475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1313 [D loss: 0.4923900365829468 | D accuracy: 76.5625] [G loss: 1.196390151977539]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1314 [D loss: 0.4520936459302902 | D accuracy: 76.5625] [G loss: 1.4005157947540283]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1315 [D loss: 0.45492035150527954 | D accuracy: 84.375] [G loss: 1.3023557662963867]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1316 [D loss: 0.6228684782981873 | D accuracy: 67.1875] [G loss: 1.2193467617034912]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1317 [D loss: 0.49505096673965454 | D accuracy: 75.0] [G loss: 1.3544340133666992]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1318 [D loss: 0.4152708351612091 | D accuracy: 85.9375] [G loss: 1.3074665069580078]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1319 [D loss: 0.5144194215536118 | D accuracy: 78.125] [G loss: 1.1835167407989502]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1320 [D loss: 0.46564388275146484 | D accuracy: 78.125] [G loss: 1.2226481437683105]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1321 [D loss: 0.41488422453403473 | D accuracy: 84.375] [G loss: 1.2426719665527344]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1322 [D loss: 0.5711512267589569 | D accuracy: 75.0] [G loss: 1.299544334411621]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1323 [D loss: 0.35725994408130646 | D accuracy: 79.6875] [G loss: 1.4273443222045898]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1324 [D loss: 0.5043209493160248 | D accuracy: 75.0] [G loss: 1.4244966506958008]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1325 [D loss: 0.43192562460899353 | D accuracy: 81.25] [G loss: 1.38710355758667]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1326 [D loss: 0.6010682284832001 | D accuracy: 71.875] [G loss: 1.3511593341827393]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1327 [D loss: 0.5304919928312302 | D accuracy: 68.75] [G loss: 1.3838372230529785]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1328 [D loss: 0.4081738442182541 | D accuracy: 85.9375] [G loss: 1.175941824913025]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1329 [D loss: 0.5770183801651001 | D accuracy: 67.1875] [G loss: 1.3029892444610596]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1330 [D loss: 0.44252316653728485 | D accuracy: 76.5625] [G loss: 1.204017996788025]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1331 [D loss: 0.528573289513588 | D accuracy: 76.5625] [G loss: 1.2746915817260742]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1332 [D loss: 0.4962329864501953 | D accuracy: 71.875] [G loss: 1.3849091529846191]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1333 [D loss: 0.340677946805954 | D accuracy: 92.1875] [G loss: 1.3850970268249512]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1334 [D loss: 0.5008931756019592 | D accuracy: 81.25] [G loss: 1.2482446432113647]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1335 [D loss: 0.5310045629739761 | D accuracy: 78.125] [G loss: 1.244391918182373]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1336 [D loss: 0.4305400997400284 | D accuracy: 85.9375] [G loss: 1.456095814704895]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1337 [D loss: 0.35940463840961456 | D accuracy: 89.0625] [G loss: 1.3690881729125977]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1338 [D loss: 0.4889054000377655 | D accuracy: 73.4375] [G loss: 1.2723342180252075]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1339 [D loss: 0.6053261905908585 | D accuracy: 65.625] [G loss: 1.4678984880447388]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1340 [D loss: 0.4754849076271057 | D accuracy: 78.125] [G loss: 1.3295824527740479]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1341 [D loss: 0.3951635807752609 | D accuracy: 85.9375] [G loss: 1.4084906578063965]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1342 [D loss: 0.4714905917644501 | D accuracy: 78.125] [G loss: 1.4087574481964111]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1343 [D loss: 0.38832953572273254 | D accuracy: 85.9375] [G loss: 1.3287827968597412]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1344 [D loss: 0.4589279890060425 | D accuracy: 79.6875] [G loss: 1.3647831678390503]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1345 [D loss: 0.42155030369758606 | D accuracy: 79.6875] [G loss: 1.0980932712554932]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1346 [D loss: 0.5668173581361771 | D accuracy: 73.4375] [G loss: 1.207521677017212]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1347 [D loss: 0.5337180942296982 | D accuracy: 76.5625] [G loss: 1.3268742561340332]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1348 [D loss: 0.38413912057876587 | D accuracy: 85.9375] [G loss: 1.2382171154022217]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1349 [D loss: 0.43628405034542084 | D accuracy: 82.8125] [G loss: 1.3236958980560303]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1350 [D loss: 0.5459409654140472 | D accuracy: 73.4375] [G loss: 1.1837431192398071]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1351 [D loss: 0.37318530678749084 | D accuracy: 90.625] [G loss: 1.1387059688568115]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1352 [D loss: 0.4338301420211792 | D accuracy: 82.8125] [G loss: 1.1556718349456787]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1353 [D loss: 0.4899964928627014 | D accuracy: 76.5625] [G loss: 1.1885547637939453]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1354 [D loss: 0.43539467453956604 | D accuracy: 82.8125] [G loss: 1.2755736112594604]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1355 [D loss: 0.4720267355442047 | D accuracy: 73.4375] [G loss: 1.280245065689087]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1356 [D loss: 0.3953494429588318 | D accuracy: 81.25] [G loss: 1.4337571859359741]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1357 [D loss: 0.5117785483598709 | D accuracy: 73.4375] [G loss: 1.1678870916366577]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1358 [D loss: 0.46249106526374817 | D accuracy: 81.25] [G loss: 1.328296184539795]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1359 [D loss: 0.4533744603395462 | D accuracy: 79.6875] [G loss: 1.292435646057129]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1360 [D loss: 0.4070034325122833 | D accuracy: 84.375] [G loss: 1.207890510559082]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1361 [D loss: 0.4684959352016449 | D accuracy: 78.125] [G loss: 1.293747901916504]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1362 [D loss: 0.5110034495592117 | D accuracy: 78.125] [G loss: 1.3088109493255615]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1363 [D loss: 0.4684337228536606 | D accuracy: 75.0] [G loss: 1.299070954322815]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1364 [D loss: 0.4252089858055115 | D accuracy: 84.375] [G loss: 1.2352356910705566]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1365 [D loss: 0.4692065119743347 | D accuracy: 79.6875] [G loss: 1.5312507152557373]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1366 [D loss: 0.48998749256134033 | D accuracy: 78.125] [G loss: 1.2425363063812256]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1367 [D loss: 0.43823273479938507 | D accuracy: 82.8125] [G loss: 1.218721866607666]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1368 [D loss: 0.5510219037532806 | D accuracy: 75.0] [G loss: 1.2621777057647705]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1369 [D loss: 0.370862141251564 | D accuracy: 89.0625] [G loss: 1.3687281608581543]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1370 [D loss: 0.43109285831451416 | D accuracy: 84.375] [G loss: 1.4059423208236694]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1371 [D loss: 0.47761666774749756 | D accuracy: 75.0] [G loss: 1.258515477180481]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1372 [D loss: 0.4237695038318634 | D accuracy: 79.6875] [G loss: 1.3833308219909668]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1373 [D loss: 0.33958932757377625 | D accuracy: 87.5] [G loss: 1.4218101501464844]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1374 [D loss: 0.42878712713718414 | D accuracy: 78.125] [G loss: 1.3113212585449219]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1375 [D loss: 0.41866718232631683 | D accuracy: 78.125] [G loss: 1.376439094543457]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1376 [D loss: 0.5131827294826508 | D accuracy: 75.0] [G loss: 1.4104245901107788]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1377 [D loss: 0.4702364653348923 | D accuracy: 76.5625] [G loss: 1.4497085809707642]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1378 [D loss: 0.44406965374946594 | D accuracy: 79.6875] [G loss: 1.5120419263839722]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1379 [D loss: 0.5444511771202087 | D accuracy: 71.875] [G loss: 1.4763680696487427]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1380 [D loss: 0.5458755493164062 | D accuracy: 71.875] [G loss: 1.312694787979126]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1381 [D loss: 0.43884600698947906 | D accuracy: 84.375] [G loss: 1.0675785541534424]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1382 [D loss: 0.5354486852884293 | D accuracy: 67.1875] [G loss: 1.3367714881896973]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1383 [D loss: 0.41318127512931824 | D accuracy: 79.6875] [G loss: 1.12737238407135]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1384 [D loss: 0.61003178358078 | D accuracy: 68.75] [G loss: 1.317840337753296]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1385 [D loss: 0.5602153241634369 | D accuracy: 73.4375] [G loss: 1.2910339832305908]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1386 [D loss: 0.49820244312286377 | D accuracy: 76.5625] [G loss: 1.2619683742523193]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1387 [D loss: 0.45234960317611694 | D accuracy: 78.125] [G loss: 1.2810077667236328]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1388 [D loss: 0.5287181288003922 | D accuracy: 75.0] [G loss: 1.304574728012085]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1389 [D loss: 0.46820996701717377 | D accuracy: 81.25] [G loss: 1.5669198036193848]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1390 [D loss: 0.48649996519088745 | D accuracy: 76.5625] [G loss: 1.4374737739562988]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1391 [D loss: 0.5092899799346924 | D accuracy: 79.6875] [G loss: 1.296598196029663]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1392 [D loss: 0.5222998261451721 | D accuracy: 78.125] [G loss: 1.084644079208374]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1393 [D loss: 0.5460467040538788 | D accuracy: 73.4375] [G loss: 1.157293677330017]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1394 [D loss: 0.3773900419473648 | D accuracy: 89.0625] [G loss: 1.3842774629592896]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1395 [D loss: 0.5545342862606049 | D accuracy: 70.3125] [G loss: 1.2112712860107422]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1396 [D loss: 0.5287909209728241 | D accuracy: 75.0] [G loss: 1.2174423933029175]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1397 [D loss: 0.46536609530448914 | D accuracy: 75.0] [G loss: 1.3529839515686035]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1398 [D loss: 0.40391890704631805 | D accuracy: 84.375] [G loss: 1.3245877027511597]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1399 [D loss: 0.45821046829223633 | D accuracy: 75.0] [G loss: 1.2243231534957886]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1400 [D loss: 0.436217337846756 | D accuracy: 76.5625] [G loss: 1.2121851444244385]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1401 [D loss: 0.5306839048862457 | D accuracy: 78.125] [G loss: 1.2222212553024292]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1402 [D loss: 0.47275128960609436 | D accuracy: 78.125] [G loss: 1.5309654474258423]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1403 [D loss: 0.5482459962368011 | D accuracy: 67.1875] [G loss: 1.4556639194488525]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1404 [D loss: 0.5045848190784454 | D accuracy: 71.875] [G loss: 1.32838773727417]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1405 [D loss: 0.44037704169750214 | D accuracy: 87.5] [G loss: 1.2066047191619873]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1406 [D loss: 0.49813422560691833 | D accuracy: 78.125] [G loss: 1.2605774402618408]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1407 [D loss: 0.47490476071834564 | D accuracy: 75.0] [G loss: 1.351810336112976]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1408 [D loss: 0.5064848065376282 | D accuracy: 73.4375] [G loss: 1.3140802383422852]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1409 [D loss: 0.42807912826538086 | D accuracy: 84.375] [G loss: 1.2471706867218018]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1410 [D loss: 0.4977576732635498 | D accuracy: 71.875] [G loss: 1.3733068704605103]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1411 [D loss: 0.5189809948205948 | D accuracy: 71.875] [G loss: 1.3734118938446045]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1412 [D loss: 0.4257762134075165 | D accuracy: 84.375] [G loss: 1.3319841623306274]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1413 [D loss: 0.43705126643180847 | D accuracy: 78.125] [G loss: 1.3429540395736694]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1414 [D loss: 0.5789578557014465 | D accuracy: 67.1875] [G loss: 1.243605136871338]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1415 [D loss: 0.47402653098106384 | D accuracy: 76.5625] [G loss: 1.2626185417175293]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1416 [D loss: 0.48814907670021057 | D accuracy: 75.0] [G loss: 1.1922399997711182]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1417 [D loss: 0.3455000966787338 | D accuracy: 89.0625] [G loss: 1.332349419593811]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1418 [D loss: 0.44315074384212494 | D accuracy: 81.25] [G loss: 1.368019938468933]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1419 [D loss: 0.3730849325656891 | D accuracy: 84.375] [G loss: 1.3020849227905273]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1420 [D loss: 0.47115257382392883 | D accuracy: 79.6875] [G loss: 1.35383939743042]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1421 [D loss: 0.4248536080121994 | D accuracy: 78.125] [G loss: 1.4259607791900635]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1422 [D loss: 0.5198440253734589 | D accuracy: 75.0] [G loss: 1.4152594804763794]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1423 [D loss: 0.4474566578865051 | D accuracy: 87.5] [G loss: 1.3498270511627197]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1424 [D loss: 0.37288397550582886 | D accuracy: 89.0625] [G loss: 1.3790608644485474]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1425 [D loss: 0.3561624437570572 | D accuracy: 87.5] [G loss: 1.2647817134857178]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1426 [D loss: 0.42547257244586945 | D accuracy: 79.6875] [G loss: 1.5130903720855713]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1427 [D loss: 0.368446409702301 | D accuracy: 85.9375] [G loss: 1.561797857284546]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1428 [D loss: 0.6472918689250946 | D accuracy: 71.875] [G loss: 1.4815824031829834]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1429 [D loss: 0.3997165262699127 | D accuracy: 79.6875] [G loss: 1.2347159385681152]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1430 [D loss: 0.5599643141031265 | D accuracy: 67.1875] [G loss: 1.288294792175293]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1431 [D loss: 0.4068353772163391 | D accuracy: 84.375] [G loss: 1.3101985454559326]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1432 [D loss: 0.5730188488960266 | D accuracy: 67.1875] [G loss: 1.4123318195343018]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1433 [D loss: 0.3882592022418976 | D accuracy: 85.9375] [G loss: 1.571000099182129]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1434 [D loss: 0.4245035797357559 | D accuracy: 85.9375] [G loss: 1.555888056755066]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1435 [D loss: 0.5813405513763428 | D accuracy: 75.0] [G loss: 1.242114782333374]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1436 [D loss: 0.4618042856454849 | D accuracy: 79.6875] [G loss: 1.2403841018676758]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1437 [D loss: 0.4371487498283386 | D accuracy: 79.6875] [G loss: 1.1370148658752441]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1438 [D loss: 0.46340131759643555 | D accuracy: 78.125] [G loss: 1.412889003753662]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1439 [D loss: 0.5197879076004028 | D accuracy: 75.0] [G loss: 1.2957651615142822]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1440 [D loss: 0.4181159436702728 | D accuracy: 82.8125] [G loss: 1.3690472841262817]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1441 [D loss: 0.5238449573516846 | D accuracy: 73.4375] [G loss: 1.2384059429168701]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1442 [D loss: 0.5414464473724365 | D accuracy: 71.875] [G loss: 1.3418554067611694]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1443 [D loss: 0.49509188532829285 | D accuracy: 79.6875] [G loss: 1.2874877452850342]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1444 [D loss: 0.4557022452354431 | D accuracy: 78.125] [G loss: 1.4449639320373535]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1445 [D loss: 0.4581775963306427 | D accuracy: 78.125] [G loss: 1.3932595252990723]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1446 [D loss: 0.5897948443889618 | D accuracy: 64.0625] [G loss: 1.3104968070983887]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1447 [D loss: 0.341819703578949 | D accuracy: 87.5] [G loss: 1.2859324216842651]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1448 [D loss: 0.48769499361515045 | D accuracy: 79.6875] [G loss: 1.3328031301498413]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1449 [D loss: 0.395145058631897 | D accuracy: 82.8125] [G loss: 1.2738325595855713]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1450 [D loss: 0.579870730638504 | D accuracy: 73.4375] [G loss: 1.3724490404129028]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1451 [D loss: 0.36781860888004303 | D accuracy: 85.9375] [G loss: 1.458829402923584]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1452 [D loss: 0.3833409696817398 | D accuracy: 87.5] [G loss: 1.4111381769180298]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1453 [D loss: 0.4310663789510727 | D accuracy: 81.25] [G loss: 1.3395671844482422]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1454 [D loss: 0.47309716045856476 | D accuracy: 81.25] [G loss: 1.2021214962005615]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1455 [D loss: 0.5339067429304123 | D accuracy: 71.875] [G loss: 1.1609525680541992]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1456 [D loss: 0.33746279776096344 | D accuracy: 89.0625] [G loss: 1.3852341175079346]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1457 [D loss: 0.476124569773674 | D accuracy: 78.125] [G loss: 1.3572487831115723]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1458 [D loss: 0.5190426558256149 | D accuracy: 76.5625] [G loss: 1.2378063201904297]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1459 [D loss: 0.4948102682828903 | D accuracy: 75.0] [G loss: 1.2727456092834473]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1460 [D loss: 0.4396989941596985 | D accuracy: 76.5625] [G loss: 1.4541947841644287]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1461 [D loss: 0.43668586015701294 | D accuracy: 76.5625] [G loss: 1.529673457145691]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1462 [D loss: 0.6311234831809998 | D accuracy: 64.0625] [G loss: 1.2368805408477783]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1463 [D loss: 0.37912094593048096 | D accuracy: 87.5] [G loss: 1.2920238971710205]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1464 [D loss: 0.4764922708272934 | D accuracy: 78.125] [G loss: 1.2951785326004028]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1465 [D loss: 0.49650023877620697 | D accuracy: 76.5625] [G loss: 1.4185104370117188]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1466 [D loss: 0.5392465889453888 | D accuracy: 73.4375] [G loss: 1.2510828971862793]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1467 [D loss: 0.49919846653938293 | D accuracy: 73.4375] [G loss: 1.332352876663208]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1468 [D loss: 0.44034019112586975 | D accuracy: 84.375] [G loss: 1.2933448553085327]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1469 [D loss: 0.4436938315629959 | D accuracy: 76.5625] [G loss: 1.3474388122558594]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1470 [D loss: 0.4879823178052902 | D accuracy: 81.25] [G loss: 1.4019676446914673]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1471 [D loss: 0.4311937242746353 | D accuracy: 76.5625] [G loss: 1.3350260257720947]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1472 [D loss: 0.49073684215545654 | D accuracy: 78.125] [G loss: 1.380183219909668]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1473 [D loss: 0.38698412477970123 | D accuracy: 87.5] [G loss: 1.5432218313217163]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1474 [D loss: 0.5360480397939682 | D accuracy: 73.4375] [G loss: 1.3206665515899658]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1475 [D loss: 0.4467757046222687 | D accuracy: 82.8125] [G loss: 1.3384889364242554]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1476 [D loss: 0.4889335036277771 | D accuracy: 73.4375] [G loss: 1.307502031326294]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1477 [D loss: 0.4859987795352936 | D accuracy: 79.6875] [G loss: 1.2159843444824219]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1478 [D loss: 0.4949502646923065 | D accuracy: 78.125] [G loss: 1.3800468444824219]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1479 [D loss: 0.6144203841686249 | D accuracy: 71.875] [G loss: 1.4295341968536377]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1480 [D loss: 0.5242302119731903 | D accuracy: 73.4375] [G loss: 1.1901376247406006]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1481 [D loss: 0.4964781403541565 | D accuracy: 78.125] [G loss: 1.2913273572921753]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1482 [D loss: 0.5040326416492462 | D accuracy: 73.4375] [G loss: 1.270263910293579]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1483 [D loss: 0.4946356415748596 | D accuracy: 76.5625] [G loss: 1.1632506847381592]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1484 [D loss: 0.48899295926094055 | D accuracy: 73.4375] [G loss: 1.1150933504104614]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1485 [D loss: 0.42353153228759766 | D accuracy: 85.9375] [G loss: 1.260582447052002]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1486 [D loss: 0.6381852924823761 | D accuracy: 64.0625] [G loss: 1.3518480062484741]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1487 [D loss: 0.5986231565475464 | D accuracy: 71.875] [G loss: 1.283818244934082]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1488 [D loss: 0.5696743130683899 | D accuracy: 75.0] [G loss: 1.3605432510375977]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1489 [D loss: 0.6220456957817078 | D accuracy: 75.0] [G loss: 1.3169167041778564]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1490 [D loss: 0.5228687524795532 | D accuracy: 79.6875] [G loss: 1.2975068092346191]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1491 [D loss: 0.43633876740932465 | D accuracy: 79.6875] [G loss: 1.2401542663574219]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1492 [D loss: 0.5496830344200134 | D accuracy: 73.4375] [G loss: 1.1665812730789185]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1493 [D loss: 0.4145863205194473 | D accuracy: 84.375] [G loss: 1.133509635925293]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1494 [D loss: 0.4395249933004379 | D accuracy: 79.6875] [G loss: 1.332912802696228]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1495 [D loss: 0.5378196835517883 | D accuracy: 71.875] [G loss: 1.242368459701538]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1496 [D loss: 0.5898368060588837 | D accuracy: 65.625] [G loss: 1.331855058670044]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1497 [D loss: 0.6803532242774963 | D accuracy: 54.6875] [G loss: 1.2518515586853027]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1498 [D loss: 0.47349685430526733 | D accuracy: 75.0] [G loss: 1.2638885974884033]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1499 [D loss: 0.38571031391620636 | D accuracy: 81.25] [G loss: 1.4753708839416504]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1500 [D loss: 0.4284437298774719 | D accuracy: 79.6875] [G loss: 1.299583077430725]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1501 [D loss: 0.5228074491024017 | D accuracy: 75.0] [G loss: 1.2920095920562744]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1502 [D loss: 0.3858191817998886 | D accuracy: 85.9375] [G loss: 1.3199050426483154]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1503 [D loss: 0.46897874772548676 | D accuracy: 78.125] [G loss: 1.408021092414856]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1504 [D loss: 0.4928527772426605 | D accuracy: 79.6875] [G loss: 1.2187035083770752]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1505 [D loss: 0.563391923904419 | D accuracy: 71.875] [G loss: 1.4287903308868408]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1506 [D loss: 0.48116324841976166 | D accuracy: 81.25] [G loss: 1.3456170558929443]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1507 [D loss: 0.5764591991901398 | D accuracy: 70.3125] [G loss: 1.345604419708252]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1508 [D loss: 0.3906317949295044 | D accuracy: 84.375] [G loss: 1.2562930583953857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1509 [D loss: 0.3826793134212494 | D accuracy: 84.375] [G loss: 1.1778595447540283]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1510 [D loss: 0.5294680744409561 | D accuracy: 73.4375] [G loss: 1.2366456985473633]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1511 [D loss: 0.47337324917316437 | D accuracy: 81.25] [G loss: 1.199414610862732]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1512 [D loss: 0.5006712824106216 | D accuracy: 75.0] [G loss: 1.2561894655227661]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1513 [D loss: 0.356524795293808 | D accuracy: 85.9375] [G loss: 1.4323179721832275]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1514 [D loss: 0.4810100495815277 | D accuracy: 81.25] [G loss: 1.078049659729004]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1515 [D loss: 0.4400170147418976 | D accuracy: 81.25] [G loss: 1.115439772605896]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1516 [D loss: 0.3697534203529358 | D accuracy: 89.0625] [G loss: 1.337817907333374]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1517 [D loss: 0.5441469848155975 | D accuracy: 71.875] [G loss: 1.251568078994751]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1518 [D loss: 0.5160402357578278 | D accuracy: 73.4375] [G loss: 1.4215774536132812]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1519 [D loss: 0.48040997982025146 | D accuracy: 75.0] [G loss: 1.364959478378296]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1520 [D loss: 0.5132608264684677 | D accuracy: 76.5625] [G loss: 1.3965317010879517]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1521 [D loss: 0.39806394279003143 | D accuracy: 89.0625] [G loss: 1.2185763120651245]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1522 [D loss: 0.45944148302078247 | D accuracy: 76.5625] [G loss: 1.2483768463134766]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1523 [D loss: 0.49864885210990906 | D accuracy: 78.125] [G loss: 1.250027060508728]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1524 [D loss: 0.5032754242420197 | D accuracy: 81.25] [G loss: 1.4976427555084229]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1525 [D loss: 0.40680962800979614 | D accuracy: 82.8125] [G loss: 1.1307364702224731]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1526 [D loss: 0.440296471118927 | D accuracy: 79.6875] [G loss: 1.4636390209197998]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1527 [D loss: 0.6507405936717987 | D accuracy: 62.5] [G loss: 1.2263121604919434]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1528 [D loss: 0.6318715512752533 | D accuracy: 64.0625] [G loss: 1.2839694023132324]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1529 [D loss: 0.5264462828636169 | D accuracy: 70.3125] [G loss: 1.4860626459121704]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1530 [D loss: 0.5614113211631775 | D accuracy: 70.3125] [G loss: 1.300096035003662]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1531 [D loss: 0.40605486929416656 | D accuracy: 81.25] [G loss: 1.3359777927398682]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1532 [D loss: 0.42870450019836426 | D accuracy: 81.25] [G loss: 1.2334613800048828]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1533 [D loss: 0.4043668061494827 | D accuracy: 84.375] [G loss: 1.1220588684082031]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1534 [D loss: 0.45298072695732117 | D accuracy: 78.125] [G loss: 1.2072521448135376]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1535 [D loss: 0.5350795388221741 | D accuracy: 71.875] [G loss: 1.3239935636520386]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1536 [D loss: 0.5951984226703644 | D accuracy: 73.4375] [G loss: 1.2286221981048584]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1537 [D loss: 0.3915610611438751 | D accuracy: 85.9375] [G loss: 1.192493200302124]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1538 [D loss: 0.6876932978630066 | D accuracy: 64.0625] [G loss: 1.2445086240768433]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1539 [D loss: 0.42908424139022827 | D accuracy: 85.9375] [G loss: 1.505042314529419]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1540 [D loss: 0.5564444065093994 | D accuracy: 65.625] [G loss: 1.3117390871047974]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1541 [D loss: 0.43425512313842773 | D accuracy: 79.6875] [G loss: 1.2070908546447754]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1542 [D loss: 0.5352984666824341 | D accuracy: 76.5625] [G loss: 1.2094323635101318]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1543 [D loss: 0.5052170753479004 | D accuracy: 76.5625] [G loss: 1.29192316532135]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1544 [D loss: 0.5133718401193619 | D accuracy: 76.5625] [G loss: 1.3291187286376953]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1545 [D loss: 0.49164968729019165 | D accuracy: 78.125] [G loss: 1.4913780689239502]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1546 [D loss: 0.507983073592186 | D accuracy: 78.125] [G loss: 1.243116021156311]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1547 [D loss: 0.4947444796562195 | D accuracy: 79.6875] [G loss: 1.4426932334899902]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1548 [D loss: 0.46551088988780975 | D accuracy: 78.125] [G loss: 1.3223345279693604]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1549 [D loss: 0.5811315774917603 | D accuracy: 71.875] [G loss: 1.216010332107544]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1550 [D loss: 0.3850100040435791 | D accuracy: 84.375] [G loss: 1.3314909934997559]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1551 [D loss: 0.5164989531040192 | D accuracy: 71.875] [G loss: 1.340111255645752]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1552 [D loss: 0.49950626492500305 | D accuracy: 81.25] [G loss: 1.1814833879470825]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1553 [D loss: 0.48845845460891724 | D accuracy: 78.125] [G loss: 1.4688537120819092]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1554 [D loss: 0.48569127917289734 | D accuracy: 76.5625] [G loss: 1.4595155715942383]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1555 [D loss: 0.47700338065624237 | D accuracy: 78.125] [G loss: 1.4472711086273193]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1556 [D loss: 0.4957423359155655 | D accuracy: 75.0] [G loss: 1.3438894748687744]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1557 [D loss: 0.4566437155008316 | D accuracy: 79.6875] [G loss: 1.3299229145050049]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1558 [D loss: 0.44703976809978485 | D accuracy: 79.6875] [G loss: 1.2433834075927734]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1559 [D loss: 0.5682951807975769 | D accuracy: 67.1875] [G loss: 1.2433357238769531]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1560 [D loss: 0.47034887969493866 | D accuracy: 78.125] [G loss: 1.2990516424179077]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1561 [D loss: 0.4709940552711487 | D accuracy: 84.375] [G loss: 1.319307804107666]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1562 [D loss: 0.4148532450199127 | D accuracy: 84.375] [G loss: 1.2516896724700928]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1563 [D loss: 0.5910664498806 | D accuracy: 68.75] [G loss: 1.335214376449585]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1564 [D loss: 0.5202760100364685 | D accuracy: 70.3125] [G loss: 1.4137070178985596]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1565 [D loss: 0.5787659287452698 | D accuracy: 70.3125] [G loss: 1.3568172454833984]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1566 [D loss: 0.604523777961731 | D accuracy: 70.3125] [G loss: 1.3807979822158813]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1567 [D loss: 0.4766678363084793 | D accuracy: 76.5625] [G loss: 1.4887616634368896]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1568 [D loss: 0.5598809123039246 | D accuracy: 75.0] [G loss: 1.3090556859970093]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1569 [D loss: 0.3635672926902771 | D accuracy: 85.9375] [G loss: 1.320056676864624]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1570 [D loss: 0.44083407521247864 | D accuracy: 78.125] [G loss: 1.3608956336975098]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1571 [D loss: 0.4511276036500931 | D accuracy: 84.375] [G loss: 1.3095686435699463]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1572 [D loss: 0.35839298367500305 | D accuracy: 82.8125] [G loss: 1.4156169891357422]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1573 [D loss: 0.3928704708814621 | D accuracy: 84.375] [G loss: 1.3057256937026978]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1574 [D loss: 0.5643875002861023 | D accuracy: 73.4375] [G loss: 1.2850923538208008]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1575 [D loss: 0.5664543509483337 | D accuracy: 65.625] [G loss: 1.2144474983215332]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1576 [D loss: 0.4118972420692444 | D accuracy: 82.8125] [G loss: 1.3395805358886719]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1577 [D loss: 0.4701171815395355 | D accuracy: 75.0] [G loss: 1.5204217433929443]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1578 [D loss: 0.38096462190151215 | D accuracy: 90.625] [G loss: 1.4848482608795166]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1579 [D loss: 0.489290326833725 | D accuracy: 79.6875] [G loss: 1.4414231777191162]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1580 [D loss: 0.6416834592819214 | D accuracy: 62.5] [G loss: 1.4852608442306519]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1581 [D loss: 0.4065977483987808 | D accuracy: 82.8125] [G loss: 1.5284578800201416]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1582 [D loss: 0.5089562684297562 | D accuracy: 78.125] [G loss: 1.442625641822815]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1583 [D loss: 0.3678911477327347 | D accuracy: 87.5] [G loss: 1.2835668325424194]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1584 [D loss: 0.6658407747745514 | D accuracy: 65.625] [G loss: 1.2223010063171387]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1585 [D loss: 0.43354278802871704 | D accuracy: 79.6875] [G loss: 1.2088255882263184]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1586 [D loss: 0.6013926267623901 | D accuracy: 70.3125] [G loss: 1.2225861549377441]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1587 [D loss: 0.4590606838464737 | D accuracy: 76.5625] [G loss: 1.2237168550491333]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1588 [D loss: 0.3941633552312851 | D accuracy: 82.8125] [G loss: 1.1431695222854614]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1589 [D loss: 0.459655299782753 | D accuracy: 84.375] [G loss: 1.1926722526550293]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1590 [D loss: 0.4408142566680908 | D accuracy: 75.0] [G loss: 1.3714237213134766]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1591 [D loss: 0.563344419002533 | D accuracy: 68.75] [G loss: 1.2646896839141846]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1592 [D loss: 0.4753868877887726 | D accuracy: 78.125] [G loss: 1.3512827157974243]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1593 [D loss: 0.5610820055007935 | D accuracy: 67.1875] [G loss: 1.4054243564605713]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1594 [D loss: 0.4046884924173355 | D accuracy: 84.375] [G loss: 1.2903140783309937]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1595 [D loss: 0.4639109820127487 | D accuracy: 81.25] [G loss: 1.275770664215088]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1596 [D loss: 0.5738040804862976 | D accuracy: 71.875] [G loss: 1.241469144821167]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1597 [D loss: 0.43342721462249756 | D accuracy: 76.5625] [G loss: 1.416959524154663]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1598 [D loss: 0.4742483049631119 | D accuracy: 78.125] [G loss: 1.4183149337768555]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1599 [D loss: 0.5561837553977966 | D accuracy: 71.875] [G loss: 1.4551761150360107]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1600 [D loss: 0.5482775568962097 | D accuracy: 73.4375] [G loss: 1.2103993892669678]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1601 [D loss: 0.5316462516784668 | D accuracy: 75.0] [G loss: 1.535032033920288]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1602 [D loss: 0.5086769759654999 | D accuracy: 76.5625] [G loss: 1.392259120941162]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1603 [D loss: 0.386095866560936 | D accuracy: 84.375] [G loss: 1.4482455253601074]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1604 [D loss: 0.5744677484035492 | D accuracy: 68.75] [G loss: 1.2098355293273926]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1605 [D loss: 0.5465689599514008 | D accuracy: 71.875] [G loss: 1.370772123336792]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1606 [D loss: 0.5144899785518646 | D accuracy: 68.75] [G loss: 1.365119457244873]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1607 [D loss: 0.4508263021707535 | D accuracy: 78.125] [G loss: 1.365967869758606]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1608 [D loss: 0.4518672525882721 | D accuracy: 79.6875] [G loss: 1.2685832977294922]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1609 [D loss: 0.48577481508255005 | D accuracy: 73.4375] [G loss: 1.2577662467956543]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1610 [D loss: 0.5200474858283997 | D accuracy: 75.0] [G loss: 1.2343885898590088]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1611 [D loss: 0.4031217098236084 | D accuracy: 85.9375] [G loss: 1.3151648044586182]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1612 [D loss: 0.5418588817119598 | D accuracy: 71.875] [G loss: 1.2768282890319824]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1613 [D loss: 0.451805517077446 | D accuracy: 81.25] [G loss: 1.1766551733016968]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1614 [D loss: 0.4598158299922943 | D accuracy: 76.5625] [G loss: 1.2563673257827759]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1615 [D loss: 0.5857604146003723 | D accuracy: 64.0625] [G loss: 1.247743010520935]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1616 [D loss: 0.5342312157154083 | D accuracy: 73.4375] [G loss: 1.3263198137283325]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1617 [D loss: 0.43637868762016296 | D accuracy: 82.8125] [G loss: 1.4435813426971436]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1618 [D loss: 0.4507814049720764 | D accuracy: 79.6875] [G loss: 1.3026418685913086]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1619 [D loss: 0.5527446269989014 | D accuracy: 70.3125] [G loss: 1.3794808387756348]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1620 [D loss: 0.5257693231105804 | D accuracy: 68.75] [G loss: 1.2794315814971924]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1621 [D loss: 0.4811549186706543 | D accuracy: 78.125] [G loss: 1.1328632831573486]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1622 [D loss: 0.5183028131723404 | D accuracy: 73.4375] [G loss: 1.1780261993408203]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1623 [D loss: 0.46104374527931213 | D accuracy: 79.6875] [G loss: 1.3635503053665161]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1624 [D loss: 0.4058312773704529 | D accuracy: 85.9375] [G loss: 1.3083062171936035]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1625 [D loss: 0.5601512789726257 | D accuracy: 68.75] [G loss: 1.4674111604690552]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1626 [D loss: 0.4893859177827835 | D accuracy: 76.5625] [G loss: 1.3875863552093506]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1627 [D loss: 0.42285899817943573 | D accuracy: 78.125] [G loss: 1.4618934392929077]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1628 [D loss: 0.6373769342899323 | D accuracy: 67.1875] [G loss: 1.414898157119751]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1629 [D loss: 0.45454423129558563 | D accuracy: 82.8125] [G loss: 1.3537267446517944]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1630 [D loss: 0.404490202665329 | D accuracy: 79.6875] [G loss: 1.381658911705017]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1631 [D loss: 0.5262739956378937 | D accuracy: 76.5625] [G loss: 1.4617232084274292]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1632 [D loss: 0.4707048684358597 | D accuracy: 84.375] [G loss: 1.4221502542495728]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1633 [D loss: 0.4209696650505066 | D accuracy: 81.25] [G loss: 1.2675952911376953]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1634 [D loss: 0.6234311759471893 | D accuracy: 68.75] [G loss: 1.1555777788162231]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1635 [D loss: 0.4952670931816101 | D accuracy: 73.4375] [G loss: 1.1895148754119873]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1636 [D loss: 0.3941979557275772 | D accuracy: 85.9375] [G loss: 1.3274794816970825]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1637 [D loss: 0.42022353410720825 | D accuracy: 87.5] [G loss: 1.2817788124084473]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1638 [D loss: 0.5750541985034943 | D accuracy: 73.4375] [G loss: 1.3250784873962402]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1639 [D loss: 0.400107741355896 | D accuracy: 78.125] [G loss: 1.1780157089233398]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1640 [D loss: 0.5308461785316467 | D accuracy: 75.0] [G loss: 1.3387806415557861]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1641 [D loss: 0.41688641905784607 | D accuracy: 85.9375] [G loss: 1.292079210281372]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1642 [D loss: 0.5783745646476746 | D accuracy: 73.4375] [G loss: 1.3592509031295776]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1643 [D loss: 0.424138605594635 | D accuracy: 85.9375] [G loss: 1.4093797206878662]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1644 [D loss: 0.4847910702228546 | D accuracy: 78.125] [G loss: 1.3195078372955322]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1645 [D loss: 0.4903238117694855 | D accuracy: 78.125] [G loss: 1.409834623336792]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1646 [D loss: 0.512231856584549 | D accuracy: 71.875] [G loss: 1.0969979763031006]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1647 [D loss: 0.5284577012062073 | D accuracy: 73.4375] [G loss: 1.2295619249343872]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1648 [D loss: 0.48595547676086426 | D accuracy: 75.0] [G loss: 1.2249349355697632]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1649 [D loss: 0.5207721292972565 | D accuracy: 70.3125] [G loss: 1.1019341945648193]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1650 [D loss: 0.4858388453722 | D accuracy: 73.4375] [G loss: 1.359689474105835]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1651 [D loss: 0.40234971046447754 | D accuracy: 84.375] [G loss: 1.330371379852295]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1652 [D loss: 0.4352288693189621 | D accuracy: 76.5625] [G loss: 1.3127942085266113]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1653 [D loss: 0.565930962562561 | D accuracy: 68.75] [G loss: 1.2472598552703857]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1654 [D loss: 0.508753091096878 | D accuracy: 75.0] [G loss: 1.2603895664215088]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1655 [D loss: 0.45178720355033875 | D accuracy: 78.125] [G loss: 1.4684460163116455]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1656 [D loss: 0.4397306591272354 | D accuracy: 82.8125] [G loss: 1.250483751296997]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1657 [D loss: 0.43673188984394073 | D accuracy: 84.375] [G loss: 1.408867597579956]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1658 [D loss: 0.4480004459619522 | D accuracy: 79.6875] [G loss: 1.3188223838806152]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1659 [D loss: 0.3814299404621124 | D accuracy: 85.9375] [G loss: 1.4888540506362915]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1660 [D loss: 0.40456150472164154 | D accuracy: 79.6875] [G loss: 1.3056806325912476]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1661 [D loss: 0.4648314118385315 | D accuracy: 84.375] [G loss: 1.3000082969665527]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1662 [D loss: 0.4496931731700897 | D accuracy: 75.0] [G loss: 1.3406879901885986]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1663 [D loss: 0.44836263358592987 | D accuracy: 78.125] [G loss: 1.3065840005874634]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1664 [D loss: 0.4726761281490326 | D accuracy: 81.25] [G loss: 1.3524422645568848]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1665 [D loss: 0.4170629680156708 | D accuracy: 76.5625] [G loss: 1.3530519008636475]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1666 [D loss: 0.44620294868946075 | D accuracy: 84.375] [G loss: 1.5529701709747314]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1667 [D loss: 0.5006118416786194 | D accuracy: 73.4375] [G loss: 1.4797790050506592]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1668 [D loss: 0.4444580525159836 | D accuracy: 81.25] [G loss: 1.4354698657989502]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1669 [D loss: 0.48774583637714386 | D accuracy: 78.125] [G loss: 1.38457190990448]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1670 [D loss: 0.47051095962524414 | D accuracy: 76.5625] [G loss: 1.487091064453125]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1671 [D loss: 0.3645774573087692 | D accuracy: 84.375] [G loss: 1.4367332458496094]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1672 [D loss: 0.5304175317287445 | D accuracy: 73.4375] [G loss: 1.1522551774978638]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1673 [D loss: 0.3957364857196808 | D accuracy: 82.8125] [G loss: 1.2708868980407715]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1674 [D loss: 0.47588396072387695 | D accuracy: 75.0] [G loss: 1.200253963470459]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1675 [D loss: 0.4487525522708893 | D accuracy: 81.25] [G loss: 1.188998818397522]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1676 [D loss: 0.48621831834316254 | D accuracy: 79.6875] [G loss: 1.566124677658081]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1677 [D loss: 0.5206484496593475 | D accuracy: 78.125] [G loss: 1.5071457624435425]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1678 [D loss: 0.45531271398067474 | D accuracy: 78.125] [G loss: 1.5722386837005615]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1679 [D loss: 0.6213600933551788 | D accuracy: 64.0625] [G loss: 1.4355382919311523]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1680 [D loss: 0.45022597908973694 | D accuracy: 78.125] [G loss: 1.3383855819702148]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1681 [D loss: 0.5305877923965454 | D accuracy: 78.125] [G loss: 1.4207184314727783]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1682 [D loss: 0.7248683571815491 | D accuracy: 56.25] [G loss: 1.375309705734253]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1683 [D loss: 0.4344164580106735 | D accuracy: 79.6875] [G loss: 1.2591832876205444]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1684 [D loss: 0.4890247583389282 | D accuracy: 78.125] [G loss: 1.2534825801849365]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1685 [D loss: 0.5116611123085022 | D accuracy: 76.5625] [G loss: 1.3547308444976807]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1686 [D loss: 0.4781140238046646 | D accuracy: 79.6875] [G loss: 1.1628270149230957]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1687 [D loss: 0.5526866465806961 | D accuracy: 73.4375] [G loss: 1.3510268926620483]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1688 [D loss: 0.5254616141319275 | D accuracy: 73.4375] [G loss: 1.1284327507019043]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1689 [D loss: 0.49947357177734375 | D accuracy: 76.5625] [G loss: 1.1752620935440063]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1690 [D loss: 0.560239851474762 | D accuracy: 73.4375] [G loss: 1.4202523231506348]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1691 [D loss: 0.44656483829021454 | D accuracy: 82.8125] [G loss: 1.4040738344192505]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1692 [D loss: 0.41299869120121 | D accuracy: 85.9375] [G loss: 1.341505765914917]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1693 [D loss: 0.4890393912792206 | D accuracy: 75.0] [G loss: 1.413780689239502]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1694 [D loss: 0.4791795313358307 | D accuracy: 78.125] [G loss: 1.5603508949279785]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1695 [D loss: 0.4590176194906235 | D accuracy: 78.125] [G loss: 1.3869298696517944]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1696 [D loss: 0.5907969176769257 | D accuracy: 65.625] [G loss: 1.1955639123916626]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1697 [D loss: 0.4995700716972351 | D accuracy: 76.5625] [G loss: 1.1623599529266357]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1698 [D loss: 0.5102151334285736 | D accuracy: 70.3125] [G loss: 1.3843148946762085]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1699 [D loss: 0.453722283244133 | D accuracy: 82.8125] [G loss: 1.2564562559127808]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1700 [D loss: 0.4422153830528259 | D accuracy: 73.4375] [G loss: 1.3770772218704224]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1701 [D loss: 0.4401281923055649 | D accuracy: 85.9375] [G loss: 1.663039207458496]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1702 [D loss: 0.35836179554462433 | D accuracy: 85.9375] [G loss: 1.434678077697754]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1703 [D loss: 0.5334750115871429 | D accuracy: 68.75] [G loss: 1.3371467590332031]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1704 [D loss: 0.47032976150512695 | D accuracy: 84.375] [G loss: 1.2875323295593262]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1705 [D loss: 0.44602102041244507 | D accuracy: 79.6875] [G loss: 1.487919807434082]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1706 [D loss: 0.4543171525001526 | D accuracy: 85.9375] [G loss: 1.5139493942260742]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1707 [D loss: 0.5728073865175247 | D accuracy: 67.1875] [G loss: 1.4988479614257812]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1708 [D loss: 0.48671500384807587 | D accuracy: 81.25] [G loss: 1.431250810623169]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1709 [D loss: 0.5027597844600677 | D accuracy: 76.5625] [G loss: 1.5945041179656982]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1710 [D loss: 0.4657905697822571 | D accuracy: 79.6875] [G loss: 1.4888296127319336]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1711 [D loss: 0.4798118472099304 | D accuracy: 76.5625] [G loss: 1.2309657335281372]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1712 [D loss: 0.479968324303627 | D accuracy: 78.125] [G loss: 1.3985726833343506]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1713 [D loss: 0.5915310978889465 | D accuracy: 68.75] [G loss: 1.2834107875823975]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1714 [D loss: 0.5662106871604919 | D accuracy: 73.4375] [G loss: 1.1198973655700684]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1715 [D loss: 0.606852650642395 | D accuracy: 68.75] [G loss: 1.078317642211914]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1716 [D loss: 0.4686008542776108 | D accuracy: 75.0] [G loss: 1.3130487203598022]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1717 [D loss: 0.393097847700119 | D accuracy: 81.25] [G loss: 1.15445077419281]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1718 [D loss: 0.49199599027633667 | D accuracy: 73.4375] [G loss: 1.3963414430618286]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1719 [D loss: 0.4656166136264801 | D accuracy: 78.125] [G loss: 1.414246678352356]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1720 [D loss: 0.6262957453727722 | D accuracy: 70.3125] [G loss: 1.4492273330688477]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1721 [D loss: 0.5235203504562378 | D accuracy: 70.3125] [G loss: 1.3387675285339355]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1722 [D loss: 0.561730831861496 | D accuracy: 68.75] [G loss: 1.360971450805664]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1723 [D loss: 0.4769163876771927 | D accuracy: 76.5625] [G loss: 1.2432841062545776]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1724 [D loss: 0.5007131546735764 | D accuracy: 75.0] [G loss: 1.4251043796539307]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1725 [D loss: 0.4609867036342621 | D accuracy: 79.6875] [G loss: 1.416251540184021]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1726 [D loss: 0.4828373193740845 | D accuracy: 81.25] [G loss: 1.332828402519226]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1727 [D loss: 0.5361275672912598 | D accuracy: 70.3125] [G loss: 1.3467047214508057]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1728 [D loss: 0.6262045204639435 | D accuracy: 70.3125] [G loss: 1.3871033191680908]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1729 [D loss: 0.5178966522216797 | D accuracy: 71.875] [G loss: 1.330495834350586]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1730 [D loss: 0.418649822473526 | D accuracy: 84.375] [G loss: 1.4420663118362427]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1731 [D loss: 0.5160936862230301 | D accuracy: 75.0] [G loss: 1.391255497932434]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1732 [D loss: 0.43276970088481903 | D accuracy: 78.125] [G loss: 1.4874628782272339]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1733 [D loss: 0.4934151917695999 | D accuracy: 76.5625] [G loss: 1.3945560455322266]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1734 [D loss: 0.5248941034078598 | D accuracy: 70.3125] [G loss: 1.2678940296173096]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1735 [D loss: 0.4437636286020279 | D accuracy: 81.25] [G loss: 1.3842260837554932]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1736 [D loss: 0.3328562378883362 | D accuracy: 87.5] [G loss: 1.3514599800109863]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1737 [D loss: 0.44474244117736816 | D accuracy: 81.25] [G loss: 1.3564966917037964]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1738 [D loss: 0.49113234877586365 | D accuracy: 78.125] [G loss: 1.3584468364715576]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1739 [D loss: 0.42705124616622925 | D accuracy: 79.6875] [G loss: 1.5320308208465576]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1740 [D loss: 0.47746486961841583 | D accuracy: 75.0] [G loss: 1.3818986415863037]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1741 [D loss: 0.46117202937602997 | D accuracy: 76.5625] [G loss: 1.3952410221099854]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1742 [D loss: 0.5223354995250702 | D accuracy: 70.3125] [G loss: 1.4480698108673096]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1743 [D loss: 0.501853421330452 | D accuracy: 76.5625] [G loss: 1.4217681884765625]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1744 [D loss: 0.5472776740789413 | D accuracy: 71.875] [G loss: 1.290998935699463]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1745 [D loss: 0.4409038722515106 | D accuracy: 81.25] [G loss: 1.3390694856643677]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1746 [D loss: 0.45972365140914917 | D accuracy: 82.8125] [G loss: 1.2456823587417603]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1747 [D loss: 0.5051894038915634 | D accuracy: 75.0] [G loss: 1.2493255138397217]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1748 [D loss: 0.5271410942077637 | D accuracy: 70.3125] [G loss: 1.6067087650299072]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1749 [D loss: 0.4951934218406677 | D accuracy: 73.4375] [G loss: 1.4401350021362305]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1750 [D loss: 0.6763753294944763 | D accuracy: 68.75] [G loss: 1.2573249340057373]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1751 [D loss: 0.5048200339078903 | D accuracy: 67.1875] [G loss: 1.3499915599822998]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1752 [D loss: 0.6436065435409546 | D accuracy: 64.0625] [G loss: 1.3323218822479248]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1753 [D loss: 0.4884270131587982 | D accuracy: 73.4375] [G loss: 1.3292293548583984]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1754 [D loss: 0.46633800864219666 | D accuracy: 79.6875] [G loss: 1.2756733894348145]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1755 [D loss: 0.42530934512615204 | D accuracy: 76.5625] [G loss: 1.3385547399520874]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1756 [D loss: 0.5045698583126068 | D accuracy: 76.5625] [G loss: 1.2670698165893555]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1757 [D loss: 0.47922462224960327 | D accuracy: 84.375] [G loss: 1.3081501722335815]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1758 [D loss: 0.5029750317335129 | D accuracy: 76.5625] [G loss: 1.315341591835022]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1759 [D loss: 0.5421432256698608 | D accuracy: 70.3125] [G loss: 1.4704177379608154]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1760 [D loss: 0.39472855627536774 | D accuracy: 81.25] [G loss: 1.402788519859314]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1761 [D loss: 0.5945944786071777 | D accuracy: 67.1875] [G loss: 1.3330423831939697]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1762 [D loss: 0.42703771591186523 | D accuracy: 71.875] [G loss: 1.3364849090576172]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1763 [D loss: 0.5355578064918518 | D accuracy: 73.4375] [G loss: 1.407809853553772]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1764 [D loss: 0.6482707858085632 | D accuracy: 70.3125] [G loss: 1.232527732849121]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1765 [D loss: 0.5117781460285187 | D accuracy: 73.4375] [G loss: 1.1574958562850952]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1766 [D loss: 0.4302721619606018 | D accuracy: 82.8125] [G loss: 1.2481156587600708]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1767 [D loss: 0.3993435204029083 | D accuracy: 87.5] [G loss: 1.1734027862548828]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1768 [D loss: 0.4818138927221298 | D accuracy: 76.5625] [G loss: 1.415557622909546]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1769 [D loss: 0.4386706054210663 | D accuracy: 81.25] [G loss: 1.3885759115219116]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1770 [D loss: 0.39513809978961945 | D accuracy: 85.9375] [G loss: 1.3811542987823486]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1771 [D loss: 0.499218225479126 | D accuracy: 78.125] [G loss: 1.1947758197784424]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1772 [D loss: 0.4872737228870392 | D accuracy: 79.6875] [G loss: 1.3148688077926636]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1773 [D loss: 0.41566091775894165 | D accuracy: 81.25] [G loss: 1.3200949430465698]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1774 [D loss: 0.37722499668598175 | D accuracy: 84.375] [G loss: 1.5086030960083008]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1775 [D loss: 0.5490905940532684 | D accuracy: 73.4375] [G loss: 1.522750973701477]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1776 [D loss: 0.5535651743412018 | D accuracy: 70.3125] [G loss: 1.4074509143829346]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1777 [D loss: 0.5086270570755005 | D accuracy: 73.4375] [G loss: 1.3889546394348145]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1778 [D loss: 0.5617939233779907 | D accuracy: 65.625] [G loss: 1.332101821899414]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1779 [D loss: 0.5571515560150146 | D accuracy: 73.4375] [G loss: 1.2102975845336914]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1780 [D loss: 0.4252835661172867 | D accuracy: 82.8125] [G loss: 1.2393338680267334]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1781 [D loss: 0.5161866247653961 | D accuracy: 75.0] [G loss: 1.3466150760650635]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1782 [D loss: 0.429713636636734 | D accuracy: 78.125] [G loss: 1.3355810642242432]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1783 [D loss: 0.3456454873085022 | D accuracy: 85.9375] [G loss: 1.5125408172607422]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1784 [D loss: 0.5356644093990326 | D accuracy: 70.3125] [G loss: 1.3542134761810303]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1785 [D loss: 0.5581124275922775 | D accuracy: 70.3125] [G loss: 1.4719576835632324]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1786 [D loss: 0.5099315792322159 | D accuracy: 76.5625] [G loss: 1.46024489402771]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1787 [D loss: 0.4923238158226013 | D accuracy: 81.25] [G loss: 1.458531141281128]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1788 [D loss: 0.42526981234550476 | D accuracy: 84.375] [G loss: 1.4928693771362305]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1789 [D loss: 0.44114379584789276 | D accuracy: 82.8125] [G loss: 1.346808671951294]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1790 [D loss: 0.37424129247665405 | D accuracy: 87.5] [G loss: 1.3356218338012695]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1791 [D loss: 0.3912826031446457 | D accuracy: 84.375] [G loss: 1.5126454830169678]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1792 [D loss: 0.4827377200126648 | D accuracy: 78.125] [G loss: 1.3323551416397095]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1793 [D loss: 0.566119909286499 | D accuracy: 68.75] [G loss: 1.3458925485610962]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1794 [D loss: 0.5219100713729858 | D accuracy: 76.5625] [G loss: 1.3683409690856934]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1795 [D loss: 0.48106199502944946 | D accuracy: 76.5625] [G loss: 1.341336965560913]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1796 [D loss: 0.40065614879131317 | D accuracy: 87.5] [G loss: 1.210482120513916]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1797 [D loss: 0.47950248420238495 | D accuracy: 73.4375] [G loss: 0.9394374489784241]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1798 [D loss: 0.45206189155578613 | D accuracy: 76.5625] [G loss: 1.18641197681427]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1799 [D loss: 0.4866192489862442 | D accuracy: 76.5625] [G loss: 1.3818848133087158]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1800 [D loss: 0.5763411819934845 | D accuracy: 73.4375] [G loss: 1.2691717147827148]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1801 [D loss: 0.48137974739074707 | D accuracy: 75.0] [G loss: 1.4588408470153809]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1802 [D loss: 0.37565918266773224 | D accuracy: 89.0625] [G loss: 1.4452860355377197]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1803 [D loss: 0.5608059167861938 | D accuracy: 73.4375] [G loss: 1.5666192770004272]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1804 [D loss: 0.5414878278970718 | D accuracy: 70.3125] [G loss: 1.3809715509414673]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1805 [D loss: 0.48105306923389435 | D accuracy: 71.875] [G loss: 1.3951038122177124]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1806 [D loss: 0.46521079540252686 | D accuracy: 78.125] [G loss: 1.4411725997924805]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1807 [D loss: 0.3725634068250656 | D accuracy: 87.5] [G loss: 1.5052244663238525]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1808 [D loss: 0.4490049481391907 | D accuracy: 85.9375] [G loss: 1.515406847000122]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1809 [D loss: 0.39944368600845337 | D accuracy: 84.375] [G loss: 1.3737001419067383]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1810 [D loss: 0.5375128984451294 | D accuracy: 68.75] [G loss: 1.2916836738586426]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1811 [D loss: 0.5188402980566025 | D accuracy: 73.4375] [G loss: 1.4042658805847168]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1812 [D loss: 0.5105357468128204 | D accuracy: 75.0] [G loss: 1.4926838874816895]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1813 [D loss: 0.5462907701730728 | D accuracy: 68.75] [G loss: 1.3184720277786255]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1814 [D loss: 0.421405091881752 | D accuracy: 85.9375] [G loss: 1.2758373022079468]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1815 [D loss: 0.5096714794635773 | D accuracy: 78.125] [G loss: 1.2175817489624023]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1816 [D loss: 0.34461797773838043 | D accuracy: 89.0625] [G loss: 1.2135299444198608]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1817 [D loss: 0.4864366948604584 | D accuracy: 76.5625] [G loss: 1.4540205001831055]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1818 [D loss: 0.427777498960495 | D accuracy: 82.8125] [G loss: 1.359163522720337]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1819 [D loss: 0.5896773338317871 | D accuracy: 68.75] [G loss: 1.5156513452529907]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1820 [D loss: 0.43773117661476135 | D accuracy: 78.125] [G loss: 1.5172340869903564]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1821 [D loss: 0.5173847079277039 | D accuracy: 75.0] [G loss: 1.585827112197876]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1822 [D loss: 0.43045875430107117 | D accuracy: 87.5] [G loss: 1.447770357131958]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1823 [D loss: 0.5775958001613617 | D accuracy: 70.3125] [G loss: 1.4658772945404053]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1824 [D loss: 0.35468819737434387 | D accuracy: 87.5] [G loss: 1.475661039352417]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1825 [D loss: 0.5024994760751724 | D accuracy: 76.5625] [G loss: 1.3047538995742798]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1826 [D loss: 0.5482506901025772 | D accuracy: 70.3125] [G loss: 1.3674038648605347]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1827 [D loss: 0.4218471348285675 | D accuracy: 85.9375] [G loss: 1.559862732887268]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1828 [D loss: 0.41295047104358673 | D accuracy: 79.6875] [G loss: 1.5195393562316895]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1829 [D loss: 0.5823145359754562 | D accuracy: 68.75] [G loss: 1.3071136474609375]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1830 [D loss: 0.4014672785997391 | D accuracy: 82.8125] [G loss: 1.3590946197509766]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1831 [D loss: 0.4191263020038605 | D accuracy: 81.25] [G loss: 1.384882926940918]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1832 [D loss: 0.5020258724689484 | D accuracy: 75.0] [G loss: 1.3858911991119385]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1833 [D loss: 0.4978662431240082 | D accuracy: 75.0] [G loss: 1.3222827911376953]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1834 [D loss: 0.3994420915842056 | D accuracy: 84.375] [G loss: 1.4977202415466309]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1835 [D loss: 0.5547516345977783 | D accuracy: 67.1875] [G loss: 1.3974730968475342]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1836 [D loss: 0.51877661049366 | D accuracy: 73.4375] [G loss: 1.3838870525360107]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1837 [D loss: 0.4549250900745392 | D accuracy: 82.8125] [G loss: 1.3251311779022217]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1838 [D loss: 0.5297544896602631 | D accuracy: 71.875] [G loss: 1.3288264274597168]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1839 [D loss: 0.45547428727149963 | D accuracy: 81.25] [G loss: 1.2292943000793457]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1840 [D loss: 0.4393148273229599 | D accuracy: 81.25] [G loss: 1.4577419757843018]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1841 [D loss: 0.487301766872406 | D accuracy: 73.4375] [G loss: 1.286827802658081]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1842 [D loss: 0.4467318654060364 | D accuracy: 79.6875] [G loss: 1.0999699831008911]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1843 [D loss: 0.45616593956947327 | D accuracy: 81.25] [G loss: 1.2153451442718506]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1844 [D loss: 0.6381926089525223 | D accuracy: 67.1875] [G loss: 1.448670506477356]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1845 [D loss: 0.4574317932128906 | D accuracy: 79.6875] [G loss: 1.3717231750488281]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1846 [D loss: 0.5043459534645081 | D accuracy: 68.75] [G loss: 1.4119641780853271]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1847 [D loss: 0.5440790802240372 | D accuracy: 78.125] [G loss: 1.3527679443359375]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1848 [D loss: 0.42358216643333435 | D accuracy: 79.6875] [G loss: 1.3147387504577637]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1849 [D loss: 0.5090031772851944 | D accuracy: 70.3125] [G loss: 1.3232409954071045]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1850 [D loss: 0.4724590629339218 | D accuracy: 76.5625] [G loss: 1.502791166305542]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1851 [D loss: 0.4517759084701538 | D accuracy: 76.5625] [G loss: 1.3933131694793701]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1852 [D loss: 0.5227348506450653 | D accuracy: 75.0] [G loss: 1.4737826585769653]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1853 [D loss: 0.4221167266368866 | D accuracy: 82.8125] [G loss: 1.4977855682373047]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1854 [D loss: 0.5372536182403564 | D accuracy: 71.875] [G loss: 1.4820921421051025]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1855 [D loss: 0.48113560676574707 | D accuracy: 75.0] [G loss: 1.3531980514526367]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1856 [D loss: 0.45185747742652893 | D accuracy: 82.8125] [G loss: 1.558837890625]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1857 [D loss: 0.4425060898065567 | D accuracy: 84.375] [G loss: 1.486283779144287]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1858 [D loss: 0.4087832272052765 | D accuracy: 78.125] [G loss: 1.3231282234191895]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1859 [D loss: 0.5510114133358002 | D accuracy: 71.875] [G loss: 1.473482370376587]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1860 [D loss: 0.5656821429729462 | D accuracy: 68.75] [G loss: 1.5033955574035645]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1861 [D loss: 0.3694937229156494 | D accuracy: 87.5] [G loss: 1.5234558582305908]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1862 [D loss: 0.5820125341415405 | D accuracy: 68.75] [G loss: 1.423420786857605]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1863 [D loss: 0.4972328245639801 | D accuracy: 75.0] [G loss: 1.3334298133850098]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1864 [D loss: 0.466118186712265 | D accuracy: 75.0] [G loss: 1.3689124584197998]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1865 [D loss: 0.5060995817184448 | D accuracy: 75.0] [G loss: 1.3006982803344727]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1866 [D loss: 0.3420378416776657 | D accuracy: 89.0625] [G loss: 1.4188406467437744]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1867 [D loss: 0.4922530800104141 | D accuracy: 78.125] [G loss: 1.279220461845398]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1868 [D loss: 0.4537269324064255 | D accuracy: 78.125] [G loss: 1.366485357284546]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1869 [D loss: 0.45613332092761993 | D accuracy: 78.125] [G loss: 1.353049397468567]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1870 [D loss: 0.39131487905979156 | D accuracy: 85.9375] [G loss: 1.3978385925292969]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1871 [D loss: 0.5669627785682678 | D accuracy: 78.125] [G loss: 1.5450525283813477]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1872 [D loss: 0.5480325520038605 | D accuracy: 73.4375] [G loss: 1.6166620254516602]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1873 [D loss: 0.4841069281101227 | D accuracy: 76.5625] [G loss: 1.3301897048950195]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1874 [D loss: 0.5373056530952454 | D accuracy: 76.5625] [G loss: 1.3563445806503296]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1875 [D loss: 0.40289877355098724 | D accuracy: 87.5] [G loss: 1.2352931499481201]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1876 [D loss: 0.46176451444625854 | D accuracy: 78.125] [G loss: 1.3364912271499634]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1877 [D loss: 0.4993453919887543 | D accuracy: 78.125] [G loss: 1.202219009399414]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1878 [D loss: 0.39430559426546097 | D accuracy: 82.8125] [G loss: 1.6286725997924805]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1879 [D loss: 0.5222154855728149 | D accuracy: 76.5625] [G loss: 1.7388279438018799]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1880 [D loss: 0.4721851199865341 | D accuracy: 79.6875] [G loss: 1.4541585445404053]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1881 [D loss: 0.4338051676750183 | D accuracy: 78.125] [G loss: 1.5719106197357178]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1882 [D loss: 0.4939460903406143 | D accuracy: 78.125] [G loss: 1.3242149353027344]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1883 [D loss: 0.4586831331253052 | D accuracy: 78.125] [G loss: 1.3398983478546143]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1884 [D loss: 0.47965873777866364 | D accuracy: 71.875] [G loss: 1.229076862335205]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1885 [D loss: 0.479731947183609 | D accuracy: 73.4375] [G loss: 1.6453580856323242]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1886 [D loss: 0.4903586506843567 | D accuracy: 76.5625] [G loss: 1.5744845867156982]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1887 [D loss: 0.5313293933868408 | D accuracy: 75.0] [G loss: 1.412108063697815]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1888 [D loss: 0.6028358936309814 | D accuracy: 73.4375] [G loss: 1.3401999473571777]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1889 [D loss: 0.49898624420166016 | D accuracy: 75.0] [G loss: 1.3913404941558838]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1890 [D loss: 0.5333170294761658 | D accuracy: 70.3125] [G loss: 1.3217356204986572]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1891 [D loss: 0.48677363991737366 | D accuracy: 71.875] [G loss: 1.6157193183898926]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1892 [D loss: 0.4815077781677246 | D accuracy: 76.5625] [G loss: 1.3993514776229858]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1893 [D loss: 0.5169015228748322 | D accuracy: 71.875] [G loss: 1.200713038444519]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1894 [D loss: 0.4963963180780411 | D accuracy: 75.0] [G loss: 1.3264763355255127]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1895 [D loss: 0.4190743565559387 | D accuracy: 84.375] [G loss: 1.3397347927093506]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1896 [D loss: 0.5060060620307922 | D accuracy: 75.0] [G loss: 1.6108667850494385]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1897 [D loss: 0.5419057309627533 | D accuracy: 76.5625] [G loss: 1.4805617332458496]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1898 [D loss: 0.40355922281742096 | D accuracy: 85.9375] [G loss: 1.253413200378418]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1899 [D loss: 0.6084519326686859 | D accuracy: 70.3125] [G loss: 1.3534836769104004]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1900 [D loss: 0.4466875493526459 | D accuracy: 81.25] [G loss: 1.5366685390472412]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1901 [D loss: 0.4371597468852997 | D accuracy: 82.8125] [G loss: 1.2968361377716064]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1902 [D loss: 0.43810364603996277 | D accuracy: 79.6875] [G loss: 1.264066457748413]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1903 [D loss: 0.4260769784450531 | D accuracy: 84.375] [G loss: 1.4711127281188965]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1904 [D loss: 0.47409720718860626 | D accuracy: 73.4375] [G loss: 1.401506781578064]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1905 [D loss: 0.4717983901500702 | D accuracy: 79.6875] [G loss: 1.5238351821899414]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1906 [D loss: 0.41817761957645416 | D accuracy: 84.375] [G loss: 1.4504148960113525]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1907 [D loss: 0.47140833735466003 | D accuracy: 75.0] [G loss: 1.635080337524414]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1908 [D loss: 0.3602009564638138 | D accuracy: 85.9375] [G loss: 1.3987408876419067]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1909 [D loss: 0.4801453948020935 | D accuracy: 76.5625] [G loss: 1.3381818532943726]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1910 [D loss: 0.629892110824585 | D accuracy: 68.75] [G loss: 1.416887640953064]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1911 [D loss: 0.49040286242961884 | D accuracy: 76.5625] [G loss: 1.4605387449264526]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1912 [D loss: 0.515395849943161 | D accuracy: 75.0] [G loss: 1.3293761014938354]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1913 [D loss: 0.49972929060459137 | D accuracy: 73.4375] [G loss: 1.3944916725158691]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1914 [D loss: 0.37667593359947205 | D accuracy: 87.5] [G loss: 1.5011454820632935]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1915 [D loss: 0.4827464818954468 | D accuracy: 79.6875] [G loss: 1.2759454250335693]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1916 [D loss: 0.4225022941827774 | D accuracy: 84.375] [G loss: 1.3474173545837402]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1917 [D loss: 0.43011274933815 | D accuracy: 79.6875] [G loss: 1.6011230945587158]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1918 [D loss: 0.509196937084198 | D accuracy: 73.4375] [G loss: 1.402995228767395]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1919 [D loss: 0.4340914487838745 | D accuracy: 84.375] [G loss: 1.3910086154937744]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1920 [D loss: 0.45901671051979065 | D accuracy: 73.4375] [G loss: 1.2308096885681152]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1921 [D loss: 0.5094101130962372 | D accuracy: 75.0] [G loss: 1.4260737895965576]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1922 [D loss: 0.4901132434606552 | D accuracy: 79.6875] [G loss: 1.359187364578247]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1923 [D loss: 0.44313497841358185 | D accuracy: 76.5625] [G loss: 1.4437062740325928]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1924 [D loss: 0.41205334663391113 | D accuracy: 85.9375] [G loss: 1.4251147508621216]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1925 [D loss: 0.5663853883743286 | D accuracy: 73.4375] [G loss: 1.1685141324996948]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1926 [D loss: 0.48020119965076447 | D accuracy: 79.6875] [G loss: 1.4217149019241333]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1927 [D loss: 0.4953760802745819 | D accuracy: 78.125] [G loss: 1.3167943954467773]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1928 [D loss: 0.4568285197019577 | D accuracy: 79.6875] [G loss: 1.3071508407592773]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1929 [D loss: 0.43659381568431854 | D accuracy: 76.5625] [G loss: 1.387365698814392]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1930 [D loss: 0.40256765484809875 | D accuracy: 79.6875] [G loss: 1.4063775539398193]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1931 [D loss: 0.3707428127527237 | D accuracy: 81.25] [G loss: 1.4736311435699463]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1932 [D loss: 0.3507431596517563 | D accuracy: 89.0625] [G loss: 1.3024113178253174]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1933 [D loss: 0.5274648368358612 | D accuracy: 76.5625] [G loss: 1.4386646747589111]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1934 [D loss: 0.4643460214138031 | D accuracy: 78.125] [G loss: 1.3858197927474976]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1935 [D loss: 0.4617161303758621 | D accuracy: 71.875] [G loss: 1.6159069538116455]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1936 [D loss: 0.6394224166870117 | D accuracy: 70.3125] [G loss: 1.4283136129379272]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1937 [D loss: 0.443925604224205 | D accuracy: 78.125] [G loss: 1.3973352909088135]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1938 [D loss: 0.4813924729824066 | D accuracy: 79.6875] [G loss: 1.5552237033843994]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1939 [D loss: 0.4199303537607193 | D accuracy: 85.9375] [G loss: 1.3074250221252441]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1940 [D loss: 0.45129770040512085 | D accuracy: 76.5625] [G loss: 1.1756880283355713]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1941 [D loss: 0.47475653886795044 | D accuracy: 71.875] [G loss: 1.336454153060913]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1942 [D loss: 0.43621690571308136 | D accuracy: 81.25] [G loss: 1.338897943496704]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1943 [D loss: 0.5143068730831146 | D accuracy: 76.5625] [G loss: 1.407470703125]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1944 [D loss: 0.5057137608528137 | D accuracy: 75.0] [G loss: 1.3905670642852783]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1945 [D loss: 0.5298764407634735 | D accuracy: 75.0] [G loss: 1.4657174348831177]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1946 [D loss: 0.4426017850637436 | D accuracy: 79.6875] [G loss: 1.5263328552246094]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1947 [D loss: 0.41841238737106323 | D accuracy: 81.25] [G loss: 1.4568158388137817]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1948 [D loss: 0.5054831653833389 | D accuracy: 73.4375] [G loss: 1.507256031036377]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1949 [D loss: 0.47722694277763367 | D accuracy: 73.4375] [G loss: 1.379678726196289]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1950 [D loss: 0.4173220247030258 | D accuracy: 82.8125] [G loss: 1.3978843688964844]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1951 [D loss: 0.5106556713581085 | D accuracy: 81.25] [G loss: 1.5322028398513794]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1952 [D loss: 0.49087876081466675 | D accuracy: 76.5625] [G loss: 1.4978923797607422]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1953 [D loss: 0.49082696437835693 | D accuracy: 76.5625] [G loss: 1.2824223041534424]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1954 [D loss: 0.43934665620326996 | D accuracy: 81.25] [G loss: 1.1998212337493896]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1955 [D loss: 0.5180216282606125 | D accuracy: 70.3125] [G loss: 1.489694595336914]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1956 [D loss: 0.5297226458787918 | D accuracy: 75.0] [G loss: 1.3273223638534546]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1957 [D loss: 0.34596334397792816 | D accuracy: 90.625] [G loss: 1.4572007656097412]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1958 [D loss: 0.42140962183475494 | D accuracy: 81.25] [G loss: 1.3402986526489258]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1959 [D loss: 0.5347164571285248 | D accuracy: 78.125] [G loss: 1.3615210056304932]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1960 [D loss: 0.4616111218929291 | D accuracy: 79.6875] [G loss: 1.4670683145523071]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1961 [D loss: 0.42748594284057617 | D accuracy: 81.25] [G loss: 1.4568288326263428]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1962 [D loss: 0.5116213858127594 | D accuracy: 71.875] [G loss: 1.3255301713943481]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1963 [D loss: 0.4465245306491852 | D accuracy: 76.5625] [G loss: 1.5442819595336914]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1964 [D loss: 0.43544819951057434 | D accuracy: 79.6875] [G loss: 1.3731403350830078]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1965 [D loss: 0.45311421155929565 | D accuracy: 75.0] [G loss: 1.4519386291503906]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1966 [D loss: 0.6328631341457367 | D accuracy: 64.0625] [G loss: 1.5208001136779785]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1967 [D loss: 0.49490001797676086 | D accuracy: 81.25] [G loss: 1.409794569015503]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1968 [D loss: 0.5886045694351196 | D accuracy: 68.75] [G loss: 1.4782624244689941]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1969 [D loss: 0.4331609457731247 | D accuracy: 82.8125] [G loss: 1.3175468444824219]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1970 [D loss: 0.48878102004528046 | D accuracy: 75.0] [G loss: 1.400351881980896]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1971 [D loss: 0.5376058667898178 | D accuracy: 70.3125] [G loss: 1.4349937438964844]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1972 [D loss: 0.45242248475551605 | D accuracy: 76.5625] [G loss: 1.3791759014129639]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1973 [D loss: 0.5093376338481903 | D accuracy: 73.4375] [G loss: 1.4281163215637207]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1974 [D loss: 0.49008530378341675 | D accuracy: 71.875] [G loss: 1.2781704664230347]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1975 [D loss: 0.4856523275375366 | D accuracy: 75.0] [G loss: 1.345740556716919]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1976 [D loss: 0.4933241754770279 | D accuracy: 81.25] [G loss: 1.2272589206695557]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1977 [D loss: 0.626410186290741 | D accuracy: 65.625] [G loss: 1.332749605178833]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1978 [D loss: 0.549053430557251 | D accuracy: 68.75] [G loss: 1.286895751953125]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1979 [D loss: 0.4235769659280777 | D accuracy: 84.375] [G loss: 1.3797084093093872]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1980 [D loss: 0.45879870653152466 | D accuracy: 81.25] [G loss: 1.362666368484497]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1981 [D loss: 0.46449142694473267 | D accuracy: 79.6875] [G loss: 1.462673306465149]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1982 [D loss: 0.44228796660900116 | D accuracy: 81.25] [G loss: 1.3493595123291016]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1983 [D loss: 0.37761634588241577 | D accuracy: 85.9375] [G loss: 1.3827054500579834]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1984 [D loss: 0.5227396190166473 | D accuracy: 73.4375] [G loss: 1.2642322778701782]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1985 [D loss: 0.5078725814819336 | D accuracy: 73.4375] [G loss: 1.089015007019043]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1986 [D loss: 0.5094372928142548 | D accuracy: 75.0] [G loss: 1.3642923831939697]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1987 [D loss: 0.604459747672081 | D accuracy: 62.5] [G loss: 1.5183173418045044]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1988 [D loss: 0.5278472006320953 | D accuracy: 70.3125] [G loss: 1.5652822256088257]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1989 [D loss: 0.5157399773597717 | D accuracy: 78.125] [G loss: 1.4245482683181763]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1990 [D loss: 0.40107642114162445 | D accuracy: 76.5625] [G loss: 1.3836700916290283]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1991 [D loss: 0.41503289341926575 | D accuracy: 82.8125] [G loss: 1.4591236114501953]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1992 [D loss: 0.5138468444347382 | D accuracy: 78.125] [G loss: 1.3631575107574463]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1993 [D loss: 0.505457192659378 | D accuracy: 78.125] [G loss: 1.5178556442260742]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1994 [D loss: 0.43518468737602234 | D accuracy: 78.125] [G loss: 1.4154338836669922]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1995 [D loss: 0.5000098645687103 | D accuracy: 73.4375] [G loss: 1.40675687789917]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1996 [D loss: 0.5925216823816299 | D accuracy: 65.625] [G loss: 1.4628355503082275]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1997 [D loss: 0.40522629022598267 | D accuracy: 81.25] [G loss: 1.501053810119629]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1998 [D loss: 0.47520455718040466 | D accuracy: 81.25] [G loss: 1.4266780614852905]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1999 [D loss: 0.43124693632125854 | D accuracy: 81.25] [G loss: 1.4319021701812744]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2000 [D loss: 0.5443538129329681 | D accuracy: 75.0] [G loss: 1.5464273691177368]\n",
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFJCAYAAADkLDW5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkwklEQVR4nO2debRUxbWHNzIL6DWCIA4gg8oUQJl5gswoKEYQNDGC8xh9CaJPnxExJksTg6CCiYhDFAQ1ghIRFEXDJJOioCAIiAMOaAScQLzU++O9W+87Rde1u29fLml/31qute17+pw6NXXx27V3lXPOORNCCCHEj5r9yroAQgghhCh7tCAQQgghhBYEQgghhNCCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEML2kQVB/fr1bdiwYWVdDJECtc2+idpl30Vts++itimeUl0QrF+/3i6++GJr0KCBValSxQ444ADr3LmzjR071r799tvSfHSp8uGHH9rgwYOtoKDADjjgABswYIBt2LChrIuVEfnYNm+//bb9+te/tk6dOlmVKlWsXLly9u6775Z1sTIiH9vlySeftCFDhliDBg1s//33t2OOOcaGDx9uW7duLeuiZUQ+ts20adOsT58+VrduXatcubIdfvjhNmjQIFu1alVZFy0j8rFtQnr16mXlypWzK664otSeUaG0bvzMM8/YGWecYZUrV7ZzzjnHmjdvbt99953Nnz/fRowYYW+++abde++9pfX4UuOrr76ybt262bZt2+z666+3ihUr2h133GFdu3a1FStW2MEHH1zWRfxB8rVtFi1aZHfeeac1bdrUmjRpYitWrCjrImVEvrbLRRddZHXr1rWzzz7bjjzySFu5cqXdfffdNnPmTHv11VetatWqZV3EHyRf22blypV20EEH2VVXXWU1a9a0jz/+2O6//35r166dLVq0yFq2bFnWRfxB8rVtyJNPPmmLFi0q/Qe5UmDDhg2uevXq7thjj3WbN2/e4+/r1q1zY8aM8f9fr149N3To0NIoSs657bbbnJm5JUuW+M9Wr17typcv76677royLFl65HPbfP7552779u3OOef+9Kc/OTNzGzduLNtCpUk+t8vcuXP3+Oyhhx5yZuYmTJiw9wuUIfncNqn4+OOPXYUKFdzFF19c1kX5QX4MbfPtt9+6+vXru5tvvtmZmbv88stL7VmlsiC45JJLnJm5BQsWpHV92Eiff/65Gz58uGvevLmrVq2aq1Gjhuvbt69bsWLFHt+98847XdOmTV3VqlVdQUGBO/74492kSZP837dv3+6uuuoqV69ePVepUiVXq1Yt17NnT7d8+XJ/zddff+1Wr17ttmzZ8oNlbdu2rWvbtu0en/fu3ds1bNgwrfctS/K5bci/24Lgx9IufIaZud/85jdZfX9v8mNrm927d7sDDjjADRkyJKvv701+DG0zatQod+SRR7pvvvmm1BcEpbKHYMaMGdagQQPr1KlTVt/fsGGDTZ8+3fr372+jR4+2ESNG2MqVK61r1662efNmf92ECRPsyiuvtKZNm9qYMWNs1KhR1qpVK1u8eLG/5pJLLrF77rnHBg4caOPHj7err77aqlataqtXr/bXLFmyxJo0aWJ33313seXavXu3vfHGG9amTZs9/tauXTtbv369ffnll1m9894iX9vm350fW7t8/PHHZmZWs2bNrL6/N/kxtM3WrVtty5YttnLlSrvgggts+/bt1qNHj6zed2+S723z3nvv2a233mq33Xbb3nGt5XqFsW3bNmdmbsCAAWl/J1y17dixwxUWFiau2bhxo6tcubK7+eab/WcDBgxwzZo1K/beBx544A+uqObOnevMzI0cObLY67Zs2eLMLFGGIsaNG+fMzK1Zs6bYe5Ql+dw2If9OCsGPqV2KOP/881358uXd2rVrs/r+3uLH0jbHHHOMMzNnZq569eruhhtu2KPM+xo/hrYZNGiQ69Spk/9/K2WFIOebCrdv325mZjVq1Mj6HpUrV/Z2YWGhbd261apXr27HHHOMvfrqq/5vBQUF9sEHH9jSpUutbdu2Ke9VUFBgixcvts2bN1vdunVTXnPiiSfa/9Z18RTtVmX5iqhSpUrimn2RfG6bf2d+bO0yefJkmzhxol1zzTXWuHHjrO6xt/ixtM0DDzxg27dvtw0bNtgDDzxg3377rRUWFtp+++0Tkekpyfe2mTt3rv39739PqBClTc5b+4ADDjAzK5F0vnv3brvjjjuscePGVrlyZatZs6bVqlXL3njjDdu2bZu/7tprr7Xq1atbu3btrHHjxnb55ZfbggULEvf64x//aKtWrbIjjjjC2rVrZzfddFPWIYJFks3OnTv3+NuOHTsS1+yL5HPb/DvzY2qXefPm2fnnn299+vSx3//+9zm5Z2nyY2mbjh07Wp8+fezSSy+12bNn2yOPPGLXXXddie9bmuRz23z//fd25ZVX2i9/+cvoAqRUKA3ZoW7duhltsAtlnN/97nfOzNx5553nHn30UTd79mz3/PPPu2bNmrmuXbsmvvvVV1+5KVOmuGHDhrnatWs7M3M33nhj4prNmze7cePGuQEDBrj999/fValSxc2cOTPj9yosLHSVK1d2l1566R5/u+GGG5yZ+V3u+yr52jYh/04uA+d+HO2yYsUKV1BQ4Nq0aeO+/PLLEt1rb/JjaJuQs846y9WpUyen9ywN8rVtJk6c6CpWrOgWLFjgNm7c6P8zM3fOOee4jRs3uq+//jrj+/4QpbIguOiii5yZuYULF6Z1fdhILVu2dN26ddvjusMOO2yPRiI7d+50/fr1c+XLl3fffvttyms++eQTd9hhh7nOnTunVbaQNm3apIwy6NWrl2vQoEFW99yb5HPbkH+3BUG+t8s777zj6tSp444++mj36aefZn2fsiDf2yYVp512mqtatWpO71ka5GvbjBw50u/piP03bdq0jO/7Q5SKg+iaa66xatWq2QUXXGCffPLJHn9fv369jR07Nvr98uXL7+Fnefzxx+3DDz9MfPb5558n/r9SpUrWtGlTc87Zrl27rLCwMCH7mJkdcsghVrdu3YTs/80339iaNWvss88++8F3GzRokC1dutSWLVvmP3v77bftxRdftDPOOOMHv1/W5HPb/DuTz+3y8ccfW+/evW2//faz2bNnW61atX7wO/sS+dw2n3766R6fvfvuu/bCCy+kjKba18jXtjnzzDNt2rRpe/xnZnbyySfbtGnTrH379sXeIxtKJVNhw4YNbfLkyTZkyBBr0qRJInvUwoUL7fHHHy82n3T//v3t5ptvtnPPPdc6depkK1eutEmTJlmDBg0S1/Xu3dvq1KljnTt3ttq1a9vq1avt7rvvtn79+lmNGjVs69atPhVny5YtrXr16jZnzhxbunSp/fnPf/b3WbJkiXXr1s1GjhxpN910U7Hvdtlll9mECROsX79+dvXVV1vFihVt9OjRVrt2bRs+fHhJqm2vkM9ts23bNrvrrrvMzLx/7+6777aCggIrKCgo1ZSfJSWf26Vv3762YcMGu+aaa2z+/Pk2f/58/7fatWtbr169sqqzvUU+t02LFi2sR48e1qpVKzvooINs3bp1NnHiRNu1a5fdeuutJam2vUK+ts2xxx5rxx57bMq/HXXUUXbaaadlUk3pk3PNAaxdu9ZdeOGFrn79+q5SpUquRo0arnPnzu6uu+5yO3bs8NelCgUZPny4O/TQQ13VqlVd586d3aJFi1zXrl0TMs5f//pX16VLF3fwwQe7ypUru4YNG7oRI0a4bdu2Oef+V9YZMWKEa9mypatRo4arVq2aa9mypRs/fnyinJmGgrz//vtu0KBB7oADDnDVq1d3/fv3d+vWrcu6nsqCfGybIh9bqv/q1atXkuraa+Rju8TaxMyKlWX3NfKxbUaOHOnatGnjDjroIFehQgVXt25dd+aZZ7o33nijRHW1t8nHtkmFlXLYYbn/e4gQQgghfsTsu0GmQgghhNhraEEghBBCCC0IhBBCCKEFgRBCCCFMCwIhhBBCmBYEQgghhDAtCIQQQghhGWQqPPDAA73NI0vffvttbxcWFnq7YcOG3v7iiy+8XXQqoJnZ1q1bE8+oVq2at7/77jtv79q1y9vVq1f3NlNFlitXztux1Ao8ypPX8/NKlSqlfG54Tx6byb/x+7yG6St3797t7bAOsoF1wvcqOg3M7P+PZw7LQnhq2EEHHRT9G9u5fPny3ua7d+zY0dt16tTxdvPmzb29YsUKbz/zzDMp7/nNN9+kLHdBQYG3//WvfyXKyn7EcvP7LCvfh30hVk/pwjpnuxD289hRs+xf4dHbbHu+65FHHuntmjVrenvlypXeZia09957z9vs902aNElZvqKjZ80skTKWZfj++++j78ExwLqhzXZhXw7TyGZDOnXNfsjP+V2+R4UKyemUbfDVV195+5BDDvE265fttGXLFm+vXbvW27HsdeyrCxcu9DbnXtZnOJ/xncJ2KyI2x/K92Xeygf2b9+Wx8nx2bFzxfVjHZmbHH398yuuOPvpob3NOYX1+/PHH3ua8xv7JlM8c32vWrPH2okWLvM13C9+H/Wb//ff3No98Zlk5L7JPsB8UhxQCIYQQQqSvEHCl89Zbb3k79q8u/suO/4KoWrWqt1u3bp14BldQXAXS5ooptjqMrWS5mufqP7Zy5vX8156Z2U9+8hNvc4XGeoqVlXWQC1hO2lwV8vm8pmLFiik//+ijjxLP4Gqd9zr44IO9fcQRR3i7UaNG3uaq/4MPPvA2+8vgwYO9PWPGDG9z1U416uuvv/Y229IsqUKxPQifzT4c/iuvJMQUAv4LjP+iorLBMvH6bt26JZ7BscV+eO6553p76dKl3l63bp232XZ89s9//nNvn3jiid7mv0qee+45b48fP97bq1ev9nZsfJolxxyJKWlUJHJB7F+ZMYWCsFz8Fyb/dWZmiUN1+K/J119/3ds9e/ZM+f1XX33V2++//763qbxRKWFbUgUaNWqUtzdv3uztUFVjH4vNn5y3jjrqKG+nOiApW/g8juN0FOCYihOqarwX5xTW7cCBA73NOuShR3Xr1vU224KKAhUd/mZs2LDB2xzDl1xySaKs7Guc89gWnGdo165d2zJFCoEQQgghtCAQQgghRAYuA0qpMSmNstOmTZu8TSmHZ6F36tQp+n1Ky5TeY8+mBEw5hcdY8h14HvX69etT3p/SEu9vlpSCDjvsMG9TkuVmoJgEnAsoi1O2p4xF+Y2bU/iO9erV83Yoy5166qneZn3xvpdddpm3p0yZ4m1uUOzTp4+36SLq2rWrt1lXPOaTfeK2227zdngOeTqbkdgGxW22Kgmhm6kIutMIy0Gp8NBDD/U2N+uaxdt+2bJl3ubGQ445SpCUpblxatasWd7mJjnKxJTDOfZCmZ/P4MY6jm+6fzhXUGLNNSVpc/a1Zs2aJf5GdxfrlGOOMj5dfJT0We/khRde8PYJJ5yQshyUwdkf77vvvsS92Aax+ojNz9xIWlJYnywHXSLsezE3ATcS3nnnnYlncGPz008/7W2OS7ry2Hac63kN5fm2bdt6m3MwxyddD2wjzsFmyfmL8yI3o/O9WdZsXDlSCIQQQgihBYEQQgghMnAZUNagVEX5i7tkKWlQsqQsGu5kpyxIOSa2Q5vyJCUlSiuUb7jbmtIUd9pTfuHnlDjNklIVZRp+TgmKO10Zs5oLYmWhnMxrWD+xPAKhrE15/5RTTvH2/fff723WKXfO0nXC+Oo33njD23ThHHfccd6my4dyN+VnumnMki6KiRMnepv1QSmOFLczPlP4PEqNdHHQNUCpl+148skne/vGG29MPIPvx3qjjMu65Xu/++67KcvKOG2OQ0YZ8B3Yb9i3w/HNPsg5gXXDMf3OO+94O8yLUVLS2bUeg3MEd9tzN7pZst6nT5/ubb4vd7l3797d22wnunYYDcI5j/MtXRUcM5zP6OozS+YBYU4KwmezfHRBlpRYu7AOYnkP2A/pWmNUnFnSxcXxt2rVKm9z/mLkTJcuXbzNOZK/a4cffri36QbieGAfYll79eqVKGv79u29/eCDD6YsN+uD7RpzWRaHFAIhhBBCaEEghBBCiAxcBhs3bvR2LO0o5ZFYQgXK1c8//3ziGZRgKBdR6qKkSHmyadOm3qaExWQQTA3KXbWUQimdtmzZMuX9zZIyOP9GaZNSE+WbMClISaFUFkvtHEtGxHen1Mj3M0uW/29/+5u36QLgzn9GmbA9WCYm9li+fLm32a5z5szxNt1FlPfCtJx8NtuDfYrlptzHuikp7M/sV+yT3EHOZCiM5Hjssce8HSa/oUTYqlUrb9P9xrZnG7OeOnTo4G2mJmc9s/4ZFdKvXz9vz50719vciW6W3PXM+9Ktx4Q8TJfOOaSs4Rz0xBNPeDt0K3Kcn3TSSd5mX+CcRBmZ8jyjNdgGTP7FSBT2efYJPpftbWY2e/Zs+yHolqCrkf25pHCMxlKkUyJnfVDO53wVRiGxjz366KPe5ljknELXDOcySv2MVmC/pWuTfb5///7epusuHDO/+c1vvP3www97O51EUuFckQ5SCIQQQgihBYEQQgghMnAZxHZ5ppPUJSbJhif98W+UzLhDn7vOmdwhdmocpZWhQ4d6m7vjeToVdzbzc+6sNzO7/fbbvX3MMcd4m5I9JUTKatx9nAv4jpSpYxEgTKpEeZ73oZxvlnwvSqbcsUtJmO9IlwZ3v7ON2UdmzpzpbUpusYiIMNET5dNY5EQsORTl9ZLCZ8T6PZOVUL6kK4d1Eyap4S5yRoK8+eab3q5fv763KSc/+eST3mYCFdbByy+/7O2f/vSn3m7RooW32S6MUHjttdcSZWWOffYhfp9yK+smvFdZwrFEOTk8U4PEEoaxnenG4k51tj/nYX5Om/2OcyTrNpSTf/WrX3l7xIgRKe8VS+zFcpeU2GmJnDfYdziuGKVBd1joymGbde7c2dt0AbB+GMXEdiH8Lscb5yK2O91JdEPQnWFm9oc//MHbsbNO0nHhp4sUAiGEEEJoQSCEEEKIDFwGlIBjuz8pz3L3MyX82FGjIUx8wYgASkqUzyiPcPctZWyWiWWlPMSd3swzHuaYvuKKK7zN+mCiklhUA+sjF7ANYgl3WEbWIZOQUMoOc+avWLHC23QZxWxK03T50LXDNqDsFYsA4TWU/8NET0wAwoRalP7YX1gfsbMysoFSIOuG7pghQ4Z4e8mSJd7m+/3iF7/wNpMUmcWPBmedcJc6y8GIA0bKsG7oAqC7gpInXVDs25Rmw2dT6qWbjn2QsnTsGOuygK4TytHcLW6WLD/nKkrH3AHPZFS0KX/36NHD26xDzmGx5zJqKoym4fHjjBZiOUjsCPSSks6ZOXS/sg/TposhPIeGifUYjcNICyaPYr3xvnxvzvusf0r7PEqciY9eeuklb4cJuDiOOSdzTHOOjEVjpIsUAiGEEEJoQSCEEEKIDFwGlEFikneYH7uIWB79EN435paglMrrKZn98pe/9DZdBpRjuOOWMiXlT0pNCxYsSJSVu+6fffZZbw8aNMjbZ5xxhrfvuuuulOXOBawf2rEkGsyZT/mSZwtQfjZL1i//xvZk29CmtMadspS6YpEIsWOAKYdRrjNLJjOiO4DfYfvzebk8/ph1QzmZbh3mv6csThcV227MmDGJZzDChe/BI165M5rtyPtSlma7sA/RFcfEL3QJFee+irk3YhFMfEauXQYlOcuAZ0awfxaXcIzRUXS9cPzxuGeOH7qY2DaEx+/GjsPle4YREWxDutmmTZuW8nkkPOa6JLCMbCP2Yb4fEy/xetYx+61ZMiqC0TL8rWD90BXB8cDEeuzDvIbtxYgGzsF0T/Aas6Q7gb9B/H3k7y4jMLI5lloKgRBCCCG0IBBCCCGEFgRCCCGEsAz2ENBvQzuWJYmf0y8Uu49Z0i8SO8CC9+X36StmOeg/or+VMKsb/Wf0gTKLnFnSB7Rs2TJv0xd34YUXevuOO+7wdjbhIMURq2uGFv385z/3NkOl6Eu//vrrU35ulvSBMiMew1Hpy+I70q9Ffz+zqNFHSP8ybfr7GI4TZhdkqBzLx4NDuG8kVn8lJZa5jv5wthE/pz+TWTLDTGYMF2Q/pl+XbcnnMaMaDzSKtSl9o7GQYR7oFb4/+wFttjEzX15++eXeZia9XFBcyHMquMeF8w73iYRhctzLwrA+9j3uFeD+GrY//crsn/QRc/7jPdnnOSbDtmF9cG8J35XPjmUtLCmxUEOG6XHu5VzGcFC+TziXMcyVvw+xQ/jYXq+//rq3OWcxLJt7PrgXiPenzdBv9hkzs4ULF3o7liEztv+quP16MaQQCCGEEEILAiGEEEJk4DIglGNiIW+UKygvxVwM4d8yfTYlT8rJPPyFMgtDhCiLUmqlTMUwQ7OkfEOboVKU0iiFhZmzSgrrhM+hdLhx40ZvM2Mf3SLMmhYe4sHQmFiIGiVJyp+xumJdhweQpIKSNcPqmFHSLOnSYPkop7GsMcmtpPBAGz6DGSx79erl7fnz53ubYYoMk2J4WXivU0891dszZszwdswlwn7DuuW57ewfPJyIY4ltx/szM5uZ2eLFi70dGxvss3Rd5DpUN9NDrCgDt27d2tucR8Lsnmy32KFNnGPYR9566y1vx0Kt2V+aNGnibbpd2F+KO3yJh0fRDZXpnFxSWAd0oXFOZ10yLDKWfTbmKg6f8c9//jPlvTjG6DplGDT7B8cDQwU5ZmKuGGZFDN+DYY4MJ+W8zd/dMBtlOkghEEIIIYQWBEIIIYTIwGUQk+pju2xjO1JJcTu6KSlSfuZuWsra//jHP7zNHZzMTsjycbc2d5FSLqVEGkrolEMpUZ933nnepoR45plnevu5556zXMIMZ9xVzDbjLljKkWxLymFhljlmMWR9cTc024YHkFC2p/THXe6sK0ZtxGRAyqjhLmL+P69jX43tmC9OVs0UZqGjXMg2euKJJ7zNnfcsHyXmNm3aJJ5BWZ3fp6zNOqBL5OWXX/Y2D82hDM7vUnqN7QbneKNrySzZvxgJQvmTsu3UqVO9nUtZOl0o61533XXepkTLduI8ZZaU6zk2YtEkdGNx5zmfx/HTs2dPb1PWptuSrgS6Rjk+zZJtw2ieWLQXyWUWSY53zkF0L9KlwT7JPk8Xcph1lYd3sX8zSy1dknSxsr05july6devn7dfeeUVb9MNSFchpf2wXfhsjm/OcZwD2EbZRExJIRBCCCGEFgRCCCGEyMBlwN2mlF4z3a2bLpRuKYNQDqO0RTmFknbsYCVKYZTbmDiH96cEZZaUgGMH0Xz00Ucpy51LWdosKdkxMRLlN5aX1zN6ghJdKF3FZPhYghJez123lNlYD3RJ8P6UiinLcTdueLgK65oy4Pvvv+9tyvn8fkwKzwb2Je5IpkxMyZOJmijtL1++3NtMnGUWbzM+I5ZUh/InZUu63Bhdwr7CMUYpdPTo0d6mpG2WbFe+E5/N94mVe2/Bvke3HF0cTAbFMWZmNm/ePG937drV2xwznLcYLcNIAY7XRx55JOU1vA8P41m7dm3KdwiTo7E9+d7puGpy2Taxe7EOOA+wDjiOi3PL0n1DdwznBM6j7JMcl3Q708XD9qXLhnVJ1xp/Q++///5EWTds2JDyvnQT8H2IXAZCCCGEyAotCIQQQgiRvssgFjUQO9cgGyipUPaldNi+fXtvc1cp5RtKmJT3KF1TiqFUy0RGw4YN83a4g5jy+MUXX+xtSlvc1cvEFdkkjCgOSl2x3cxz5871NuuTsnFxu4W5C5n1Syk85uah1ExZlP2IO4FZ13TnUB6kRMd6Nku6begyoGTNyIfJkyd7O9wZXxLYFoyoYBQF5fmTTjrJ208//bS3jzvuOG+HMiB3TNNFwf7Nvsc25tile4tyK3O9021GiZlydffu3b1N2dXMrG3btt5m4iTKqpRC6eIL71VSONfEpFW6jygts7ysk1CG5zPY7+liZJ+mm43zHMcVxwbHLtuSfZtzHmXqMGKAdcAxzbHEaCqSS7cxxyjnSfYrRgDwXAMmeWJfY1SVWbK/8hns92xXugz4XUaR0OaZCuzPdJMtWrQoZfnoDjFL9iH2rzByooh0ovuKQwqBEEIIIbQgEEIIIUQGLoOYHJwpxe1ajR0LTImbMix3rDOhCXesU6qjdE3ZjvIqpVA+i64Hs6QUR6kqlju8VatW3qaEmwtiUQuUwyi/suysW7ZrmJiI7x87EpcSK90YLAflxdjOZrqLeB9+zudSdjdLuhO4s5o7rpmoKba7uKRQhn/22We9zRz3rEvWDWVbysShPMs+zffu1q2bt2PJc+hyo+T85z//2dsxtwfrNXbcLiMUzJKSM9uSbc/kU4R1Vhaw7JTROfbCczBi0VGsL7bZkiVLvD1kyJCU3+U4Zv1yjLHNONfEjv01S7Yn24NHL8dcBrmMMuAcwvqjlE7Xyvr1671N9wvdCpTqzZLuH7oc2K6x5Ec83ptuCfZP/ubE5ixGRPD3KoyY4lzNyCG+K+eZWMRBukghEEIIIYQWBEIIIYTIwGUQk4VixzgSyrDcpRlKity9y52a3JVNyXThwoXepvRGqYmSHp9N+ZPvQAmdcu4zzzyTKCsldcqw3MVNOYu54hnVkAtYJ5TcKK0xaUosKQblqTASgu/IiAPuymdEAGVRSlqU9ylvMZkKE+xQ5qRLiWVlTn6zpFzIxDF8V96Ln4eukpLAfj906FBv89wNXkOplmOB5WNUgVmyf/NdKQmzf/O9+by3337b26x/jge6VriTna4f7qpmxI5ZUp7ldewffF7MhZgLWG+xXfKsH84vHGMvvviit8OjqV966SVvU3bmfenG4s52jhOORdYJ653jm3VIl9Ls2bO9Hbp9WXbeiy6KGLmMMuC9ODbatWvnbc5rPBKYMvrYsWO9He7IHzhwoLc5nvhs9k+6gjin8xrWGedBzifsA0ySRjdBGDHF62LHJ9NlHZvX0kUKgRBCCCG0IBBCCCFEBi4DymSUJbhzkjIx5Xke2UkZKJRHKCHzGGLKZ9z1yugAyjeUtylpM3ELpR/K1ZQvmdSGbguzpPzDd126dKm3ufOU0jd3i+Yaum0oRVFiolzYoUMHb1OGZ/2YJaU13pfvws/5DLY/P+eOctY7JT66jvg56zyMXOHfKMmyj3CnMcll0qjYMassB3c2c2yccMIJ3qb8T9neLBktw7FISZwuIo457oDm8d4ch6xbHgfOvkKbCXUonZolpV6W77TTTvP2ww8/7G261nJ5xkS6sIwnn3yyt3kcNecB1r9Z0kVCFyWvY5+mm4hjJnbcPOuH9+QcwDqnC4PvY5Y88poyN4/y5TkKJJsEODEoc7MfMlIgPGelCP420MVD14pZcp6i+5NjizbPTeFvEccP51FGRMTOX4lF/oSuHD6jf//+3p4zZ4632T9iicfSRQqBEEIIIbQgEEIIIUQGLgNKh5QiYrvteQ2lQ14THhca20VJ+ZoSMF0ATIjCpB7MGU2pllI0y8QdpbHd2WZJGYry7lNPPeVtysFM7EP5MBdwxzfbg21G9wflMLoy+O6hNM3/5y5m1imlPD6bMhY/p3zN+uRua+5+pjuGbR8eTU2ZlDZlREp/fJ90dlWnS+wMB7YF3QosXywC4Mgjj0w8gxIr2y88e6MItiOT0bDtYruT2Z/ZLnSz8P6ha4y7oSkB8/04TthvSpIMLRXpuCA45vku3PnNcz3Ccc35jG6VWFQQXUaUtekWYl/lNbHoGM4N7F90q4Ww3jdu3OjtdM5/yCV8Btvitttu83YYYVQE+yoT/5gl3QS8L+cRJgZjn2Qdcnxz3qCbmu3LdmS9ch4MZX6+B8d0LFEcnxdLWFccUgiEEEIIoQWBEEIIITJwGVCqok1JlpIZr6HsEctZb5bML095hZII5R9KctyRSnmxT58+KZ/HXO+UvZmAiHJ6uIOYR1bS/RBLfhRzXeQC7kKndMUdzJTYKU1ydz+vCcvIXeiMnmCkQOw4VspYLBPLwTajHMbvsv0okbLcZsm+wPzr7Htsp1iu+JLC+9Ltxffj89ifWa+UfUMZMCarst7ojqHbheOS7cLvMpKH45B9jnI45XQeuW2WjOzgrvbYsdt8HuXZXBCTvFmHfCYT4xDWD8e4WfK92CdZvy1atPA2JWH2VbYfXU90kzLH/s9+9jNv830YuRCeGUGJnC5eHsn93//931ba0P3EMrK9pk6d6m32N9YrJfnQ3dSmTRtvsw4553FOYZ0TutzoBuLYYPI9ugc5jlnuMPEY5y+Wm9/nby3rSYmJhBBCCJEVWhAIIYQQIn2XAaUISqGUXmNuBe7ophQza9asxDMon1LK5u5PSkQ8opISG49CHjdunLeZ7IjvQ1mHO54pe4fHr1Je4r2YtIQREUx+FEqLJYXSFROlcAc083yz3pishDupw8Q9rF++O90ilFgpQYc53ougjMod6Kxr9glKdyxfeGRo7NwFPi+MoigidGOVBD7v1VdfTfk5JVJKw3w/1n0Y7UJZkDLp8ccf7226KJgchX2CdchERqxLlpv1xGso87P/myWjKyjj8pwPuuliZ5jkGrYBjwvm3EYZnX1y8ODB3uacZRZ3eXBu5LwQKxPvQzcExz1daBw/sfHJnfBmSdcv+xtdCbFonGx2s8fge9P1MW3aNG/T1cWzDFgf7KvhkcCMxuHvCec1uvjoAli3bp23L730Um9zPnnssce8TZmf7UhXQJjAi9Adx/mP70q3B3+LioskiSGFQAghhBBaEAghhBAiy+OPuUOY0iZ3SFKGp6RECTfcHc5nUH5r3bp1ymdT5uI1CxYs8DZ3qrIcdB+wrJRc6NII5RdKt5SdWKauXbt6m7uRcy1/UkakNE3pkLIUj8mlm4B56MOdtYwI4K5Yyoh0lzCHN5PeUJqmdEf5mruhY/C54Y5pyqSvvPKKtylzUhalpBjeqyTw+F+Wg/VHqZd1zD5JqZcRB2bJyBzuND/uuOO8zeQtjIhhW1AiZT+gHEk3EO/Pd2A/6927d6KsbFe2EcdPLKFSNvJnurAvsN+zPTiuONdQKmYbmyXrMRY1QImccxth+3P+ZF9ghE8sooEy87x58xLPuOCCC7zNdmL7x1wGuTxngnXOfsu59JRTTvH2vffe6+1Ywjze0yxZP/zNmj9/vrf5W0H3Ft+brjXOwXSRshzsKzyHgn2b7nWz5Bjl7xr7EH9PYmdBpIsUAiGEEEJoQSCEEEKIDFwGlK0of1FGiklHlOd5xGd4bC1lL8o0lHUomXFHfd++fb1NWYdRA5T9uKu9Y8eO3qZkyGso/5kl5VlKnpRCWQ7WU0wazBa6I3hvSkZsP0pdlKv4OeVhs6Q8yagPulgog7H9uPudUhd30FJqZntTQuMOcO72pRRqlpTZ6AKIlY+ybUyyzga6leg2YRvRNcCy8l2Ly+PPXeDcxc/2jiXtYt2yrCwH5WNGp7DPs/4YfcCxahZPwsTIApaVMmw6bqRMiCWG4Rg4/fTTvc2oDZblgQce8DajesyS5ef4YV9goiiOK7YBxyLritfwqGXOozHXWni8OWF7sn/SHUp3Xy6h7M9zA9hvH3roIW/TTUl5nnXPujFLuhDo1uLcz+OhOafPnj3b2/wNoFTPd2CdDRw40Nscn/x9DMc6xwP7EG0+LzbHpYsUAiGEEEJoQSCEEEKILBMTUYqgREjZhJIG5RtKKJ07d048g/Inoxco2VBm5g553peSGRNA0Kb0xmdRCosdr2yWlKUp61CGpTRMGTzXR7kyyUhMCqdUz/ZgMg5GBjCJhlnSLUE5mzIk35fyHV0GsR21lOopqfJ9eJ4C2yM8EpiSLndT853YZuzbuXQZUG5lkpUZM2Z4m/12yZIl3mbf/uabb7zNNjVLjj+60CiJh98pgm1KtxnLxERGHNO8J8cbZfNwzFDOpAxO2Zc7tB9//HFv032XC9gP2VdjkRTsO+wjxY1rzm90ldI9w/mG8xzHBt0rdLtwPNBtxrLSZcB5gm1vloyc4Pkv7MOxsREe2VsS2NcJJXa2F+evWGRAOJdxLly8eHFKm+PvP//zP73N358XXnjB25xD6I5hZAH7Nu/PeTM8S4XjjO8auuOKoPtLiYmEEEIIkRVaEAghhBBCCwIhhBBCZLCHgD5z+sDo92/VqpW3GbbxxhtveJvhZQzlMUv6S3r27OltnhlOH8lbb73lbformeGKBx3RB8oDX+iHZSY3+mDCg0voZ6Nvh++wcuVKbz/77LPeznUIFf1XsXPe6T9kPdAnRl9/8+bNE99nXdDPxfAz+hJZDvplGWpK3x7bgNfQlxq75/LlyxNlZRvGnk2b5Q59eCUhNma4N2XIkCHepj+a+12YmY31bWb21FNPefuss87yNrNUsn8yS+Uzzzzjbfo9zznnHG+zTzBTGvcWcCxwT0kYVsywOtYz+wF9yAyjzGW7mCX90PQ3c35h5kH6bLlnhX2HYWhmyf0UHTp08HZsPwL9/Swf93TEwiXpk2Z7M+SOczIPBTJLzgP16tXzNvcb5XrvUyo4N7IPsx9yLuaY4dzLuYJ7LcySezXYRjxoiuGnbFfOnRw/3IPBvSOxPWz87eL7hPM3QyH5ruwH/Jzf596edJFCIIQQQggtCIQQQgiRgcuAchEPoqGESVk0POijCIZ7UZYxMzv11FO9Tdl/zpw53qYczJCdv/zlL96mfMZyUxbl5wwNYTgOw33Cc+jpKqGkxBAqZkmk9Jbrg1piUlksSxYPxKF8SXmdmQDNknImJW/WC+uU0jHDUeky4rMpL7N/8RqGI7IOWbdmSZmN78Ty8Xkx6bWksA+zXebOnetthjotWrTI2+w7HDOU6sPvU7ZknU+ZMsXbHHMMv2JWPsrHlJ9jmQ3phqAETsnXLBlGyLHLOo9lkXvwwQctl8Rca3wv1hVlZpaXrji6vcyS7cH+xmcz1JfjlW3D9uez2beZ1Y/uCX6XmVrDkNBHHnnE28zKyvag24aukvDwoJLAkGa+K/se5zuOXfZ51jFDJ82S8wXneGbiZAgvYX1ynuK8xvuwbjgvcZyw39AVYJZ8J87BdGGxH7CewnkxHaQQCCGEEEILAiGEEEJk4DKgNEMpghIFd+5T7qPkT6kplDQomcYyNDE7FO/FTGbMCMWdza+//rqlglIYbe4KDSVGSoDcTf7cc895m5Ip5WpmRswFlJlYzljGMsrtlL3oLuH1ZkkplbtaWb+Uvti2dKlQomP90A3BzF2UxvhdvhvdN2bx88j5DpT+2JbZyGwxuHuYLgBKw6wbjiXKi2wj1rdZUuqfNGmSt3/5y196m/Ikd5q/9NJL3h41apS3Y1I03YB0XdBtsWzZMm+HEjpdPvwbP6fEynFFt14uoBRL2C+465zjgYfrMPti6G5ivXMOY//kDnjOC3xe7MAa3pPQXcd5m3NDWFb+/4QJE7zNCBe2U3E740sC2zyWHZf9M/Zsfs7fDDOzTp06eZuuGUaPMPqA0XCMHGMb8bsc3+zPnFs4pjnuw6yK/E3lO3HuZL8paVtIIRBCCCGEFgRCCCGEyPJwI0oflFspzzIhEGUgSlihDEiZlAkqGjZs6G3KRZRjKN/w4CLuFKa0Qvk4JofTfRBKjHwGJR/CuuEzwkQZJYXyE10ndKmwDSjX9urVy9szZ870drhDnHI9XQ58r9ghVJRI2eaxemMiKu4Qju1ADpP1UEplgiUmMGJ7MhlOLhPg8F5MREIpmRIh24tlorTPOjZLJiaiW4KSLiXn+++/39s8MIb95tZbb/U2JXSOH0YucFc1+3x4qNL06dO9HUtuxvmBu/Qpw+aC2EE4LD933rNPsf/z0KIwcQ/bmeXndaw7wjHKMUC3Hu/Da5g8h3My+2NYn5xLzzjjDG+znpjoprSiDPjbEkZ2FcGDnCipE7ZRePgZx1bs/TgeWFddunTxNhPu0U1DtwLrqV27dt7mXMTPZ8+enSgr249wfMeizNgP0kUKgRBCCCG0IBBCCCFEBi4DSlixXfKUNyjLxHLchzI8JTY+gznUKQWxTHw2ZT/ek2XisylNUcKlJBfuuqf0HdulTtcA75tNjuniYNn4HErC3FnLZCrz5s3zNnPHh3I+y0w3A9+Xdc0dyZT4unfv7m1K/R07dvQ2XUSUwXn/F1980dthMo+rrrrK25TmKG2yH7JfhDJ3SWD/YX2y78XcaWxHSv7c9W+WlLL5HY4Z9k+OmZh7hGOM78D6oyuOiZYorzLpjllyjHJOYMIw1j+jTegqzAVsA/afWORSmzZtvE131axZs7zN9jMz+9vf/ubtiy66yNscl+yHfF8SS/gVO4OD9Tl06FBvr1q1ytvheSpnnnlmyjIxgoSJjdhHchllQFcl+y1dKwMGDPA2k11xnLBu+LlZsg6ZSI5RaJwvWVeTJ0/2NpO30dVMFwXdpTzPhsnhGMXAJF9myfmVY46fMxEV25hlShcpBEIIIYTQgkAIIYQQZuVcmnpPLHc85TbKkZRlYnJ+mISBkkjsrAF+nzugYy4ASkeU9CizUzaizBJL7GOWlHpZJsqqfDbrgHI6IyuyhUl9YruhWUZGAHCHN+Ut5po3S+6u5ZGqS5cuTXlf7nDlTnheQ3cFE+ww6c1tt93mbbotuPOergSzpKsmzNleBPsO+xr7M10J2cDxwHpmf+az2W9jkiBzppslk2cxmUpszDFahG451i2Pv6Usyu9S9mZyF74Px4hZss457cSOvuZ4Zd2EfTMbeD+6KSi9cywzWoVzDSXaMKlVOud2cMxRLmf0AucRRjdxHmEb0D3FPlxcBAjHXI8ePbzNI37p4uMz2OZs42xgP4y5ezmW+B50hcaONzdL9l1GaNFVSTcBo5uY5KhRo0bepuzPfs9n0/1C9wTHaug2ivVTjhlGZdFVyOtjEV0hUgiEEEIIoQWBEEIIITJwGQghhBAif5FCIIQQQggtCIQQQgihBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYVoQCCGEEMK0IBBCCCGEaUEghBBCCNOCQAghhBCmBYEQQgghTAsCIYQQQpgWBEIIIYQwLQiEEEIIYfvIgqB+/fo2bNiwsi6GSIHaZt9E7bLvorbZd1HbFE+pLgjWr19vF198sTVo0MCqVKliBxxwgHXu3NnGjh1r3377bWk+utS46aabrFy5cnv8V6VKlbIuWkbkY9sUMXXqVOvYsaNVq1bNCgoKrFOnTvbiiy+WdbHSIh/bpX79+inHTLly5axx48ZlXby0yce2MTObM2eOdevWzWrWrGkFBQXWrl07e/jhh8u6WBmRr20zZcoUO+6446xKlSpWq1YtO//88+2zzz4rtedVKK0bP/PMM3bGGWdY5cqV7ZxzzrHmzZvbd999Z/Pnz7cRI0bYm2++affee29pPb7Uueeee6x69er+/8uXL1+GpcmMfG6bm266yW6++WYbNGiQDRs2zHbt2mWrVq2yDz/8sKyL9oPka7uMGTPGvvrqq8RnmzZtshtuuMF69+5dRqXKjHxtm6efftpOO+0069ixo//HzmOPPWbnnHOOffbZZ/brX/+6rIv4g+Rr29xzzz122WWXWY8ePWz06NH2wQcf2NixY23ZsmW2ePHi0vlHqCsFNmzY4KpXr+6OPfZYt3nz5j3+vm7dOjdmzBj///Xq1XNDhw4tjaLknJEjRzozc1u2bCnromRFPrfNokWLXLly5dzo0aPLuigZk8/tkorf/e53zszcggULyrooP0g+t02vXr1c3bp13Y4dO/xnu3btcg0bNnQ//elPy7Bk6ZGvbbNz505XUFDgunTp4nbv3u0/nzFjhjMzd+edd5bKc0tlQXDJJZdkNNjDRvr888/d8OHDXfPmzV21atVcjRo1XN++fd2KFSv2+O6dd97pmjZt6qpWreoKCgrc8ccf7yZNmuT/vn37dnfVVVe5evXquUqVKrlatWq5nj17uuXLl/trvv76a7d69eq0fuSLFgSffvqp27ZtW6Kx/h3I57YZMmSIO/TQQ11hYaHbvXu3+/LLL9N6x32BfG6XVDRp0sQdddRRWX13b5PPbdO+fXvXrFmzlJ+3b98+rfctS/K1bZYvX+7MzI0bN26Pv1WvXt116tQprffNlFLZQzBjxgxr0KCBderUKavvb9iwwaZPn279+/e30aNH24gRI2zlypXWtWtX27x5s79uwoQJduWVV1rTpk1tzJgxNmrUKGvVqpUtXrzYX3PJJZfYPffcYwMHDrTx48fb1VdfbVWrVrXVq1f7a5YsWWJNmjSxu+++O+0yNmjQwA488ECrUaOGnX322fbJJ59k9a57m3xumxdeeMHatm1rd955p9WqVctq1Khhhx56aEbtWlbkc7uEvPbaa7Z69Wr7+c9/ntW77m3yuW1OPPFEe/PNN+23v/2tvfPOO7Z+/Xr73e9+Z8uWLbNrrrkmq/fdm+Rr2+zcudPMzKpWrbrH36pWrWqvvfaa7d69O6t3LpZcrzC2bdvmzMwNGDAg7e+Eq7YdO3a4wsLCxDUbN250lStXdjfffLP/bMCAASlXt+TAAw90l19+ebHXzJ0715mZGzly5A+WdcyYMe6KK65wkyZNck888YS76qqrXIUKFVzjxo3dtm3bfvD7ZUk+t82//vUvZ2bu4IMPdtWrV3d/+tOf3NSpU13fvn2dmbm//OUvxX6/LMnndknF8OHDnZm5t956K+Pv7m3yvW2++uorN3jwYFeuXDlnZs7M3P777++mT5/+g98ta/K5bbZs2eLKlSvnzj///MTna9as8e302WefFXuPbMj5psLt27ebmVmNGjWyvkflypW9XVhYaFu3brXq1avbMcccY6+++qr/W0FBgX3wwQe2dOlSa9u2bcp7FRQU2OLFi23z5s1Wt27dlNeceOKJ5pxLq2xXXXVV4v8HDhxo7dq1s1/84hc2fvx4+6//+q+07lMW5HPbFG1a+/zzz23KlCk2ZMgQMzMbNGiQtWjRwm655Ra7+OKL037PvUk+t0vI7t27bcqUKda6dWtr0qRJxt/f2+R721SuXNmOPvpoGzRokJ1++ulWWFho9957r5199tn2/PPPW4cOHTJ4071LPrdNzZo1bfDgwfbQQw9ZkyZN7Gc/+5l9+OGH9qtf/coqVqxou3btKp3oiVyvMHKxaissLHSjR492jRo1cuXLl/crIjNz3bp189e99dZb7rDDDnNm5ho1auQuu+wyN3/+/MS9p06d6qpUqeL2228/17ZtWzdy5Ei3fv36kr7mHtSpU8f16NEj5/fNJfncNlu2bHFm5ipWrOi+//77xN9GjRrlzMxt2rQpq3uXNvncLiEvvviiMzN3++235+R+pU2+t83FF1/sWrZsmfhX8nfffecaN27s2rVrl/V99wb53jZbt251p556aqJMZ599tjv99NOdmbkvvvgi63vHKJVNhXXr1nUNGzZM+/qwkYp2IJ933nnu0UcfdbNnz3bPP/+8a9asmevatWviu1999ZWbMmWKGzZsmKtdu7YzM3fjjTcmrtm8ebMbN26cGzBggNt///1dlSpV3MyZM0vyinvQtm1b17p165zeszTI17YpLCx0VapUcXXq1Nnjb/fcc48zs5QbhfYV8rVdQs4//3y33377uQ8//LDE99pb5Gvb7Ny501WoUMFdf/31e/ztyiuvdPvtt5/buXNnxvfdm+Rr25BNmza5l19+2b377rvOOec6duzoatWqVaJ7xiiVBcFFF13kzMwtXLgwrevDRmrZsmVidVbEYYcdtkcjkZ07d7p+/fq58uXLu2+//TblNZ988ok77LDDXOfOndMqWzrs3r3b1apVy/Xu3Ttn9ywt8rltOnTo4MqXL7/HJPbb3/7Wmdk+/SOUz+1SxI4dO1xBQYHr3r17ie6zt8nXttm8ebMzM3fttdfu8bdLL73UmZn75ptvMr7v3iRf2ybGF1984SpVquTOOuusnN2TlEqUwTXXXGPVqlWzCy64IOXu+/Xr19vYsWOj3y9fvvwefpbHH398j+Qyn3/+eeL/K1WqZE2bNjXnnO3atcsKCwtt27ZtiWsOOeQQq1u3rt/FaWb2zTff2Jo1a9LKALVly5Y9Prvnnntsy5Yt1rdv3x/8flmTz20zZMgQKywstIceesh/tmPHDps0aZI1bdo06tfbF8jndili5syZtnXrVvvFL36R9nf2BfK1bQ455BArKCiwadOm2Xfffec//+qrr2zGjBl27LHHptzlvi+Rr20T47rrrrPvv/++1BJGlUqmwoYNG9rkyZNtyJAh1qRJk0T2qIULF9rjjz9ebD7p/v37280332znnnuuderUyVauXGmTJk2yBg0aJK7r3bu31alTxzp37my1a9e21atX29133239+vWzGjVq2NatW+3www+3QYMGWcuWLa169eo2Z84cW7p0qf35z3/291myZIl169bNRo4caTfddFOx71avXj0bMmSItWjRwqpUqWLz58+3KVOmWKtWrfbZTWskn9vm4osvtvvuu88uv/xyW7t2rR155JH28MMP26ZNm2zGjBklqbZSJ5/bpYhJkyZZ5cqVbeDAgdlUUZmRr21Tvnx5u/rqq+2GG26wDh062DnnnGOFhYU2ceJE++CDD+yRRx4padWVOvnaNmZmt956q61atcrat29vFSpUsOnTp9tzzz1nt9xyS3RjY4kpFd3h/1i7dq278MILXf369V2lSpVcjRo1XOfOnd1dd92VyIyVKhRk+PDh7tBDD3VVq1Z1nTt3dosWLXJdu3ZNyDh//etfXZcuXdzBBx/sKleu7Bo2bOhGjBjhw/927tzpRowY4Vq2bOlq1KjhqlWr5lq2bOnGjx+fKGcmYToXXHCBa9q0qatRo4arWLGia9Sokbv22mvd9u3bS1RXe5t8bBvn/lemGzp0qPvJT37iKleu7Nq3b+9mzZqVdT3tbfK1XbZt2+aqVKniTj/99KzrpqzJ17aZNGmSa9eunSsoKHBVq1Z17du3d0888UTW9VQW5GPb/OMf/3Dt2rVzNWrUcPvvv7/r0KGDe+yxx0pUTz9EOeeyiB0SQgghRF6xTxx/LIQQQoiyRQsCIYQQQmhBIIQQQggtCIQQQghhWhAIIYQQwrQgEEIIIYRlkJiofPny3t5vv/9fRxQWFnq7UqVK3uZZzd9//723y5Ur522eNGVmVq1aNW/v2LHD2zzN6ogjjvA2s2tt3bo1pX3IIYd4++ijj/Y2Mw4yg92LL77obb5nWFZmmuI7MYqTdUNYl7t27Up5TSbwfiwL4buwjBUq/H8XYHlr1qyZ+D4zdbGdyf777+/tPn36eJvtz4Qa77//vrdXrlzp7Q8++MDbzBj2zTffpCxDGDnLzGCsD9YBP69YsWLK9/n6669Tfp4urFuWl/2WdR7rR2zfn/zkJ4lntGrVytu1a9f2Nsu+adOmlDafzbpluTl+2Fd5Pccq2zpsl9i8UaVKFW+zDvg8zgGpsoVmCssSGxuxOY9l5DXhHPHll1+m/D7nRvYLzm3HHHOMt9mWLN/69etTPqvo5E+zeD2zPGbJPnnggQd6m23L9+ZczfdmmbKBmRHZlwjfg+Vjv+UcwM/NzA4++GBvc55r2LCht5mYaOnSpd7mvM9+yP7505/+1Nucv1hWfpf1GmaG5LzLd+KcxXFCm/eN/RaFSCEQQgghhBYEQgghhMjAZUCpipIXoewUkz9pU3YyS8o3Rx55pLd79OjhbcpF//Ef/+FtSs6UYxo1auRtHj5Byezwww/3NuU2XvPGG28kyhqTswi/H75rLonVL4lJ07H3SHWYRxGUxCiznX322d6m5MlDR+rUqeNt1inrh/e/9NJLvc22+fbbb1OWuzhYN5TX2afee++9jO8bg+1PKS/WRrExQ8mT9WpmiYNbeF3jxo29/a9//cvb69at8zbPd7jvvvu8zTM5Pv30U2937tzZ25Son3zySW/T3fPxxx8nyhpzwcSkTc4zbPtcwPqlqysmt1MW53sUJ8uy/SnDH3/88d5u3ry5t3nGA8cb25VuhY8++sjbo0eP9vbTTz/t7S+++MLbxY0Z1nVBQUHKcjdr1szb7777rrfnzZsXvW+m8F35e0LXDD+PQddarVq1En/j/MLfGY4tzlOHHXaYt19++WVvd+zY0dt0f1L2j7mBTjvtNG8feuih3l6zZk2irLfccou3OV+yP7IPcqzHXKHFIYVACCGEEFoQCCGEECIDl0FsJy7lCspOMVmU0k+vXr0Sf6NMRun2zTff9DalUF7DSAFKM9xROm7cOG9TMqYE1bNnT29Tyhk1alSirCeccIK3Y5EClL+4KzvmcsmWXJ1PVdzO+w4dOnibddeyZUtvP/jgg94eNGiQt9mubCdKynweJcuDDjrI29yly/os7v1jri7Kp+yTuTzri++xfft2b8d2CNN9w77DyIwRI0YknkFpk66ymOuLY4MScO/evb3NfsD78304Jm+77TZvb9y40dtLlixJlJVy66uvvuptyp+sD0rwpXkGWzrzFvtLzEUXStmUjun25HG8/A5l7s2bN3ub7RpzqbD9GCnF8tFlGkYjse/xeWxzyuJ0RXD8lBTWR+x3hs/jOGnatKm3O3Xq5G3+Bpgl53W+01FHHeVttjfrgFI/3Sn//Oc/vc3fKLpUWVa6iliG1atXJ8rKeYN1w7mQ5WOd8Zp0kUIghBBCCC0IhBBCCJGByyAdWS0G5Z7q1at7e/DgwYnr3n77bW9TOqGUxqRD3MH5j3/8w9uUJk8++WRvP/vss97mTl+Wg1JYbKdv+E6xzynlUK4L71VSYrvTY8SuobTMnddmycQb3JnLdqLcywQ4/C6fTamYNnf9s53mzp3rbcph4e7udCJcKOfSdZFLaZr1FEap/NDzmBCI0TR0uZgl351JYRgdwHbhjmtKm/ycLg22BXfXMyLogAMO8DZdDOG70c123nnneZttwX73zjvveDvXY4Yw4QuJuUNj14RwfqKEzaQ3lOpZD4y6YcQP25ttzPZjUrANGzZ4m9E+jMoyS7YV51j2KbYt5+p0k96kQyyxFfsw24L9c8CAAd5etmyZt5m8yyzZLnwPukJZb5zj6DplkqIwoqYIzlN0SbBe//KXv3g77Ivnn3++tydMmOBt1gFd52yLbFw5UgiEEEIIoQWBEEIIITJwGWQqSxNKYQ8//LC3KaGYJZOanHjiid6mDMLEDdxNS2mGchtlIO4Q5TtQXuLubO625Y5ss+SuXrorYkkiKInnWv7k/UpyNgLrLZSmGTXA/NyUF+naqVevnrfpimBiHO72pSzHyAJGMVCCp8wWJq1Jp3+WlpuAxHLux87IYB+mrMl24e5zs6SMz/HTvn17b1NyZpIVfpd1SBcApUmWg66/WJKUY489NlFW9hX2D0qbLAc/Z5lyQeycApLOnMf7sE7MzKZMmeLt2DkQtGNyOV2PrDfuQKcL58orr0x5T9pMgmSWTDTEZ9OFymRUsQiAkhI7S4L9kM8bMmSIt1u0aOFtumjDvjNr1ixv0zXA8TBp0iRvs+04p4f9uwgmjOJ8x8gC3pNlDefdVatWeZtzIV0Osd+TbH5npBAIIYQQQgsCIYQQQmQZZZAOlOF47DB3w3LXq1lSQqa8RTmL0hglJUppsSMgubuXMiplIO5yXrRokbcp94TEjlJlncWOEc0F6ZyrEIN1SMkt3DnMOmJyG+6GZ1KaFStWeLt79+7epozF9uZ5EoTSNyW9yZMnezt8f9Z1pmc75NJ9QNdKLNoh5j648MILvU0XCvOwh/diAhZGyPD7lIBD90MRHAOMEGFf4X0oaXPndQjdAXQfcGc1k73EjubOBRybMTk6nTNCGJFBSdcsWe887yF2pgalbSbGoZuUriTu+ud9eD3bkvNteCYG+0JsrmI9peNyyQbelxEEdK1QVr/ooou8zTmdvxnhGRp8P7qC+a50rbGvtmnTxts8FpllYlswUobXvPbaa95mYqLQvUE3FMf+K6+84u2YayCdMx9CpBAIIYQQQgsCIYQQQmTgMsgUymKtW7f2Nt0HlFTNkokXGIFA+YeSGeXM559/3tuUY15//XVv169fP+X9KZeddNJJ3uYO0VDK4Ts999xz3o7JNJSDKbPvS1ByowvGLNlulAiZLIhuBUaWsP0oYVIGZG573of5yXlPHtcbnjNBOS0dYjubcwnLThcH3Vvsz5TkKQmGkjwjGSi30x3z1ltveZv1yWRJdDFwjHH8cMyw7egqoozK6B2zpDzLZDEcP2x7vnc2x12nSzpJxmI2pfewH7L8ffv29Xbs7IxYpA3nLdY75ye6CSiRM6kVXTt0n5olc/GT2Njg59kcsxsjFnXDOYcuJvYxlo91EO7c530XL17sbR7vzV38dHOzTfn7xf7JqAG6ungNIzaYICxMCMd5l1FyL730krfnzJljqWBdposUAiGEEEJoQSCEEEKIUkxMxOspm1Dyoqxplkxsc8opp3j7uOOOS/l9yrCMPuD1lOpiCT6YpIZyLo+uDMv6s5/9zNt//OMfLRWUuSg1hYl0yhLu5KUkfPbZZyeui51HwWRBzI9++umne5vSFeuEbhjKopTTKL9RmqQkyN3W4TOyyUGfK/hs9ivKwbyGR+R269bN25SSWd9mZsuXL/c2JVPWCV0RtGMJrXgfupGYx53jkO3CndB0PZglz7dgUh2Wg3XDsvL6XBAbm7Hjl2MuA7pawkQ1rDsmUaOMT3caEz8xYoFjNOZu5JjhOKa8znZlEiuz9NwmjGLhzvtcutk4p7Nfcfxw/uFZJ5TwKbWHLg260Hgvuq5iLgC6o/k7yN+umKuD/alRo0beDqMgCN16TZo08TZdebGoumyQQiCEEEIILQiEEEIIoQWBEEIIIawUww7pG2WIC31a4UE8DLWiD4c+VPqm6W9iuBN9NbwnfTv0xdI3Q39Y165dvc2zx83M1q5d6236+GK+WPqS6H8taxgmyYxZzLBlltz3QN8ww8cYMnPqqad6m/41+r6474MhPwsWLPB2bK8H/b70I5olDy9hm8fYGwe1sE+yTKyDTp06eZv7Xdg/wwN06Ldm+Cz7JH2U7Me027Vr522OGbY1xzTDTU844QRv0z8bZlCjv5z9iT5vhlGyDnK974bjMXaoUKwvxDJNhnureE492ybmi2e2Ts5tM2fO9Db343CvVCxbHcce2/u8885LXEf/O0OAOaY5n7E/5zJTIduZ7cK24H4JZl/k3MJ6DWG9cS8F79uxY0dvv/32297mHg62Kecplon7pNgWfDfWJfuMWXJcch9br169vD1x4kRLRTYZbKUQCCGEEEILAiGEEEJk4DIoyaEvlPwpqYeSBmV/yqeUi2JnpDNLG2VOhndQVuMBFAx5Y+YqSngMgTJLym+xQ1BiB6hkc051aRELjWM4m5nZBRdckPJvlNDYBpSd+Tnla7pdmO2OcjRlY0rtdBPwWWbJMKPYQS2x0MRcHqLDEDrWASV2ugDYt+kyY2gbM/mZJV0DDIniGGAWOo4r1gEzn9GNwWx4l19+ubdZT/PmzfM26z4MkWQdMMMfD/6hW4h1E2ZwKymxsRlzGcTmP9Yz3R1mydBPZqNjn6YLgBk2BwwY4G1mqOO8Q7cCxwDdssxMyTrkXGu2Z9bYIjheY+OkuLC5TGHZCcvO3xC6CViX7F/hfMv5nr9NH330kbfZDxnySlcEf38YmkjXGF0JbCO+A11moWt6+vTp3ubvEefL2KFTnDfSRQqBEEIIIbQgEEIIIUSWmQpJ7PALSoeUICl5MhOgWXJneu/evb3NDF6UyWLSe0zi4bMpV/MaHrDE+7BsZkkXAqWqmMRGCTibQydKC8rGlGjDzIyUGBmB0K9fP2+zPZi1kLuqWW/du3dPeU/uVKd0xx3IPK+ccl1YDhJz55TEHVYcvC9dF9zN3LNnT28zqiV2uBEPWjFL9t0WLVp4m32MkSCMWKB0ymsYeUI3Ep/N8rGNKJu3bds2UdbmzZt7+9lnn/U2ZdUlS5Z4m66Vhx9+2HJJrM1jGQk5Tvg555QwMyPnj5jkzV3ubDO2AQ/noWxMOC+OHTvW23QZ8J1DOZkuOEY1cJywTHQZxLKBZgPrlu4wunhZl+wjdHvxu6FLkf2e7cqoAT6Pv2ucazg2WDex6znu6TbivBtmVaTbje/NqKxFixZ5m3Mkn5EuUgiEEEIIoQWBEEIIIbJMTBST22Lugy5dunibSRu4w9MsKRdS/tywYYO3eegHEz3wviwHpWvuCuX54ZThKO2uWLHC2zxsKXwed9rzQJMYYUKmsoTSH6VbSmBmyUM2+B3upGf9Uv7kNeEu2iIolfEQHR4ixR3IlK+feuqpxL3Y9zI9lCuXULKjREu5jzvR6VqhlEmpMYTSKJ/B6JrYgTh0N7Cv8yx4yt50D91xxx3eppRJiZQuIbOk649luvTSS73997//PeW96JbIBbHIINY7+xFt1jmT3ISuQPZ71gXnLX7O/s3vcrxxXHJXPN0VnKvo+qPEzUOozJLRVbHDnmKyeC7HVczN1qxZM2/zcCiWj/2FrpwwqRXHHBMB8Z0o47McHA/sK3wexyvvw2exTdkuobszdsjViSee6O3bb7/d23TfZPM7I4VACCGEEFoQCCGEECIDl0EskUts5yp3aTLxAmWdMNkP5V3KPMwrTRcAZVEmomBZeQ3lfEpszBdNtwV3Sbdv3z5RVu5y565cRi9QFipNubok92adU6pnrmwzs2uvvdbbsSQxfPdp06Z5+6KLLvI2k9OwPSi3Lly40NvsL+wHlEK5c94s8/PZS8utQLmQZRw0aJC3KYWzvzAq5eWXX055TzOzG2+80dscf+y7zE3Psw94xgifwV3YmzZt8jbrhpI/5WaWL4xMYrtw7PO9KXfH3Eu5IJ12jl1DKZb1QznZLBlxwXfnWSb8Pl0GlIdjCXDY3nRDUL6mHE03RDhm6NalC+6zzz7zdixKJ5fnf8TuRbdxt27dvM2IJEZacFyxz5slxxYTGzEig/MR5x22C9uCn9NlwN9BtjUTQXEsMCLPLNnGjDZhGzM6afbs2Sm/my5SCIQQQgihBYEQQgghskxMlM4RoZSUKC9S1gl3f1LGZ8IJSooPPvigt+kmiB0pzLJSKpo8ebK3mbiC8g2l0PD+lL75rrFjZ0vriN3wfplK3tzdz12wYYIMugmYTCd29DPdRGw/SmJMRkRZlPXJnfCUwCgJrlq1KlHWdFwGezvigG6Qxx57zNuMcOHOb8qDdDGEbjbK/oxeYPtxnFCG57PpNmOedO7o5i5z9n9K0cuWLfN2mNyKfYVjnS4+tjcTGYXJp3JJbPyw37I96FJp06aNtxklYpYcT6xr9mP2ex4/zjKxr7MfxY4mZqTGGWec4W32ifDIYpadZUonaiqXxx9zlz3dHXTH0A3Mo4kZDUBJPoyy4XWMZmP9MKqK/TYWUcbEXryez2IUF90KvD6MVKEbl2OO7ge6DNg/wvGXDlIIhBBCCKEFgRBCCCFyfPwxJUXKn5T7nn76aW9T+jGLS8JHH320tykpUY7hbk5Kb4S7SCmnxGS1Z555JuXnZkl5nIkuYrJc7LjVsoayKI/P5a5es+QxuJSRuUuX32ndurW3KbfGolJYDsrilMOYnISSW5hEKbbTPR23TS5dCXxv5qxnX6VUT4mZiZdeeOEFb4c7h9mX6PpioiH2VbrBOK54RDLblEmDKKOeddZZ3mZbU7KknGuWbD9CN+LQoUO9/cADD3ibboxcwPZnnVKmZp9k3TLhFBPHhH2H13HeoiuREjFdJJxHGEFAOZ9uFx6527dvX2+zD/LdWOdmyTF0xRVXePuWW27xNne2s/5yeZx7bIxyPLBfsT+zznhOThiZw+gPlp3zF10DbC/WE6MXGCHC3yW2LyV/JpVi+Tg3mCX7PSND6ILiuKRbPHSlpoMUAiGEEEJoQSCEEEKIDFwGMZk7JvEwcQ/lZiZJCeURShyUMCm1UI6h7MVdsjzGsnHjxik/pyQUSwzBXbwsg1lSmqGcRfcBoyhiOdJzQaYyN9uJZeGOVrafWTJqgEdysh6465a7zVknlMcoc8bOUeCuc+7G5S7iMNc/pcN0+m1pQTcB62nGjBneZr+KJZFhXYZ9h/I+JUyOH0qelMHZXjxngPXJ6BqWg/I2oxhiCXjMktImx1ns+Fe6sMKIpJLCMRC6nFJBSZhzDccC69YsKU1TOuZ8yPvGjlFnnXDMsA4pQdMdyntyzHC8mSWPP2af4rNjiYly6TKg+4ZzPRMQ8XhntgWjP4YMGeJtjiuzpGuAY5RuIbpH6FpjmTim33zzTW+zTXkuCF3k/M1g3+Y7mJk9//zz3uZvGaMu+PtF9xL7RLpIIRBCCCGEFgRCCCGEyEGUAaU3yuLhzs4iuPuzuGMpKQ8vXbrU25TbKKdQrqMkRLcEc+1TvvzNb37jbcpwLB9zepslJSJGNXCnOHd3xyIOckFJEhPxu5SpX3nllcR1lN0oXdEFRHmSO8rpqqFsxvrh7uk//OEP3o4lKqE0zZ36ZmYTJ060TCitsww6derkbbb58OHDvc0zMigv8njtSy65xNujRo2KPoORPWwj3ot1SLmVNscuXQkcD48++qi3Y3U2derUxP8PHDjQ24wiokzM/kSXBl1WuSAWWRCLYqIse/LJJ3u7OPdU7LhnPpuJoihTs344NuiqoWuA8jXdbJy3KImH55HQXctIMJaJcMyErpKSwDmE9c92obuDkRwsEyPbwggVur5Yb6wr/m6wjehK5TN4DeuDLkG2O5/F+ZEuKLPkbyLLynstX77c23RF8L7pIoVACCGEEFoQCCGEECIDlwGhNJPOcZWUtubMmeNt5pE2S0owlOIobzG5EOV97qClZEbZhLue+exYMhLKV2GOaZaVkil3mJK95TKIyd+0KbfzetYbdzObJWVnJgZhO8fyslP64y5YJk2hi4iuC5aVNnfZhruIGX2Sjjsg12dLFEGXFvvF/Pnzvc0c6Nw9TUmR+fKZLMvM7KqrrvI2ZV/WM900HFesJ8rbHDMcewMGDPA2XXexscpoCjOzs88+29s8ppWujgsvvNDbL774ordj0nW2xHbMx8YG+zCTL9F9QBeYWVLiZeRGLEc/pXCWgzIw78O6pnTOuYljKZYwJyw7y02pntfEXMUlhc/mfdnHOHdzXmK0CF084XxLlxjrkC4V1jn7Hr/LuuFvC8saO9KcY4/Xs43CMrE++H2OdbrFs3HlSCEQQgghhBYEQgghhMjSZUBichETPlDmZw7mUOrlTmImJSHcDc2jX/k55WcmeqAUyp2nlGSZEISyWJiXnXIMJSV+zrrZW4mJYvI3P6ecxnc/77zzvB0mtWBdU2ZjG/KMA0qblMroPuIRntxhTzmTbUmZjO4Jls0smVuf0SR7230QO1abfY8yJyNw6E5ZsmSJt8Ny9+vXz9vs34xeoKzKKBgmzmFOfu6YjiX84tHV5557rrdjibnMzGbNmpWyHHRXUN6lW4KyaC7gOGWdxo5Rp8uH13A3+po1axLf4ZinC407ydm/6T6gC4Cfs23oDoi5NynzMzKqd+/eibLyXmwD7mbnvXhNLscMnxGT29mf6W5in+Icy4iN8PscA+wH/P1iP+b5Eelcw3HCOZHlpnswdOUwSmHBggXeZj/gfWO/P+kihUAIIYQQWhAIIYQQIgOXQSz/PaUjShSUDimLnnPOOd5mfmqzpCxECYa737mzk/fld2NHUTLRSWyHKKUY3j/c/UlZKNMjj3PtMiCxyALC96Vsz93TdO2YJSV9JgJiPcQiLCg1s04pU3J3LCVklpVSH+swfM8uXbp4+5FHHvF2bNct75XLJCuUW9n+dNPw2XSJUGKmi4H93Cwpw3PMMIEK3Tp0Y8TOIGDb03VxwgkneJtRPUy6Q/cNoynMkjvyWTfPPfectxl1wd3k4VxRUlgn4ZHSRcQkV7YB62HlypWJ6+hOYF1zvuCudZaJYyA2HlhuXkMJOpYcKTzenPMe5272vfAI+FTlLikxVw7HD8c3I83Y39guTERkZtajRw9v02XD77Pe2EZ0edKtyutZJs5ZbDvOd5yD6TY0M+vfv7+36Ubn/MBxz7aQy0AIIYQQWaEFgRBCCCHSdxlQfoglwqHNnbGUqhYvXuxtyjpmyR2Z3bt39zaTRDDpBiVFyi6UTbi7mxJeLMkN3RNNmjTxNnf9hjDKIHZcaDrJnHJBOrn4KcvxvbjTPIyqYFvR9ULZknI0d6dT3qKsyh3FrEPKg7HEKtxZGyaEoezMfst+EUuskkt3DqU8vhNdMzxalRIkd6wzUiKUZzk2GFHD9qLsT5cNd0nzyNtFixZ5e/Dgwd6O1Rnl0lNOOcXb3NVultxdz93UsTz/7CthPvpcEnMTxdyhdH3QNUO3gFmyvuhm4H1jSZ0oU/O7vCcjbWLuBsIxzaOyQ2JzCF2CLGs4/kpC7NmU9jn2Kb1zvPH8G87vZsm5hmeucCyybvmuMZcwI+RixxEzCot1yXHLudXM7KWXXvI2xyXrg5ESJT1jQgqBEEIIIbQgEEIIIUQGLgNKfLHjQilXcHcld7TyWFZKHWZJaYw7MpmYhRLb+PHjvU1ZmtIdj1PlPSn3UEalZMyd9WPGjEmUlQlhKMlSeo0dg8k6ywWZJtyh3MTjcynzhwlamGed9UIZjP2C8ttxxx3nbdYJ25+uC0qQlNwogzNvf4cOHRJlpRQek81YT3xeLl0GvBfrhhIkj5qlzMl3iOWQN0u6VI4//nhvr1ixwtuUSClVcizF5GcerUp3H3eiT58+3duTJ09O+Vwzs9tvv93bdPfR5rikfJrLnexmcRco+wvHKd2N7G+Uh8NxzT7G69gGrCOOS/Z7uuI4l/Id6E5j/2KiNc6vdFuZJcd7LDkbKa3jj2PPYNn5exCLzIlFcpjF5366VDp37uxtzne8b5h4qwj+xjHCii5B3ofXhK5autM4R7K9GSGSjuuoOKQQCCGEEEILAiGEEEJoQSCEEEIIyzJTYSwbEm36xphljIc60CdplvRd0S/C7FCxgynoC6JPi9fTj8f3YagT78n3ZNnMktnAGBJF/x39XixTzPeULemEMdKfyXLNmTPH2wwxmzlzZuL7DI2h3471QB8Z646hnAw9Yzhd7LzzmH+f9RxmUKOPMZ26yfWejiLYb+mH5OcM9Zw6daq3WcfFQZ8yDz+hL5JhcoS+Ve5fiO3hYEghw9aeeuopb3OMheFojz32mLeHDRvm7dhemyuuuMLb4R6eXBLLjhfL8MhQMPbVxx9/PHFf7p1hWFosWyfHJX3E9CPzuww55f4DjjfOw9xXwhA2s+QBVb169fI2D5iK7bvI9cFTqeDzuC+MYeixkG/u/zBL1hvHIudxhjay/lnPLBP3DbCNWCbu0XrhhRe8zd+fMBSfcyr38cVCYvl5NvtupBAIIYQQQgsCIYQQQmTgMkjnYJiYXMFDI5h9jBKKWVIeYdgaw3Qor/AQFob7MeNhLMMgXQOU8ygVUdqnvG0WP3CG9RGTuGnngnSyExJKXazDWDipWTLskM+jFM7PKcsx/IWyF+W0d99919tsb8rOlLjpUmK2MrNkP0rHZVBaWSTZl9hvKTtSxqXsyLAwSoJhu/D/2UbMoNe8eXNvc2wwpPDee+9N+Q6Ux1n/Z511VsprGL4Y1iXl3dmzZ3ubh2XR5vjJdXZP9j32sdjhYJz/OG9R2g/bhvMhoaTPvkA3Educ8xDlaNY7XU/8Lucmumvp6jNLugQpkXO8sg5iMnVJYR3G5k/2wzB0vQj2NbqxzMw+/vjjlPel+4BtwfZm23F8c85iX23UqFFKm/MB24ghiGbJfsp5jeVmCDDdhjrcSAghhBBZoQWBEEIIIbJzGcSkCEollJG445mSECUUs2REAM+wZiZARixwtyl3uvKgI0ouPM+d5TjiiCO8zd3TEyZM8DalOrOkXESb9cTsX/x+rnflZuoy4PWUeOl2CTOZUW5kO1100UXe5u5+Hs5z0kkneZtSJWVtugAo9/FZjErhjm7u1DZLuokorfG+JHbueklhv+B9Z8yY4W2WNbabma4cSo1mZs8//7y3Y9LhP//5T2+zPjmuGjRo4G3WGd0KbC/KsMwoSDk2jMwhjDjgvMHxF8uemAtiUngs62ffvn29TRfYk08+GS0jxz93j7NtecY93aScI9jmbGOON2YMZRvQ3dC0aVNvh1FEsWx5sWisWKbPksJ5mWOG78GoAfaRMNqoCM7vZsl+zLbg8/hOr7zyirfpxmjfvr23Gc3Bg/mYUZWRHRyH7H90+5mZzZs3z9vsT/ztpDs75vJKFykEQgghhNCCQAghhBAZuAwo5VCKoITCnZaEuzcpdYTXU4aMSb3c1cvd09yBSXmJkiyTbHAXPHd5chc23y2UX/g3ykuxRDqUhcIdviUlncONCK+hm4DtwXo2SyZZqVmzprcps3GnM6VUynI8gIdyX6tWrbzNHc90T/Xp08fbjCyg7GqWlEaZcIeSWywZTS4PauF9KVMyCQz73qxZs7xNNwjLFLpHmCzomWee8TYTQLGeKfvSZcAoDx4ORpdBjx49vN2lSxdvz50719uxCAqzZF+hhM6d4hzHrBu+Qy5gX4+Nc45luic5Nt58801v86Aws6S0zfmG8xnfl5Ly0KFDvc05k67HAQMGeDuWMIft/dxzz3mbLjqzpIuW4ynmAuUz6H4pKXSJbN++3dt8P7ri+OxmzZqlvE+Y5IsuH84PDRs29DZdV2zjmKuY7cK5ifXEOY6fc5yErtpYpBITePG3sqRJ76QQCCGEEEILAiGEEEJk4DKIJUehrMdrKOf37NnT25ThmLDILJ7vn1J/mMyoCEqevA+lHEpQlFmYXCcmoYfJLXgmOt0MdAfweZQZw4iFkpLpblLKbK1bt/Y265kSnZnZ9ddf723Kn2eeeaa36Q4YNGiQt7l7mrIX65eJnlgOyugffPCBtymPh8mnKHPH3FixXOC5hM+m3Mod9tyd3LZtW29Tyizu7HnK0nTlUD6lq+X3v/+9tyk583mUNinnczczIz7YdpRjw4gNSvOMTLjvvvu8zbFBV0QsQiRbWI8sFyMFOK5i/YhuF7qFzJIRINyRTpcW3TDcJc8kVSwrbebDf++991Leh2OV7RpGGXDei0UpcO7m/MDfgJLC3xY+gxE4w4cP9/a4ceO8TTcB65U79c2SfZQRUCeeeKK3OZY4d7PeeI4I25S/UezPdEnw94f9jGPJLBl1QHdhx44dvU23E8dcNr8zUgiEEEIIoQWBEEIIIczKuTT1Zko2lIhoUw7mrmDuPqd0yiRDZklZjtIYpSpKSrEjmSmb8HqWj5INpZXYuQR8fzOzJk2aeJsuB0o+sYQntHOR1IO7aFkPsZ30fHfujH7//fe9He5W5b3YTpTH+vXr523K9kOGDPE2j5Gl7M9ds5TwV69enfJZLCuTJoUwqQilv1gCIvaXkrp2Ym421j9lZl5POZJlZZ80SyakibkZKCGz/ukyYGQBj/Rlki/aTHbEiAE+N4ym4d9i0vBll13m7YceeihlucMImGzgXEA7lpyGcxjz2RcX4cMy8x3pZuC9+H2eFRGLUGJym3AuLYL1zDNbOGeZJd+bLoPYfMjr2b84v2dDbPd86MIsgvXHaAyOpdDdw7bke3AsMZkR537O75xrOTcxyoBtRDcQ65URWWH0B92kdI3Sjh3bzP6U7lwmhUAIIYQQWhAIIYQQIgOXgRBCCCHyFykEQgghhNCCQAghhBBaEAghhBDCtCAQQgghhGlBIIQQQgjTgkAIIYQQpgWBEEIIIUwLAiGEEEKYFgRCCCGEMLP/AcYBwphEudsHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "2001 [D loss: 0.5675278007984161 | D accuracy: 73.4375] [G loss: 1.4229490756988525]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2002 [D loss: 0.46934306621551514 | D accuracy: 79.6875] [G loss: 1.4821033477783203]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2003 [D loss: 0.4492032676935196 | D accuracy: 82.8125] [G loss: 1.3039700984954834]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2004 [D loss: 0.4589973986148834 | D accuracy: 75.0] [G loss: 1.4435961246490479]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2005 [D loss: 0.4984517991542816 | D accuracy: 76.5625] [G loss: 1.5241966247558594]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2006 [D loss: 0.4529486149549484 | D accuracy: 76.5625] [G loss: 1.4652631282806396]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2007 [D loss: 0.5087891668081284 | D accuracy: 70.3125] [G loss: 1.5212047100067139]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2008 [D loss: 0.5472489595413208 | D accuracy: 71.875] [G loss: 1.3379487991333008]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2009 [D loss: 0.543708473443985 | D accuracy: 76.5625] [G loss: 1.29158616065979]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2010 [D loss: 0.46992090344429016 | D accuracy: 75.0] [G loss: 1.3465158939361572]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2011 [D loss: 0.46214625239372253 | D accuracy: 76.5625] [G loss: 1.4607996940612793]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2012 [D loss: 0.5175715088844299 | D accuracy: 73.4375] [G loss: 1.6268398761749268]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2013 [D loss: 0.45463240146636963 | D accuracy: 82.8125] [G loss: 1.511582851409912]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2014 [D loss: 0.4829956144094467 | D accuracy: 76.5625] [G loss: 1.1958985328674316]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2015 [D loss: 0.5377136766910553 | D accuracy: 79.6875] [G loss: 1.5920777320861816]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2016 [D loss: 0.48472970724105835 | D accuracy: 75.0] [G loss: 1.5909464359283447]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2017 [D loss: 0.5720048546791077 | D accuracy: 75.0] [G loss: 1.5817029476165771]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2018 [D loss: 0.49474459886550903 | D accuracy: 76.5625] [G loss: 1.554948091506958]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2019 [D loss: 0.47993050515651703 | D accuracy: 78.125] [G loss: 1.4307234287261963]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2020 [D loss: 0.44413962960243225 | D accuracy: 81.25] [G loss: 1.2827622890472412]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2021 [D loss: 0.5175240933895111 | D accuracy: 78.125] [G loss: 1.3535808324813843]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2022 [D loss: 0.4937707185745239 | D accuracy: 76.5625] [G loss: 1.3169342279434204]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2023 [D loss: 0.4899652898311615 | D accuracy: 76.5625] [G loss: 1.5228619575500488]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2024 [D loss: 0.4148281663656235 | D accuracy: 78.125] [G loss: 1.4587438106536865]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2025 [D loss: 0.4397100359201431 | D accuracy: 79.6875] [G loss: 1.4269850254058838]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2026 [D loss: 0.5155082941055298 | D accuracy: 71.875] [G loss: 1.3468554019927979]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2027 [D loss: 0.581879198551178 | D accuracy: 73.4375] [G loss: 1.4334790706634521]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2028 [D loss: 0.36411021649837494 | D accuracy: 85.9375] [G loss: 1.315415620803833]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2029 [D loss: 0.40421102941036224 | D accuracy: 82.8125] [G loss: 1.3852243423461914]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2030 [D loss: 0.47747910022735596 | D accuracy: 79.6875] [G loss: 1.5602281093597412]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2031 [D loss: 0.5390340983867645 | D accuracy: 71.875] [G loss: 1.3372942209243774]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2032 [D loss: 0.4488913118839264 | D accuracy: 78.125] [G loss: 1.3964495658874512]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2033 [D loss: 0.5191799998283386 | D accuracy: 70.3125] [G loss: 1.4395785331726074]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2034 [D loss: 0.5518205761909485 | D accuracy: 65.625] [G loss: 1.3275659084320068]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2035 [D loss: 0.48234882950782776 | D accuracy: 79.6875] [G loss: 1.3845524787902832]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2036 [D loss: 0.5513217151165009 | D accuracy: 67.1875] [G loss: 1.3465068340301514]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2037 [D loss: 0.43264418840408325 | D accuracy: 81.25] [G loss: 1.448747992515564]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2038 [D loss: 0.5899620056152344 | D accuracy: 70.3125] [G loss: 1.5716125965118408]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2039 [D loss: 0.45995032787323 | D accuracy: 78.125] [G loss: 1.367978811264038]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2040 [D loss: 0.4862908124923706 | D accuracy: 75.0] [G loss: 1.622692584991455]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2041 [D loss: 0.5843559801578522 | D accuracy: 75.0] [G loss: 1.2950336933135986]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2042 [D loss: 0.3811907172203064 | D accuracy: 84.375] [G loss: 1.2208046913146973]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2043 [D loss: 0.39193806052207947 | D accuracy: 79.6875] [G loss: 1.2284479141235352]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2044 [D loss: 0.559704452753067 | D accuracy: 70.3125] [G loss: 1.2707552909851074]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2045 [D loss: 0.4975496381521225 | D accuracy: 78.125] [G loss: 1.425592064857483]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2046 [D loss: 0.5340916067361832 | D accuracy: 76.5625] [G loss: 1.5622038841247559]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2047 [D loss: 0.36133238673210144 | D accuracy: 81.25] [G loss: 1.4123141765594482]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2048 [D loss: 0.6617264151573181 | D accuracy: 60.9375] [G loss: 1.2252931594848633]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2049 [D loss: 0.5770859122276306 | D accuracy: 70.3125] [G loss: 1.3114957809448242]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2050 [D loss: 0.5470858216285706 | D accuracy: 71.875] [G loss: 1.3626773357391357]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2051 [D loss: 0.4492693394422531 | D accuracy: 78.125] [G loss: 1.5103671550750732]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2052 [D loss: 0.560504749417305 | D accuracy: 73.4375] [G loss: 1.4601292610168457]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2053 [D loss: 0.4649863690137863 | D accuracy: 75.0] [G loss: 1.4259660243988037]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2054 [D loss: 0.5637800097465515 | D accuracy: 76.5625] [G loss: 1.4793241024017334]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2055 [D loss: 0.35988521575927734 | D accuracy: 89.0625] [G loss: 1.4631386995315552]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2056 [D loss: 0.5481443703174591 | D accuracy: 68.75] [G loss: 1.3091204166412354]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2057 [D loss: 0.4335927963256836 | D accuracy: 76.5625] [G loss: 1.3829729557037354]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2058 [D loss: 0.4723382145166397 | D accuracy: 78.125] [G loss: 1.511751651763916]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2059 [D loss: 0.4327840507030487 | D accuracy: 78.125] [G loss: 1.4397603273391724]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2060 [D loss: 0.48813289403915405 | D accuracy: 73.4375] [G loss: 1.3728458881378174]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2061 [D loss: 0.4496007561683655 | D accuracy: 79.6875] [G loss: 1.3104236125946045]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2062 [D loss: 0.4953986704349518 | D accuracy: 73.4375] [G loss: 1.4097890853881836]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2063 [D loss: 0.4086439907550812 | D accuracy: 81.25] [G loss: 1.377143144607544]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2064 [D loss: 0.44640156626701355 | D accuracy: 82.8125] [G loss: 1.496936559677124]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2065 [D loss: 0.5117289125919342 | D accuracy: 65.625] [G loss: 1.453211784362793]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2066 [D loss: 0.4549219459295273 | D accuracy: 79.6875] [G loss: 1.4239397048950195]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2067 [D loss: 0.4262102246284485 | D accuracy: 85.9375] [G loss: 1.408106803894043]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "2068 [D loss: 0.48446066677570343 | D accuracy: 76.5625] [G loss: 1.354370355606079]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2069 [D loss: 0.5347525030374527 | D accuracy: 70.3125] [G loss: 1.332197904586792]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2070 [D loss: 0.4526837021112442 | D accuracy: 79.6875] [G loss: 1.4665484428405762]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2071 [D loss: 0.5141845345497131 | D accuracy: 73.4375] [G loss: 1.411482810974121]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2072 [D loss: 0.5860252678394318 | D accuracy: 73.4375] [G loss: 1.3903093338012695]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2073 [D loss: 0.4303736239671707 | D accuracy: 81.25] [G loss: 1.3521485328674316]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2074 [D loss: 0.49388760328292847 | D accuracy: 78.125] [G loss: 1.318882942199707]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2075 [D loss: 0.4363614171743393 | D accuracy: 82.8125] [G loss: 1.5169451236724854]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2076 [D loss: 0.443916454911232 | D accuracy: 78.125] [G loss: 1.3706239461898804]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2077 [D loss: 0.43428345024585724 | D accuracy: 82.8125] [G loss: 1.4392309188842773]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2078 [D loss: 0.5287294089794159 | D accuracy: 71.875] [G loss: 1.410103678703308]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2079 [D loss: 0.4233160465955734 | D accuracy: 81.25] [G loss: 1.333552360534668]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2080 [D loss: 0.5096728205680847 | D accuracy: 73.4375] [G loss: 1.4143669605255127]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2081 [D loss: 0.473398819565773 | D accuracy: 81.25] [G loss: 1.4779868125915527]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2082 [D loss: 0.4689229428768158 | D accuracy: 75.0] [G loss: 1.239262342453003]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2083 [D loss: 0.40428370237350464 | D accuracy: 82.8125] [G loss: 1.4485383033752441]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2084 [D loss: 0.6982879042625427 | D accuracy: 59.375] [G loss: 1.5282392501831055]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2085 [D loss: 0.5365131497383118 | D accuracy: 73.4375] [G loss: 1.4875200986862183]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2086 [D loss: 0.6110028624534607 | D accuracy: 62.5] [G loss: 1.4785447120666504]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2087 [D loss: 0.4704471379518509 | D accuracy: 75.0] [G loss: 1.2915033102035522]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2088 [D loss: 0.5701000690460205 | D accuracy: 67.1875] [G loss: 1.3350473642349243]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2089 [D loss: 0.5169563889503479 | D accuracy: 75.0] [G loss: 1.2322444915771484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2090 [D loss: 0.5700596272945404 | D accuracy: 68.75] [G loss: 1.3770198822021484]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2091 [D loss: 0.5262604057788849 | D accuracy: 70.3125] [G loss: 1.3121159076690674]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2092 [D loss: 0.5165367424488068 | D accuracy: 75.0] [G loss: 1.706882119178772]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2093 [D loss: 0.6974793970584869 | D accuracy: 56.25] [G loss: 1.4120607376098633]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2094 [D loss: 0.4000367522239685 | D accuracy: 87.5] [G loss: 1.6264210939407349]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2095 [D loss: 0.5246070474386215 | D accuracy: 70.3125] [G loss: 1.4497261047363281]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2096 [D loss: 0.5337989181280136 | D accuracy: 70.3125] [G loss: 1.327474594116211]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2097 [D loss: 0.530469611287117 | D accuracy: 75.0] [G loss: 1.4555110931396484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2098 [D loss: 0.4598951041698456 | D accuracy: 82.8125] [G loss: 1.3331387042999268]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2099 [D loss: 0.44527044892311096 | D accuracy: 82.8125] [G loss: 1.3797425031661987]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2100 [D loss: 0.5258325934410095 | D accuracy: 73.4375] [G loss: 1.4173916578292847]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2101 [D loss: 0.37024207413196564 | D accuracy: 82.8125] [G loss: 1.546322226524353]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2102 [D loss: 0.4129074364900589 | D accuracy: 82.8125] [G loss: 1.326195478439331]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2103 [D loss: 0.5026240795850754 | D accuracy: 76.5625] [G loss: 1.4336152076721191]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2104 [D loss: 0.4424279034137726 | D accuracy: 76.5625] [G loss: 1.4441020488739014]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2105 [D loss: 0.4217875897884369 | D accuracy: 87.5] [G loss: 1.4090769290924072]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2106 [D loss: 0.4465633034706116 | D accuracy: 82.8125] [G loss: 1.2616771459579468]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2107 [D loss: 0.48135584592819214 | D accuracy: 79.6875] [G loss: 1.376248836517334]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2108 [D loss: 0.45526760816574097 | D accuracy: 75.0] [G loss: 1.3694605827331543]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2109 [D loss: 0.3920668214559555 | D accuracy: 87.5] [G loss: 1.4704773426055908]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2110 [D loss: 0.502807542681694 | D accuracy: 76.5625] [G loss: 1.534958839416504]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2111 [D loss: 0.6127679347991943 | D accuracy: 65.625] [G loss: 1.3347294330596924]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2112 [D loss: 0.48918162286281586 | D accuracy: 82.8125] [G loss: 1.3084052801132202]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2113 [D loss: 0.6930513978004456 | D accuracy: 60.9375] [G loss: 1.3740248680114746]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2114 [D loss: 0.5101399421691895 | D accuracy: 73.4375] [G loss: 1.6437102556228638]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2115 [D loss: 0.5218513011932373 | D accuracy: 65.625] [G loss: 1.3284740447998047]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2116 [D loss: 0.4108385145664215 | D accuracy: 87.5] [G loss: 1.3528037071228027]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2117 [D loss: 0.502394437789917 | D accuracy: 71.875] [G loss: 1.3689223527908325]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2118 [D loss: 0.4290618598461151 | D accuracy: 79.6875] [G loss: 1.4118242263793945]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2119 [D loss: 0.38210441172122955 | D accuracy: 81.25] [G loss: 1.353157877922058]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2120 [D loss: 0.3847603052854538 | D accuracy: 85.9375] [G loss: 1.5581986904144287]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2121 [D loss: 0.4794357568025589 | D accuracy: 71.875] [G loss: 1.3566550016403198]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2122 [D loss: 0.5275290906429291 | D accuracy: 78.125] [G loss: 1.3442559242248535]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2123 [D loss: 0.5216311514377594 | D accuracy: 73.4375] [G loss: 1.3694168329238892]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2124 [D loss: 0.45298443734645844 | D accuracy: 76.5625] [G loss: 1.4172663688659668]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2125 [D loss: 0.46896786987781525 | D accuracy: 71.875] [G loss: 1.3638157844543457]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2126 [D loss: 0.4869161695241928 | D accuracy: 76.5625] [G loss: 1.2443674802780151]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2127 [D loss: 0.654452919960022 | D accuracy: 62.5] [G loss: 1.2737231254577637]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2128 [D loss: 0.51360222697258 | D accuracy: 78.125] [G loss: 1.2573186159133911]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2129 [D loss: 0.6022744625806808 | D accuracy: 67.1875] [G loss: 1.3076682090759277]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2130 [D loss: 0.4555344581604004 | D accuracy: 78.125] [G loss: 1.245060682296753]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2131 [D loss: 0.5126093775033951 | D accuracy: 71.875] [G loss: 1.5047390460968018]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2132 [D loss: 0.45594973862171173 | D accuracy: 84.375] [G loss: 1.399274468421936]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2133 [D loss: 0.46454524993896484 | D accuracy: 73.4375] [G loss: 1.2208057641983032]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2134 [D loss: 0.47720927000045776 | D accuracy: 79.6875] [G loss: 1.3563604354858398]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2135 [D loss: 0.478511244058609 | D accuracy: 82.8125] [G loss: 1.429410457611084]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2136 [D loss: 0.5169485211372375 | D accuracy: 73.4375] [G loss: 1.4976823329925537]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2137 [D loss: 0.468960165977478 | D accuracy: 78.125] [G loss: 1.5737178325653076]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2138 [D loss: 0.42743128538131714 | D accuracy: 78.125] [G loss: 1.634472131729126]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2139 [D loss: 0.48161444067955017 | D accuracy: 75.0] [G loss: 1.6264863014221191]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2140 [D loss: 0.412378191947937 | D accuracy: 78.125] [G loss: 1.4277936220169067]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2141 [D loss: 0.47427883744239807 | D accuracy: 79.6875] [G loss: 1.4728130102157593]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2142 [D loss: 0.5277141481637955 | D accuracy: 75.0] [G loss: 1.6683138608932495]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2143 [D loss: 0.39757058024406433 | D accuracy: 85.9375] [G loss: 1.521397590637207]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2144 [D loss: 0.536177396774292 | D accuracy: 71.875] [G loss: 1.5411951541900635]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2145 [D loss: 0.48722390830516815 | D accuracy: 76.5625] [G loss: 1.4831703901290894]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "2146 [D loss: 0.4427393674850464 | D accuracy: 81.25] [G loss: 1.5184388160705566]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2147 [D loss: 0.483980268239975 | D accuracy: 73.4375] [G loss: 1.1459156274795532]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2148 [D loss: 0.5441951304674149 | D accuracy: 71.875] [G loss: 1.37215256690979]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2149 [D loss: 0.4871155470609665 | D accuracy: 78.125] [G loss: 1.4368427991867065]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2150 [D loss: 0.405218243598938 | D accuracy: 84.375] [G loss: 1.6117640733718872]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2151 [D loss: 0.440369188785553 | D accuracy: 76.5625] [G loss: 1.5974187850952148]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2152 [D loss: 0.5596142113208771 | D accuracy: 68.75] [G loss: 1.5677026510238647]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2153 [D loss: 0.48678168654441833 | D accuracy: 75.0] [G loss: 1.4939402341842651]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2154 [D loss: 0.39066460728645325 | D accuracy: 87.5] [G loss: 1.552671194076538]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2155 [D loss: 0.49744078516960144 | D accuracy: 75.0] [G loss: 1.6514698266983032]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2156 [D loss: 0.5010397434234619 | D accuracy: 68.75] [G loss: 1.6085985898971558]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2157 [D loss: 0.42417237162590027 | D accuracy: 76.5625] [G loss: 1.507689356803894]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2158 [D loss: 0.5609612762928009 | D accuracy: 73.4375] [G loss: 1.4181158542633057]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2159 [D loss: 0.5329733490943909 | D accuracy: 73.4375] [G loss: 1.6068357229232788]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2160 [D loss: 0.4895663410425186 | D accuracy: 73.4375] [G loss: 1.4754202365875244]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2161 [D loss: 0.6508151888847351 | D accuracy: 62.5] [G loss: 1.2099361419677734]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2162 [D loss: 0.4517095535993576 | D accuracy: 78.125] [G loss: 1.1725636720657349]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2163 [D loss: 0.49694564938545227 | D accuracy: 76.5625] [G loss: 1.457868218421936]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2164 [D loss: 0.36685094237327576 | D accuracy: 87.5] [G loss: 1.5326098203659058]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2165 [D loss: 0.3829031437635422 | D accuracy: 87.5] [G loss: 1.4830089807510376]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2166 [D loss: 0.4067411720752716 | D accuracy: 84.375] [G loss: 1.4041295051574707]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2167 [D loss: 0.5153347998857498 | D accuracy: 70.3125] [G loss: 1.5265216827392578]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2168 [D loss: 0.44602566957473755 | D accuracy: 76.5625] [G loss: 1.537459373474121]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2169 [D loss: 0.3816100060939789 | D accuracy: 84.375] [G loss: 1.4353878498077393]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2170 [D loss: 0.43640604615211487 | D accuracy: 75.0] [G loss: 1.4168522357940674]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2171 [D loss: 0.5806185901165009 | D accuracy: 67.1875] [G loss: 1.4768767356872559]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2172 [D loss: 0.46660150587558746 | D accuracy: 75.0] [G loss: 1.5169404745101929]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2173 [D loss: 0.4161398112773895 | D accuracy: 75.0] [G loss: 1.5019714832305908]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2174 [D loss: 0.5506476312875748 | D accuracy: 76.5625] [G loss: 1.4494398832321167]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2175 [D loss: 0.5458617806434631 | D accuracy: 68.75] [G loss: 1.4174779653549194]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2176 [D loss: 0.562938004732132 | D accuracy: 70.3125] [G loss: 1.4261195659637451]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2177 [D loss: 0.5219870060682297 | D accuracy: 68.75] [G loss: 1.3764196634292603]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2178 [D loss: 0.5172406435012817 | D accuracy: 79.6875] [G loss: 1.4306124448776245]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2179 [D loss: 0.5282126069068909 | D accuracy: 75.0] [G loss: 1.2879005670547485]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2180 [D loss: 0.4539872407913208 | D accuracy: 81.25] [G loss: 1.5115506649017334]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2181 [D loss: 0.5030810683965683 | D accuracy: 78.125] [G loss: 1.467642068862915]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2182 [D loss: 0.4925537407398224 | D accuracy: 75.0] [G loss: 1.4262888431549072]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2183 [D loss: 0.4603862464427948 | D accuracy: 76.5625] [G loss: 1.3763387203216553]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2184 [D loss: 0.4425157904624939 | D accuracy: 76.5625] [G loss: 1.5554466247558594]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2185 [D loss: 0.600152313709259 | D accuracy: 70.3125] [G loss: 1.5964019298553467]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2186 [D loss: 0.46359045803546906 | D accuracy: 79.6875] [G loss: 1.4824583530426025]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2187 [D loss: 0.5620711743831635 | D accuracy: 75.0] [G loss: 1.351177453994751]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2188 [D loss: 0.6793972253799438 | D accuracy: 62.5] [G loss: 1.3554317951202393]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2189 [D loss: 0.46746550500392914 | D accuracy: 79.6875] [G loss: 1.3263909816741943]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2190 [D loss: 0.5218797922134399 | D accuracy: 75.0] [G loss: 1.4235665798187256]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2191 [D loss: 0.553925633430481 | D accuracy: 68.75] [G loss: 1.246338129043579]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2192 [D loss: 0.5525579154491425 | D accuracy: 71.875] [G loss: 1.5881898403167725]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2193 [D loss: 0.44233599305152893 | D accuracy: 79.6875] [G loss: 1.505795955657959]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2194 [D loss: 0.5685012340545654 | D accuracy: 70.3125] [G loss: 1.4164155721664429]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2195 [D loss: 0.42635461688041687 | D accuracy: 82.8125] [G loss: 1.256831407546997]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2196 [D loss: 0.4231836497783661 | D accuracy: 79.6875] [G loss: 1.4008171558380127]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2197 [D loss: 0.4914156198501587 | D accuracy: 79.6875] [G loss: 1.1397806406021118]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2198 [D loss: 0.35982489585876465 | D accuracy: 85.9375] [G loss: 1.3695619106292725]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2199 [D loss: 0.40656255185604095 | D accuracy: 79.6875] [G loss: 1.3554857969284058]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2200 [D loss: 0.5918415188789368 | D accuracy: 73.4375] [G loss: 1.7154752016067505]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2201 [D loss: 0.5088190734386444 | D accuracy: 75.0] [G loss: 1.4448168277740479]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2202 [D loss: 0.4863906502723694 | D accuracy: 76.5625] [G loss: 1.438201904296875]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2203 [D loss: 0.44361017644405365 | D accuracy: 75.0] [G loss: 1.3890131711959839]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2204 [D loss: 0.49688565731048584 | D accuracy: 71.875] [G loss: 1.4716516733169556]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2205 [D loss: 0.4458092749118805 | D accuracy: 81.25] [G loss: 1.4886250495910645]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2206 [D loss: 0.48593200743198395 | D accuracy: 75.0] [G loss: 1.2060000896453857]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2207 [D loss: 0.5423683077096939 | D accuracy: 71.875] [G loss: 1.3323161602020264]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2208 [D loss: 0.4031019061803818 | D accuracy: 85.9375] [G loss: 1.4369139671325684]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2209 [D loss: 0.46995311975479126 | D accuracy: 75.0] [G loss: 1.37800931930542]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2210 [D loss: 0.4833377003669739 | D accuracy: 73.4375] [G loss: 1.4551788568496704]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2211 [D loss: 0.44353997707366943 | D accuracy: 76.5625] [G loss: 1.4634760618209839]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2212 [D loss: 0.43442000448703766 | D accuracy: 76.5625] [G loss: 1.290027379989624]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2213 [D loss: 0.4960451126098633 | D accuracy: 71.875] [G loss: 1.4813451766967773]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2214 [D loss: 0.42668431997299194 | D accuracy: 79.6875] [G loss: 1.277235984802246]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2215 [D loss: 0.472104012966156 | D accuracy: 81.25] [G loss: 1.2295880317687988]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2216 [D loss: 0.5678461343050003 | D accuracy: 71.875] [G loss: 1.4002457857131958]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2217 [D loss: 0.4761943817138672 | D accuracy: 76.5625] [G loss: 1.3182839155197144]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2218 [D loss: 0.5115603506565094 | D accuracy: 79.6875] [G loss: 1.425031065940857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2219 [D loss: 0.4132595658302307 | D accuracy: 76.5625] [G loss: 1.2952589988708496]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2220 [D loss: 0.4789295494556427 | D accuracy: 79.6875] [G loss: 1.5884931087493896]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2221 [D loss: 0.5888454616069794 | D accuracy: 67.1875] [G loss: 1.657351016998291]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2222 [D loss: 0.5194063782691956 | D accuracy: 73.4375] [G loss: 1.447320818901062]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2223 [D loss: 0.4411955177783966 | D accuracy: 82.8125] [G loss: 1.4330744743347168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2224 [D loss: 0.5115064084529877 | D accuracy: 75.0] [G loss: 1.4030070304870605]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2225 [D loss: 0.4184032678604126 | D accuracy: 79.6875] [G loss: 1.2927621603012085]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2226 [D loss: 0.5257219970226288 | D accuracy: 76.5625] [G loss: 1.3245227336883545]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2227 [D loss: 0.5608980059623718 | D accuracy: 68.75] [G loss: 1.530655860900879]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2228 [D loss: 0.4896846115589142 | D accuracy: 73.4375] [G loss: 1.4111859798431396]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "2229 [D loss: 0.4426898658275604 | D accuracy: 81.25] [G loss: 1.3967440128326416]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2230 [D loss: 0.5385197401046753 | D accuracy: 67.1875] [G loss: 1.265163779258728]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2231 [D loss: 0.4010336548089981 | D accuracy: 85.9375] [G loss: 1.2640267610549927]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2232 [D loss: 0.38765430450439453 | D accuracy: 84.375] [G loss: 1.2587180137634277]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2233 [D loss: 0.42450015246868134 | D accuracy: 84.375] [G loss: 1.3299351930618286]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2234 [D loss: 0.5148828029632568 | D accuracy: 68.75] [G loss: 1.24375319480896]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2235 [D loss: 0.461166113615036 | D accuracy: 71.875] [G loss: 1.5774673223495483]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2236 [D loss: 0.4517343193292618 | D accuracy: 84.375] [G loss: 1.5149338245391846]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2237 [D loss: 0.48074258863925934 | D accuracy: 82.8125] [G loss: 1.3779261112213135]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2238 [D loss: 0.4791135936975479 | D accuracy: 73.4375] [G loss: 1.3395142555236816]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2239 [D loss: 0.5678747892379761 | D accuracy: 73.4375] [G loss: 1.3351166248321533]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2240 [D loss: 0.5154761373996735 | D accuracy: 73.4375] [G loss: 1.14803147315979]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2241 [D loss: 0.40629658102989197 | D accuracy: 79.6875] [G loss: 1.407731056213379]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2242 [D loss: 0.4278687387704849 | D accuracy: 79.6875] [G loss: 1.3980517387390137]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2243 [D loss: 0.4247940480709076 | D accuracy: 81.25] [G loss: 1.2636076211929321]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2244 [D loss: 0.48130157589912415 | D accuracy: 76.5625] [G loss: 1.357945203781128]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2245 [D loss: 0.49274349212646484 | D accuracy: 73.4375] [G loss: 1.409304141998291]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2246 [D loss: 0.4269466996192932 | D accuracy: 79.6875] [G loss: 1.478001594543457]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2247 [D loss: 0.45513245463371277 | D accuracy: 78.125] [G loss: 1.3003740310668945]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2248 [D loss: 0.5255629569292068 | D accuracy: 73.4375] [G loss: 1.2786061763763428]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2249 [D loss: 0.556317999958992 | D accuracy: 73.4375] [G loss: 1.417083501815796]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2250 [D loss: 0.5185595750808716 | D accuracy: 73.4375] [G loss: 1.312716007232666]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2251 [D loss: 0.4479000121355057 | D accuracy: 79.6875] [G loss: 1.3446061611175537]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2252 [D loss: 0.47004762291908264 | D accuracy: 78.125] [G loss: 1.370469331741333]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2253 [D loss: 0.4934921860694885 | D accuracy: 76.5625] [G loss: 1.374828577041626]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2254 [D loss: 0.48803383111953735 | D accuracy: 76.5625] [G loss: 1.304395079612732]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2255 [D loss: 0.43948785960674286 | D accuracy: 78.125] [G loss: 1.4994633197784424]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2256 [D loss: 0.381862610578537 | D accuracy: 85.9375] [G loss: 1.341953158378601]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2257 [D loss: 0.6281756162643433 | D accuracy: 64.0625] [G loss: 1.2539311647415161]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2258 [D loss: 0.5616070926189423 | D accuracy: 73.4375] [G loss: 1.3565946817398071]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2259 [D loss: 0.4988021105527878 | D accuracy: 78.125] [G loss: 1.305662751197815]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2260 [D loss: 0.5030778646469116 | D accuracy: 73.4375] [G loss: 1.407821536064148]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2261 [D loss: 0.5310193598270416 | D accuracy: 71.875] [G loss: 1.4631468057632446]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2262 [D loss: 0.47840043902397156 | D accuracy: 81.25] [G loss: 1.4487183094024658]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2263 [D loss: 0.5726732611656189 | D accuracy: 60.9375] [G loss: 1.2708916664123535]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2264 [D loss: 0.4431789219379425 | D accuracy: 81.25] [G loss: 1.3835735321044922]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2265 [D loss: 0.5088629126548767 | D accuracy: 73.4375] [G loss: 1.1926460266113281]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2266 [D loss: 0.503860667347908 | D accuracy: 76.5625] [G loss: 1.3110997676849365]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2267 [D loss: 0.5082214027643204 | D accuracy: 76.5625] [G loss: 1.4168813228607178]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2268 [D loss: 0.4650879055261612 | D accuracy: 78.125] [G loss: 1.3536301851272583]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2269 [D loss: 0.5648719966411591 | D accuracy: 79.6875] [G loss: 1.41158926486969]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2270 [D loss: 0.39055897295475006 | D accuracy: 84.375] [G loss: 1.465504765510559]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2271 [D loss: 0.5309723913669586 | D accuracy: 68.75] [G loss: 1.4910378456115723]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2272 [D loss: 0.4329720139503479 | D accuracy: 78.125] [G loss: 1.473132610321045]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2273 [D loss: 0.4755595475435257 | D accuracy: 78.125] [G loss: 1.4766654968261719]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2274 [D loss: 0.4547213464975357 | D accuracy: 81.25] [G loss: 1.4304362535476685]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2275 [D loss: 0.48886461555957794 | D accuracy: 76.5625] [G loss: 1.570894479751587]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2276 [D loss: 0.45727360248565674 | D accuracy: 78.125] [G loss: 1.533250093460083]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2277 [D loss: 0.5021496564149857 | D accuracy: 73.4375] [G loss: 1.2947478294372559]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2278 [D loss: 0.5573206543922424 | D accuracy: 71.875] [G loss: 1.30580735206604]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2279 [D loss: 0.3426542729139328 | D accuracy: 90.625] [G loss: 1.4041881561279297]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2280 [D loss: 0.41165733337402344 | D accuracy: 84.375] [G loss: 1.4140398502349854]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2281 [D loss: 0.47191697359085083 | D accuracy: 78.125] [G loss: 1.2004518508911133]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2282 [D loss: 0.5238968133926392 | D accuracy: 76.5625] [G loss: 1.2619041204452515]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2283 [D loss: 0.6279497146606445 | D accuracy: 67.1875] [G loss: 1.3497694730758667]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2284 [D loss: 0.46808546781539917 | D accuracy: 76.5625] [G loss: 1.4849779605865479]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2285 [D loss: 0.4702131301164627 | D accuracy: 76.5625] [G loss: 1.5365872383117676]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2286 [D loss: 0.40393607318401337 | D accuracy: 82.8125] [G loss: 1.4121220111846924]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2287 [D loss: 0.6040614545345306 | D accuracy: 65.625] [G loss: 1.2333444356918335]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2288 [D loss: 0.4988197982311249 | D accuracy: 78.125] [G loss: 1.4843363761901855]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2289 [D loss: 0.4358972907066345 | D accuracy: 73.4375] [G loss: 1.5601555109024048]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2290 [D loss: 0.4977624863386154 | D accuracy: 70.3125] [G loss: 1.6070165634155273]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2291 [D loss: 0.4775470346212387 | D accuracy: 76.5625] [G loss: 1.658584475517273]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2292 [D loss: 0.4938816875219345 | D accuracy: 73.4375] [G loss: 1.4677553176879883]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2293 [D loss: 0.4264495372772217 | D accuracy: 81.25] [G loss: 1.385148525238037]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2294 [D loss: 0.4693126678466797 | D accuracy: 81.25] [G loss: 1.395259141921997]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2295 [D loss: 0.404386967420578 | D accuracy: 79.6875] [G loss: 1.4535279273986816]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2296 [D loss: 0.45241865515708923 | D accuracy: 75.0] [G loss: 1.4424231052398682]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2297 [D loss: 0.45617982745170593 | D accuracy: 79.6875] [G loss: 1.4427988529205322]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2298 [D loss: 0.486600399017334 | D accuracy: 78.125] [G loss: 1.4238741397857666]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2299 [D loss: 0.5256845355033875 | D accuracy: 73.4375] [G loss: 1.5637657642364502]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2300 [D loss: 0.6133831441402435 | D accuracy: 65.625] [G loss: 1.4192945957183838]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2301 [D loss: 0.4121309816837311 | D accuracy: 81.25] [G loss: 1.6460671424865723]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2302 [D loss: 0.5127899348735809 | D accuracy: 78.125] [G loss: 1.3901827335357666]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2303 [D loss: 0.5936376303434372 | D accuracy: 68.75] [G loss: 1.4991905689239502]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2304 [D loss: 0.4678810238838196 | D accuracy: 75.0] [G loss: 1.4545950889587402]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2305 [D loss: 0.5354276299476624 | D accuracy: 70.3125] [G loss: 1.4134550094604492]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2306 [D loss: 0.4139898419380188 | D accuracy: 78.125] [G loss: 1.232306957244873]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2307 [D loss: 0.4512614756822586 | D accuracy: 78.125] [G loss: 1.3685197830200195]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2308 [D loss: 0.5560973584651947 | D accuracy: 73.4375] [G loss: 1.5047533512115479]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2309 [D loss: 0.3868411183357239 | D accuracy: 84.375] [G loss: 1.3595318794250488]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2310 [D loss: 0.418463796377182 | D accuracy: 79.6875] [G loss: 1.4441936016082764]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2311 [D loss: 0.504834771156311 | D accuracy: 71.875] [G loss: 1.1738295555114746]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2312 [D loss: 0.5511398911476135 | D accuracy: 70.3125] [G loss: 1.470603346824646]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2313 [D loss: 0.4131492078304291 | D accuracy: 82.8125] [G loss: 1.5622942447662354]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2314 [D loss: 0.4266761243343353 | D accuracy: 76.5625] [G loss: 1.3416657447814941]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2315 [D loss: 0.42094995081424713 | D accuracy: 78.125] [G loss: 1.3662590980529785]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2316 [D loss: 0.4671544134616852 | D accuracy: 84.375] [G loss: 1.3985915184020996]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2317 [D loss: 0.4771827310323715 | D accuracy: 81.25] [G loss: 1.3636393547058105]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2318 [D loss: 0.5126663446426392 | D accuracy: 75.0] [G loss: 1.414361596107483]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2319 [D loss: 0.4162035137414932 | D accuracy: 82.8125] [G loss: 1.2900116443634033]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2320 [D loss: 0.455684632062912 | D accuracy: 79.6875] [G loss: 1.3692253828048706]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2321 [D loss: 0.5350004434585571 | D accuracy: 71.875] [G loss: 1.588087558746338]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2322 [D loss: 0.5184812396764755 | D accuracy: 70.3125] [G loss: 1.441272258758545]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2323 [D loss: 0.5531152486801147 | D accuracy: 70.3125] [G loss: 1.3109276294708252]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2324 [D loss: 0.5090907216072083 | D accuracy: 75.0] [G loss: 1.598803997039795]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "2325 [D loss: 0.4784262180328369 | D accuracy: 75.0] [G loss: 1.5078129768371582]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2326 [D loss: 0.5781647562980652 | D accuracy: 75.0] [G loss: 1.3271934986114502]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2327 [D loss: 0.4340669810771942 | D accuracy: 84.375] [G loss: 1.3889884948730469]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2328 [D loss: 0.4855031967163086 | D accuracy: 78.125] [G loss: 1.3295286893844604]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2329 [D loss: 0.5608337223529816 | D accuracy: 67.1875] [G loss: 1.5640771389007568]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2330 [D loss: 0.4535461664199829 | D accuracy: 81.25] [G loss: 1.4142009019851685]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2331 [D loss: 0.45359987020492554 | D accuracy: 78.125] [G loss: 1.4429484605789185]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2332 [D loss: 0.5753182768821716 | D accuracy: 62.5] [G loss: 1.3857159614562988]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2333 [D loss: 0.3976006954908371 | D accuracy: 79.6875] [G loss: 1.443057894706726]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2334 [D loss: 0.395887091755867 | D accuracy: 81.25] [G loss: 1.4399487972259521]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2335 [D loss: 0.53325255215168 | D accuracy: 67.1875] [G loss: 1.3612990379333496]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2336 [D loss: 0.43295565247535706 | D accuracy: 81.25] [G loss: 1.364746332168579]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2337 [D loss: 0.49706849455833435 | D accuracy: 73.4375] [G loss: 1.3407793045043945]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2338 [D loss: 0.5492361783981323 | D accuracy: 73.4375] [G loss: 1.3660894632339478]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2339 [D loss: 0.44903820753097534 | D accuracy: 78.125] [G loss: 1.4846378564834595]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2340 [D loss: 0.5183359235525131 | D accuracy: 73.4375] [G loss: 1.5486159324645996]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2341 [D loss: 0.38661669194698334 | D accuracy: 85.9375] [G loss: 1.5458494424819946]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2342 [D loss: 0.5310771018266678 | D accuracy: 73.4375] [G loss: 1.4574782848358154]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2343 [D loss: 0.5030501782894135 | D accuracy: 76.5625] [G loss: 1.396100401878357]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2344 [D loss: 0.45045414566993713 | D accuracy: 75.0] [G loss: 1.3669378757476807]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2345 [D loss: 0.48450711369514465 | D accuracy: 76.5625] [G loss: 1.410652756690979]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2346 [D loss: 0.38496120274066925 | D accuracy: 89.0625] [G loss: 1.5900084972381592]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2347 [D loss: 0.4379602074623108 | D accuracy: 82.8125] [G loss: 1.6151459217071533]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2348 [D loss: 0.5484814643859863 | D accuracy: 75.0] [G loss: 1.4066016674041748]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2349 [D loss: 0.4429495632648468 | D accuracy: 82.8125] [G loss: 1.6436042785644531]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2350 [D loss: 0.4424968361854553 | D accuracy: 78.125] [G loss: 1.646024465560913]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2351 [D loss: 0.415198415517807 | D accuracy: 81.25] [G loss: 1.6737957000732422]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2352 [D loss: 0.4666476845741272 | D accuracy: 73.4375] [G loss: 1.4601216316223145]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2353 [D loss: 0.5008994340896606 | D accuracy: 76.5625] [G loss: 1.4852221012115479]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2354 [D loss: 0.4258056730031967 | D accuracy: 79.6875] [G loss: 1.6030547618865967]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2355 [D loss: 0.4252130836248398 | D accuracy: 81.25] [G loss: 1.2806018590927124]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2356 [D loss: 0.6459220349788666 | D accuracy: 60.9375] [G loss: 1.199689507484436]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2357 [D loss: 0.4833070933818817 | D accuracy: 75.0] [G loss: 1.326181173324585]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2358 [D loss: 0.4026968628168106 | D accuracy: 85.9375] [G loss: 1.3047611713409424]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2359 [D loss: 0.5118217468261719 | D accuracy: 65.625] [G loss: 1.238907814025879]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2360 [D loss: 0.5012660622596741 | D accuracy: 70.3125] [G loss: 1.460191011428833]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2361 [D loss: 0.5350696742534637 | D accuracy: 75.0] [G loss: 1.596176266670227]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2362 [D loss: 0.399146169424057 | D accuracy: 81.25] [G loss: 1.3963557481765747]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2363 [D loss: 0.5371358245611191 | D accuracy: 75.0] [G loss: 1.3661335706710815]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2364 [D loss: 0.4078749716281891 | D accuracy: 79.6875] [G loss: 1.5237751007080078]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2365 [D loss: 0.4994637966156006 | D accuracy: 78.125] [G loss: 1.4486241340637207]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2366 [D loss: 0.3738810122013092 | D accuracy: 85.9375] [G loss: 1.410391926765442]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2367 [D loss: 0.5416547358036041 | D accuracy: 62.5] [G loss: 1.289980173110962]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2368 [D loss: 0.4748857915401459 | D accuracy: 79.6875] [G loss: 1.3464266061782837]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2369 [D loss: 0.4163135886192322 | D accuracy: 81.25] [G loss: 1.4371534585952759]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2370 [D loss: 0.5366507917642593 | D accuracy: 71.875] [G loss: 1.6308538913726807]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2371 [D loss: 0.5627980530261993 | D accuracy: 67.1875] [G loss: 1.4292117357254028]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2372 [D loss: 0.5642948746681213 | D accuracy: 75.0] [G loss: 1.4898688793182373]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2373 [D loss: 0.40386059880256653 | D accuracy: 75.0] [G loss: 1.3880722522735596]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2374 [D loss: 0.6503628790378571 | D accuracy: 67.1875] [G loss: 1.3632797002792358]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2375 [D loss: 0.3896697163581848 | D accuracy: 82.8125] [G loss: 1.5572052001953125]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2376 [D loss: 0.4701671004295349 | D accuracy: 76.5625] [G loss: 1.469761610031128]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2377 [D loss: 0.45432907342910767 | D accuracy: 73.4375] [G loss: 1.5175851583480835]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2378 [D loss: 0.5519816279411316 | D accuracy: 70.3125] [G loss: 1.3825347423553467]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2379 [D loss: 0.4642692804336548 | D accuracy: 78.125] [G loss: 1.3549721240997314]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2380 [D loss: 0.5156794488430023 | D accuracy: 73.4375] [G loss: 1.293107271194458]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2381 [D loss: 0.38375331461429596 | D accuracy: 84.375] [G loss: 1.4190618991851807]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2382 [D loss: 0.3948323577642441 | D accuracy: 84.375] [G loss: 1.4929327964782715]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2383 [D loss: 0.42795591056346893 | D accuracy: 79.6875] [G loss: 1.2861210107803345]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2384 [D loss: 0.49073436856269836 | D accuracy: 78.125] [G loss: 1.2794301509857178]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2385 [D loss: 0.4137348532676697 | D accuracy: 79.6875] [G loss: 1.4334356784820557]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2386 [D loss: 0.5271729379892349 | D accuracy: 67.1875] [G loss: 1.3560892343521118]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2387 [D loss: 0.42463913559913635 | D accuracy: 81.25] [G loss: 1.3242796659469604]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2388 [D loss: 0.551319032907486 | D accuracy: 73.4375] [G loss: 1.328819990158081]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2389 [D loss: 0.4440946877002716 | D accuracy: 81.25] [G loss: 1.4621613025665283]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2390 [D loss: 0.41163206100463867 | D accuracy: 84.375] [G loss: 1.446923851966858]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2391 [D loss: 0.6192305088043213 | D accuracy: 68.75] [G loss: 1.4268200397491455]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2392 [D loss: 0.5209091007709503 | D accuracy: 76.5625] [G loss: 1.4102497100830078]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2393 [D loss: 0.4002208709716797 | D accuracy: 84.375] [G loss: 1.5059422254562378]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2394 [D loss: 0.6071920394897461 | D accuracy: 68.75] [G loss: 1.5194995403289795]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2395 [D loss: 0.5304803848266602 | D accuracy: 68.75] [G loss: 1.4071683883666992]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2396 [D loss: 0.5037883222103119 | D accuracy: 82.8125] [G loss: 1.5094339847564697]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2397 [D loss: 0.4749712347984314 | D accuracy: 78.125] [G loss: 1.5447213649749756]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2398 [D loss: 0.6233991980552673 | D accuracy: 57.8125] [G loss: 1.552785873413086]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "2399 [D loss: 0.4823518842458725 | D accuracy: 76.5625] [G loss: 1.5398335456848145]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2400 [D loss: 0.4637769013643265 | D accuracy: 73.4375] [G loss: 1.3144252300262451]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2401 [D loss: 0.45041877031326294 | D accuracy: 81.25] [G loss: 1.5720443725585938]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2402 [D loss: 0.5744937658309937 | D accuracy: 73.4375] [G loss: 1.295536756515503]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2403 [D loss: 0.5551268458366394 | D accuracy: 71.875] [G loss: 1.2649598121643066]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2404 [D loss: 0.5600804686546326 | D accuracy: 68.75] [G loss: 1.39413583278656]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2405 [D loss: 0.4783509373664856 | D accuracy: 67.1875] [G loss: 1.4229443073272705]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2406 [D loss: 0.37458816170692444 | D accuracy: 84.375] [G loss: 1.5004032850265503]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2407 [D loss: 0.47231733798980713 | D accuracy: 79.6875] [G loss: 1.5574978590011597]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2408 [D loss: 0.4744451344013214 | D accuracy: 73.4375] [G loss: 1.5146141052246094]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2409 [D loss: 0.593959778547287 | D accuracy: 62.5] [G loss: 1.5698144435882568]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2410 [D loss: 0.506858691573143 | D accuracy: 78.125] [G loss: 1.3166934251785278]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2411 [D loss: 0.4894508719444275 | D accuracy: 78.125] [G loss: 1.4049593210220337]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2412 [D loss: 0.5404412597417831 | D accuracy: 70.3125] [G loss: 1.3081663846969604]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2413 [D loss: 0.44353774189949036 | D accuracy: 78.125] [G loss: 1.2963292598724365]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2414 [D loss: 0.4619344621896744 | D accuracy: 76.5625] [G loss: 1.2900012731552124]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2415 [D loss: 0.4279137849807739 | D accuracy: 82.8125] [G loss: 1.3879948854446411]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2416 [D loss: 0.47291703522205353 | D accuracy: 75.0] [G loss: 1.4069857597351074]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2417 [D loss: 0.5829871594905853 | D accuracy: 67.1875] [G loss: 1.3393195867538452]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2418 [D loss: 0.46756498515605927 | D accuracy: 79.6875] [G loss: 1.3543627262115479]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2419 [D loss: 0.47510431706905365 | D accuracy: 79.6875] [G loss: 1.3716137409210205]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2420 [D loss: 0.4959211051464081 | D accuracy: 73.4375] [G loss: 1.3902113437652588]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2421 [D loss: 0.5676968097686768 | D accuracy: 67.1875] [G loss: 1.4448153972625732]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2422 [D loss: 0.49006977677345276 | D accuracy: 79.6875] [G loss: 1.6285796165466309]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2423 [D loss: 0.540031760931015 | D accuracy: 68.75] [G loss: 1.3817553520202637]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2424 [D loss: 0.5405551791191101 | D accuracy: 67.1875] [G loss: 1.4949536323547363]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2425 [D loss: 0.4894023984670639 | D accuracy: 75.0] [G loss: 1.5380222797393799]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2426 [D loss: 0.5275848209857941 | D accuracy: 70.3125] [G loss: 1.3461246490478516]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2427 [D loss: 0.39460113644599915 | D accuracy: 81.25] [G loss: 1.1685090065002441]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2428 [D loss: 0.5230056941509247 | D accuracy: 79.6875] [G loss: 1.3561491966247559]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2429 [D loss: 0.5395064949989319 | D accuracy: 78.125] [G loss: 1.3529024124145508]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2430 [D loss: 0.36400024592876434 | D accuracy: 82.8125] [G loss: 1.5649726390838623]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2431 [D loss: 0.6251278817653656 | D accuracy: 67.1875] [G loss: 1.3635188341140747]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2432 [D loss: 0.49466024339199066 | D accuracy: 70.3125] [G loss: 1.497725486755371]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2433 [D loss: 0.4480245113372803 | D accuracy: 81.25] [G loss: 1.3574191331863403]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2434 [D loss: 0.47069182991981506 | D accuracy: 76.5625] [G loss: 1.597795009613037]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2435 [D loss: 0.3868745416402817 | D accuracy: 84.375] [G loss: 1.4725799560546875]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2436 [D loss: 0.5268388092517853 | D accuracy: 70.3125] [G loss: 1.2806345224380493]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2437 [D loss: 0.5572162866592407 | D accuracy: 70.3125] [G loss: 1.4382648468017578]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2438 [D loss: 0.4794120788574219 | D accuracy: 71.875] [G loss: 1.2222447395324707]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2439 [D loss: 0.6407086849212646 | D accuracy: 68.75] [G loss: 1.3150092363357544]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2440 [D loss: 0.4782811254262924 | D accuracy: 82.8125] [G loss: 1.2264974117279053]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2441 [D loss: 0.46950189769268036 | D accuracy: 75.0] [G loss: 1.316231369972229]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2442 [D loss: 0.5688053071498871 | D accuracy: 70.3125] [G loss: 1.237683653831482]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2443 [D loss: 0.3933780640363693 | D accuracy: 82.8125] [G loss: 1.2714942693710327]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2444 [D loss: 0.39678043127059937 | D accuracy: 82.8125] [G loss: 1.2728180885314941]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2445 [D loss: 0.4877246916294098 | D accuracy: 75.0] [G loss: 1.3865941762924194]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2446 [D loss: 0.5408757627010345 | D accuracy: 71.875] [G loss: 1.3384068012237549]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2447 [D loss: 0.5442316234111786 | D accuracy: 71.875] [G loss: 1.4111926555633545]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2448 [D loss: 0.44789114594459534 | D accuracy: 79.6875] [G loss: 1.5133450031280518]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2449 [D loss: 0.4835141599178314 | D accuracy: 78.125] [G loss: 1.5877161026000977]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2450 [D loss: 0.504374086856842 | D accuracy: 73.4375] [G loss: 1.3874911069869995]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2451 [D loss: 0.5635356605052948 | D accuracy: 70.3125] [G loss: 1.4294614791870117]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2452 [D loss: 0.5221932977437973 | D accuracy: 70.3125] [G loss: 1.309023141860962]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2453 [D loss: 0.46589335799217224 | D accuracy: 75.0] [G loss: 1.348597764968872]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2454 [D loss: 0.45368097722530365 | D accuracy: 78.125] [G loss: 1.5248022079467773]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2455 [D loss: 0.45652031898498535 | D accuracy: 78.125] [G loss: 1.3920915126800537]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2456 [D loss: 0.46393586695194244 | D accuracy: 82.8125] [G loss: 1.4496725797653198]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2457 [D loss: 0.5048081278800964 | D accuracy: 71.875] [G loss: 1.3002345561981201]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2458 [D loss: 0.3843192160129547 | D accuracy: 87.5] [G loss: 1.410282850265503]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2459 [D loss: 0.5502208173274994 | D accuracy: 67.1875] [G loss: 1.268504023551941]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2460 [D loss: 0.5326092839241028 | D accuracy: 76.5625] [G loss: 1.593811273574829]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2461 [D loss: 0.5719986706972122 | D accuracy: 76.5625] [G loss: 1.4739733934402466]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2462 [D loss: 0.3977401852607727 | D accuracy: 79.6875] [G loss: 1.452620506286621]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2463 [D loss: 0.45354557037353516 | D accuracy: 76.5625] [G loss: 1.360109567642212]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2464 [D loss: 0.528745710849762 | D accuracy: 73.4375] [G loss: 1.4162089824676514]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2465 [D loss: 0.5956472158432007 | D accuracy: 65.625] [G loss: 1.3515228033065796]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2466 [D loss: 0.5126483738422394 | D accuracy: 71.875] [G loss: 1.2977204322814941]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2467 [D loss: 0.42776307463645935 | D accuracy: 78.125] [G loss: 1.5028706789016724]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2468 [D loss: 0.5096835047006607 | D accuracy: 76.5625] [G loss: 1.5947551727294922]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2469 [D loss: 0.48189936578273773 | D accuracy: 70.3125] [G loss: 1.4909271001815796]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2470 [D loss: 0.4087876081466675 | D accuracy: 82.8125] [G loss: 1.380063533782959]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2471 [D loss: 0.4781850129365921 | D accuracy: 79.6875] [G loss: 1.511487603187561]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2472 [D loss: 0.4258331060409546 | D accuracy: 82.8125] [G loss: 1.493837833404541]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2473 [D loss: 0.5091072916984558 | D accuracy: 68.75] [G loss: 1.5194722414016724]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2474 [D loss: 0.43599508702754974 | D accuracy: 81.25] [G loss: 1.399031400680542]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2475 [D loss: 0.49507296085357666 | D accuracy: 79.6875] [G loss: 1.3417757749557495]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2476 [D loss: 0.6115759611129761 | D accuracy: 67.1875] [G loss: 1.6061887741088867]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2477 [D loss: 0.496891126036644 | D accuracy: 73.4375] [G loss: 1.3709793090820312]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2478 [D loss: 0.5078011155128479 | D accuracy: 76.5625] [G loss: 1.6949177980422974]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2479 [D loss: 0.454144611954689 | D accuracy: 81.25] [G loss: 1.3883371353149414]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2480 [D loss: 0.5318753272294998 | D accuracy: 78.125] [G loss: 1.390120267868042]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2481 [D loss: 0.6467666029930115 | D accuracy: 65.625] [G loss: 1.6350958347320557]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2482 [D loss: 0.43664349615573883 | D accuracy: 76.5625] [G loss: 1.582519292831421]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2483 [D loss: 0.549182191491127 | D accuracy: 71.875] [G loss: 1.3380744457244873]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2484 [D loss: 0.5476721823215485 | D accuracy: 71.875] [G loss: 1.3209948539733887]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2485 [D loss: 0.5405503213405609 | D accuracy: 81.25] [G loss: 1.5663256645202637]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2486 [D loss: 0.4468841254711151 | D accuracy: 85.9375] [G loss: 1.5279316902160645]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2487 [D loss: 0.5598682314157486 | D accuracy: 75.0] [G loss: 1.4263606071472168]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2488 [D loss: 0.5632579028606415 | D accuracy: 64.0625] [G loss: 1.5811452865600586]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2489 [D loss: 0.4841519892215729 | D accuracy: 76.5625] [G loss: 1.509256362915039]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2490 [D loss: 0.5485565066337585 | D accuracy: 65.625] [G loss: 1.4948601722717285]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2491 [D loss: 0.6033992767333984 | D accuracy: 65.625] [G loss: 1.401005744934082]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2492 [D loss: 0.5721079111099243 | D accuracy: 73.4375] [G loss: 1.4452004432678223]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2493 [D loss: 0.5289588421583176 | D accuracy: 73.4375] [G loss: 1.5261033773422241]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2494 [D loss: 0.44840243458747864 | D accuracy: 78.125] [G loss: 1.3669551610946655]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2495 [D loss: 0.5283436179161072 | D accuracy: 71.875] [G loss: 1.5858941078186035]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2496 [D loss: 0.5919957756996155 | D accuracy: 67.1875] [G loss: 1.4979844093322754]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2497 [D loss: 0.5006549060344696 | D accuracy: 71.875] [G loss: 1.3350133895874023]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2498 [D loss: 0.509384423494339 | D accuracy: 73.4375] [G loss: 1.4104394912719727]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2499 [D loss: 0.4556921422481537 | D accuracy: 76.5625] [G loss: 1.5384020805358887]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2500 [D loss: 0.4457864463329315 | D accuracy: 82.8125] [G loss: 1.4996726512908936]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2501 [D loss: 0.4860588610172272 | D accuracy: 76.5625] [G loss: 1.5269997119903564]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2502 [D loss: 0.5667950510978699 | D accuracy: 71.875] [G loss: 1.3175764083862305]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2503 [D loss: 0.44024190306663513 | D accuracy: 79.6875] [G loss: 1.4932281970977783]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2504 [D loss: 0.5945529639720917 | D accuracy: 67.1875] [G loss: 1.3632118701934814]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2505 [D loss: 0.5099186301231384 | D accuracy: 73.4375] [G loss: 1.4461729526519775]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2506 [D loss: 0.4949563294649124 | D accuracy: 79.6875] [G loss: 1.4111218452453613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2507 [D loss: 0.4787595272064209 | D accuracy: 79.6875] [G loss: 1.2166671752929688]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2508 [D loss: 0.48963025212287903 | D accuracy: 79.6875] [G loss: 1.1690278053283691]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2509 [D loss: 0.467200368642807 | D accuracy: 76.5625] [G loss: 1.3566608428955078]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2510 [D loss: 0.4698035418987274 | D accuracy: 73.4375] [G loss: 1.3791272640228271]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2511 [D loss: 0.5414003133773804 | D accuracy: 73.4375] [G loss: 1.4572412967681885]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2512 [D loss: 0.5256615281105042 | D accuracy: 71.875] [G loss: 1.4092775583267212]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2513 [D loss: 0.47327038645744324 | D accuracy: 73.4375] [G loss: 1.4731156826019287]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2514 [D loss: 0.47893981635570526 | D accuracy: 75.0] [G loss: 1.4977670907974243]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2515 [D loss: 0.5759583413600922 | D accuracy: 73.4375] [G loss: 1.5019915103912354]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2516 [D loss: 0.572488009929657 | D accuracy: 71.875] [G loss: 1.3357477188110352]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2517 [D loss: 0.49987131357192993 | D accuracy: 73.4375] [G loss: 1.2702200412750244]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2518 [D loss: 0.46237093210220337 | D accuracy: 76.5625] [G loss: 1.3200273513793945]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2519 [D loss: 0.5421094000339508 | D accuracy: 71.875] [G loss: 1.3875372409820557]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2520 [D loss: 0.5140236616134644 | D accuracy: 73.4375] [G loss: 1.3295471668243408]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2521 [D loss: 0.508202850818634 | D accuracy: 76.5625] [G loss: 1.3274091482162476]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2522 [D loss: 0.5192193686962128 | D accuracy: 68.75] [G loss: 1.5161607265472412]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2523 [D loss: 0.34892913699150085 | D accuracy: 87.5] [G loss: 1.4820795059204102]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2524 [D loss: 0.46683473885059357 | D accuracy: 84.375] [G loss: 1.2365646362304688]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2525 [D loss: 0.4748077690601349 | D accuracy: 75.0] [G loss: 1.4210833311080933]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2526 [D loss: 0.5860475152730942 | D accuracy: 67.1875] [G loss: 1.6113755702972412]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2527 [D loss: 0.5380362868309021 | D accuracy: 68.75] [G loss: 1.4416117668151855]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2528 [D loss: 0.41247236728668213 | D accuracy: 84.375] [G loss: 1.3515549898147583]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2529 [D loss: 0.4973047822713852 | D accuracy: 75.0] [G loss: 1.4867792129516602]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2530 [D loss: 0.5182605385780334 | D accuracy: 71.875] [G loss: 1.4775536060333252]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2531 [D loss: 0.5941347479820251 | D accuracy: 64.0625] [G loss: 1.4783706665039062]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2532 [D loss: 0.5281026065349579 | D accuracy: 75.0] [G loss: 1.424806833267212]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2533 [D loss: 0.4018583595752716 | D accuracy: 84.375] [G loss: 1.370918869972229]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2534 [D loss: 0.48509325087070465 | D accuracy: 75.0] [G loss: 1.3020687103271484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2535 [D loss: 0.4759087860584259 | D accuracy: 81.25] [G loss: 1.4362233877182007]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2536 [D loss: 0.45268121361732483 | D accuracy: 81.25] [G loss: 1.456187129020691]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2537 [D loss: 0.6115089356899261 | D accuracy: 64.0625] [G loss: 1.2238481044769287]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2538 [D loss: 0.49031753838062286 | D accuracy: 76.5625] [G loss: 1.4883954524993896]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2539 [D loss: 0.5868216753005981 | D accuracy: 76.5625] [G loss: 1.216820240020752]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2540 [D loss: 0.5126400738954544 | D accuracy: 71.875] [G loss: 1.396146297454834]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2541 [D loss: 0.3751724362373352 | D accuracy: 85.9375] [G loss: 1.4417108297348022]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2542 [D loss: 0.38281187415122986 | D accuracy: 89.0625] [G loss: 1.273674726486206]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2543 [D loss: 0.5788453817367554 | D accuracy: 68.75] [G loss: 1.5111780166625977]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2544 [D loss: 0.47597846388816833 | D accuracy: 71.875] [G loss: 1.3906214237213135]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2545 [D loss: 0.43621936440467834 | D accuracy: 79.6875] [G loss: 1.3429272174835205]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2546 [D loss: 0.4583863615989685 | D accuracy: 81.25] [G loss: 1.472213864326477]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2547 [D loss: 0.5049002170562744 | D accuracy: 75.0] [G loss: 1.1774964332580566]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2548 [D loss: 0.5031729340553284 | D accuracy: 76.5625] [G loss: 1.3436310291290283]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2549 [D loss: 0.5346411168575287 | D accuracy: 71.875] [G loss: 1.404726505279541]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2550 [D loss: 0.4877626746892929 | D accuracy: 75.0] [G loss: 1.352118968963623]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2551 [D loss: 0.35654768347740173 | D accuracy: 84.375] [G loss: 1.4381626844406128]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2552 [D loss: 0.5952966809272766 | D accuracy: 70.3125] [G loss: 1.470170497894287]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2553 [D loss: 0.4837108701467514 | D accuracy: 81.25] [G loss: 1.508561372756958]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2554 [D loss: 0.5382356643676758 | D accuracy: 78.125] [G loss: 1.4203088283538818]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2555 [D loss: 0.44735264778137207 | D accuracy: 82.8125] [G loss: 1.3692924976348877]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2556 [D loss: 0.5031816959381104 | D accuracy: 68.75] [G loss: 1.3945684432983398]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2557 [D loss: 0.4683125168085098 | D accuracy: 78.125] [G loss: 1.3745009899139404]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2558 [D loss: 0.5433237850666046 | D accuracy: 71.875] [G loss: 1.53373122215271]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2559 [D loss: 0.5254243016242981 | D accuracy: 79.6875] [G loss: 1.5384254455566406]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2560 [D loss: 0.45227932929992676 | D accuracy: 79.6875] [G loss: 1.5640370845794678]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2561 [D loss: 0.4619483947753906 | D accuracy: 73.4375] [G loss: 1.5073163509368896]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2562 [D loss: 0.6092396378517151 | D accuracy: 68.75] [G loss: 1.383619785308838]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2563 [D loss: 0.5115642845630646 | D accuracy: 75.0] [G loss: 1.6232318878173828]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2564 [D loss: 0.5470980405807495 | D accuracy: 70.3125] [G loss: 1.3349297046661377]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2565 [D loss: 0.5249796062707901 | D accuracy: 73.4375] [G loss: 1.4783895015716553]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2566 [D loss: 0.5616514682769775 | D accuracy: 73.4375] [G loss: 1.3532421588897705]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2567 [D loss: 0.5059279799461365 | D accuracy: 76.5625] [G loss: 1.4873636960983276]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2568 [D loss: 0.5211063027381897 | D accuracy: 70.3125] [G loss: 1.3952677249908447]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2569 [D loss: 0.5050686001777649 | D accuracy: 75.0] [G loss: 1.4052603244781494]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2570 [D loss: 0.5245488286018372 | D accuracy: 78.125] [G loss: 1.3876755237579346]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2571 [D loss: 0.5430901348590851 | D accuracy: 70.3125] [G loss: 1.409450650215149]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "2572 [D loss: 0.5353296846151352 | D accuracy: 75.0] [G loss: 1.381772756576538]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2573 [D loss: 0.5137502551078796 | D accuracy: 71.875] [G loss: 1.2509247064590454]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2574 [D loss: 0.5475490093231201 | D accuracy: 73.4375] [G loss: 1.2842552661895752]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2575 [D loss: 0.4982023686170578 | D accuracy: 78.125] [G loss: 1.553443193435669]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2576 [D loss: 0.5601807236671448 | D accuracy: 67.1875] [G loss: 1.4041292667388916]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2577 [D loss: 0.5837201476097107 | D accuracy: 60.9375] [G loss: 1.3562581539154053]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2578 [D loss: 0.425229549407959 | D accuracy: 84.375] [G loss: 1.491129994392395]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2579 [D loss: 0.4919246733188629 | D accuracy: 75.0] [G loss: 1.2833129167556763]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2580 [D loss: 0.5060618221759796 | D accuracy: 75.0] [G loss: 1.3811752796173096]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2581 [D loss: 0.5418734103441238 | D accuracy: 73.4375] [G loss: 1.232750654220581]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2582 [D loss: 0.4572576731443405 | D accuracy: 68.75] [G loss: 1.1545968055725098]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2583 [D loss: 0.4460628628730774 | D accuracy: 70.3125] [G loss: 1.1741164922714233]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2584 [D loss: 0.4618840962648392 | D accuracy: 76.5625] [G loss: 1.323270559310913]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2585 [D loss: 0.5987651944160461 | D accuracy: 64.0625] [G loss: 1.1831645965576172]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2586 [D loss: 0.4112388491630554 | D accuracy: 81.25] [G loss: 1.2018702030181885]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2587 [D loss: 0.6627783179283142 | D accuracy: 64.0625] [G loss: 1.4627381563186646]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2588 [D loss: 0.5719699263572693 | D accuracy: 68.75] [G loss: 1.341221809387207]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2589 [D loss: 0.3847677856683731 | D accuracy: 87.5] [G loss: 1.489276647567749]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2590 [D loss: 0.5861576795578003 | D accuracy: 64.0625] [G loss: 1.255555272102356]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2591 [D loss: 0.5486045479774475 | D accuracy: 68.75] [G loss: 1.19063401222229]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2592 [D loss: 0.5779935121536255 | D accuracy: 73.4375] [G loss: 1.2983590364456177]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2593 [D loss: 0.6183673739433289 | D accuracy: 68.75] [G loss: 1.2105982303619385]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2594 [D loss: 0.5702515542507172 | D accuracy: 73.4375] [G loss: 1.2019479274749756]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2595 [D loss: 0.4784614145755768 | D accuracy: 73.4375] [G loss: 1.391413927078247]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2596 [D loss: 0.5976583659648895 | D accuracy: 68.75] [G loss: 1.3486392498016357]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2597 [D loss: 0.5172744244337082 | D accuracy: 75.0] [G loss: 1.4305143356323242]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2598 [D loss: 0.4489275813102722 | D accuracy: 76.5625] [G loss: 1.4317598342895508]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2599 [D loss: 0.44109222292900085 | D accuracy: 76.5625] [G loss: 1.4238160848617554]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2600 [D loss: 0.5557646751403809 | D accuracy: 70.3125] [G loss: 1.2743678092956543]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2601 [D loss: 0.3985893130302429 | D accuracy: 81.25] [G loss: 1.2679338455200195]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2602 [D loss: 0.5170554518699646 | D accuracy: 73.4375] [G loss: 1.3961083889007568]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2603 [D loss: 0.39926718175411224 | D accuracy: 85.9375] [G loss: 1.4873679876327515]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2604 [D loss: 0.4645870625972748 | D accuracy: 73.4375] [G loss: 1.2820632457733154]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2605 [D loss: 0.350848525762558 | D accuracy: 85.9375] [G loss: 1.3351082801818848]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2606 [D loss: 0.48529545962810516 | D accuracy: 75.0] [G loss: 1.3233379125595093]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2607 [D loss: 0.41318279504776 | D accuracy: 81.25] [G loss: 1.435144066810608]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2608 [D loss: 0.39422760903835297 | D accuracy: 85.9375] [G loss: 1.4522056579589844]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2609 [D loss: 0.6350548565387726 | D accuracy: 60.9375] [G loss: 1.367002010345459]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2610 [D loss: 0.4796884059906006 | D accuracy: 75.0] [G loss: 1.447137475013733]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2611 [D loss: 0.49873754382133484 | D accuracy: 76.5625] [G loss: 1.4479721784591675]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2612 [D loss: 0.4078601896762848 | D accuracy: 81.25] [G loss: 1.5147396326065063]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2613 [D loss: 0.5254186689853668 | D accuracy: 68.75] [G loss: 1.4454970359802246]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2614 [D loss: 0.5428239554166794 | D accuracy: 67.1875] [G loss: 1.536766767501831]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2615 [D loss: 0.5155608355998993 | D accuracy: 73.4375] [G loss: 1.5728117227554321]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2616 [D loss: 0.5288069248199463 | D accuracy: 73.4375] [G loss: 1.4091548919677734]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2617 [D loss: 0.48028090596199036 | D accuracy: 76.5625] [G loss: 1.5945537090301514]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2618 [D loss: 0.45210331678390503 | D accuracy: 81.25] [G loss: 1.1833925247192383]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2619 [D loss: 0.505096048116684 | D accuracy: 79.6875] [G loss: 1.2907723188400269]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2620 [D loss: 0.5609585046768188 | D accuracy: 70.3125] [G loss: 1.200332760810852]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2621 [D loss: 0.43339645862579346 | D accuracy: 78.125] [G loss: 1.2713699340820312]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2622 [D loss: 0.5808598399162292 | D accuracy: 67.1875] [G loss: 1.53448486328125]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2623 [D loss: 0.4063264727592468 | D accuracy: 78.125] [G loss: 1.475396990776062]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2624 [D loss: 0.5788350105285645 | D accuracy: 64.0625] [G loss: 1.3248203992843628]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2625 [D loss: 0.5714320540428162 | D accuracy: 73.4375] [G loss: 1.428908348083496]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2626 [D loss: 0.5421517640352249 | D accuracy: 70.3125] [G loss: 1.4904059171676636]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2627 [D loss: 0.43052420020103455 | D accuracy: 82.8125] [G loss: 1.3985071182250977]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2628 [D loss: 0.5983264148235321 | D accuracy: 67.1875] [G loss: 1.4157252311706543]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2629 [D loss: 0.5025656521320343 | D accuracy: 71.875] [G loss: 1.2332167625427246]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2630 [D loss: 0.4690760225057602 | D accuracy: 78.125] [G loss: 1.1181915998458862]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2631 [D loss: 0.5182619392871857 | D accuracy: 71.875] [G loss: 1.3214102983474731]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2632 [D loss: 0.5083153545856476 | D accuracy: 70.3125] [G loss: 1.2663822174072266]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2633 [D loss: 0.4574946463108063 | D accuracy: 78.125] [G loss: 1.322089672088623]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2634 [D loss: 0.6677981019020081 | D accuracy: 59.375] [G loss: 1.1424589157104492]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2635 [D loss: 0.43446776270866394 | D accuracy: 79.6875] [G loss: 1.620577096939087]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2636 [D loss: 0.4846263527870178 | D accuracy: 76.5625] [G loss: 1.4441983699798584]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2637 [D loss: 0.6264120638370514 | D accuracy: 65.625] [G loss: 1.532019019126892]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2638 [D loss: 0.5231955200433731 | D accuracy: 76.5625] [G loss: 1.5539958477020264]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2639 [D loss: 0.46577438712120056 | D accuracy: 76.5625] [G loss: 1.3545548915863037]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2640 [D loss: 0.5186390280723572 | D accuracy: 75.0] [G loss: 1.5529251098632812]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2641 [D loss: 0.531989112496376 | D accuracy: 70.3125] [G loss: 1.308190941810608]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2642 [D loss: 0.5311114192008972 | D accuracy: 65.625] [G loss: 1.2759661674499512]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2643 [D loss: 0.4988138675689697 | D accuracy: 75.0] [G loss: 1.3895595073699951]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2644 [D loss: 0.48383888602256775 | D accuracy: 71.875] [G loss: 1.2974019050598145]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2645 [D loss: 0.40152791142463684 | D accuracy: 85.9375] [G loss: 1.2637598514556885]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2646 [D loss: 0.6145011186599731 | D accuracy: 62.5] [G loss: 1.243276834487915]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "2647 [D loss: 0.65824294090271 | D accuracy: 64.0625] [G loss: 1.430152177810669]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2648 [D loss: 0.582836776971817 | D accuracy: 68.75] [G loss: 1.5233526229858398]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2649 [D loss: 0.4678114503622055 | D accuracy: 78.125] [G loss: 1.513563632965088]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2650 [D loss: 0.5621345639228821 | D accuracy: 65.625] [G loss: 1.3162944316864014]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2651 [D loss: 0.5830458402633667 | D accuracy: 70.3125] [G loss: 1.1605392694473267]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2652 [D loss: 0.4669070243835449 | D accuracy: 81.25] [G loss: 1.287946343421936]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2653 [D loss: 0.48338429629802704 | D accuracy: 75.0] [G loss: 1.2813390493392944]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2654 [D loss: 0.6143841296434402 | D accuracy: 73.4375] [G loss: 1.4448586702346802]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2655 [D loss: 0.5541220903396606 | D accuracy: 75.0] [G loss: 1.4651551246643066]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2656 [D loss: 0.5624315142631531 | D accuracy: 64.0625] [G loss: 1.3602278232574463]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2657 [D loss: 0.4911596477031708 | D accuracy: 76.5625] [G loss: 1.4756972789764404]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "2658 [D loss: 0.6190594583749771 | D accuracy: 65.625] [G loss: 1.2881600856781006]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2659 [D loss: 0.43170639872550964 | D accuracy: 76.5625] [G loss: 1.3788702487945557]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2660 [D loss: 0.45302441716194153 | D accuracy: 78.125] [G loss: 1.3880586624145508]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2661 [D loss: 0.5536152124404907 | D accuracy: 70.3125] [G loss: 1.5996448993682861]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2662 [D loss: 0.5536159574985504 | D accuracy: 71.875] [G loss: 1.5169798135757446]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2663 [D loss: 0.5188853442668915 | D accuracy: 73.4375] [G loss: 1.5683773756027222]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2664 [D loss: 0.5160559564828873 | D accuracy: 71.875] [G loss: 1.2982457876205444]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2665 [D loss: 0.5416322350502014 | D accuracy: 71.875] [G loss: 1.3482125997543335]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2666 [D loss: 0.5108546316623688 | D accuracy: 68.75] [G loss: 1.2155568599700928]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2667 [D loss: 0.5750539302825928 | D accuracy: 68.75] [G loss: 1.3419616222381592]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2668 [D loss: 0.5226155370473862 | D accuracy: 76.5625] [G loss: 1.3055905103683472]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2669 [D loss: 0.5575929284095764 | D accuracy: 70.3125] [G loss: 1.2329888343811035]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2670 [D loss: 0.3908383846282959 | D accuracy: 89.0625] [G loss: 1.3210114240646362]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2671 [D loss: 0.39080531895160675 | D accuracy: 79.6875] [G loss: 1.2512669563293457]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2672 [D loss: 0.5541382133960724 | D accuracy: 73.4375] [G loss: 1.2857778072357178]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2673 [D loss: 0.5133091807365417 | D accuracy: 78.125] [G loss: 1.4511221647262573]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2674 [D loss: 0.6658622920513153 | D accuracy: 62.5] [G loss: 1.4864636659622192]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2675 [D loss: 0.4843125641345978 | D accuracy: 81.25] [G loss: 1.429813265800476]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2676 [D loss: 0.4521920382976532 | D accuracy: 84.375] [G loss: 1.361189603805542]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2677 [D loss: 0.47444935142993927 | D accuracy: 76.5625] [G loss: 1.3158283233642578]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2678 [D loss: 0.5379347652196884 | D accuracy: 76.5625] [G loss: 1.383176326751709]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2679 [D loss: 0.4451824873685837 | D accuracy: 87.5] [G loss: 1.3277361392974854]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2680 [D loss: 0.5514788031578064 | D accuracy: 70.3125] [G loss: 1.2482867240905762]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2681 [D loss: 0.5804216116666794 | D accuracy: 68.75] [G loss: 1.4327186346054077]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2682 [D loss: 0.5691269934177399 | D accuracy: 75.0] [G loss: 1.4292664527893066]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2683 [D loss: 0.5222014784812927 | D accuracy: 73.4375] [G loss: 1.4212706089019775]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2684 [D loss: 0.5331286042928696 | D accuracy: 75.0] [G loss: 1.2473022937774658]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2685 [D loss: 0.529284656047821 | D accuracy: 75.0] [G loss: 1.2392879724502563]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2686 [D loss: 0.5706424415111542 | D accuracy: 67.1875] [G loss: 1.2572566270828247]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2687 [D loss: 0.5503465235233307 | D accuracy: 71.875] [G loss: 1.2817630767822266]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2688 [D loss: 0.5120248794555664 | D accuracy: 67.1875] [G loss: 1.2066757678985596]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2689 [D loss: 0.49467042088508606 | D accuracy: 70.3125] [G loss: 1.2336848974227905]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2690 [D loss: 0.5711606740951538 | D accuracy: 70.3125] [G loss: 1.2227051258087158]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2691 [D loss: 0.4059455692768097 | D accuracy: 87.5] [G loss: 1.3501429557800293]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2692 [D loss: 0.5303190350532532 | D accuracy: 76.5625] [G loss: 1.5079843997955322]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2693 [D loss: 0.5170874446630478 | D accuracy: 78.125] [G loss: 1.3835445642471313]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2694 [D loss: 0.5585036277770996 | D accuracy: 67.1875] [G loss: 1.4386754035949707]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2695 [D loss: 0.5421649366617203 | D accuracy: 68.75] [G loss: 1.3814761638641357]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2696 [D loss: 0.4998138099908829 | D accuracy: 73.4375] [G loss: 1.2240209579467773]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2697 [D loss: 0.5055481940507889 | D accuracy: 75.0] [G loss: 1.3748079538345337]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2698 [D loss: 0.5015882849693298 | D accuracy: 75.0] [G loss: 1.31802237033844]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2699 [D loss: 0.5745284557342529 | D accuracy: 64.0625] [G loss: 1.34238862991333]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2700 [D loss: 0.5694430768489838 | D accuracy: 71.875] [G loss: 1.324697732925415]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2701 [D loss: 0.5393160879611969 | D accuracy: 71.875] [G loss: 1.3543204069137573]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2702 [D loss: 0.5612859129905701 | D accuracy: 68.75] [G loss: 1.4336494207382202]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2703 [D loss: 0.6485137939453125 | D accuracy: 60.9375] [G loss: 1.4806798696517944]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2704 [D loss: 0.5280507802963257 | D accuracy: 67.1875] [G loss: 1.5234129428863525]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2705 [D loss: 0.4794944077730179 | D accuracy: 75.0] [G loss: 1.4865986108779907]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2706 [D loss: 0.5380735099315643 | D accuracy: 70.3125] [G loss: 1.3492655754089355]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2707 [D loss: 0.5761738717556 | D accuracy: 68.75] [G loss: 1.4254052639007568]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2708 [D loss: 0.5367881208658218 | D accuracy: 70.3125] [G loss: 1.2817071676254272]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2709 [D loss: 0.5413597226142883 | D accuracy: 70.3125] [G loss: 1.320090889930725]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2710 [D loss: 0.5366435945034027 | D accuracy: 73.4375] [G loss: 1.3234853744506836]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2711 [D loss: 0.5219449996948242 | D accuracy: 76.5625] [G loss: 1.1717944145202637]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2712 [D loss: 0.5975346714258194 | D accuracy: 68.75] [G loss: 1.1694331169128418]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2713 [D loss: 0.47544021904468536 | D accuracy: 75.0] [G loss: 1.2642412185668945]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2714 [D loss: 0.4708027094602585 | D accuracy: 84.375] [G loss: 1.3773493766784668]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2715 [D loss: 0.5304502546787262 | D accuracy: 73.4375] [G loss: 1.399129867553711]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2716 [D loss: 0.5085541158914566 | D accuracy: 71.875] [G loss: 1.4253342151641846]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2717 [D loss: 0.5002200454473495 | D accuracy: 71.875] [G loss: 1.471766710281372]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2718 [D loss: 0.47784067690372467 | D accuracy: 82.8125] [G loss: 1.3180134296417236]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2719 [D loss: 0.4226478934288025 | D accuracy: 84.375] [G loss: 1.303365707397461]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2720 [D loss: 0.5181988179683685 | D accuracy: 75.0] [G loss: 1.4758659601211548]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2721 [D loss: 0.5481342226266861 | D accuracy: 65.625] [G loss: 1.3416297435760498]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "2722 [D loss: 0.48851917684078217 | D accuracy: 73.4375] [G loss: 1.0753023624420166]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2723 [D loss: 0.5831627547740936 | D accuracy: 68.75] [G loss: 1.2044988870620728]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2724 [D loss: 0.4502031058073044 | D accuracy: 81.25] [G loss: 1.536816120147705]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2725 [D loss: 0.47874118387699127 | D accuracy: 79.6875] [G loss: 1.3060319423675537]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2726 [D loss: 0.5804207026958466 | D accuracy: 68.75] [G loss: 1.355581521987915]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2727 [D loss: 0.5240126550197601 | D accuracy: 73.4375] [G loss: 1.3589093685150146]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2728 [D loss: 0.5242629945278168 | D accuracy: 73.4375] [G loss: 1.1645314693450928]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2729 [D loss: 0.537497878074646 | D accuracy: 73.4375] [G loss: 1.5364969968795776]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2730 [D loss: 0.6063290238380432 | D accuracy: 67.1875] [G loss: 1.268494963645935]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "2731 [D loss: 0.5432372987270355 | D accuracy: 71.875] [G loss: 1.2829194068908691]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2732 [D loss: 0.49909818172454834 | D accuracy: 73.4375] [G loss: 1.4812097549438477]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2733 [D loss: 0.493793323636055 | D accuracy: 75.0] [G loss: 1.2536282539367676]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2734 [D loss: 0.5234998762607574 | D accuracy: 76.5625] [G loss: 1.3517343997955322]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2735 [D loss: 0.5221377611160278 | D accuracy: 71.875] [G loss: 1.3855841159820557]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2736 [D loss: 0.5408985912799835 | D accuracy: 75.0] [G loss: 1.5007102489471436]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2737 [D loss: 0.4649369418621063 | D accuracy: 84.375] [G loss: 1.4315922260284424]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2738 [D loss: 0.41422969102859497 | D accuracy: 81.25] [G loss: 1.3127737045288086]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2739 [D loss: 0.5972788631916046 | D accuracy: 65.625] [G loss: 1.4498789310455322]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2740 [D loss: 0.47924093902111053 | D accuracy: 78.125] [G loss: 1.4646623134613037]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2741 [D loss: 0.431657999753952 | D accuracy: 78.125] [G loss: 1.6129282712936401]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2742 [D loss: 0.5600394308567047 | D accuracy: 68.75] [G loss: 1.3275405168533325]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2743 [D loss: 0.5249893069267273 | D accuracy: 75.0] [G loss: 1.3368785381317139]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2744 [D loss: 0.49792973697185516 | D accuracy: 70.3125] [G loss: 1.3515944480895996]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2745 [D loss: 0.5322248637676239 | D accuracy: 71.875] [G loss: 1.2283512353897095]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2746 [D loss: 0.47094033658504486 | D accuracy: 73.4375] [G loss: 1.2734102010726929]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2747 [D loss: 0.4892258942127228 | D accuracy: 78.125] [G loss: 1.3208534717559814]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2748 [D loss: 0.5133790373802185 | D accuracy: 73.4375] [G loss: 1.4619438648223877]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2749 [D loss: 0.4364768713712692 | D accuracy: 85.9375] [G loss: 1.3727370500564575]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2750 [D loss: 0.45379963517189026 | D accuracy: 79.6875] [G loss: 1.2445900440216064]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2751 [D loss: 0.5305738151073456 | D accuracy: 68.75] [G loss: 1.2645409107208252]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2752 [D loss: 0.57365283370018 | D accuracy: 71.875] [G loss: 1.417588710784912]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2753 [D loss: 0.4910724461078644 | D accuracy: 76.5625] [G loss: 1.3640562295913696]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2754 [D loss: 0.5029028058052063 | D accuracy: 68.75] [G loss: 1.2535320520401]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2755 [D loss: 0.4724387228488922 | D accuracy: 73.4375] [G loss: 1.3831491470336914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2756 [D loss: 0.47069184482097626 | D accuracy: 76.5625] [G loss: 1.201413631439209]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2757 [D loss: 0.542614072561264 | D accuracy: 64.0625] [G loss: 1.4027907848358154]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2758 [D loss: 0.47678233683109283 | D accuracy: 76.5625] [G loss: 1.2805747985839844]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2759 [D loss: 0.4561147689819336 | D accuracy: 78.125] [G loss: 1.2877894639968872]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2760 [D loss: 0.5145010650157928 | D accuracy: 73.4375] [G loss: 1.4177201986312866]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2761 [D loss: 0.4607250392436981 | D accuracy: 78.125] [G loss: 1.3256421089172363]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2762 [D loss: 0.6197159886360168 | D accuracy: 62.5] [G loss: 1.1797659397125244]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2763 [D loss: 0.4445270895957947 | D accuracy: 79.6875] [G loss: 1.4084925651550293]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2764 [D loss: 0.43178999423980713 | D accuracy: 78.125] [G loss: 1.3790738582611084]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2765 [D loss: 0.5370905101299286 | D accuracy: 68.75] [G loss: 1.260392665863037]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2766 [D loss: 0.6140905320644379 | D accuracy: 60.9375] [G loss: 1.2672898769378662]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2767 [D loss: 0.43682119250297546 | D accuracy: 78.125] [G loss: 1.4833908081054688]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2768 [D loss: 0.5200518369674683 | D accuracy: 68.75] [G loss: 1.2927740812301636]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2769 [D loss: 0.5505394339561462 | D accuracy: 76.5625] [G loss: 1.3716137409210205]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2770 [D loss: 0.4930036813020706 | D accuracy: 78.125] [G loss: 1.2784699201583862]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2771 [D loss: 0.5491719841957092 | D accuracy: 73.4375] [G loss: 1.3667898178100586]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2772 [D loss: 0.5033821165561676 | D accuracy: 76.5625] [G loss: 1.2909917831420898]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2773 [D loss: 0.4665220081806183 | D accuracy: 78.125] [G loss: 1.577911615371704]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2774 [D loss: 0.5573767870664597 | D accuracy: 70.3125] [G loss: 1.318070888519287]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2775 [D loss: 0.4167812168598175 | D accuracy: 84.375] [G loss: 1.373531460762024]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2776 [D loss: 0.5163961052894592 | D accuracy: 71.875] [G loss: 1.3683295249938965]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2777 [D loss: 0.51783087849617 | D accuracy: 73.4375] [G loss: 1.3069496154785156]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2778 [D loss: 0.5067550987005234 | D accuracy: 73.4375] [G loss: 1.3860869407653809]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2779 [D loss: 0.603429988026619 | D accuracy: 70.3125] [G loss: 1.1142959594726562]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2780 [D loss: 0.5987623333930969 | D accuracy: 62.5] [G loss: 1.4067736864089966]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2781 [D loss: 0.5117376148700714 | D accuracy: 82.8125] [G loss: 1.2678680419921875]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2782 [D loss: 0.5253890156745911 | D accuracy: 76.5625] [G loss: 1.2443640232086182]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2783 [D loss: 0.5335763394832611 | D accuracy: 71.875] [G loss: 1.2098777294158936]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2784 [D loss: 0.5160097181797028 | D accuracy: 73.4375] [G loss: 1.0585863590240479]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2785 [D loss: 0.5520266592502594 | D accuracy: 68.75] [G loss: 1.3044580221176147]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2786 [D loss: 0.40090301632881165 | D accuracy: 76.5625] [G loss: 1.1890621185302734]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2787 [D loss: 0.570458710193634 | D accuracy: 67.1875] [G loss: 1.403772234916687]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2788 [D loss: 0.48675835132598877 | D accuracy: 76.5625] [G loss: 1.3884358406066895]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2789 [D loss: 0.5780729055404663 | D accuracy: 71.875] [G loss: 1.3414621353149414]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2790 [D loss: 0.5421213805675507 | D accuracy: 68.75] [G loss: 1.3083802461624146]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2791 [D loss: 0.5031868517398834 | D accuracy: 68.75] [G loss: 1.328777551651001]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2792 [D loss: 0.5539240539073944 | D accuracy: 73.4375] [G loss: 1.4145176410675049]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2793 [D loss: 0.597806453704834 | D accuracy: 57.8125] [G loss: 1.2997642755508423]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2794 [D loss: 0.5353178679943085 | D accuracy: 68.75] [G loss: 1.2940757274627686]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2795 [D loss: 0.4735393822193146 | D accuracy: 78.125] [G loss: 1.294208288192749]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2796 [D loss: 0.5553199052810669 | D accuracy: 68.75] [G loss: 1.272552251815796]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2797 [D loss: 0.442302867770195 | D accuracy: 82.8125] [G loss: 1.3060904741287231]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "2798 [D loss: 0.600409209728241 | D accuracy: 64.0625] [G loss: 1.3385522365570068]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2799 [D loss: 0.5444520860910416 | D accuracy: 78.125] [G loss: 1.4304405450820923]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2800 [D loss: 0.6304776072502136 | D accuracy: 57.8125] [G loss: 1.4060258865356445]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2801 [D loss: 0.5119118094444275 | D accuracy: 73.4375] [G loss: 1.3523199558258057]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2802 [D loss: 0.48027291893959045 | D accuracy: 73.4375] [G loss: 1.411597728729248]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2803 [D loss: 0.5068959444761276 | D accuracy: 82.8125] [G loss: 1.378891944885254]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2804 [D loss: 0.42349305748939514 | D accuracy: 81.25] [G loss: 1.0460271835327148]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2805 [D loss: 0.3852764219045639 | D accuracy: 90.625] [G loss: 1.2734184265136719]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2806 [D loss: 0.5564794540405273 | D accuracy: 70.3125] [G loss: 1.5109435319900513]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2807 [D loss: 0.4821420907974243 | D accuracy: 84.375] [G loss: 1.4861366748809814]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2808 [D loss: 0.41878925263881683 | D accuracy: 81.25] [G loss: 1.4798461198806763]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2809 [D loss: 0.562822014093399 | D accuracy: 68.75] [G loss: 1.2830697298049927]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2810 [D loss: 0.49132268130779266 | D accuracy: 76.5625] [G loss: 1.5211368799209595]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2811 [D loss: 0.5034323185682297 | D accuracy: 75.0] [G loss: 1.5102981328964233]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2812 [D loss: 0.545943558216095 | D accuracy: 71.875] [G loss: 1.3601700067520142]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2813 [D loss: 0.5729297697544098 | D accuracy: 67.1875] [G loss: 1.4294214248657227]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2814 [D loss: 0.46269311010837555 | D accuracy: 76.5625] [G loss: 1.3150649070739746]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2815 [D loss: 0.6927680671215057 | D accuracy: 70.3125] [G loss: 1.3795182704925537]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2816 [D loss: 0.5041517615318298 | D accuracy: 67.1875] [G loss: 1.3429661989212036]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2817 [D loss: 0.47468051314353943 | D accuracy: 73.4375] [G loss: 1.3742990493774414]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2818 [D loss: 0.422426700592041 | D accuracy: 81.25] [G loss: 1.1273658275604248]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2819 [D loss: 0.5528087466955185 | D accuracy: 70.3125] [G loss: 1.2516441345214844]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2820 [D loss: 0.5384454727172852 | D accuracy: 64.0625] [G loss: 1.3429815769195557]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2821 [D loss: 0.533281683921814 | D accuracy: 71.875] [G loss: 1.5838518142700195]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2822 [D loss: 0.6110941171646118 | D accuracy: 62.5] [G loss: 1.3674687147140503]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2823 [D loss: 0.5903196930885315 | D accuracy: 67.1875] [G loss: 1.3263976573944092]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2824 [D loss: 0.45427970588207245 | D accuracy: 76.5625] [G loss: 1.4438612461090088]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2825 [D loss: 0.4955165386199951 | D accuracy: 78.125] [G loss: 1.3692800998687744]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2826 [D loss: 0.5456931889057159 | D accuracy: 68.75] [G loss: 1.2211599349975586]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2827 [D loss: 0.4730117917060852 | D accuracy: 79.6875] [G loss: 1.1369061470031738]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2828 [D loss: 0.5608760416507721 | D accuracy: 70.3125] [G loss: 1.2017313241958618]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2829 [D loss: 0.5271706879138947 | D accuracy: 67.1875] [G loss: 1.3389400243759155]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2830 [D loss: 0.458200067281723 | D accuracy: 79.6875] [G loss: 1.3992793560028076]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2831 [D loss: 0.394996702671051 | D accuracy: 84.375] [G loss: 1.3438284397125244]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2832 [D loss: 0.518220067024231 | D accuracy: 73.4375] [G loss: 1.2893552780151367]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2833 [D loss: 0.5728335380554199 | D accuracy: 76.5625] [G loss: 1.273747205734253]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2834 [D loss: 0.5224801301956177 | D accuracy: 71.875] [G loss: 1.3345972299575806]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2835 [D loss: 0.5787193775177002 | D accuracy: 70.3125] [G loss: 1.4101134538650513]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2836 [D loss: 0.5994433462619781 | D accuracy: 68.75] [G loss: 1.4978965520858765]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2837 [D loss: 0.47372347116470337 | D accuracy: 78.125] [G loss: 1.4498851299285889]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2838 [D loss: 0.5754116773605347 | D accuracy: 70.3125] [G loss: 1.4593346118927002]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2839 [D loss: 0.5072412490844727 | D accuracy: 73.4375] [G loss: 1.2052881717681885]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2840 [D loss: 0.5563471764326096 | D accuracy: 78.125] [G loss: 1.1793837547302246]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2841 [D loss: 0.5241722762584686 | D accuracy: 73.4375] [G loss: 1.238336205482483]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2842 [D loss: 0.4620116055011749 | D accuracy: 79.6875] [G loss: 1.165532112121582]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2843 [D loss: 0.5633859932422638 | D accuracy: 71.875] [G loss: 1.3551385402679443]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2844 [D loss: 0.588252454996109 | D accuracy: 62.5] [G loss: 1.3140864372253418]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2845 [D loss: 0.4553115516901016 | D accuracy: 79.6875] [G loss: 1.2869534492492676]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2846 [D loss: 0.5322372317314148 | D accuracy: 73.4375] [G loss: 1.4278738498687744]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2847 [D loss: 0.5554094612598419 | D accuracy: 67.1875] [G loss: 1.4172347784042358]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2848 [D loss: 0.5135502219200134 | D accuracy: 75.0] [G loss: 1.3909034729003906]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2849 [D loss: 0.5868551135063171 | D accuracy: 71.875] [G loss: 1.3504737615585327]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2850 [D loss: 0.5271291881799698 | D accuracy: 70.3125] [G loss: 1.3396471738815308]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2851 [D loss: 0.5752732753753662 | D accuracy: 65.625] [G loss: 1.383367896080017]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2852 [D loss: 0.6025209724903107 | D accuracy: 68.75] [G loss: 1.2919410467147827]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2853 [D loss: 0.5337985903024673 | D accuracy: 67.1875] [G loss: 1.2913706302642822]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2854 [D loss: 0.42559996247291565 | D accuracy: 81.25] [G loss: 1.365516185760498]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2855 [D loss: 0.5958214998245239 | D accuracy: 65.625] [G loss: 1.287981629371643]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2856 [D loss: 0.6217840313911438 | D accuracy: 59.375] [G loss: 1.1704356670379639]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2857 [D loss: 0.46333998441696167 | D accuracy: 78.125] [G loss: 1.2944071292877197]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2858 [D loss: 0.5986078381538391 | D accuracy: 70.3125] [G loss: 1.3098742961883545]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2859 [D loss: 0.4518668204545975 | D accuracy: 78.125] [G loss: 1.2653093338012695]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2860 [D loss: 0.5946522057056427 | D accuracy: 71.875] [G loss: 1.2634882926940918]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2861 [D loss: 0.5849789381027222 | D accuracy: 71.875] [G loss: 1.226357340812683]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2862 [D loss: 0.6243312954902649 | D accuracy: 65.625] [G loss: 1.3212083578109741]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2863 [D loss: 0.5317719578742981 | D accuracy: 76.5625] [G loss: 1.402160882949829]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2864 [D loss: 0.41701023280620575 | D accuracy: 81.25] [G loss: 1.6033923625946045]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2865 [D loss: 0.49342724680900574 | D accuracy: 73.4375] [G loss: 1.4374961853027344]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2866 [D loss: 0.45099465548992157 | D accuracy: 82.8125] [G loss: 1.1532621383666992]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2867 [D loss: 0.6628066599369049 | D accuracy: 59.375] [G loss: 1.2136507034301758]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2868 [D loss: 0.4319385886192322 | D accuracy: 82.8125] [G loss: 1.3240554332733154]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2869 [D loss: 0.608467161655426 | D accuracy: 65.625] [G loss: 1.242279291152954]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2870 [D loss: 0.5520600080490112 | D accuracy: 78.125] [G loss: 1.3153272867202759]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2871 [D loss: 0.5395501405000687 | D accuracy: 68.75] [G loss: 1.5922629833221436]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2872 [D loss: 0.6256008148193359 | D accuracy: 60.9375] [G loss: 1.316213846206665]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2873 [D loss: 0.5443674325942993 | D accuracy: 70.3125] [G loss: 1.3868297338485718]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2874 [D loss: 0.5058344602584839 | D accuracy: 73.4375] [G loss: 1.1783113479614258]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2875 [D loss: 0.5196656584739685 | D accuracy: 75.0] [G loss: 1.15548574924469]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2876 [D loss: 0.5107620358467102 | D accuracy: 73.4375] [G loss: 1.3133955001831055]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2877 [D loss: 0.5679050385951996 | D accuracy: 67.1875] [G loss: 1.4688812494277954]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2878 [D loss: 0.44370439648628235 | D accuracy: 75.0] [G loss: 1.3024910688400269]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2879 [D loss: 0.6603564620018005 | D accuracy: 60.9375] [G loss: 1.2348675727844238]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2880 [D loss: 0.5492623150348663 | D accuracy: 67.1875] [G loss: 1.3907639980316162]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "2881 [D loss: 0.5310581028461456 | D accuracy: 75.0] [G loss: 1.3885958194732666]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "2882 [D loss: 0.561227098107338 | D accuracy: 70.3125] [G loss: 1.0606629848480225]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2883 [D loss: 0.49921196699142456 | D accuracy: 71.875] [G loss: 1.3112289905548096]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "2884 [D loss: 0.6664628982543945 | D accuracy: 56.25] [G loss: 0.9870133996009827]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2885 [D loss: 0.36334922909736633 | D accuracy: 82.8125] [G loss: 1.2665233612060547]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2886 [D loss: 0.5290287584066391 | D accuracy: 71.875] [G loss: 1.1553654670715332]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2887 [D loss: 0.6021179258823395 | D accuracy: 65.625] [G loss: 1.2257556915283203]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2888 [D loss: 0.4368315786123276 | D accuracy: 75.0] [G loss: 1.3164324760437012]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "2889 [D loss: 0.48114460706710815 | D accuracy: 70.3125] [G loss: 1.3616092205047607]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "2890 [D loss: 0.689513623714447 | D accuracy: 57.8125] [G loss: 1.2599217891693115]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2891 [D loss: 0.5923833847045898 | D accuracy: 71.875] [G loss: 1.261840581893921]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2892 [D loss: 0.46467021107673645 | D accuracy: 79.6875] [G loss: 1.4382669925689697]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2893 [D loss: 0.539051279425621 | D accuracy: 73.4375] [G loss: 1.4414722919464111]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2894 [D loss: 0.4596966803073883 | D accuracy: 78.125] [G loss: 1.5143011808395386]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2895 [D loss: 0.6095034778118134 | D accuracy: 67.1875] [G loss: 1.326319932937622]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2896 [D loss: 0.5132225751876831 | D accuracy: 75.0] [G loss: 1.1080336570739746]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2897 [D loss: 0.5262728929519653 | D accuracy: 68.75] [G loss: 1.163339376449585]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2898 [D loss: 0.5750808119773865 | D accuracy: 65.625] [G loss: 0.9722337126731873]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2899 [D loss: 0.522583395242691 | D accuracy: 71.875] [G loss: 1.1599335670471191]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2900 [D loss: 0.4648432582616806 | D accuracy: 81.25] [G loss: 1.2264901399612427]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2901 [D loss: 0.44035589694976807 | D accuracy: 78.125] [G loss: 1.185166358947754]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2902 [D loss: 0.4357717037200928 | D accuracy: 81.25] [G loss: 1.305117130279541]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2903 [D loss: 0.4736102670431137 | D accuracy: 75.0] [G loss: 1.3006635904312134]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2904 [D loss: 0.4793016314506531 | D accuracy: 75.0] [G loss: 1.2086734771728516]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2905 [D loss: 0.5362160354852676 | D accuracy: 75.0] [G loss: 1.4180946350097656]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2906 [D loss: 0.4655582159757614 | D accuracy: 79.6875] [G loss: 1.324101209640503]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2907 [D loss: 0.5186833143234253 | D accuracy: 78.125] [G loss: 1.3307886123657227]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2908 [D loss: 0.6048970222473145 | D accuracy: 68.75] [G loss: 1.1894428730010986]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2909 [D loss: 0.430597648024559 | D accuracy: 82.8125] [G loss: 1.3368312120437622]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2910 [D loss: 0.48876985907554626 | D accuracy: 78.125] [G loss: 1.4166295528411865]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2911 [D loss: 0.4650264382362366 | D accuracy: 75.0] [G loss: 1.2330656051635742]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2912 [D loss: 0.5536257028579712 | D accuracy: 76.5625] [G loss: 1.162603735923767]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2913 [D loss: 0.5377026200294495 | D accuracy: 65.625] [G loss: 1.3201597929000854]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2914 [D loss: 0.5414754152297974 | D accuracy: 78.125] [G loss: 1.3436154127120972]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2915 [D loss: 0.5815513432025909 | D accuracy: 68.75] [G loss: 1.3125488758087158]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2916 [D loss: 0.5437560677528381 | D accuracy: 71.875] [G loss: 1.1923624277114868]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2917 [D loss: 0.580719530582428 | D accuracy: 67.1875] [G loss: 1.2775208950042725]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2918 [D loss: 0.420475572347641 | D accuracy: 76.5625] [G loss: 1.363567590713501]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2919 [D loss: 0.5391466170549393 | D accuracy: 67.1875] [G loss: 1.286224603652954]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2920 [D loss: 0.4789902865886688 | D accuracy: 78.125] [G loss: 1.3952887058258057]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2921 [D loss: 0.5104779750108719 | D accuracy: 78.125] [G loss: 1.39020574092865]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2922 [D loss: 0.4868839979171753 | D accuracy: 73.4375] [G loss: 1.2585484981536865]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2923 [D loss: 0.5911326706409454 | D accuracy: 67.1875] [G loss: 1.3691734075546265]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2924 [D loss: 0.6043038070201874 | D accuracy: 67.1875] [G loss: 1.3980790376663208]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2925 [D loss: 0.5149737298488617 | D accuracy: 70.3125] [G loss: 1.4038821458816528]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2926 [D loss: 0.4828418344259262 | D accuracy: 78.125] [G loss: 1.2668263912200928]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2927 [D loss: 0.4921724796295166 | D accuracy: 68.75] [G loss: 1.2910854816436768]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2928 [D loss: 0.6105629503726959 | D accuracy: 60.9375] [G loss: 1.2597090005874634]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2929 [D loss: 0.5259589105844498 | D accuracy: 71.875] [G loss: 1.3891236782073975]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2930 [D loss: 0.5649444013834 | D accuracy: 73.4375] [G loss: 1.2438992261886597]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2931 [D loss: 0.6116475462913513 | D accuracy: 60.9375] [G loss: 1.2671077251434326]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2932 [D loss: 0.5654423832893372 | D accuracy: 73.4375] [G loss: 1.2811193466186523]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2933 [D loss: 0.46736663579940796 | D accuracy: 75.0] [G loss: 1.2649794816970825]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2934 [D loss: 0.5564513206481934 | D accuracy: 70.3125] [G loss: 1.268692135810852]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2935 [D loss: 0.4702892005443573 | D accuracy: 82.8125] [G loss: 1.4831256866455078]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2936 [D loss: 0.6360778212547302 | D accuracy: 62.5] [G loss: 1.362262487411499]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2937 [D loss: 0.5785322189331055 | D accuracy: 65.625] [G loss: 1.2588293552398682]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2938 [D loss: 0.5021311342716217 | D accuracy: 78.125] [G loss: 1.2760205268859863]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2939 [D loss: 0.5340307652950287 | D accuracy: 71.875] [G loss: 1.2148730754852295]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2940 [D loss: 0.5393598675727844 | D accuracy: 71.875] [G loss: 1.2243402004241943]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2941 [D loss: 0.5129221081733704 | D accuracy: 75.0] [G loss: 1.2844908237457275]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2942 [D loss: 0.5525563061237335 | D accuracy: 67.1875] [G loss: 1.35172700881958]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2943 [D loss: 0.4801572859287262 | D accuracy: 76.5625] [G loss: 1.3199609518051147]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2944 [D loss: 0.5947893559932709 | D accuracy: 67.1875] [G loss: 1.225559949874878]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2945 [D loss: 0.5849686861038208 | D accuracy: 73.4375] [G loss: 1.3354840278625488]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2946 [D loss: 0.6074851453304291 | D accuracy: 70.3125] [G loss: 1.292496681213379]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2947 [D loss: 0.5076034367084503 | D accuracy: 73.4375] [G loss: 1.2217451333999634]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2948 [D loss: 0.4577292203903198 | D accuracy: 81.25] [G loss: 1.166980266571045]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2949 [D loss: 0.548585057258606 | D accuracy: 68.75] [G loss: 1.192766547203064]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2950 [D loss: 0.4170612692832947 | D accuracy: 81.25] [G loss: 1.275172233581543]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2951 [D loss: 0.45206740498542786 | D accuracy: 84.375] [G loss: 1.2594661712646484]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2952 [D loss: 0.5609754323959351 | D accuracy: 70.3125] [G loss: 1.3996028900146484]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2953 [D loss: 0.5568480789661407 | D accuracy: 70.3125] [G loss: 1.1898488998413086]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2954 [D loss: 0.5302620977163315 | D accuracy: 62.5] [G loss: 1.1213171482086182]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2955 [D loss: 0.5044741034507751 | D accuracy: 68.75] [G loss: 1.1847662925720215]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2956 [D loss: 0.5358435213565826 | D accuracy: 76.5625] [G loss: 1.1639819145202637]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2957 [D loss: 0.49200382828712463 | D accuracy: 73.4375] [G loss: 1.1680259704589844]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2958 [D loss: 0.5678436160087585 | D accuracy: 67.1875] [G loss: 1.2318187952041626]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2959 [D loss: 0.4789992868900299 | D accuracy: 76.5625] [G loss: 1.3715040683746338]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2960 [D loss: 0.4628738760948181 | D accuracy: 82.8125] [G loss: 1.3843095302581787]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2961 [D loss: 0.5625012069940567 | D accuracy: 75.0] [G loss: 1.415761947631836]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2962 [D loss: 0.475581556558609 | D accuracy: 78.125] [G loss: 1.1932157278060913]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2963 [D loss: 0.5274014621973038 | D accuracy: 67.1875] [G loss: 1.2147037982940674]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2964 [D loss: 0.501648336648941 | D accuracy: 73.4375] [G loss: 1.1714001893997192]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2965 [D loss: 0.5549294948577881 | D accuracy: 70.3125] [G loss: 1.290604591369629]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2966 [D loss: 0.4966253638267517 | D accuracy: 73.4375] [G loss: 1.4071252346038818]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "2967 [D loss: 0.5584039390087128 | D accuracy: 71.875] [G loss: 1.1089427471160889]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2968 [D loss: 0.45900511741638184 | D accuracy: 78.125] [G loss: 1.2142765522003174]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "2969 [D loss: 0.4540761709213257 | D accuracy: 78.125] [G loss: 1.2092492580413818]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "2970 [D loss: 0.5915703177452087 | D accuracy: 68.75] [G loss: 1.3652156591415405]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "2971 [D loss: 0.5217798948287964 | D accuracy: 71.875] [G loss: 1.3072843551635742]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "2972 [D loss: 0.579498291015625 | D accuracy: 65.625] [G loss: 1.2710468769073486]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2973 [D loss: 0.5124215185642242 | D accuracy: 78.125] [G loss: 1.3419382572174072]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "2974 [D loss: 0.4521976113319397 | D accuracy: 81.25] [G loss: 1.2802865505218506]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "2975 [D loss: 0.7198919951915741 | D accuracy: 46.875] [G loss: 1.2961724996566772]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2976 [D loss: 0.49777287244796753 | D accuracy: 73.4375] [G loss: 1.0700271129608154]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2977 [D loss: 0.4703812152147293 | D accuracy: 82.8125] [G loss: 1.331428050994873]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2978 [D loss: 0.4987929165363312 | D accuracy: 81.25] [G loss: 1.4827673435211182]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2979 [D loss: 0.5825629532337189 | D accuracy: 70.3125] [G loss: 1.2996437549591064]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2980 [D loss: 0.44942423701286316 | D accuracy: 73.4375] [G loss: 1.1999822854995728]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2981 [D loss: 0.5206130743026733 | D accuracy: 73.4375] [G loss: 1.2294527292251587]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2982 [D loss: 0.6446885466575623 | D accuracy: 64.0625] [G loss: 1.2833787202835083]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2983 [D loss: 0.4822329729795456 | D accuracy: 76.5625] [G loss: 1.29888916015625]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2984 [D loss: 0.5991370975971222 | D accuracy: 70.3125] [G loss: 1.3716719150543213]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2985 [D loss: 0.5192154049873352 | D accuracy: 76.5625] [G loss: 1.2946643829345703]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2986 [D loss: 0.5405383706092834 | D accuracy: 67.1875] [G loss: 1.330945372581482]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2987 [D loss: 0.42483362555503845 | D accuracy: 79.6875] [G loss: 1.2344107627868652]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2988 [D loss: 0.6206555962562561 | D accuracy: 67.1875] [G loss: 1.189159631729126]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2989 [D loss: 0.49644333124160767 | D accuracy: 73.4375] [G loss: 1.1857293844223022]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2990 [D loss: 0.6311736404895782 | D accuracy: 65.625] [G loss: 1.2979449033737183]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2991 [D loss: 0.5101376473903656 | D accuracy: 75.0] [G loss: 1.200118064880371]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2992 [D loss: 0.6422324180603027 | D accuracy: 62.5] [G loss: 1.205079436302185]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2993 [D loss: 0.5020734965801239 | D accuracy: 73.4375] [G loss: 1.141891360282898]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2994 [D loss: 0.6066203117370605 | D accuracy: 64.0625] [G loss: 1.4345026016235352]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "2995 [D loss: 0.4925219416618347 | D accuracy: 78.125] [G loss: 1.4500384330749512]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2996 [D loss: 0.513765424489975 | D accuracy: 71.875] [G loss: 1.3207011222839355]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "2997 [D loss: 0.6243448257446289 | D accuracy: 60.9375] [G loss: 1.2748783826828003]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2998 [D loss: 0.5119057297706604 | D accuracy: 68.75] [G loss: 1.3478882312774658]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2999 [D loss: 0.49228203296661377 | D accuracy: 76.5625] [G loss: 1.2152957916259766]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3000 [D loss: 0.5125691145658493 | D accuracy: 81.25] [G loss: 1.1629350185394287]\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "3001 [D loss: 0.4773150235414505 | D accuracy: 76.5625] [G loss: 1.2608263492584229]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3002 [D loss: 0.6584146022796631 | D accuracy: 57.8125] [G loss: 1.323370099067688]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3003 [D loss: 0.6632242798805237 | D accuracy: 59.375] [G loss: 1.3774456977844238]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3004 [D loss: 0.5482673048973083 | D accuracy: 73.4375] [G loss: 1.2770607471466064]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3005 [D loss: 0.5308398902416229 | D accuracy: 76.5625] [G loss: 1.3504719734191895]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3006 [D loss: 0.521356463432312 | D accuracy: 79.6875] [G loss: 1.1943333148956299]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3007 [D loss: 0.4616843909025192 | D accuracy: 76.5625] [G loss: 1.202246069908142]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3008 [D loss: 0.5634581446647644 | D accuracy: 67.1875] [G loss: 1.2489783763885498]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3009 [D loss: 0.5203574597835541 | D accuracy: 73.4375] [G loss: 1.2121831178665161]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3010 [D loss: 0.4385980814695358 | D accuracy: 76.5625] [G loss: 1.324425458908081]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3011 [D loss: 0.5279660075902939 | D accuracy: 71.875] [G loss: 1.391826868057251]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3012 [D loss: 0.5528627038002014 | D accuracy: 73.4375] [G loss: 1.1618455648422241]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3013 [D loss: 0.5020926147699356 | D accuracy: 73.4375] [G loss: 1.3124663829803467]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3014 [D loss: 0.489160418510437 | D accuracy: 67.1875] [G loss: 1.3275325298309326]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3015 [D loss: 0.48911887407302856 | D accuracy: 67.1875] [G loss: 1.4608303308486938]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3016 [D loss: 0.5504454374313354 | D accuracy: 67.1875] [G loss: 1.3917765617370605]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3017 [D loss: 0.5254113078117371 | D accuracy: 68.75] [G loss: 1.4535458087921143]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3018 [D loss: 0.5595204830169678 | D accuracy: 70.3125] [G loss: 1.1098642349243164]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3019 [D loss: 0.6116338074207306 | D accuracy: 62.5] [G loss: 1.2471013069152832]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3020 [D loss: 0.4416435658931732 | D accuracy: 79.6875] [G loss: 1.270324468612671]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3021 [D loss: 0.459705114364624 | D accuracy: 79.6875] [G loss: 1.2567079067230225]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3022 [D loss: 0.7035663425922394 | D accuracy: 59.375] [G loss: 1.364248275756836]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3023 [D loss: 0.5186566263437271 | D accuracy: 76.5625] [G loss: 1.068293571472168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3024 [D loss: 0.49638600647449493 | D accuracy: 81.25] [G loss: 1.1930619478225708]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3025 [D loss: 0.5897026360034943 | D accuracy: 65.625] [G loss: 1.3618898391723633]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3026 [D loss: 0.43396803736686707 | D accuracy: 78.125] [G loss: 1.3297295570373535]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3027 [D loss: 0.4916365295648575 | D accuracy: 78.125] [G loss: 1.3589534759521484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3028 [D loss: 0.6311322450637817 | D accuracy: 68.75] [G loss: 1.1112148761749268]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3029 [D loss: 0.5768913328647614 | D accuracy: 68.75] [G loss: 1.1782653331756592]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3030 [D loss: 0.5533210635185242 | D accuracy: 73.4375] [G loss: 1.2919716835021973]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3031 [D loss: 0.5214261710643768 | D accuracy: 71.875] [G loss: 1.3153505325317383]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3032 [D loss: 0.5572657883167267 | D accuracy: 73.4375] [G loss: 1.2896335124969482]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3033 [D loss: 0.48163820803165436 | D accuracy: 78.125] [G loss: 1.2848739624023438]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3034 [D loss: 0.5327843278646469 | D accuracy: 73.4375] [G loss: 1.3860384225845337]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3035 [D loss: 0.45870253443717957 | D accuracy: 68.75] [G loss: 1.32326078414917]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3036 [D loss: 0.48917505145072937 | D accuracy: 78.125] [G loss: 1.2180436849594116]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3037 [D loss: 0.5043297857046127 | D accuracy: 70.3125] [G loss: 1.2113771438598633]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3038 [D loss: 0.5001059472560883 | D accuracy: 75.0] [G loss: 1.2364070415496826]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3039 [D loss: 0.5358857214450836 | D accuracy: 71.875] [G loss: 1.3273403644561768]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3040 [D loss: 0.590944230556488 | D accuracy: 65.625] [G loss: 1.3997987508773804]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3041 [D loss: 0.5126423537731171 | D accuracy: 76.5625] [G loss: 1.2163023948669434]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3042 [D loss: 0.6844162940979004 | D accuracy: 62.5] [G loss: 0.9960988163948059]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3043 [D loss: 0.6070859432220459 | D accuracy: 64.0625] [G loss: 1.2738673686981201]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3044 [D loss: 0.5334528535604477 | D accuracy: 67.1875] [G loss: 1.3265876770019531]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3045 [D loss: 0.5578164756298065 | D accuracy: 71.875] [G loss: 1.2746448516845703]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3046 [D loss: 0.6717079281806946 | D accuracy: 64.0625] [G loss: 1.2908236980438232]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3047 [D loss: 0.5610736310482025 | D accuracy: 75.0] [G loss: 1.297716498374939]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3048 [D loss: 0.5620324015617371 | D accuracy: 67.1875] [G loss: 1.2289185523986816]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3049 [D loss: 0.6037180125713348 | D accuracy: 65.625] [G loss: 1.1104305982589722]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3050 [D loss: 0.40936486423015594 | D accuracy: 79.6875] [G loss: 1.2455575466156006]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3051 [D loss: 0.5008927881717682 | D accuracy: 70.3125] [G loss: 1.3098502159118652]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3052 [D loss: 0.48745134472846985 | D accuracy: 75.0] [G loss: 1.2973031997680664]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3053 [D loss: 0.5075467824935913 | D accuracy: 73.4375] [G loss: 1.3385368585586548]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3054 [D loss: 0.40619702637195587 | D accuracy: 81.25] [G loss: 1.2435981035232544]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3055 [D loss: 0.6378542482852936 | D accuracy: 71.875] [G loss: 1.1543678045272827]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3056 [D loss: 0.5432597696781158 | D accuracy: 68.75] [G loss: 1.303835153579712]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3057 [D loss: 0.5497450232505798 | D accuracy: 76.5625] [G loss: 1.136858582496643]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3058 [D loss: 0.6021031737327576 | D accuracy: 64.0625] [G loss: 1.1847381591796875]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3059 [D loss: 0.5473986268043518 | D accuracy: 75.0] [G loss: 1.2402749061584473]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3060 [D loss: 0.555575430393219 | D accuracy: 71.875] [G loss: 1.2153239250183105]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3061 [D loss: 0.5693839937448502 | D accuracy: 73.4375] [G loss: 1.2154752016067505]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3062 [D loss: 0.44414447247982025 | D accuracy: 78.125] [G loss: 1.2392408847808838]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3063 [D loss: 0.5644887089729309 | D accuracy: 71.875] [G loss: 1.2133517265319824]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3064 [D loss: 0.6387977004051208 | D accuracy: 54.6875] [G loss: 1.1558361053466797]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3065 [D loss: 0.6031892001628876 | D accuracy: 67.1875] [G loss: 1.3576772212982178]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3066 [D loss: 0.6727751791477203 | D accuracy: 65.625] [G loss: 1.2696013450622559]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3067 [D loss: 0.5362337827682495 | D accuracy: 71.875] [G loss: 1.1961641311645508]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3068 [D loss: 0.517298012971878 | D accuracy: 73.4375] [G loss: 1.2047843933105469]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3069 [D loss: 0.5439464151859283 | D accuracy: 75.0] [G loss: 1.1959922313690186]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3070 [D loss: 0.4489029198884964 | D accuracy: 81.25] [G loss: 1.1607717275619507]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3071 [D loss: 0.5911921858787537 | D accuracy: 59.375] [G loss: 1.1597659587860107]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3072 [D loss: 0.5381391644477844 | D accuracy: 76.5625] [G loss: 1.2834105491638184]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3073 [D loss: 0.5715036392211914 | D accuracy: 67.1875] [G loss: 1.2137881517410278]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3074 [D loss: 0.5711955726146698 | D accuracy: 62.5] [G loss: 1.2419531345367432]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3075 [D loss: 0.55289027094841 | D accuracy: 75.0] [G loss: 1.304159164428711]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3076 [D loss: 0.5960560441017151 | D accuracy: 65.625] [G loss: 1.3726015090942383]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3077 [D loss: 0.5493068695068359 | D accuracy: 65.625] [G loss: 1.2010717391967773]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3078 [D loss: 0.5269708186388016 | D accuracy: 79.6875] [G loss: 1.3840968608856201]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3079 [D loss: 0.5787652134895325 | D accuracy: 71.875] [G loss: 1.2785627841949463]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3080 [D loss: 0.5747140049934387 | D accuracy: 62.5] [G loss: 1.2450215816497803]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3081 [D loss: 0.5700335502624512 | D accuracy: 75.0] [G loss: 1.2569148540496826]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3082 [D loss: 0.5849134027957916 | D accuracy: 65.625] [G loss: 1.3062821626663208]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3083 [D loss: 0.6329171359539032 | D accuracy: 64.0625] [G loss: 1.260432481765747]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3084 [D loss: 0.45778127014636993 | D accuracy: 79.6875] [G loss: 1.354844331741333]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3085 [D loss: 0.49055491387844086 | D accuracy: 79.6875] [G loss: 1.2797162532806396]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3086 [D loss: 0.5358099937438965 | D accuracy: 78.125] [G loss: 1.40274977684021]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3087 [D loss: 0.5452444851398468 | D accuracy: 73.4375] [G loss: 1.3727591037750244]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3088 [D loss: 0.5498350262641907 | D accuracy: 73.4375] [G loss: 1.224682092666626]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3089 [D loss: 0.49607184529304504 | D accuracy: 70.3125] [G loss: 1.1785755157470703]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3090 [D loss: 0.5715713202953339 | D accuracy: 76.5625] [G loss: 1.351125955581665]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3091 [D loss: 0.4260576367378235 | D accuracy: 84.375] [G loss: 1.327374815940857]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3092 [D loss: 0.4640117287635803 | D accuracy: 81.25] [G loss: 1.2150893211364746]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3093 [D loss: 0.7075223326683044 | D accuracy: 59.375] [G loss: 1.1796526908874512]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3094 [D loss: 0.540022224187851 | D accuracy: 70.3125] [G loss: 1.413623332977295]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3095 [D loss: 0.505335658788681 | D accuracy: 73.4375] [G loss: 1.4306594133377075]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3096 [D loss: 0.5110865980386734 | D accuracy: 73.4375] [G loss: 1.0856143236160278]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3097 [D loss: 0.5644761621952057 | D accuracy: 68.75] [G loss: 1.2900766134262085]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3098 [D loss: 0.5619123876094818 | D accuracy: 71.875] [G loss: 1.327449083328247]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3099 [D loss: 0.6461693644523621 | D accuracy: 59.375] [G loss: 1.0512328147888184]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3100 [D loss: 0.5967658460140228 | D accuracy: 62.5] [G loss: 1.1206984519958496]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3101 [D loss: 0.6826144158840179 | D accuracy: 62.5] [G loss: 1.237330436706543]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3102 [D loss: 0.5268813967704773 | D accuracy: 75.0] [G loss: 1.208566427230835]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3103 [D loss: 0.549479216337204 | D accuracy: 71.875] [G loss: 1.2912561893463135]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3104 [D loss: 0.47405506670475006 | D accuracy: 76.5625] [G loss: 1.3112529516220093]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3105 [D loss: 0.5248967111110687 | D accuracy: 75.0] [G loss: 1.32157564163208]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3106 [D loss: 0.5080031752586365 | D accuracy: 76.5625] [G loss: 1.257014513015747]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3107 [D loss: 0.5035111457109451 | D accuracy: 75.0] [G loss: 1.0016640424728394]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3108 [D loss: 0.4462246745824814 | D accuracy: 81.25] [G loss: 1.1478257179260254]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3109 [D loss: 0.5380501449108124 | D accuracy: 76.5625] [G loss: 1.1722819805145264]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3110 [D loss: 0.5513125360012054 | D accuracy: 68.75] [G loss: 1.1392879486083984]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3111 [D loss: 0.6501394510269165 | D accuracy: 60.9375] [G loss: 1.2003769874572754]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3112 [D loss: 0.5355071723461151 | D accuracy: 73.4375] [G loss: 1.3513076305389404]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3113 [D loss: 0.5418462157249451 | D accuracy: 67.1875] [G loss: 1.228283166885376]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3114 [D loss: 0.525326132774353 | D accuracy: 76.5625] [G loss: 1.2732186317443848]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3115 [D loss: 0.5410473942756653 | D accuracy: 76.5625] [G loss: 1.3535857200622559]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3116 [D loss: 0.5803936123847961 | D accuracy: 70.3125] [G loss: 1.2629870176315308]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3117 [D loss: 0.484277680516243 | D accuracy: 75.0] [G loss: 1.1696754693984985]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3118 [D loss: 0.4288302958011627 | D accuracy: 82.8125] [G loss: 1.0643370151519775]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3119 [D loss: 0.5714850425720215 | D accuracy: 70.3125] [G loss: 1.2598832845687866]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3120 [D loss: 0.5783892571926117 | D accuracy: 73.4375] [G loss: 1.3182944059371948]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3121 [D loss: 0.5884017050266266 | D accuracy: 64.0625] [G loss: 1.1492784023284912]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3122 [D loss: 0.5064976811408997 | D accuracy: 76.5625] [G loss: 1.2005605697631836]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3123 [D loss: 0.610477089881897 | D accuracy: 65.625] [G loss: 1.1243207454681396]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3124 [D loss: 0.5545037388801575 | D accuracy: 71.875] [G loss: 1.2702994346618652]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3125 [D loss: 0.5414262413978577 | D accuracy: 73.4375] [G loss: 1.2396153211593628]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3126 [D loss: 0.4604802429676056 | D accuracy: 79.6875] [G loss: 1.2441329956054688]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3127 [D loss: 0.6063925921916962 | D accuracy: 67.1875] [G loss: 1.4243128299713135]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3128 [D loss: 0.5763049274682999 | D accuracy: 71.875] [G loss: 1.2872676849365234]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3129 [D loss: 0.6277883648872375 | D accuracy: 64.0625] [G loss: 1.277280569076538]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3130 [D loss: 0.6017554849386215 | D accuracy: 68.75] [G loss: 1.2493269443511963]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3131 [D loss: 0.5304210484027863 | D accuracy: 71.875] [G loss: 1.5203251838684082]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3132 [D loss: 0.5287600457668304 | D accuracy: 76.5625] [G loss: 1.4121824502944946]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3133 [D loss: 0.647829681634903 | D accuracy: 68.75] [G loss: 1.2961511611938477]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3134 [D loss: 0.5396345257759094 | D accuracy: 70.3125] [G loss: 1.1642569303512573]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "3135 [D loss: 0.5408431440591812 | D accuracy: 65.625] [G loss: 1.0294222831726074]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3136 [D loss: 0.6294567286968231 | D accuracy: 59.375] [G loss: 1.177390456199646]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3137 [D loss: 0.5683670490980148 | D accuracy: 70.3125] [G loss: 1.260472059249878]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3138 [D loss: 0.4773010015487671 | D accuracy: 78.125] [G loss: 1.2853026390075684]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3139 [D loss: 0.5134519189596176 | D accuracy: 79.6875] [G loss: 1.1590967178344727]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3140 [D loss: 0.5204144567251205 | D accuracy: 71.875] [G loss: 1.1830674409866333]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3141 [D loss: 0.49121689796447754 | D accuracy: 79.6875] [G loss: 1.2525672912597656]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3142 [D loss: 0.4859582334756851 | D accuracy: 76.5625] [G loss: 1.3041598796844482]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3143 [D loss: 0.5822360217571259 | D accuracy: 71.875] [G loss: 1.2543160915374756]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3144 [D loss: 0.6533612310886383 | D accuracy: 59.375] [G loss: 1.226828694343567]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3145 [D loss: 0.5276317000389099 | D accuracy: 68.75] [G loss: 1.0516011714935303]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3146 [D loss: 0.5493656694889069 | D accuracy: 71.875] [G loss: 1.2500851154327393]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3147 [D loss: 0.5911678671836853 | D accuracy: 65.625] [G loss: 1.1235995292663574]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3148 [D loss: 0.5471568405628204 | D accuracy: 73.4375] [G loss: 1.356472134590149]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3149 [D loss: 0.5031053125858307 | D accuracy: 75.0] [G loss: 1.106691837310791]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3150 [D loss: 0.5014306604862213 | D accuracy: 73.4375] [G loss: 1.1148531436920166]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3151 [D loss: 0.5582000315189362 | D accuracy: 71.875] [G loss: 1.2786219120025635]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3152 [D loss: 0.6667188704013824 | D accuracy: 59.375] [G loss: 1.2688571214675903]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3153 [D loss: 0.5629981756210327 | D accuracy: 79.6875] [G loss: 1.2382054328918457]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3154 [D loss: 0.5949819982051849 | D accuracy: 65.625] [G loss: 1.2065448760986328]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3155 [D loss: 0.4708138704299927 | D accuracy: 81.25] [G loss: 1.0066126585006714]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3156 [D loss: 0.6141961216926575 | D accuracy: 75.0] [G loss: 1.1360546350479126]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3157 [D loss: 0.5294683277606964 | D accuracy: 76.5625] [G loss: 1.0132955312728882]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3158 [D loss: 0.604722797870636 | D accuracy: 75.0] [G loss: 1.2570172548294067]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3159 [D loss: 0.5042405277490616 | D accuracy: 73.4375] [G loss: 1.2790424823760986]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3160 [D loss: 0.6662732064723969 | D accuracy: 60.9375] [G loss: 1.1953682899475098]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3161 [D loss: 0.5901631712913513 | D accuracy: 73.4375] [G loss: 1.288608431816101]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3162 [D loss: 0.4967573583126068 | D accuracy: 78.125] [G loss: 1.2859910726547241]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3163 [D loss: 0.6885402798652649 | D accuracy: 51.5625] [G loss: 1.1967864036560059]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3164 [D loss: 0.5094339102506638 | D accuracy: 79.6875] [G loss: 1.1764671802520752]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3165 [D loss: 0.5357850939035416 | D accuracy: 76.5625] [G loss: 1.1921319961547852]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3166 [D loss: 0.49344855546951294 | D accuracy: 75.0] [G loss: 1.2221803665161133]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3167 [D loss: 0.4758453071117401 | D accuracy: 81.25] [G loss: 1.092484712600708]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3168 [D loss: 0.5362020432949066 | D accuracy: 75.0] [G loss: 1.2084450721740723]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3169 [D loss: 0.6280300617218018 | D accuracy: 64.0625] [G loss: 1.2783722877502441]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3170 [D loss: 0.5316563844680786 | D accuracy: 67.1875] [G loss: 1.3826444149017334]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3171 [D loss: 0.5812947154045105 | D accuracy: 70.3125] [G loss: 1.206709861755371]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3172 [D loss: 0.5837087631225586 | D accuracy: 65.625] [G loss: 1.2018641233444214]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3173 [D loss: 0.5832008719444275 | D accuracy: 68.75] [G loss: 1.2480627298355103]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3174 [D loss: 0.598298043012619 | D accuracy: 65.625] [G loss: 1.3122048377990723]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3175 [D loss: 0.5567587018013 | D accuracy: 68.75] [G loss: 1.1563835144042969]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3176 [D loss: 0.6110213100910187 | D accuracy: 62.5] [G loss: 1.268639087677002]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3177 [D loss: 0.5369947552680969 | D accuracy: 73.4375] [G loss: 1.256469964981079]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3178 [D loss: 0.5348077565431595 | D accuracy: 68.75] [G loss: 1.211272954940796]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3179 [D loss: 0.5270926207304001 | D accuracy: 71.875] [G loss: 1.1894052028656006]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3180 [D loss: 0.5039747059345245 | D accuracy: 81.25] [G loss: 1.2273650169372559]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3181 [D loss: 0.5977914035320282 | D accuracy: 62.5] [G loss: 1.2311888933181763]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3182 [D loss: 0.47844743728637695 | D accuracy: 75.0] [G loss: 1.2882716655731201]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3183 [D loss: 0.5317120552062988 | D accuracy: 76.5625] [G loss: 1.1870989799499512]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3184 [D loss: 0.6622986197471619 | D accuracy: 60.9375] [G loss: 1.2678356170654297]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3185 [D loss: 0.5819674730300903 | D accuracy: 71.875] [G loss: 1.1550954580307007]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3186 [D loss: 0.5380205810070038 | D accuracy: 76.5625] [G loss: 1.331863522529602]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3187 [D loss: 0.6307117640972137 | D accuracy: 65.625] [G loss: 1.2093589305877686]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3188 [D loss: 0.5681723058223724 | D accuracy: 67.1875] [G loss: 1.2648571729660034]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3189 [D loss: 0.5444688200950623 | D accuracy: 75.0] [G loss: 1.2320804595947266]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3190 [D loss: 0.5686878263950348 | D accuracy: 70.3125] [G loss: 1.2521026134490967]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3191 [D loss: 0.4655574858188629 | D accuracy: 82.8125] [G loss: 1.2065021991729736]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3192 [D loss: 0.5852656364440918 | D accuracy: 68.75] [G loss: 1.4004182815551758]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3193 [D loss: 0.5563577115535736 | D accuracy: 75.0] [G loss: 1.285845398902893]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3194 [D loss: 0.6259258985519409 | D accuracy: 60.9375] [G loss: 1.2319111824035645]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3195 [D loss: 0.5872600972652435 | D accuracy: 67.1875] [G loss: 1.162396788597107]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3196 [D loss: 0.5804532468318939 | D accuracy: 68.75] [G loss: 1.1588518619537354]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3197 [D loss: 0.47148260474205017 | D accuracy: 84.375] [G loss: 1.2866994142532349]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3198 [D loss: 0.5241339802742004 | D accuracy: 70.3125] [G loss: 1.0900988578796387]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3199 [D loss: 0.49761664867401123 | D accuracy: 78.125] [G loss: 1.3323781490325928]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3200 [D loss: 0.6296477615833282 | D accuracy: 62.5] [G loss: 1.3414833545684814]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3201 [D loss: 0.467923104763031 | D accuracy: 79.6875] [G loss: 1.1794826984405518]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3202 [D loss: 0.5343214124441147 | D accuracy: 71.875] [G loss: 1.2275371551513672]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3203 [D loss: 0.489959254860878 | D accuracy: 75.0] [G loss: 1.1144160032272339]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3204 [D loss: 0.5708324909210205 | D accuracy: 70.3125] [G loss: 1.0929780006408691]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3205 [D loss: 0.5663572251796722 | D accuracy: 67.1875] [G loss: 1.1044710874557495]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3206 [D loss: 0.6664468050003052 | D accuracy: 67.1875] [G loss: 1.2674249410629272]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3207 [D loss: 0.5651071965694427 | D accuracy: 76.5625] [G loss: 1.3286741971969604]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3208 [D loss: 0.5137795507907867 | D accuracy: 76.5625] [G loss: 1.2677701711654663]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3209 [D loss: 0.4630223214626312 | D accuracy: 79.6875] [G loss: 1.2369372844696045]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3210 [D loss: 0.5259854197502136 | D accuracy: 73.4375] [G loss: 1.2423152923583984]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3211 [D loss: 0.5201717913150787 | D accuracy: 73.4375] [G loss: 1.347015380859375]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3212 [D loss: 0.5749690234661102 | D accuracy: 68.75] [G loss: 1.2238225936889648]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3213 [D loss: 0.5764039754867554 | D accuracy: 67.1875] [G loss: 1.142288088798523]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3214 [D loss: 0.5783780515193939 | D accuracy: 67.1875] [G loss: 1.278752326965332]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3215 [D loss: 0.5067282915115356 | D accuracy: 76.5625] [G loss: 1.164802074432373]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3216 [D loss: 0.6822987496852875 | D accuracy: 65.625] [G loss: 1.2273926734924316]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3217 [D loss: 0.5485000163316727 | D accuracy: 67.1875] [G loss: 1.2256197929382324]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3218 [D loss: 0.5754984617233276 | D accuracy: 68.75] [G loss: 1.0707271099090576]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3219 [D loss: 0.5646713972091675 | D accuracy: 75.0] [G loss: 1.1475238800048828]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3220 [D loss: 0.5098735094070435 | D accuracy: 73.4375] [G loss: 1.291733980178833]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3221 [D loss: 0.583456814289093 | D accuracy: 76.5625] [G loss: 1.1185033321380615]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3222 [D loss: 0.5005784034729004 | D accuracy: 71.875] [G loss: 1.2074711322784424]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3223 [D loss: 0.47253771126270294 | D accuracy: 78.125] [G loss: 1.2036181688308716]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3224 [D loss: 0.48727187514305115 | D accuracy: 73.4375] [G loss: 1.1356712579727173]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3225 [D loss: 0.5814763307571411 | D accuracy: 71.875] [G loss: 1.184924840927124]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3226 [D loss: 0.5688804984092712 | D accuracy: 68.75] [G loss: 1.1798129081726074]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3227 [D loss: 0.6137976050376892 | D accuracy: 68.75] [G loss: 1.2139497995376587]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3228 [D loss: 0.5292108505964279 | D accuracy: 75.0] [G loss: 1.1175717115402222]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3229 [D loss: 0.6206700205802917 | D accuracy: 62.5] [G loss: 1.055551528930664]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3230 [D loss: 0.6092717200517654 | D accuracy: 65.625] [G loss: 1.0196809768676758]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3231 [D loss: 0.5152532309293747 | D accuracy: 73.4375] [G loss: 1.133284091949463]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3232 [D loss: 0.5527928173542023 | D accuracy: 75.0] [G loss: 1.254960298538208]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3233 [D loss: 0.684014230966568 | D accuracy: 60.9375] [G loss: 1.1121147871017456]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3234 [D loss: 0.4847881644964218 | D accuracy: 73.4375] [G loss: 1.2679321765899658]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3235 [D loss: 0.5504274964332581 | D accuracy: 70.3125] [G loss: 1.3879339694976807]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3236 [D loss: 0.6163551211357117 | D accuracy: 67.1875] [G loss: 1.314314365386963]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3237 [D loss: 0.5350659340620041 | D accuracy: 68.75] [G loss: 1.2126102447509766]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3238 [D loss: 0.6458975672721863 | D accuracy: 64.0625] [G loss: 1.2360535860061646]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3239 [D loss: 0.5886067152023315 | D accuracy: 67.1875] [G loss: 1.039061188697815]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3240 [D loss: 0.5575887560844421 | D accuracy: 70.3125] [G loss: 1.2837159633636475]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3241 [D loss: 0.6013313233852386 | D accuracy: 67.1875] [G loss: 1.0748815536499023]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3242 [D loss: 0.6135229170322418 | D accuracy: 68.75] [G loss: 1.2944616079330444]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3243 [D loss: 0.5232259929180145 | D accuracy: 78.125] [G loss: 1.1837058067321777]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3244 [D loss: 0.6474951505661011 | D accuracy: 56.25] [G loss: 1.130702257156372]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3245 [D loss: 0.5986310541629791 | D accuracy: 68.75] [G loss: 1.1256991624832153]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3246 [D loss: 0.6780898571014404 | D accuracy: 57.8125] [G loss: 1.098832130432129]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3247 [D loss: 0.5043594390153885 | D accuracy: 75.0] [G loss: 1.3212789297103882]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3248 [D loss: 0.5649427771568298 | D accuracy: 73.4375] [G loss: 1.2120838165283203]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3249 [D loss: 0.6420592963695526 | D accuracy: 62.5] [G loss: 1.2037240266799927]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3250 [D loss: 0.5976600646972656 | D accuracy: 62.5] [G loss: 1.1305217742919922]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3251 [D loss: 0.6476802825927734 | D accuracy: 65.625] [G loss: 1.171097993850708]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3252 [D loss: 0.6047030985355377 | D accuracy: 60.9375] [G loss: 1.2720370292663574]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3253 [D loss: 0.5783835053443909 | D accuracy: 73.4375] [G loss: 1.2615935802459717]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3254 [D loss: 0.6696657836437225 | D accuracy: 57.8125] [G loss: 1.1889361143112183]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3255 [D loss: 0.6064637303352356 | D accuracy: 64.0625] [G loss: 1.1553981304168701]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3256 [D loss: 0.6631467640399933 | D accuracy: 62.5] [G loss: 1.1924829483032227]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3257 [D loss: 0.5644799768924713 | D accuracy: 68.75] [G loss: 1.1834039688110352]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3258 [D loss: 0.545832172036171 | D accuracy: 78.125] [G loss: 1.2323967218399048]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3259 [D loss: 0.5659763962030411 | D accuracy: 73.4375] [G loss: 1.2018754482269287]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3260 [D loss: 0.6083604693412781 | D accuracy: 62.5] [G loss: 1.196565866470337]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3261 [D loss: 0.5212530493736267 | D accuracy: 73.4375] [G loss: 1.1813488006591797]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3262 [D loss: 0.5994439423084259 | D accuracy: 65.625] [G loss: 1.1300386190414429]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3263 [D loss: 0.5617175400257111 | D accuracy: 70.3125] [G loss: 1.1212126016616821]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3264 [D loss: 0.6749044060707092 | D accuracy: 62.5] [G loss: 1.2520699501037598]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3265 [D loss: 0.5644195377826691 | D accuracy: 67.1875] [G loss: 1.0849130153656006]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3266 [D loss: 0.544116884469986 | D accuracy: 67.1875] [G loss: 1.2096396684646606]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3267 [D loss: 0.4942152351140976 | D accuracy: 75.0] [G loss: 1.3683156967163086]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3268 [D loss: 0.5905104279518127 | D accuracy: 65.625] [G loss: 1.2817761898040771]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3269 [D loss: 0.5520594269037247 | D accuracy: 73.4375] [G loss: 1.0538872480392456]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3270 [D loss: 0.6162125468254089 | D accuracy: 62.5] [G loss: 1.311403751373291]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3271 [D loss: 0.5325157046318054 | D accuracy: 76.5625] [G loss: 1.2125475406646729]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3272 [D loss: 0.5324283242225647 | D accuracy: 76.5625] [G loss: 1.1066621541976929]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3273 [D loss: 0.5568818151950836 | D accuracy: 68.75] [G loss: 1.1476939916610718]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3274 [D loss: 0.5530092418193817 | D accuracy: 71.875] [G loss: 1.1670398712158203]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3275 [D loss: 0.5237066149711609 | D accuracy: 70.3125] [G loss: 1.1075835227966309]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3276 [D loss: 0.5706925392150879 | D accuracy: 68.75] [G loss: 1.1833550930023193]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3277 [D loss: 0.5660155415534973 | D accuracy: 65.625] [G loss: 1.195206880569458]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3278 [D loss: 0.5401192605495453 | D accuracy: 76.5625] [G loss: 1.233983039855957]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3279 [D loss: 0.5935826897621155 | D accuracy: 64.0625] [G loss: 1.2113056182861328]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3280 [D loss: 0.6392828822135925 | D accuracy: 60.9375] [G loss: 1.2703455686569214]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3281 [D loss: 0.619458794593811 | D accuracy: 71.875] [G loss: 1.2666171789169312]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3282 [D loss: 0.5651086866855621 | D accuracy: 73.4375] [G loss: 1.2717151641845703]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3283 [D loss: 0.5700452625751495 | D accuracy: 70.3125] [G loss: 1.2977778911590576]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3284 [D loss: 0.6187922954559326 | D accuracy: 64.0625] [G loss: 1.2117106914520264]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3285 [D loss: 0.6491760015487671 | D accuracy: 57.8125] [G loss: 1.2127187252044678]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3286 [D loss: 0.5976512283086777 | D accuracy: 76.5625] [G loss: 1.0356066226959229]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3287 [D loss: 0.5113441050052643 | D accuracy: 76.5625] [G loss: 1.070430040359497]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3288 [D loss: 0.6197580993175507 | D accuracy: 65.625] [G loss: 1.1901202201843262]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3289 [D loss: 0.511750340461731 | D accuracy: 75.0] [G loss: 1.0938783884048462]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3290 [D loss: 0.6115099787712097 | D accuracy: 67.1875] [G loss: 1.0962409973144531]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3291 [D loss: 0.6052829027175903 | D accuracy: 71.875] [G loss: 1.1877834796905518]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3292 [D loss: 0.6297245621681213 | D accuracy: 59.375] [G loss: 1.2779532670974731]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3293 [D loss: 0.49514587223529816 | D accuracy: 78.125] [G loss: 1.1205310821533203]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3294 [D loss: 0.48488572239875793 | D accuracy: 78.125] [G loss: 1.2055045366287231]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3295 [D loss: 0.6027862727642059 | D accuracy: 67.1875] [G loss: 1.055844783782959]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3296 [D loss: 0.6685674488544464 | D accuracy: 65.625] [G loss: 1.1327266693115234]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3297 [D loss: 0.5161568224430084 | D accuracy: 73.4375] [G loss: 1.1516740322113037]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3298 [D loss: 0.5845863521099091 | D accuracy: 62.5] [G loss: 1.2751034498214722]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3299 [D loss: 0.4591120481491089 | D accuracy: 78.125] [G loss: 1.2055902481079102]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3300 [D loss: 0.5696443915367126 | D accuracy: 62.5] [G loss: 1.113067388534546]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3301 [D loss: 0.5543907880783081 | D accuracy: 65.625] [G loss: 1.1783828735351562]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3302 [D loss: 0.5475821793079376 | D accuracy: 68.75] [G loss: 1.25439453125]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3303 [D loss: 0.6245313286781311 | D accuracy: 64.0625] [G loss: 1.3611427545547485]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3304 [D loss: 0.5659933388233185 | D accuracy: 70.3125] [G loss: 1.330199122428894]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3305 [D loss: 0.6337581276893616 | D accuracy: 68.75] [G loss: 1.2914434671401978]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3306 [D loss: 0.5693412125110626 | D accuracy: 71.875] [G loss: 1.223257064819336]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3307 [D loss: 0.626347541809082 | D accuracy: 60.9375] [G loss: 1.2113182544708252]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3308 [D loss: 0.5185435116291046 | D accuracy: 78.125] [G loss: 1.1262013912200928]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3309 [D loss: 0.47781093418598175 | D accuracy: 78.125] [G loss: 1.1870038509368896]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3310 [D loss: 0.5364117920398712 | D accuracy: 73.4375] [G loss: 1.2608088254928589]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3311 [D loss: 0.6221543550491333 | D accuracy: 62.5] [G loss: 1.327986240386963]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3312 [D loss: 0.4795708954334259 | D accuracy: 78.125] [G loss: 1.2752928733825684]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3313 [D loss: 0.5631363987922668 | D accuracy: 73.4375] [G loss: 1.089621663093567]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3314 [D loss: 0.6950371563434601 | D accuracy: 51.5625] [G loss: 1.0096015930175781]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3315 [D loss: 0.6068147271871567 | D accuracy: 60.9375] [G loss: 1.2548173666000366]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3316 [D loss: 0.694305807352066 | D accuracy: 51.5625] [G loss: 1.239995002746582]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3317 [D loss: 0.5905269980430603 | D accuracy: 64.0625] [G loss: 1.1891505718231201]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3318 [D loss: 0.6209627985954285 | D accuracy: 67.1875] [G loss: 1.1810709238052368]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3319 [D loss: 0.49869102239608765 | D accuracy: 75.0] [G loss: 1.3173295259475708]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3320 [D loss: 0.6365865468978882 | D accuracy: 62.5] [G loss: 1.255430817604065]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3321 [D loss: 0.5658090263605118 | D accuracy: 67.1875] [G loss: 1.179890513420105]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3322 [D loss: 0.6537202000617981 | D accuracy: 57.8125] [G loss: 1.2470730543136597]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3323 [D loss: 0.6551677882671356 | D accuracy: 57.8125] [G loss: 1.0850365161895752]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3324 [D loss: 0.6110254526138306 | D accuracy: 65.625] [G loss: 1.1490815877914429]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3325 [D loss: 0.47771361470222473 | D accuracy: 82.8125] [G loss: 1.1060454845428467]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3326 [D loss: 0.5706333518028259 | D accuracy: 71.875] [G loss: 1.1223516464233398]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3327 [D loss: 0.4832206666469574 | D accuracy: 82.8125] [G loss: 1.153233289718628]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3328 [D loss: 0.6012794375419617 | D accuracy: 67.1875] [G loss: 1.1318833827972412]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3329 [D loss: 0.5912803560495377 | D accuracy: 65.625] [G loss: 0.9751469492912292]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3330 [D loss: 0.6241012811660767 | D accuracy: 60.9375] [G loss: 1.1159939765930176]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3331 [D loss: 0.49349696934223175 | D accuracy: 82.8125] [G loss: 1.1160019636154175]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3332 [D loss: 0.6253575384616852 | D accuracy: 67.1875] [G loss: 1.180317997932434]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3333 [D loss: 0.6246777772903442 | D accuracy: 71.875] [G loss: 1.1102259159088135]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3334 [D loss: 0.6764141917228699 | D accuracy: 60.9375] [G loss: 1.1604681015014648]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3335 [D loss: 0.6408356130123138 | D accuracy: 60.9375] [G loss: 1.3503228425979614]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3336 [D loss: 0.6450576633214951 | D accuracy: 57.8125] [G loss: 1.2010432481765747]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3337 [D loss: 0.5901786983013153 | D accuracy: 67.1875] [G loss: 1.1136313676834106]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3338 [D loss: 0.6150330007076263 | D accuracy: 67.1875] [G loss: 1.110069751739502]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3339 [D loss: 0.5957779288291931 | D accuracy: 65.625] [G loss: 1.0550129413604736]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3340 [D loss: 0.542914628982544 | D accuracy: 82.8125] [G loss: 1.0654263496398926]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3341 [D loss: 0.6288115084171295 | D accuracy: 60.9375] [G loss: 1.0139658451080322]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3342 [D loss: 0.5017999112606049 | D accuracy: 79.6875] [G loss: 1.079329490661621]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3343 [D loss: 0.7049778699874878 | D accuracy: 64.0625] [G loss: 1.2055463790893555]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3344 [D loss: 0.5433266162872314 | D accuracy: 75.0] [G loss: 1.1685067415237427]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3345 [D loss: 0.46632806956768036 | D accuracy: 84.375] [G loss: 1.1578785181045532]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3346 [D loss: 0.521594375371933 | D accuracy: 70.3125] [G loss: 1.2385333776474]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3347 [D loss: 0.562593623995781 | D accuracy: 68.75] [G loss: 1.2456953525543213]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3348 [D loss: 0.7133450508117676 | D accuracy: 54.6875] [G loss: 1.2411675453186035]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3349 [D loss: 0.5682757496833801 | D accuracy: 65.625] [G loss: 1.1673420667648315]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3350 [D loss: 0.5619035214185715 | D accuracy: 67.1875] [G loss: 1.2021782398223877]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3351 [D loss: 0.5735841393470764 | D accuracy: 68.75] [G loss: 1.2166831493377686]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3352 [D loss: 0.5686488151550293 | D accuracy: 68.75] [G loss: 1.0242611169815063]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3353 [D loss: 0.6241723001003265 | D accuracy: 65.625] [G loss: 1.1053106784820557]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3354 [D loss: 0.5811060070991516 | D accuracy: 68.75] [G loss: 1.2000422477722168]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3355 [D loss: 0.5701100826263428 | D accuracy: 68.75] [G loss: 1.2138588428497314]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3356 [D loss: 0.5126503854990005 | D accuracy: 79.6875] [G loss: 1.1117888689041138]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3357 [D loss: 0.5612937808036804 | D accuracy: 68.75] [G loss: 1.1268413066864014]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3358 [D loss: 0.5287433862686157 | D accuracy: 71.875] [G loss: 1.1296353340148926]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3359 [D loss: 0.5541037917137146 | D accuracy: 73.4375] [G loss: 1.0970687866210938]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3360 [D loss: 0.5793498158454895 | D accuracy: 65.625] [G loss: 1.2131118774414062]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3361 [D loss: 0.639015793800354 | D accuracy: 65.625] [G loss: 1.1208572387695312]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3362 [D loss: 0.5315399467945099 | D accuracy: 75.0] [G loss: 1.0767219066619873]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3363 [D loss: 0.6132358312606812 | D accuracy: 65.625] [G loss: 1.1019008159637451]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3364 [D loss: 0.5598087906837463 | D accuracy: 73.4375] [G loss: 1.204601764678955]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3365 [D loss: 0.5874131619930267 | D accuracy: 59.375] [G loss: 1.1354881525039673]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3366 [D loss: 0.5961339473724365 | D accuracy: 67.1875] [G loss: 1.1268612146377563]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3367 [D loss: 0.6170433759689331 | D accuracy: 62.5] [G loss: 1.2333848476409912]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3368 [D loss: 0.5998753309249878 | D accuracy: 62.5] [G loss: 1.1395357847213745]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3369 [D loss: 0.5716739594936371 | D accuracy: 71.875] [G loss: 1.1249058246612549]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3370 [D loss: 0.6505123972892761 | D accuracy: 59.375] [G loss: 1.0595982074737549]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3371 [D loss: 0.6541949808597565 | D accuracy: 65.625] [G loss: 1.2822458744049072]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "3372 [D loss: 0.5879096686840057 | D accuracy: 62.5] [G loss: 1.0971894264221191]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3373 [D loss: 0.5919689238071442 | D accuracy: 68.75] [G loss: 1.1678709983825684]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3374 [D loss: 0.5592280626296997 | D accuracy: 65.625] [G loss: 1.1136174201965332]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3375 [D loss: 0.556745707988739 | D accuracy: 70.3125] [G loss: 1.0948584079742432]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3376 [D loss: 0.5998165905475616 | D accuracy: 65.625] [G loss: 1.0543112754821777]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3377 [D loss: 0.5834388732910156 | D accuracy: 68.75] [G loss: 1.1083472967147827]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3378 [D loss: 0.5431306064128876 | D accuracy: 67.1875] [G loss: 1.0842864513397217]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3379 [D loss: 0.529665470123291 | D accuracy: 78.125] [G loss: 1.1518092155456543]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "3380 [D loss: 0.6729274094104767 | D accuracy: 67.1875] [G loss: 1.1567895412445068]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3381 [D loss: 0.6464153230190277 | D accuracy: 62.5] [G loss: 1.1504957675933838]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3382 [D loss: 0.5440769195556641 | D accuracy: 76.5625] [G loss: 1.2104687690734863]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3383 [D loss: 0.7069078385829926 | D accuracy: 54.6875] [G loss: 1.1898441314697266]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3384 [D loss: 0.6350245773792267 | D accuracy: 62.5] [G loss: 1.2134474515914917]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3385 [D loss: 0.6323669850826263 | D accuracy: 70.3125] [G loss: 1.2263484001159668]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "3386 [D loss: 0.6262127161026001 | D accuracy: 62.5] [G loss: 1.0191073417663574]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3387 [D loss: 0.6778543293476105 | D accuracy: 64.0625] [G loss: 1.1129462718963623]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3388 [D loss: 0.6345617771148682 | D accuracy: 60.9375] [G loss: 1.110377550125122]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3389 [D loss: 0.6657138764858246 | D accuracy: 64.0625] [G loss: 1.1556744575500488]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3390 [D loss: 0.6123469471931458 | D accuracy: 64.0625] [G loss: 1.1193697452545166]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3391 [D loss: 0.5588407516479492 | D accuracy: 71.875] [G loss: 1.1696481704711914]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3392 [D loss: 0.47747449576854706 | D accuracy: 78.125] [G loss: 1.2024564743041992]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3393 [D loss: 0.5694725513458252 | D accuracy: 70.3125] [G loss: 1.2160074710845947]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3394 [D loss: 0.6207396984100342 | D accuracy: 60.9375] [G loss: 1.0846115350723267]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3395 [D loss: 0.6719408333301544 | D accuracy: 54.6875] [G loss: 1.0670442581176758]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3396 [D loss: 0.57398521900177 | D accuracy: 67.1875] [G loss: 1.122294306755066]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3397 [D loss: 0.5190404653549194 | D accuracy: 73.4375] [G loss: 1.2764253616333008]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3398 [D loss: 0.5735421478748322 | D accuracy: 65.625] [G loss: 1.0962159633636475]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3399 [D loss: 0.57575923204422 | D accuracy: 70.3125] [G loss: 0.9297178983688354]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3400 [D loss: 0.6527170538902283 | D accuracy: 64.0625] [G loss: 1.0073758363723755]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3401 [D loss: 0.5641459077596664 | D accuracy: 68.75] [G loss: 1.1031286716461182]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3402 [D loss: 0.5587362051010132 | D accuracy: 73.4375] [G loss: 1.0935901403427124]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3403 [D loss: 0.5787481069564819 | D accuracy: 73.4375] [G loss: 1.2481436729431152]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3404 [D loss: 0.7186233997344971 | D accuracy: 51.5625] [G loss: 1.0700576305389404]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3405 [D loss: 0.6050272285938263 | D accuracy: 65.625] [G loss: 1.2332899570465088]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3406 [D loss: 0.609270840883255 | D accuracy: 67.1875] [G loss: 1.0523061752319336]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3407 [D loss: 0.6924072206020355 | D accuracy: 57.8125] [G loss: 1.1344969272613525]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3408 [D loss: 0.5847048163414001 | D accuracy: 64.0625] [G loss: 1.2370543479919434]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3409 [D loss: 0.5486133396625519 | D accuracy: 68.75] [G loss: 1.2901160717010498]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3410 [D loss: 0.6159196197986603 | D accuracy: 59.375] [G loss: 1.0979986190795898]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3411 [D loss: 0.531266450881958 | D accuracy: 76.5625] [G loss: 1.260741114616394]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3412 [D loss: 0.5945479720830917 | D accuracy: 71.875] [G loss: 1.1424610614776611]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3413 [D loss: 0.6438878178596497 | D accuracy: 62.5] [G loss: 1.1072683334350586]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3414 [D loss: 0.6910824477672577 | D accuracy: 62.5] [G loss: 1.1279425621032715]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3415 [D loss: 0.5188848078250885 | D accuracy: 73.4375] [G loss: 1.149074673652649]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3416 [D loss: 0.5190734565258026 | D accuracy: 76.5625] [G loss: 1.143676996231079]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3417 [D loss: 0.6030324101448059 | D accuracy: 64.0625] [G loss: 1.3121845722198486]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3418 [D loss: 0.6550365090370178 | D accuracy: 60.9375] [G loss: 1.1028106212615967]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3419 [D loss: 0.5815492868423462 | D accuracy: 65.625] [G loss: 1.0259909629821777]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3420 [D loss: 0.600967288017273 | D accuracy: 70.3125] [G loss: 1.1932543516159058]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3421 [D loss: 0.5549806952476501 | D accuracy: 73.4375] [G loss: 1.0879261493682861]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3422 [D loss: 0.5735243856906891 | D accuracy: 65.625] [G loss: 1.2622511386871338]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3423 [D loss: 0.5660946369171143 | D accuracy: 65.625] [G loss: 1.1034767627716064]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3424 [D loss: 0.5485574007034302 | D accuracy: 71.875] [G loss: 1.0810952186584473]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3425 [D loss: 0.6304195821285248 | D accuracy: 68.75] [G loss: 1.1691367626190186]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3426 [D loss: 0.5937080085277557 | D accuracy: 67.1875] [G loss: 1.1224699020385742]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3427 [D loss: 0.5207961052656174 | D accuracy: 81.25] [G loss: 1.126459002494812]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3428 [D loss: 0.626134842634201 | D accuracy: 59.375] [G loss: 1.174652338027954]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3429 [D loss: 0.5869738161563873 | D accuracy: 68.75] [G loss: 1.1941592693328857]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3430 [D loss: 0.5375086069107056 | D accuracy: 78.125] [G loss: 1.0552973747253418]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3431 [D loss: 0.619907021522522 | D accuracy: 60.9375] [G loss: 0.9370613098144531]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3432 [D loss: 0.5845311284065247 | D accuracy: 71.875] [G loss: 1.1759779453277588]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3433 [D loss: 0.5658582448959351 | D accuracy: 68.75] [G loss: 1.1645152568817139]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3434 [D loss: 0.5162432938814163 | D accuracy: 71.875] [G loss: 1.1907436847686768]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3435 [D loss: 0.5568201839923859 | D accuracy: 65.625] [G loss: 1.1829124689102173]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3436 [D loss: 0.53214031457901 | D accuracy: 71.875] [G loss: 1.1617991924285889]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3437 [D loss: 0.5241383612155914 | D accuracy: 76.5625] [G loss: 1.2026671171188354]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3438 [D loss: 0.5791394114494324 | D accuracy: 76.5625] [G loss: 1.1390297412872314]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3439 [D loss: 0.6317026615142822 | D accuracy: 60.9375] [G loss: 1.2764842510223389]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3440 [D loss: 0.6586905717849731 | D accuracy: 57.8125] [G loss: 1.170233964920044]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3441 [D loss: 0.5356556475162506 | D accuracy: 78.125] [G loss: 1.2009114027023315]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3442 [D loss: 0.5394352972507477 | D accuracy: 70.3125] [G loss: 1.1864582300186157]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3443 [D loss: 0.6020947694778442 | D accuracy: 62.5] [G loss: 1.2234153747558594]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3444 [D loss: 0.5974400639533997 | D accuracy: 70.3125] [G loss: 1.1880857944488525]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3445 [D loss: 0.5274935066699982 | D accuracy: 71.875] [G loss: 1.1293416023254395]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3446 [D loss: 0.5877042412757874 | D accuracy: 65.625] [G loss: 1.1238627433776855]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3447 [D loss: 0.5712091028690338 | D accuracy: 65.625] [G loss: 1.0913257598876953]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3448 [D loss: 0.4361066520214081 | D accuracy: 85.9375] [G loss: 1.1979509592056274]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3449 [D loss: 0.6009355783462524 | D accuracy: 59.375] [G loss: 1.1414539813995361]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3450 [D loss: 0.552130788564682 | D accuracy: 70.3125] [G loss: 1.1991477012634277]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3451 [D loss: 0.6145939826965332 | D accuracy: 68.75] [G loss: 1.1464619636535645]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3452 [D loss: 0.5798628330230713 | D accuracy: 71.875] [G loss: 1.1328909397125244]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3453 [D loss: 0.5385427176952362 | D accuracy: 68.75] [G loss: 1.248612880706787]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3454 [D loss: 0.5640623569488525 | D accuracy: 70.3125] [G loss: 1.0746808052062988]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3455 [D loss: 0.5939328372478485 | D accuracy: 67.1875] [G loss: 1.0779364109039307]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3456 [D loss: 0.5899495184421539 | D accuracy: 57.8125] [G loss: 1.1104846000671387]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3457 [D loss: 0.5251770615577698 | D accuracy: 81.25] [G loss: 1.0740798711776733]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3458 [D loss: 0.6645474433898926 | D accuracy: 64.0625] [G loss: 1.1310451030731201]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3459 [D loss: 0.5758897960186005 | D accuracy: 75.0] [G loss: 1.1328177452087402]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3460 [D loss: 0.6387717127799988 | D accuracy: 57.8125] [G loss: 1.1277391910552979]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3461 [D loss: 0.545790821313858 | D accuracy: 76.5625] [G loss: 1.1918928623199463]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "3462 [D loss: 0.5932367444038391 | D accuracy: 67.1875] [G loss: 1.2327067852020264]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3463 [D loss: 0.6442601680755615 | D accuracy: 68.75] [G loss: 1.1746177673339844]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3464 [D loss: 0.6289910078048706 | D accuracy: 65.625] [G loss: 1.255353331565857]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3465 [D loss: 0.6217682361602783 | D accuracy: 64.0625] [G loss: 1.174151062965393]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3466 [D loss: 0.5531738698482513 | D accuracy: 79.6875] [G loss: 1.1796433925628662]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3467 [D loss: 0.7181751728057861 | D accuracy: 50.0] [G loss: 0.9092714786529541]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3468 [D loss: 0.6719619631767273 | D accuracy: 64.0625] [G loss: 1.0613601207733154]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3469 [D loss: 0.5791719257831573 | D accuracy: 65.625] [G loss: 1.1701242923736572]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3470 [D loss: 0.5496105253696442 | D accuracy: 75.0] [G loss: 1.1403753757476807]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3471 [D loss: 0.5811344087123871 | D accuracy: 71.875] [G loss: 1.133727788925171]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3472 [D loss: 0.6029869318008423 | D accuracy: 70.3125] [G loss: 1.2272398471832275]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3473 [D loss: 0.6727697849273682 | D accuracy: 59.375] [G loss: 1.1083035469055176]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3474 [D loss: 0.5523338615894318 | D accuracy: 73.4375] [G loss: 1.1127251386642456]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3475 [D loss: 0.5358778089284897 | D accuracy: 68.75] [G loss: 1.1824628114700317]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3476 [D loss: 0.5758476853370667 | D accuracy: 67.1875] [G loss: 1.1345916986465454]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3477 [D loss: 0.6231696605682373 | D accuracy: 60.9375] [G loss: 1.074578046798706]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3478 [D loss: 0.5578998923301697 | D accuracy: 70.3125] [G loss: 1.1654503345489502]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3479 [D loss: 0.5466277599334717 | D accuracy: 76.5625] [G loss: 1.296975016593933]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3480 [D loss: 0.5541661977767944 | D accuracy: 71.875] [G loss: 1.0314514636993408]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3481 [D loss: 0.4688326418399811 | D accuracy: 81.25] [G loss: 1.119497299194336]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3482 [D loss: 0.5764438509941101 | D accuracy: 75.0] [G loss: 1.1008930206298828]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3483 [D loss: 0.5941830277442932 | D accuracy: 64.0625] [G loss: 1.23696768283844]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3484 [D loss: 0.5165793895721436 | D accuracy: 79.6875] [G loss: 1.1435774564743042]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3485 [D loss: 0.6721134781837463 | D accuracy: 51.5625] [G loss: 1.1736377477645874]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3486 [D loss: 0.5034427642822266 | D accuracy: 79.6875] [G loss: 1.2270132303237915]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3487 [D loss: 0.638129711151123 | D accuracy: 64.0625] [G loss: 1.0886749029159546]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3488 [D loss: 0.6332653164863586 | D accuracy: 62.5] [G loss: 1.1364184617996216]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3489 [D loss: 0.6048303246498108 | D accuracy: 60.9375] [G loss: 1.0429877042770386]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3490 [D loss: 0.5354327261447906 | D accuracy: 75.0] [G loss: 1.1112940311431885]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3491 [D loss: 0.6140233874320984 | D accuracy: 71.875] [G loss: 1.1935330629348755]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3492 [D loss: 0.5983281135559082 | D accuracy: 62.5] [G loss: 1.1240408420562744]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3493 [D loss: 0.5748431384563446 | D accuracy: 73.4375] [G loss: 1.034693717956543]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3494 [D loss: 0.5649546086788177 | D accuracy: 71.875] [G loss: 1.0377519130706787]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3495 [D loss: 0.5490186959505081 | D accuracy: 73.4375] [G loss: 1.1373785734176636]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3496 [D loss: 0.6054699420928955 | D accuracy: 65.625] [G loss: 1.1483076810836792]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3497 [D loss: 0.638437420129776 | D accuracy: 62.5] [G loss: 1.2389092445373535]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3498 [D loss: 0.5481785535812378 | D accuracy: 71.875] [G loss: 1.0106146335601807]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3499 [D loss: 0.5405212342739105 | D accuracy: 71.875] [G loss: 1.1491210460662842]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3500 [D loss: 0.692428320646286 | D accuracy: 54.6875] [G loss: 1.054586410522461]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3501 [D loss: 0.648891031742096 | D accuracy: 56.25] [G loss: 1.0391672849655151]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3502 [D loss: 0.6515019536018372 | D accuracy: 62.5] [G loss: 1.0863313674926758]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3503 [D loss: 0.6176501363515854 | D accuracy: 62.5] [G loss: 1.1237766742706299]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3504 [D loss: 0.6287754476070404 | D accuracy: 65.625] [G loss: 1.1602654457092285]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3505 [D loss: 0.6817452907562256 | D accuracy: 68.75] [G loss: 1.0072872638702393]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3506 [D loss: 0.6621045768260956 | D accuracy: 57.8125] [G loss: 1.1575963497161865]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3507 [D loss: 0.5292147994041443 | D accuracy: 73.4375] [G loss: 1.0874077081680298]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3508 [D loss: 0.6675995886325836 | D accuracy: 65.625] [G loss: 1.1699146032333374]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3509 [D loss: 0.5045425146818161 | D accuracy: 76.5625] [G loss: 1.1241815090179443]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3510 [D loss: 0.5027429610490799 | D accuracy: 73.4375] [G loss: 1.1780881881713867]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3511 [D loss: 0.701135665178299 | D accuracy: 53.125] [G loss: 0.9635732769966125]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3512 [D loss: 0.6729759871959686 | D accuracy: 53.125] [G loss: 1.0296919345855713]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3513 [D loss: 0.5982796251773834 | D accuracy: 68.75] [G loss: 1.0821449756622314]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3514 [D loss: 0.5929631590843201 | D accuracy: 70.3125] [G loss: 1.270462155342102]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3515 [D loss: 0.5634579658508301 | D accuracy: 71.875] [G loss: 1.2427669763565063]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3516 [D loss: 0.6647708415985107 | D accuracy: 60.9375] [G loss: 1.1740689277648926]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3517 [D loss: 0.555033951997757 | D accuracy: 67.1875] [G loss: 1.0520734786987305]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3518 [D loss: 0.6027812659740448 | D accuracy: 64.0625] [G loss: 1.194777011871338]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3519 [D loss: 0.5822555720806122 | D accuracy: 73.4375] [G loss: 1.2212563753128052]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3520 [D loss: 0.6414074003696442 | D accuracy: 62.5] [G loss: 1.162217378616333]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3521 [D loss: 0.621297687292099 | D accuracy: 64.0625] [G loss: 1.307293176651001]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3522 [D loss: 0.641130805015564 | D accuracy: 62.5] [G loss: 1.184023380279541]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3523 [D loss: 0.5011346191167831 | D accuracy: 76.5625] [G loss: 1.1371815204620361]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3524 [D loss: 0.6685447692871094 | D accuracy: 62.5] [G loss: 1.1146788597106934]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3525 [D loss: 0.6096997559070587 | D accuracy: 65.625] [G loss: 1.0010368824005127]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3526 [D loss: 0.6476690173149109 | D accuracy: 67.1875] [G loss: 1.1718418598175049]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3527 [D loss: 0.5936926305294037 | D accuracy: 67.1875] [G loss: 1.2151761054992676]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3528 [D loss: 0.5784143805503845 | D accuracy: 67.1875] [G loss: 1.1713688373565674]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3529 [D loss: 0.6239696145057678 | D accuracy: 64.0625] [G loss: 0.9964267015457153]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3530 [D loss: 0.5806578993797302 | D accuracy: 65.625] [G loss: 1.1932153701782227]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3531 [D loss: 0.5997874736785889 | D accuracy: 67.1875] [G loss: 1.0702459812164307]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3532 [D loss: 0.660805732011795 | D accuracy: 64.0625] [G loss: 1.0200188159942627]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3533 [D loss: 0.6218321919441223 | D accuracy: 57.8125] [G loss: 1.0589714050292969]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3534 [D loss: 0.5076462030410767 | D accuracy: 76.5625] [G loss: 1.1474387645721436]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3535 [D loss: 0.655530571937561 | D accuracy: 62.5] [G loss: 1.1246602535247803]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3536 [D loss: 0.6184978485107422 | D accuracy: 65.625] [G loss: 1.111131191253662]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3537 [D loss: 0.5737191736698151 | D accuracy: 68.75] [G loss: 1.1062524318695068]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3538 [D loss: 0.5866655111312866 | D accuracy: 67.1875] [G loss: 1.1830940246582031]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3539 [D loss: 0.5505089461803436 | D accuracy: 68.75] [G loss: 1.0936131477355957]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3540 [D loss: 0.6341133713722229 | D accuracy: 67.1875] [G loss: 1.2004375457763672]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3541 [D loss: 0.6117495894432068 | D accuracy: 76.5625] [G loss: 1.1368769407272339]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3542 [D loss: 0.5524573028087616 | D accuracy: 73.4375] [G loss: 1.087886095046997]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3543 [D loss: 0.6178249418735504 | D accuracy: 71.875] [G loss: 1.098433017730713]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3544 [D loss: 0.5541908442974091 | D accuracy: 73.4375] [G loss: 1.1057319641113281]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3545 [D loss: 0.5682335793972015 | D accuracy: 70.3125] [G loss: 1.271793007850647]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3546 [D loss: 0.6193783581256866 | D accuracy: 64.0625] [G loss: 1.0816036462783813]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "3547 [D loss: 0.5524314939975739 | D accuracy: 76.5625] [G loss: 1.120579481124878]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3548 [D loss: 0.6036373674869537 | D accuracy: 64.0625] [G loss: 1.287825107574463]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "3549 [D loss: 0.6702483892440796 | D accuracy: 65.625] [G loss: 1.0772721767425537]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3550 [D loss: 0.5415653586387634 | D accuracy: 70.3125] [G loss: 1.0509839057922363]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3551 [D loss: 0.5490704774856567 | D accuracy: 65.625] [G loss: 1.0625852346420288]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3552 [D loss: 0.5969013571739197 | D accuracy: 68.75] [G loss: 1.0670095682144165]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3553 [D loss: 0.6213021576404572 | D accuracy: 62.5] [G loss: 1.0624912977218628]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3554 [D loss: 0.6018638610839844 | D accuracy: 62.5] [G loss: 1.0415635108947754]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3555 [D loss: 0.5824140012264252 | D accuracy: 70.3125] [G loss: 1.1255666017532349]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3556 [D loss: 0.5793333649635315 | D accuracy: 67.1875] [G loss: 1.127570629119873]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3557 [D loss: 0.7273123562335968 | D accuracy: 65.625] [G loss: 1.099979281425476]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3558 [D loss: 0.5838510990142822 | D accuracy: 65.625] [G loss: 1.049677848815918]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3559 [D loss: 0.6315743923187256 | D accuracy: 62.5] [G loss: 1.115121603012085]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3560 [D loss: 0.5624892115592957 | D accuracy: 68.75] [G loss: 1.1130683422088623]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3561 [D loss: 0.6531152129173279 | D accuracy: 67.1875] [G loss: 1.1936991214752197]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3562 [D loss: 0.5613032877445221 | D accuracy: 70.3125] [G loss: 1.2717432975769043]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3563 [D loss: 0.6144473254680634 | D accuracy: 65.625] [G loss: 1.203654408454895]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3564 [D loss: 0.6153633892536163 | D accuracy: 65.625] [G loss: 1.2154110670089722]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3565 [D loss: 0.5980386435985565 | D accuracy: 59.375] [G loss: 1.0577881336212158]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3566 [D loss: 0.5003814399242401 | D accuracy: 75.0] [G loss: 1.1875919103622437]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3567 [D loss: 0.615839958190918 | D accuracy: 62.5] [G loss: 1.263033390045166]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3568 [D loss: 0.5719226002693176 | D accuracy: 70.3125] [G loss: 1.1563966274261475]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3569 [D loss: 0.5651713609695435 | D accuracy: 65.625] [G loss: 1.0591347217559814]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3570 [D loss: 0.6572737395763397 | D accuracy: 60.9375] [G loss: 1.1605112552642822]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3571 [D loss: 0.5326075255870819 | D accuracy: 71.875] [G loss: 0.972480297088623]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3572 [D loss: 0.6094056665897369 | D accuracy: 67.1875] [G loss: 1.0052025318145752]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3573 [D loss: 0.6085759401321411 | D accuracy: 71.875] [G loss: 1.044668197631836]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3574 [D loss: 0.5985383987426758 | D accuracy: 71.875] [G loss: 1.2054927349090576]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3575 [D loss: 0.7096954882144928 | D accuracy: 57.8125] [G loss: 1.132432460784912]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3576 [D loss: 0.5587350726127625 | D accuracy: 68.75] [G loss: 1.154152750968933]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3577 [D loss: 0.6381881535053253 | D accuracy: 57.8125] [G loss: 1.134076476097107]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3578 [D loss: 0.654692143201828 | D accuracy: 60.9375] [G loss: 1.1818360090255737]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3579 [D loss: 0.6245503723621368 | D accuracy: 60.9375] [G loss: 1.1522325277328491]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3580 [D loss: 0.5713307857513428 | D accuracy: 68.75] [G loss: 1.1405657529830933]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3581 [D loss: 0.6510367393493652 | D accuracy: 62.5] [G loss: 1.0361093282699585]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3582 [D loss: 0.5980208814144135 | D accuracy: 62.5] [G loss: 1.101445198059082]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3583 [D loss: 0.5188047289848328 | D accuracy: 81.25] [G loss: 1.132598876953125]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3584 [D loss: 0.6813565790653229 | D accuracy: 57.8125] [G loss: 1.0160020589828491]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3585 [D loss: 0.548895388841629 | D accuracy: 75.0] [G loss: 1.1028085947036743]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3586 [D loss: 0.6101038753986359 | D accuracy: 60.9375] [G loss: 1.19990873336792]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3587 [D loss: 0.604017436504364 | D accuracy: 70.3125] [G loss: 1.111353874206543]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3588 [D loss: 0.5946986377239227 | D accuracy: 62.5] [G loss: 1.1676089763641357]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3589 [D loss: 0.5750243961811066 | D accuracy: 60.9375] [G loss: 1.071639895439148]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3590 [D loss: 0.6472067832946777 | D accuracy: 59.375] [G loss: 1.0005600452423096]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3591 [D loss: 0.599741131067276 | D accuracy: 71.875] [G loss: 1.1180546283721924]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3592 [D loss: 0.6399088501930237 | D accuracy: 60.9375] [G loss: 1.1693307161331177]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3593 [D loss: 0.5499886870384216 | D accuracy: 71.875] [G loss: 1.1446154117584229]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3594 [D loss: 0.6021847128868103 | D accuracy: 67.1875] [G loss: 1.0863794088363647]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3595 [D loss: 0.6196651458740234 | D accuracy: 67.1875] [G loss: 1.0508744716644287]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3596 [D loss: 0.6563816666603088 | D accuracy: 64.0625] [G loss: 0.9329838752746582]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3597 [D loss: 0.46198081970214844 | D accuracy: 84.375] [G loss: 1.0235164165496826]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3598 [D loss: 0.6657937169075012 | D accuracy: 54.6875] [G loss: 1.071998119354248]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3599 [D loss: 0.6322737634181976 | D accuracy: 64.0625] [G loss: 1.02882981300354]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3600 [D loss: 0.6429915726184845 | D accuracy: 62.5] [G loss: 1.110274076461792]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3601 [D loss: 0.5584261119365692 | D accuracy: 75.0] [G loss: 1.1206181049346924]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3602 [D loss: 0.6220219731330872 | D accuracy: 67.1875] [G loss: 1.074595332145691]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3603 [D loss: 0.5326948016881943 | D accuracy: 75.0] [G loss: 1.140572428703308]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3604 [D loss: 0.5926781892776489 | D accuracy: 68.75] [G loss: 1.038024663925171]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3605 [D loss: 0.6309133768081665 | D accuracy: 59.375] [G loss: 1.0689783096313477]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3606 [D loss: 0.6607809662818909 | D accuracy: 57.8125] [G loss: 1.009575605392456]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3607 [D loss: 0.6728743016719818 | D accuracy: 65.625] [G loss: 1.34139084815979]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3608 [D loss: 0.5381609797477722 | D accuracy: 70.3125] [G loss: 1.2189196348190308]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3609 [D loss: 0.5647662580013275 | D accuracy: 73.4375] [G loss: 1.2164345979690552]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3610 [D loss: 0.6136711835861206 | D accuracy: 65.625] [G loss: 1.1602802276611328]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3611 [D loss: 0.6311385631561279 | D accuracy: 54.6875] [G loss: 1.1821458339691162]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3612 [D loss: 0.5356035232543945 | D accuracy: 73.4375] [G loss: 1.1684253215789795]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3613 [D loss: 0.6062994003295898 | D accuracy: 62.5] [G loss: 1.0161077976226807]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3614 [D loss: 0.5732490122318268 | D accuracy: 76.5625] [G loss: 0.9660155773162842]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3615 [D loss: 0.578456312417984 | D accuracy: 67.1875] [G loss: 1.030602216720581]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3616 [D loss: 0.5966260433197021 | D accuracy: 68.75] [G loss: 1.0055252313613892]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3617 [D loss: 0.5663004517555237 | D accuracy: 70.3125] [G loss: 1.0793852806091309]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3618 [D loss: 0.6321107745170593 | D accuracy: 60.9375] [G loss: 1.0127328634262085]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3619 [D loss: 0.5681714117527008 | D accuracy: 70.3125] [G loss: 1.1341469287872314]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "3620 [D loss: 0.5994996130466461 | D accuracy: 67.1875] [G loss: 1.2267296314239502]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3621 [D loss: 0.6709505319595337 | D accuracy: 56.25] [G loss: 1.0413851737976074]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3622 [D loss: 0.6042563319206238 | D accuracy: 67.1875] [G loss: 1.188021183013916]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "3623 [D loss: 0.5574110448360443 | D accuracy: 70.3125] [G loss: 1.1575894355773926]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3624 [D loss: 0.5402510166168213 | D accuracy: 75.0] [G loss: 1.1231919527053833]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "3625 [D loss: 0.5507884621620178 | D accuracy: 68.75] [G loss: 1.116612434387207]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3626 [D loss: 0.6358636617660522 | D accuracy: 65.625] [G loss: 1.0496760606765747]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3627 [D loss: 0.5057084858417511 | D accuracy: 73.4375] [G loss: 1.0978807210922241]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3628 [D loss: 0.5932775735855103 | D accuracy: 65.625] [G loss: 1.1097275018692017]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3629 [D loss: 0.7757427394390106 | D accuracy: 53.125] [G loss: 1.07534921169281]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3630 [D loss: 0.5949479341506958 | D accuracy: 70.3125] [G loss: 1.060570240020752]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3631 [D loss: 0.5579938739538193 | D accuracy: 73.4375] [G loss: 1.1890848875045776]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3632 [D loss: 0.5542318820953369 | D accuracy: 70.3125] [G loss: 1.1728768348693848]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3633 [D loss: 0.6518273651599884 | D accuracy: 56.25] [G loss: 1.0454121828079224]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3634 [D loss: 0.6762065589427948 | D accuracy: 67.1875] [G loss: 1.0666694641113281]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3635 [D loss: 0.6230076551437378 | D accuracy: 67.1875] [G loss: 1.052013874053955]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3636 [D loss: 0.6393637657165527 | D accuracy: 56.25] [G loss: 1.0658178329467773]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3637 [D loss: 0.6270631551742554 | D accuracy: 68.75] [G loss: 1.2008018493652344]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3638 [D loss: 0.5705138444900513 | D accuracy: 67.1875] [G loss: 1.1588950157165527]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3639 [D loss: 0.6129895150661469 | D accuracy: 67.1875] [G loss: 1.1370025873184204]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3640 [D loss: 0.5458781719207764 | D accuracy: 65.625] [G loss: 1.082053303718567]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3641 [D loss: 0.6170990169048309 | D accuracy: 59.375] [G loss: 1.0754519701004028]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3642 [D loss: 0.5001142621040344 | D accuracy: 68.75] [G loss: 1.1086188554763794]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3643 [D loss: 0.5525349974632263 | D accuracy: 68.75] [G loss: 1.1287503242492676]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3644 [D loss: 0.6664007604122162 | D accuracy: 60.9375] [G loss: 1.2640314102172852]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3645 [D loss: 0.6420056223869324 | D accuracy: 67.1875] [G loss: 1.0699787139892578]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3646 [D loss: 0.601073145866394 | D accuracy: 60.9375] [G loss: 1.0583051443099976]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3647 [D loss: 0.6320620179176331 | D accuracy: 59.375] [G loss: 1.0406808853149414]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3648 [D loss: 0.5318625867366791 | D accuracy: 75.0] [G loss: 1.1586570739746094]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3649 [D loss: 0.6377983689308167 | D accuracy: 60.9375] [G loss: 1.0738873481750488]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3650 [D loss: 0.5771556198596954 | D accuracy: 67.1875] [G loss: 1.1801836490631104]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3651 [D loss: 0.5735494196414948 | D accuracy: 70.3125] [G loss: 1.1186213493347168]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3652 [D loss: 0.5122959613800049 | D accuracy: 75.0] [G loss: 1.1070239543914795]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3653 [D loss: 0.585615873336792 | D accuracy: 64.0625] [G loss: 1.042771339416504]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3654 [D loss: 0.6026420295238495 | D accuracy: 70.3125] [G loss: 1.0555387735366821]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3655 [D loss: 0.6918065547943115 | D accuracy: 56.25] [G loss: 1.118774652481079]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3656 [D loss: 0.624921441078186 | D accuracy: 68.75] [G loss: 1.2257215976715088]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3657 [D loss: 0.6519486308097839 | D accuracy: 67.1875] [G loss: 1.202179193496704]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3658 [D loss: 0.6039655208587646 | D accuracy: 70.3125] [G loss: 1.2393044233322144]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3659 [D loss: 0.5861314833164215 | D accuracy: 68.75] [G loss: 1.0836269855499268]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3660 [D loss: 0.6474158465862274 | D accuracy: 60.9375] [G loss: 0.9859155416488647]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3661 [D loss: 0.5648875534534454 | D accuracy: 67.1875] [G loss: 1.1126432418823242]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3662 [D loss: 0.5918560326099396 | D accuracy: 67.1875] [G loss: 1.1581015586853027]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3663 [D loss: 0.619347482919693 | D accuracy: 64.0625] [G loss: 1.2101318836212158]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3664 [D loss: 0.6176978945732117 | D accuracy: 68.75] [G loss: 1.083482265472412]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3665 [D loss: 0.5804937481880188 | D accuracy: 70.3125] [G loss: 1.0746586322784424]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3666 [D loss: 0.5332252681255341 | D accuracy: 81.25] [G loss: 1.0845906734466553]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3667 [D loss: 0.6720389723777771 | D accuracy: 60.9375] [G loss: 0.9847935438156128]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3668 [D loss: 0.6753103137016296 | D accuracy: 65.625] [G loss: 1.1918745040893555]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3669 [D loss: 0.6096300184726715 | D accuracy: 67.1875] [G loss: 1.0741631984710693]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3670 [D loss: 0.5983080863952637 | D accuracy: 65.625] [G loss: 1.0890967845916748]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3671 [D loss: 0.6445261240005493 | D accuracy: 60.9375] [G loss: 1.1318117380142212]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3672 [D loss: 0.5429194569587708 | D accuracy: 65.625] [G loss: 1.1488608121871948]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3673 [D loss: 0.6528793573379517 | D accuracy: 62.5] [G loss: 1.1518925428390503]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3674 [D loss: 0.6045684814453125 | D accuracy: 65.625] [G loss: 1.0604679584503174]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3675 [D loss: 0.5808714330196381 | D accuracy: 68.75] [G loss: 0.9426587820053101]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3676 [D loss: 0.5557328760623932 | D accuracy: 71.875] [G loss: 1.0155469179153442]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3677 [D loss: 0.597797304391861 | D accuracy: 57.8125] [G loss: 1.1025569438934326]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3678 [D loss: 0.5403188467025757 | D accuracy: 76.5625] [G loss: 1.0956220626831055]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3679 [D loss: 0.5660328269004822 | D accuracy: 64.0625] [G loss: 1.042912244796753]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3680 [D loss: 0.5977387428283691 | D accuracy: 67.1875] [G loss: 1.0859696865081787]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3681 [D loss: 0.6401335895061493 | D accuracy: 60.9375] [G loss: 1.0637733936309814]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3682 [D loss: 0.5585508346557617 | D accuracy: 76.5625] [G loss: 1.0712751150131226]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3683 [D loss: 0.5991462469100952 | D accuracy: 67.1875] [G loss: 1.0987682342529297]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3684 [D loss: 0.6215643882751465 | D accuracy: 57.8125] [G loss: 1.190335750579834]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3685 [D loss: 0.5609954595565796 | D accuracy: 65.625] [G loss: 1.1878176927566528]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3686 [D loss: 0.60157710313797 | D accuracy: 67.1875] [G loss: 1.1208027601242065]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3687 [D loss: 0.5512180626392365 | D accuracy: 71.875] [G loss: 1.0726888179779053]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3688 [D loss: 0.6595428287982941 | D accuracy: 59.375] [G loss: 1.0723636150360107]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3689 [D loss: 0.6471849977970123 | D accuracy: 60.9375] [G loss: 1.0302207469940186]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3690 [D loss: 0.6005302667617798 | D accuracy: 62.5] [G loss: 1.0113927125930786]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3691 [D loss: 0.5022642612457275 | D accuracy: 78.125] [G loss: 1.0304725170135498]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3692 [D loss: 0.5700521767139435 | D accuracy: 71.875] [G loss: 1.0372202396392822]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3693 [D loss: 0.5906400680541992 | D accuracy: 64.0625] [G loss: 0.9732580184936523]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3694 [D loss: 0.6167045533657074 | D accuracy: 71.875] [G loss: 0.9518779516220093]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3695 [D loss: 0.6206229031085968 | D accuracy: 56.25] [G loss: 1.0724759101867676]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3696 [D loss: 0.6823486983776093 | D accuracy: 59.375] [G loss: 1.0165214538574219]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3697 [D loss: 0.6824100315570831 | D accuracy: 57.8125] [G loss: 1.1180181503295898]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3698 [D loss: 0.5888030827045441 | D accuracy: 67.1875] [G loss: 1.2525663375854492]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3699 [D loss: 0.6171636581420898 | D accuracy: 62.5] [G loss: 1.117217779159546]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3700 [D loss: 0.6047636270523071 | D accuracy: 57.8125] [G loss: 1.0653574466705322]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3701 [D loss: 0.6424050331115723 | D accuracy: 60.9375] [G loss: 0.9945199489593506]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3702 [D loss: 0.6897597014904022 | D accuracy: 54.6875] [G loss: 1.0028809309005737]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3703 [D loss: 0.6579625606536865 | D accuracy: 59.375] [G loss: 0.9724081158638]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3704 [D loss: 0.6403912305831909 | D accuracy: 56.25] [G loss: 1.0993366241455078]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3705 [D loss: 0.64168980717659 | D accuracy: 59.375] [G loss: 1.0337207317352295]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3706 [D loss: 0.5649572312831879 | D accuracy: 68.75] [G loss: 0.9782738089561462]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3707 [D loss: 0.567911759018898 | D accuracy: 70.3125] [G loss: 0.9974321126937866]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3708 [D loss: 0.6296947300434113 | D accuracy: 64.0625] [G loss: 1.1249364614486694]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3709 [D loss: 0.6248487830162048 | D accuracy: 64.0625] [G loss: 1.042702317237854]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3710 [D loss: 0.6030218303203583 | D accuracy: 60.9375] [G loss: 1.083726406097412]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3711 [D loss: 0.6639045774936676 | D accuracy: 53.125] [G loss: 1.046234369277954]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3712 [D loss: 0.5363375544548035 | D accuracy: 76.5625] [G loss: 0.9044831991195679]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3713 [D loss: 0.7479572594165802 | D accuracy: 51.5625] [G loss: 1.1181128025054932]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3714 [D loss: 0.602416455745697 | D accuracy: 62.5] [G loss: 1.1262037754058838]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3715 [D loss: 0.7134809494018555 | D accuracy: 56.25] [G loss: 1.0668309926986694]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3716 [D loss: 0.6007392704486847 | D accuracy: 65.625] [G loss: 1.1066771745681763]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3717 [D loss: 0.5840559005737305 | D accuracy: 73.4375] [G loss: 1.0227397680282593]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3718 [D loss: 0.5564008951187134 | D accuracy: 68.75] [G loss: 0.975103497505188]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3719 [D loss: 0.6313379108905792 | D accuracy: 65.625] [G loss: 0.9424856901168823]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3720 [D loss: 0.5945355594158173 | D accuracy: 75.0] [G loss: 1.073140263557434]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3721 [D loss: 0.566326230764389 | D accuracy: 67.1875] [G loss: 1.1418536901474]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3722 [D loss: 0.5873943567276001 | D accuracy: 67.1875] [G loss: 0.9469941258430481]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3723 [D loss: 0.5139796733856201 | D accuracy: 73.4375] [G loss: 1.0753298997879028]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3724 [D loss: 0.6754885911941528 | D accuracy: 59.375] [G loss: 1.0301039218902588]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3725 [D loss: 0.5673991441726685 | D accuracy: 70.3125] [G loss: 1.112485647201538]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3726 [D loss: 0.6515548527240753 | D accuracy: 64.0625] [G loss: 1.0681437253952026]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3727 [D loss: 0.6401146650314331 | D accuracy: 59.375] [G loss: 1.1073246002197266]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3728 [D loss: 0.5895229876041412 | D accuracy: 64.0625] [G loss: 1.04635751247406]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3729 [D loss: 0.5687209069728851 | D accuracy: 71.875] [G loss: 1.0207545757293701]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3730 [D loss: 0.5939710140228271 | D accuracy: 70.3125] [G loss: 0.9816551208496094]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3731 [D loss: 0.6180094480514526 | D accuracy: 62.5] [G loss: 0.932062029838562]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3732 [D loss: 0.6154236793518066 | D accuracy: 59.375] [G loss: 1.0013540983200073]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3733 [D loss: 0.6081067323684692 | D accuracy: 64.0625] [G loss: 0.9419739842414856]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3734 [D loss: 0.569866806268692 | D accuracy: 71.875] [G loss: 1.0247254371643066]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3735 [D loss: 0.703976958990097 | D accuracy: 53.125] [G loss: 1.0308973789215088]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3736 [D loss: 0.6329524517059326 | D accuracy: 62.5] [G loss: 0.9942947626113892]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3737 [D loss: 0.5605026185512543 | D accuracy: 71.875] [G loss: 1.0857545137405396]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3738 [D loss: 0.6670605540275574 | D accuracy: 59.375] [G loss: 1.132950782775879]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3739 [D loss: 0.6179270148277283 | D accuracy: 59.375] [G loss: 0.987669050693512]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3740 [D loss: 0.5973068475723267 | D accuracy: 65.625] [G loss: 1.203340768814087]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3741 [D loss: 0.6555931270122528 | D accuracy: 57.8125] [G loss: 1.0554198026657104]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3742 [D loss: 0.5117866694927216 | D accuracy: 79.6875] [G loss: 0.977888822555542]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3743 [D loss: 0.6453770399093628 | D accuracy: 65.625] [G loss: 0.9785469770431519]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3744 [D loss: 0.5677960813045502 | D accuracy: 73.4375] [G loss: 0.9415092468261719]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3745 [D loss: 0.7011091709136963 | D accuracy: 59.375] [G loss: 0.9441224336624146]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3746 [D loss: 0.6403328478336334 | D accuracy: 64.0625] [G loss: 1.0098109245300293]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3747 [D loss: 0.5871194005012512 | D accuracy: 67.1875] [G loss: 1.1797888278961182]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3748 [D loss: 0.6994622051715851 | D accuracy: 59.375] [G loss: 1.167527675628662]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3749 [D loss: 0.5576225519180298 | D accuracy: 67.1875] [G loss: 1.113943099975586]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3750 [D loss: 0.6149619519710541 | D accuracy: 62.5] [G loss: 1.1729671955108643]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3751 [D loss: 0.5267095267772675 | D accuracy: 73.4375] [G loss: 1.0597286224365234]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3752 [D loss: 0.5754359662532806 | D accuracy: 67.1875] [G loss: 1.1199814081192017]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3753 [D loss: 0.6777611076831818 | D accuracy: 60.9375] [G loss: 0.9324601888656616]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3754 [D loss: 0.6663627028465271 | D accuracy: 62.5] [G loss: 0.8763051629066467]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3755 [D loss: 0.5835165083408356 | D accuracy: 68.75] [G loss: 0.9990525245666504]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3756 [D loss: 0.6280304491519928 | D accuracy: 59.375] [G loss: 1.0696910619735718]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3757 [D loss: 0.6349658071994781 | D accuracy: 62.5] [G loss: 1.0171701908111572]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3758 [D loss: 0.5839653313159943 | D accuracy: 73.4375] [G loss: 1.1269161701202393]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3759 [D loss: 0.5544546842575073 | D accuracy: 73.4375] [G loss: 1.077590823173523]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3760 [D loss: 0.632463276386261 | D accuracy: 60.9375] [G loss: 0.9732251167297363]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3761 [D loss: 0.5799596309661865 | D accuracy: 64.0625] [G loss: 1.1634702682495117]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3762 [D loss: 0.5420276671648026 | D accuracy: 67.1875] [G loss: 1.1606484651565552]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3763 [D loss: 0.5750228613615036 | D accuracy: 70.3125] [G loss: 0.9510170221328735]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3764 [D loss: 0.6443226337432861 | D accuracy: 56.25] [G loss: 0.9816329479217529]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3765 [D loss: 0.6553149521350861 | D accuracy: 59.375] [G loss: 0.9905842542648315]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3766 [D loss: 0.6000432670116425 | D accuracy: 68.75] [G loss: 1.0144456624984741]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3767 [D loss: 0.5519648194313049 | D accuracy: 73.4375] [G loss: 1.131876826286316]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3768 [D loss: 0.6423426270484924 | D accuracy: 64.0625] [G loss: 0.960193395614624]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3769 [D loss: 0.5830555856227875 | D accuracy: 68.75] [G loss: 1.1086413860321045]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3770 [D loss: 0.5655516982078552 | D accuracy: 71.875] [G loss: 0.9970760345458984]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3771 [D loss: 0.6378546059131622 | D accuracy: 64.0625] [G loss: 1.0450050830841064]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3772 [D loss: 0.6283373236656189 | D accuracy: 59.375] [G loss: 1.0716255903244019]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3773 [D loss: 0.6355506181716919 | D accuracy: 64.0625] [G loss: 0.9541420936584473]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3774 [D loss: 0.6431338787078857 | D accuracy: 62.5] [G loss: 1.0572718381881714]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3775 [D loss: 0.5561101138591766 | D accuracy: 75.0] [G loss: 1.0570051670074463]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3776 [D loss: 0.6000906825065613 | D accuracy: 68.75] [G loss: 0.9708094596862793]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3777 [D loss: 0.5550508797168732 | D accuracy: 71.875] [G loss: 1.0832250118255615]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3778 [D loss: 0.5657746493816376 | D accuracy: 73.4375] [G loss: 1.110840082168579]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3779 [D loss: 0.5566065013408661 | D accuracy: 67.1875] [G loss: 1.0314702987670898]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3780 [D loss: 0.6016949415206909 | D accuracy: 67.1875] [G loss: 1.126321792602539]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3781 [D loss: 0.5906816124916077 | D accuracy: 71.875] [G loss: 1.1551456451416016]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3782 [D loss: 0.6253343522548676 | D accuracy: 65.625] [G loss: 0.9907150268554688]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3783 [D loss: 0.6540960669517517 | D accuracy: 59.375] [G loss: 1.051867127418518]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3784 [D loss: 0.6444607377052307 | D accuracy: 65.625] [G loss: 1.0520763397216797]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3785 [D loss: 0.5627018809318542 | D accuracy: 70.3125] [G loss: 1.0524424314498901]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "3786 [D loss: 0.7082318663597107 | D accuracy: 59.375] [G loss: 1.0812761783599854]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3787 [D loss: 0.6412500143051147 | D accuracy: 62.5] [G loss: 0.9907135367393494]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3788 [D loss: 0.5996324121952057 | D accuracy: 67.1875] [G loss: 0.9070807695388794]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3789 [D loss: 0.6273569166660309 | D accuracy: 70.3125] [G loss: 0.9574291706085205]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3790 [D loss: 0.6325936317443848 | D accuracy: 67.1875] [G loss: 1.1250115633010864]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3791 [D loss: 0.5851825177669525 | D accuracy: 65.625] [G loss: 1.0779330730438232]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3792 [D loss: 0.6139001846313477 | D accuracy: 65.625] [G loss: 1.1203879117965698]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3793 [D loss: 0.5838065445423126 | D accuracy: 71.875] [G loss: 1.10224449634552]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3794 [D loss: 0.6697344779968262 | D accuracy: 53.125] [G loss: 1.0031057596206665]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3795 [D loss: 0.625185638666153 | D accuracy: 62.5] [G loss: 0.9855125546455383]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3796 [D loss: 0.6675843000411987 | D accuracy: 57.8125] [G loss: 1.0306484699249268]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3797 [D loss: 0.6078841090202332 | D accuracy: 75.0] [G loss: 1.1010783910751343]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3798 [D loss: 0.6197722554206848 | D accuracy: 64.0625] [G loss: 1.0212172269821167]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3799 [D loss: 0.6262170076370239 | D accuracy: 57.8125] [G loss: 1.0609103441238403]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3800 [D loss: 0.6922577619552612 | D accuracy: 54.6875] [G loss: 1.0720674991607666]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3801 [D loss: 0.5485282987356186 | D accuracy: 71.875] [G loss: 1.1180636882781982]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3802 [D loss: 0.6430593729019165 | D accuracy: 64.0625] [G loss: 1.0345628261566162]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3803 [D loss: 0.5894458889961243 | D accuracy: 68.75] [G loss: 1.0064221620559692]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3804 [D loss: 0.5580494403839111 | D accuracy: 71.875] [G loss: 1.1140663623809814]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3805 [D loss: 0.5617300570011139 | D accuracy: 71.875] [G loss: 1.124442219734192]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3806 [D loss: 0.6580826938152313 | D accuracy: 51.5625] [G loss: 1.1296693086624146]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3807 [D loss: 0.647109866142273 | D accuracy: 65.625] [G loss: 0.9690989255905151]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3808 [D loss: 0.5880913436412811 | D accuracy: 60.9375] [G loss: 1.0427579879760742]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3809 [D loss: 0.6072891652584076 | D accuracy: 62.5] [G loss: 1.1327579021453857]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3810 [D loss: 0.5190459191799164 | D accuracy: 75.0] [G loss: 1.079249382019043]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3811 [D loss: 0.6628488004207611 | D accuracy: 54.6875] [G loss: 1.0004925727844238]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3812 [D loss: 0.6148566007614136 | D accuracy: 67.1875] [G loss: 1.0203313827514648]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3813 [D loss: 0.6197482943534851 | D accuracy: 64.0625] [G loss: 1.0714409351348877]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3814 [D loss: 0.6434561312198639 | D accuracy: 65.625] [G loss: 1.1490387916564941]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3815 [D loss: 0.6736985743045807 | D accuracy: 60.9375] [G loss: 1.0355854034423828]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3816 [D loss: 0.6270039677619934 | D accuracy: 59.375] [G loss: 0.9728974103927612]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3817 [D loss: 0.6284899115562439 | D accuracy: 62.5] [G loss: 1.0294344425201416]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3818 [D loss: 0.7024499773979187 | D accuracy: 59.375] [G loss: 1.0317680835723877]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3819 [D loss: 0.597131609916687 | D accuracy: 67.1875] [G loss: 1.096563696861267]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3820 [D loss: 0.6176980137825012 | D accuracy: 67.1875] [G loss: 1.1076247692108154]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3821 [D loss: 0.607892632484436 | D accuracy: 64.0625] [G loss: 1.1897352933883667]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3822 [D loss: 0.661321759223938 | D accuracy: 64.0625] [G loss: 1.0344632863998413]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3823 [D loss: 0.5938361585140228 | D accuracy: 70.3125] [G loss: 1.0439202785491943]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3824 [D loss: 0.5916904807090759 | D accuracy: 71.875] [G loss: 1.0418068170547485]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3825 [D loss: 0.5793069303035736 | D accuracy: 65.625] [G loss: 1.0251225233078003]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3826 [D loss: 0.564428448677063 | D accuracy: 73.4375] [G loss: 1.069239854812622]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3827 [D loss: 0.649155855178833 | D accuracy: 62.5] [G loss: 1.051866054534912]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3828 [D loss: 0.6498336791992188 | D accuracy: 59.375] [G loss: 1.0139083862304688]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3829 [D loss: 0.5813576579093933 | D accuracy: 70.3125] [G loss: 1.0200893878936768]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3830 [D loss: 0.5884436070919037 | D accuracy: 64.0625] [G loss: 1.1219812631607056]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3831 [D loss: 0.6697844862937927 | D accuracy: 57.8125] [G loss: 1.1153082847595215]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3832 [D loss: 0.572648823261261 | D accuracy: 70.3125] [G loss: 1.1877250671386719]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3833 [D loss: 0.6848048865795135 | D accuracy: 57.8125] [G loss: 1.0149543285369873]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3834 [D loss: 0.575605034828186 | D accuracy: 65.625] [G loss: 1.0637025833129883]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3835 [D loss: 0.6581315398216248 | D accuracy: 56.25] [G loss: 0.982498049736023]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3836 [D loss: 0.7102084159851074 | D accuracy: 57.8125] [G loss: 1.1376911401748657]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3837 [D loss: 0.715791255235672 | D accuracy: 46.875] [G loss: 1.0232720375061035]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3838 [D loss: 0.6204167902469635 | D accuracy: 68.75] [G loss: 0.986865222454071]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3839 [D loss: 0.6386490762233734 | D accuracy: 65.625] [G loss: 1.0251861810684204]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3840 [D loss: 0.6732002794742584 | D accuracy: 56.25] [G loss: 1.0634617805480957]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3841 [D loss: 0.5393372178077698 | D accuracy: 75.0] [G loss: 1.0354048013687134]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3842 [D loss: 0.6430022716522217 | D accuracy: 64.0625] [G loss: 1.0246877670288086]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3843 [D loss: 0.5872317552566528 | D accuracy: 68.75] [G loss: 1.066231369972229]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3844 [D loss: 0.5884774625301361 | D accuracy: 60.9375] [G loss: 0.9816283583641052]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3845 [D loss: 0.6348361670970917 | D accuracy: 60.9375] [G loss: 0.9589347243309021]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3846 [D loss: 0.6018580794334412 | D accuracy: 62.5] [G loss: 0.999421238899231]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3847 [D loss: 0.6673586368560791 | D accuracy: 60.9375] [G loss: 1.0084753036499023]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3848 [D loss: 0.6509870886802673 | D accuracy: 60.9375] [G loss: 1.067900538444519]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3849 [D loss: 0.5341910719871521 | D accuracy: 73.4375] [G loss: 1.197044849395752]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3850 [D loss: 0.6161856651306152 | D accuracy: 60.9375] [G loss: 1.1141040325164795]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3851 [D loss: 0.5377407670021057 | D accuracy: 78.125] [G loss: 1.1476855278015137]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3852 [D loss: 0.6250663101673126 | D accuracy: 62.5] [G loss: 1.0772428512573242]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3853 [D loss: 0.6913802921772003 | D accuracy: 59.375] [G loss: 1.0875436067581177]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3854 [D loss: 0.6153008937835693 | D accuracy: 62.5] [G loss: 1.0455788373947144]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3855 [D loss: 0.6552621126174927 | D accuracy: 62.5] [G loss: 0.9302745461463928]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3856 [D loss: 0.6594115495681763 | D accuracy: 54.6875] [G loss: 1.0215167999267578]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3857 [D loss: 0.6294934749603271 | D accuracy: 67.1875] [G loss: 1.0479108095169067]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "3858 [D loss: 0.5128617584705353 | D accuracy: 75.0] [G loss: 0.9995559453964233]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3859 [D loss: 0.615329772233963 | D accuracy: 67.1875] [G loss: 1.0428756475448608]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3860 [D loss: 0.5910787582397461 | D accuracy: 64.0625] [G loss: 0.983112633228302]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3861 [D loss: 0.6184613406658173 | D accuracy: 57.8125] [G loss: 1.011560082435608]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3862 [D loss: 0.6186671555042267 | D accuracy: 59.375] [G loss: 1.0356152057647705]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3863 [D loss: 0.6531325876712799 | D accuracy: 68.75] [G loss: 1.006438136100769]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3864 [D loss: 0.6089133024215698 | D accuracy: 73.4375] [G loss: 1.0693081617355347]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3865 [D loss: 0.5189197063446045 | D accuracy: 76.5625] [G loss: 1.0424046516418457]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3866 [D loss: 0.6095530092716217 | D accuracy: 62.5] [G loss: 1.0759046077728271]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3867 [D loss: 0.5249645709991455 | D accuracy: 79.6875] [G loss: 1.2276179790496826]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "3868 [D loss: 0.5056249648332596 | D accuracy: 79.6875] [G loss: 1.1176598072052002]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "3869 [D loss: 0.6587035953998566 | D accuracy: 60.9375] [G loss: 1.1803300380706787]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3870 [D loss: 0.5412994027137756 | D accuracy: 73.4375] [G loss: 1.0885792970657349]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "3871 [D loss: 0.561056911945343 | D accuracy: 71.875] [G loss: 1.0510642528533936]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3872 [D loss: 0.5869761109352112 | D accuracy: 64.0625] [G loss: 1.064178705215454]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3873 [D loss: 0.6004705727100372 | D accuracy: 71.875] [G loss: 1.1256495714187622]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3874 [D loss: 0.5501863956451416 | D accuracy: 65.625] [G loss: 1.0315372943878174]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3875 [D loss: 0.6904196441173553 | D accuracy: 54.6875] [G loss: 1.1161645650863647]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3876 [D loss: 0.6018616259098053 | D accuracy: 68.75] [G loss: 1.0474485158920288]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3877 [D loss: 0.7256379425525665 | D accuracy: 56.25] [G loss: 1.0421544313430786]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3878 [D loss: 0.6520112454891205 | D accuracy: 60.9375] [G loss: 1.0551159381866455]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3879 [D loss: 0.5998392701148987 | D accuracy: 62.5] [G loss: 1.1967997550964355]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3880 [D loss: 0.6827763020992279 | D accuracy: 59.375] [G loss: 1.0885679721832275]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3881 [D loss: 0.5175981223583221 | D accuracy: 79.6875] [G loss: 1.1131172180175781]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3882 [D loss: 0.6252843141555786 | D accuracy: 68.75] [G loss: 0.8441585302352905]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3883 [D loss: 0.5883350372314453 | D accuracy: 67.1875] [G loss: 0.9325576424598694]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3884 [D loss: 0.6414082646369934 | D accuracy: 62.5] [G loss: 0.9573091268539429]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3885 [D loss: 0.7034120857715607 | D accuracy: 56.25] [G loss: 1.0040788650512695]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3886 [D loss: 0.6037111580371857 | D accuracy: 67.1875] [G loss: 1.0753875970840454]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3887 [D loss: 0.6271761655807495 | D accuracy: 57.8125] [G loss: 0.9646519422531128]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3888 [D loss: 0.6135847866535187 | D accuracy: 67.1875] [G loss: 0.9319610595703125]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3889 [D loss: 0.595909595489502 | D accuracy: 70.3125] [G loss: 1.0117905139923096]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3890 [D loss: 0.55389204621315 | D accuracy: 78.125] [G loss: 0.9968093633651733]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3891 [D loss: 0.6315897703170776 | D accuracy: 60.9375] [G loss: 1.0221965312957764]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3892 [D loss: 0.6987786293029785 | D accuracy: 56.25] [G loss: 0.9182285666465759]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3893 [D loss: 0.7090197205543518 | D accuracy: 51.5625] [G loss: 0.9657964706420898]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3894 [D loss: 0.6837767362594604 | D accuracy: 51.5625] [G loss: 0.9263757467269897]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3895 [D loss: 0.6010178327560425 | D accuracy: 68.75] [G loss: 0.9507295489311218]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3896 [D loss: 0.5801961123943329 | D accuracy: 73.4375] [G loss: 1.0369805097579956]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3897 [D loss: 0.5618127286434174 | D accuracy: 70.3125] [G loss: 0.93879234790802]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3898 [D loss: 0.6735845804214478 | D accuracy: 54.6875] [G loss: 1.0586349964141846]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3899 [D loss: 0.6718985438346863 | D accuracy: 59.375] [G loss: 1.0556178092956543]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3900 [D loss: 0.6129125356674194 | D accuracy: 71.875] [G loss: 1.0279872417449951]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "3901 [D loss: 0.6060563921928406 | D accuracy: 65.625] [G loss: 0.9978246688842773]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3902 [D loss: 0.5956966280937195 | D accuracy: 64.0625] [G loss: 1.0562421083450317]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3903 [D loss: 0.5748994052410126 | D accuracy: 70.3125] [G loss: 1.013702154159546]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3904 [D loss: 0.5795406997203827 | D accuracy: 71.875] [G loss: 1.0485472679138184]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3905 [D loss: 0.6625611186027527 | D accuracy: 60.9375] [G loss: 1.0664384365081787]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3906 [D loss: 0.6114494204521179 | D accuracy: 68.75] [G loss: 1.0723364353179932]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3907 [D loss: 0.681908905506134 | D accuracy: 59.375] [G loss: 1.0715184211730957]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3908 [D loss: 0.7084251344203949 | D accuracy: 59.375] [G loss: 1.030538558959961]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3909 [D loss: 0.6560742259025574 | D accuracy: 56.25] [G loss: 1.037595510482788]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3910 [D loss: 0.6098161041736603 | D accuracy: 60.9375] [G loss: 1.1172019243240356]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3911 [D loss: 0.5737848579883575 | D accuracy: 70.3125] [G loss: 1.0695067644119263]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3912 [D loss: 0.6511550545692444 | D accuracy: 65.625] [G loss: 1.0578231811523438]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3913 [D loss: 0.6821153461933136 | D accuracy: 60.9375] [G loss: 1.035919189453125]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3914 [D loss: 0.558641791343689 | D accuracy: 67.1875] [G loss: 1.0250911712646484]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3915 [D loss: 0.5945280194282532 | D accuracy: 68.75] [G loss: 1.0512816905975342]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3916 [D loss: 0.5252332985401154 | D accuracy: 75.0] [G loss: 1.100433349609375]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3917 [D loss: 0.6348225772380829 | D accuracy: 62.5] [G loss: 1.0701888799667358]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3918 [D loss: 0.5320040881633759 | D accuracy: 71.875] [G loss: 1.03989577293396]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3919 [D loss: 0.6389530003070831 | D accuracy: 60.9375] [G loss: 0.9616119265556335]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3920 [D loss: 0.650604248046875 | D accuracy: 65.625] [G loss: 1.0338375568389893]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3921 [D loss: 0.636193037033081 | D accuracy: 64.0625] [G loss: 1.1091890335083008]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3922 [D loss: 0.6725295186042786 | D accuracy: 57.8125] [G loss: 1.18595290184021]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3923 [D loss: 0.6285188794136047 | D accuracy: 62.5] [G loss: 1.0012922286987305]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3924 [D loss: 0.6004399359226227 | D accuracy: 70.3125] [G loss: 0.9620907306671143]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3925 [D loss: 0.6163131296634674 | D accuracy: 59.375] [G loss: 1.1306613683700562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3926 [D loss: 0.6890408396720886 | D accuracy: 56.25] [G loss: 1.0646792650222778]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3927 [D loss: 0.6274468004703522 | D accuracy: 71.875] [G loss: 0.9530527591705322]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3928 [D loss: 0.6116169691085815 | D accuracy: 70.3125] [G loss: 1.0463322401046753]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3929 [D loss: 0.6067520678043365 | D accuracy: 59.375] [G loss: 1.0362379550933838]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3930 [D loss: 0.6293658316135406 | D accuracy: 62.5] [G loss: 1.0460880994796753]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3931 [D loss: 0.645614743232727 | D accuracy: 59.375] [G loss: 0.9252891540527344]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3932 [D loss: 0.5529998242855072 | D accuracy: 73.4375] [G loss: 0.9850167036056519]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3933 [D loss: 0.5983355343341827 | D accuracy: 71.875] [G loss: 1.0405887365341187]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3934 [D loss: 0.6600200831890106 | D accuracy: 59.375] [G loss: 0.9958184957504272]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3935 [D loss: 0.5930444002151489 | D accuracy: 75.0] [G loss: 0.9395796060562134]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3936 [D loss: 0.6628278195858002 | D accuracy: 64.0625] [G loss: 1.03080415725708]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3937 [D loss: 0.5391120910644531 | D accuracy: 75.0] [G loss: 1.139573097229004]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3938 [D loss: 0.6651975810527802 | D accuracy: 73.4375] [G loss: 1.0790228843688965]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3939 [D loss: 0.6047398149967194 | D accuracy: 70.3125] [G loss: 1.1311824321746826]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3940 [D loss: 0.5767422467470169 | D accuracy: 60.9375] [G loss: 1.0550479888916016]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3941 [D loss: 0.6195482611656189 | D accuracy: 59.375] [G loss: 1.084978699684143]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "3942 [D loss: 0.5437640696763992 | D accuracy: 71.875] [G loss: 0.9533182382583618]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3943 [D loss: 0.6116082668304443 | D accuracy: 56.25] [G loss: 1.0030525922775269]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3944 [D loss: 0.5325232744216919 | D accuracy: 73.4375] [G loss: 1.0069670677185059]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "3945 [D loss: 0.6468170881271362 | D accuracy: 67.1875] [G loss: 0.9943859577178955]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3946 [D loss: 0.6143261194229126 | D accuracy: 62.5] [G loss: 1.0013298988342285]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3947 [D loss: 0.6261502504348755 | D accuracy: 62.5] [G loss: 0.9704850316047668]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3948 [D loss: 0.6318868696689606 | D accuracy: 68.75] [G loss: 1.063446044921875]\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "3949 [D loss: 0.627842366695404 | D accuracy: 62.5] [G loss: 1.04298996925354]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3950 [D loss: 0.5859585106372833 | D accuracy: 67.1875] [G loss: 0.9833517670631409]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3951 [D loss: 0.6127251982688904 | D accuracy: 64.0625] [G loss: 1.0546772480010986]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3952 [D loss: 0.5930738747119904 | D accuracy: 64.0625] [G loss: 1.0039957761764526]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3953 [D loss: 0.6509141325950623 | D accuracy: 59.375] [G loss: 1.0252902507781982]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3954 [D loss: 0.6360456347465515 | D accuracy: 59.375] [G loss: 1.126007080078125]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3955 [D loss: 0.6047344207763672 | D accuracy: 62.5] [G loss: 0.9984228610992432]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3956 [D loss: 0.615837037563324 | D accuracy: 57.8125] [G loss: 0.968661904335022]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3957 [D loss: 0.5804861187934875 | D accuracy: 75.0] [G loss: 1.1018280982971191]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3958 [D loss: 0.5931162238121033 | D accuracy: 71.875] [G loss: 0.8873293399810791]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3959 [D loss: 0.6300126314163208 | D accuracy: 62.5] [G loss: 1.055656909942627]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3960 [D loss: 0.7727755308151245 | D accuracy: 50.0] [G loss: 0.9765263795852661]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3961 [D loss: 0.5548412650823593 | D accuracy: 71.875] [G loss: 0.9768913388252258]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3962 [D loss: 0.5721814036369324 | D accuracy: 73.4375] [G loss: 1.0168966054916382]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3963 [D loss: 0.6458440124988556 | D accuracy: 60.9375] [G loss: 0.9980692863464355]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3964 [D loss: 0.6741609573364258 | D accuracy: 65.625] [G loss: 0.9765949249267578]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3965 [D loss: 0.6374553740024567 | D accuracy: 64.0625] [G loss: 0.9482109546661377]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3966 [D loss: 0.5450155436992645 | D accuracy: 71.875] [G loss: 1.1023166179656982]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3967 [D loss: 0.6053421199321747 | D accuracy: 67.1875] [G loss: 0.9885278940200806]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3968 [D loss: 0.6589118540287018 | D accuracy: 64.0625] [G loss: 0.9296489953994751]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3969 [D loss: 0.6402771174907684 | D accuracy: 65.625] [G loss: 0.9215165376663208]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3970 [D loss: 0.6335832178592682 | D accuracy: 65.625] [G loss: 0.9562941789627075]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3971 [D loss: 0.5940376222133636 | D accuracy: 76.5625] [G loss: 1.019452691078186]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3972 [D loss: 0.6148272454738617 | D accuracy: 60.9375] [G loss: 0.9982632994651794]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3973 [D loss: 0.6069560050964355 | D accuracy: 67.1875] [G loss: 1.0561573505401611]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3974 [D loss: 0.5615558922290802 | D accuracy: 71.875] [G loss: 1.0905863046646118]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3975 [D loss: 0.5860283076763153 | D accuracy: 67.1875] [G loss: 1.0411547422409058]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3976 [D loss: 0.5846876502037048 | D accuracy: 73.4375] [G loss: 1.030164122581482]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3977 [D loss: 0.6202507019042969 | D accuracy: 65.625] [G loss: 1.0295171737670898]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3978 [D loss: 0.7192174792289734 | D accuracy: 54.6875] [G loss: 0.9918099045753479]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3979 [D loss: 0.6178082525730133 | D accuracy: 65.625] [G loss: 1.075033187866211]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3980 [D loss: 0.6414156854152679 | D accuracy: 56.25] [G loss: 1.0292198657989502]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3981 [D loss: 0.5782297551631927 | D accuracy: 70.3125] [G loss: 1.010587453842163]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3982 [D loss: 0.6244155168533325 | D accuracy: 67.1875] [G loss: 1.0359094142913818]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3983 [D loss: 0.6293100118637085 | D accuracy: 60.9375] [G loss: 0.9653869867324829]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3984 [D loss: 0.723626971244812 | D accuracy: 60.9375] [G loss: 1.0018082857131958]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3985 [D loss: 0.6679553389549255 | D accuracy: 53.125] [G loss: 1.0725550651550293]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "3986 [D loss: 0.758863776922226 | D accuracy: 50.0] [G loss: 1.067733883857727]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3987 [D loss: 0.6288585364818573 | D accuracy: 60.9375] [G loss: 1.1358015537261963]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3988 [D loss: 0.6649919748306274 | D accuracy: 65.625] [G loss: 1.0950958728790283]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3989 [D loss: 0.6532638072967529 | D accuracy: 56.25] [G loss: 1.1266632080078125]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3990 [D loss: 0.6396968066692352 | D accuracy: 71.875] [G loss: 0.9654622077941895]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3991 [D loss: 0.6425104737281799 | D accuracy: 68.75] [G loss: 1.0378952026367188]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3992 [D loss: 0.5319967269897461 | D accuracy: 79.6875] [G loss: 0.9929933547973633]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3993 [D loss: 0.650676965713501 | D accuracy: 68.75] [G loss: 1.0421620607376099]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3994 [D loss: 0.7294511497020721 | D accuracy: 50.0] [G loss: 0.9588618278503418]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3995 [D loss: 0.6233205497264862 | D accuracy: 64.0625] [G loss: 1.1480929851531982]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3996 [D loss: 0.5907211899757385 | D accuracy: 65.625] [G loss: 1.1103205680847168]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3997 [D loss: 0.5571344494819641 | D accuracy: 67.1875] [G loss: 1.0727691650390625]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3998 [D loss: 0.6308468282222748 | D accuracy: 64.0625] [G loss: 1.0537432432174683]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3999 [D loss: 0.6395255029201508 | D accuracy: 53.125] [G loss: 1.0778454542160034]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4000 [D loss: 0.6288138031959534 | D accuracy: 60.9375] [G loss: 0.9130854606628418]\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "4001 [D loss: 0.600307047367096 | D accuracy: 64.0625] [G loss: 1.0868884325027466]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4002 [D loss: 0.6804942190647125 | D accuracy: 53.125] [G loss: 1.0684958696365356]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4003 [D loss: 0.544907346367836 | D accuracy: 79.6875] [G loss: 0.9046269655227661]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4004 [D loss: 0.677454799413681 | D accuracy: 54.6875] [G loss: 0.9414767026901245]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4005 [D loss: 0.6050240397453308 | D accuracy: 70.3125] [G loss: 1.056959867477417]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4006 [D loss: 0.5999174416065216 | D accuracy: 70.3125] [G loss: 1.0027600526809692]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4007 [D loss: 0.6373671889305115 | D accuracy: 64.0625] [G loss: 1.099116325378418]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4008 [D loss: 0.5688629150390625 | D accuracy: 65.625] [G loss: 1.0496717691421509]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4009 [D loss: 0.7081209123134613 | D accuracy: 57.8125] [G loss: 1.0363849401474]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4010 [D loss: 0.673265278339386 | D accuracy: 56.25] [G loss: 1.0724490880966187]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4011 [D loss: 0.6023618280887604 | D accuracy: 65.625] [G loss: 0.9423498511314392]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4012 [D loss: 0.5813146233558655 | D accuracy: 67.1875] [G loss: 1.047411561012268]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4013 [D loss: 0.5737276077270508 | D accuracy: 70.3125] [G loss: 0.9791436195373535]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4014 [D loss: 0.6506613790988922 | D accuracy: 57.8125] [G loss: 0.9784080982208252]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4015 [D loss: 0.6811098456382751 | D accuracy: 65.625] [G loss: 1.0132336616516113]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4016 [D loss: 0.5271099805831909 | D accuracy: 78.125] [G loss: 0.9733173251152039]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4017 [D loss: 0.6579223871231079 | D accuracy: 59.375] [G loss: 1.0247364044189453]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4018 [D loss: 0.6840465664863586 | D accuracy: 64.0625] [G loss: 1.0116496086120605]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4019 [D loss: 0.6591807901859283 | D accuracy: 56.25] [G loss: 1.054429531097412]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4020 [D loss: 0.608220249414444 | D accuracy: 70.3125] [G loss: 0.8850646018981934]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4021 [D loss: 0.5883640944957733 | D accuracy: 68.75] [G loss: 1.0227235555648804]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4022 [D loss: 0.6414651870727539 | D accuracy: 65.625] [G loss: 1.009403944015503]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4023 [D loss: 0.5892498195171356 | D accuracy: 65.625] [G loss: 0.9839105606079102]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4024 [D loss: 0.6045770645141602 | D accuracy: 60.9375] [G loss: 0.9586280584335327]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4025 [D loss: 0.6625368893146515 | D accuracy: 57.8125] [G loss: 0.991482138633728]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4026 [D loss: 0.6385585963726044 | D accuracy: 62.5] [G loss: 0.9924517869949341]\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "4027 [D loss: 0.6519058644771576 | D accuracy: 59.375] [G loss: 1.0596212148666382]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4028 [D loss: 0.6581504642963409 | D accuracy: 64.0625] [G loss: 0.8982692956924438]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4029 [D loss: 0.5497696101665497 | D accuracy: 79.6875] [G loss: 1.0767775774002075]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4030 [D loss: 0.728381872177124 | D accuracy: 54.6875] [G loss: 1.0955240726470947]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4031 [D loss: 0.6928623020648956 | D accuracy: 65.625] [G loss: 1.0334293842315674]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4032 [D loss: 0.6328804790973663 | D accuracy: 67.1875] [G loss: 0.9701559543609619]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4033 [D loss: 0.589903712272644 | D accuracy: 67.1875] [G loss: 0.9974250793457031]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4034 [D loss: 0.6629105508327484 | D accuracy: 60.9375] [G loss: 0.9670413732528687]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4035 [D loss: 0.594434916973114 | D accuracy: 60.9375] [G loss: 1.0170788764953613]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4036 [D loss: 0.5607070922851562 | D accuracy: 65.625] [G loss: 1.0589289665222168]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4037 [D loss: 0.6350310444831848 | D accuracy: 64.0625] [G loss: 1.0221214294433594]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4038 [D loss: 0.6142254173755646 | D accuracy: 60.9375] [G loss: 1.0092462301254272]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4039 [D loss: 0.5742326378822327 | D accuracy: 71.875] [G loss: 0.9587364196777344]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4040 [D loss: 0.6192860305309296 | D accuracy: 59.375] [G loss: 0.9696201086044312]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4041 [D loss: 0.6654625535011292 | D accuracy: 59.375] [G loss: 0.9525793790817261]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4042 [D loss: 0.6078922748565674 | D accuracy: 60.9375] [G loss: 1.0375734567642212]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4043 [D loss: 0.6154743731021881 | D accuracy: 65.625] [G loss: 0.8875125646591187]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4044 [D loss: 0.5936448574066162 | D accuracy: 75.0] [G loss: 0.9287991523742676]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4045 [D loss: 0.6295079290866852 | D accuracy: 67.1875] [G loss: 1.0438562631607056]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4046 [D loss: 0.5328981727361679 | D accuracy: 81.25] [G loss: 0.9631597399711609]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4047 [D loss: 0.6317535042762756 | D accuracy: 65.625] [G loss: 0.9152777194976807]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4048 [D loss: 0.5995338261127472 | D accuracy: 65.625] [G loss: 1.013193130493164]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4049 [D loss: 0.6110402643680573 | D accuracy: 71.875] [G loss: 1.0600943565368652]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4050 [D loss: 0.6460403800010681 | D accuracy: 60.9375] [G loss: 1.0639307498931885]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4051 [D loss: 0.5770733058452606 | D accuracy: 71.875] [G loss: 1.0502166748046875]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4052 [D loss: 0.6736657321453094 | D accuracy: 54.6875] [G loss: 0.9953612089157104]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4053 [D loss: 0.6328268051147461 | D accuracy: 60.9375] [G loss: 1.0497641563415527]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4054 [D loss: 0.5580843091011047 | D accuracy: 65.625] [G loss: 1.046567440032959]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4055 [D loss: 0.5875855386257172 | D accuracy: 71.875] [G loss: 1.043616533279419]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4056 [D loss: 0.5507552921772003 | D accuracy: 75.0] [G loss: 1.0772902965545654]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4057 [D loss: 0.6617154479026794 | D accuracy: 56.25] [G loss: 1.0503077507019043]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4058 [D loss: 0.617917537689209 | D accuracy: 67.1875] [G loss: 1.179656982421875]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4059 [D loss: 0.6698567867279053 | D accuracy: 54.6875] [G loss: 1.032899022102356]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4060 [D loss: 0.6026315987110138 | D accuracy: 65.625] [G loss: 1.0755951404571533]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4061 [D loss: 0.5496021807193756 | D accuracy: 70.3125] [G loss: 1.0861656665802002]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4062 [D loss: 0.6638347208499908 | D accuracy: 57.8125] [G loss: 1.0025025606155396]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4063 [D loss: 0.6329246163368225 | D accuracy: 59.375] [G loss: 1.0225515365600586]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4064 [D loss: 0.7100480794906616 | D accuracy: 51.5625] [G loss: 0.9381763339042664]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4065 [D loss: 0.6851372718811035 | D accuracy: 57.8125] [G loss: 1.0043179988861084]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4066 [D loss: 0.6443454325199127 | D accuracy: 65.625] [G loss: 1.0459084510803223]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4067 [D loss: 0.6091009080410004 | D accuracy: 73.4375] [G loss: 0.9808567762374878]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4068 [D loss: 0.6748432517051697 | D accuracy: 59.375] [G loss: 0.8653331398963928]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4069 [D loss: 0.6092187762260437 | D accuracy: 65.625] [G loss: 0.9697368741035461]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4070 [D loss: 0.6050115823745728 | D accuracy: 64.0625] [G loss: 1.0395938158035278]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4071 [D loss: 0.6634007096290588 | D accuracy: 71.875] [G loss: 1.0901715755462646]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4072 [D loss: 0.6133482456207275 | D accuracy: 60.9375] [G loss: 1.039116382598877]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4073 [D loss: 0.6401726305484772 | D accuracy: 62.5] [G loss: 0.9541018009185791]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4074 [D loss: 0.6958420276641846 | D accuracy: 51.5625] [G loss: 0.9247899055480957]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4075 [D loss: 0.5918954610824585 | D accuracy: 64.0625] [G loss: 1.0100514888763428]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4076 [D loss: 0.5577289462089539 | D accuracy: 70.3125] [G loss: 0.9984570741653442]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4077 [D loss: 0.6330963671207428 | D accuracy: 65.625] [G loss: 1.0064750909805298]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4078 [D loss: 0.6359864473342896 | D accuracy: 53.125] [G loss: 1.0255703926086426]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4079 [D loss: 0.6621776521205902 | D accuracy: 54.6875] [G loss: 0.9376835823059082]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4080 [D loss: 0.548660397529602 | D accuracy: 70.3125] [G loss: 1.0013153553009033]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4081 [D loss: 0.6608197093009949 | D accuracy: 54.6875] [G loss: 0.9477051496505737]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4082 [D loss: 0.585459440946579 | D accuracy: 71.875] [G loss: 1.0206527709960938]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4083 [D loss: 0.739904910326004 | D accuracy: 54.6875] [G loss: 0.9066154360771179]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4084 [D loss: 0.6800899505615234 | D accuracy: 54.6875] [G loss: 0.9349180459976196]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4085 [D loss: 0.5917699337005615 | D accuracy: 71.875] [G loss: 0.9544031620025635]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4086 [D loss: 0.5740704238414764 | D accuracy: 65.625] [G loss: 1.0928401947021484]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4087 [D loss: 0.6937128603458405 | D accuracy: 57.8125] [G loss: 1.0637831687927246]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4088 [D loss: 0.6649055778980255 | D accuracy: 53.125] [G loss: 1.009354591369629]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4089 [D loss: 0.6530039608478546 | D accuracy: 64.0625] [G loss: 1.085902452468872]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4090 [D loss: 0.6344733238220215 | D accuracy: 64.0625] [G loss: 1.082076072692871]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4091 [D loss: 0.7091878950595856 | D accuracy: 53.125] [G loss: 1.0568678379058838]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4092 [D loss: 0.6070269644260406 | D accuracy: 68.75] [G loss: 1.0402114391326904]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4093 [D loss: 0.6464237570762634 | D accuracy: 65.625] [G loss: 1.0167887210845947]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4094 [D loss: 0.677082359790802 | D accuracy: 57.8125] [G loss: 0.9158734679222107]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4095 [D loss: 0.5900318920612335 | D accuracy: 67.1875] [G loss: 0.9482884407043457]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4096 [D loss: 0.6125314831733704 | D accuracy: 67.1875] [G loss: 0.8972378969192505]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4097 [D loss: 0.5574002265930176 | D accuracy: 71.875] [G loss: 0.8974486589431763]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4098 [D loss: 0.6259435415267944 | D accuracy: 62.5] [G loss: 0.9905062317848206]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4099 [D loss: 0.564328521490097 | D accuracy: 76.5625] [G loss: 0.9394692182540894]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4100 [D loss: 0.5858571529388428 | D accuracy: 65.625] [G loss: 0.9058300256729126]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4101 [D loss: 0.6011577844619751 | D accuracy: 65.625] [G loss: 0.9845686554908752]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4102 [D loss: 0.6005079746246338 | D accuracy: 75.0] [G loss: 0.9463135600090027]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4103 [D loss: 0.6313589513301849 | D accuracy: 62.5] [G loss: 1.0087120532989502]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4104 [D loss: 0.5707577168941498 | D accuracy: 65.625] [G loss: 0.9830542802810669]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4105 [D loss: 0.6322988867759705 | D accuracy: 59.375] [G loss: 1.0047497749328613]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4106 [D loss: 0.6414032578468323 | D accuracy: 59.375] [G loss: 1.0389890670776367]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4107 [D loss: 0.5941942632198334 | D accuracy: 64.0625] [G loss: 0.9786916971206665]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4108 [D loss: 0.5733752250671387 | D accuracy: 67.1875] [G loss: 1.051311731338501]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4109 [D loss: 0.646550863981247 | D accuracy: 57.8125] [G loss: 0.9878418445587158]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4110 [D loss: 0.5889846980571747 | D accuracy: 71.875] [G loss: 1.0243916511535645]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4111 [D loss: 0.6729250252246857 | D accuracy: 59.375] [G loss: 1.0221904516220093]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "4112 [D loss: 0.628253847360611 | D accuracy: 60.9375] [G loss: 1.0689001083374023]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4113 [D loss: 0.6264623701572418 | D accuracy: 67.1875] [G loss: 0.9415674209594727]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4114 [D loss: 0.6757817268371582 | D accuracy: 60.9375] [G loss: 0.96954345703125]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4115 [D loss: 0.589390754699707 | D accuracy: 67.1875] [G loss: 0.9833935499191284]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4116 [D loss: 0.6226161122322083 | D accuracy: 64.0625] [G loss: 1.0033013820648193]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4117 [D loss: 0.6080203950405121 | D accuracy: 70.3125] [G loss: 1.0483229160308838]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4118 [D loss: 0.6533389985561371 | D accuracy: 56.25] [G loss: 0.926850438117981]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4119 [D loss: 0.6343702077865601 | D accuracy: 53.125] [G loss: 0.9492632150650024]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4120 [D loss: 0.5615387409925461 | D accuracy: 73.4375] [G loss: 0.987005352973938]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4121 [D loss: 0.6325911581516266 | D accuracy: 64.0625] [G loss: 0.9770004749298096]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4122 [D loss: 0.6094466745853424 | D accuracy: 67.1875] [G loss: 1.050912857055664]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4123 [D loss: 0.6152684986591339 | D accuracy: 65.625] [G loss: 1.043023943901062]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4124 [D loss: 0.5836693942546844 | D accuracy: 70.3125] [G loss: 0.9326977133750916]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4125 [D loss: 0.6645954251289368 | D accuracy: 57.8125] [G loss: 1.0534374713897705]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4126 [D loss: 0.6659902036190033 | D accuracy: 56.25] [G loss: 0.8473974466323853]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4127 [D loss: 0.6043007969856262 | D accuracy: 68.75] [G loss: 0.9808239936828613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4128 [D loss: 0.6166999042034149 | D accuracy: 65.625] [G loss: 0.9696251749992371]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4129 [D loss: 0.574601411819458 | D accuracy: 67.1875] [G loss: 1.0840634107589722]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4130 [D loss: 0.7664409577846527 | D accuracy: 37.5] [G loss: 1.044721007347107]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4131 [D loss: 0.6051909923553467 | D accuracy: 67.1875] [G loss: 0.9858306050300598]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4132 [D loss: 0.6568342745304108 | D accuracy: 59.375] [G loss: 0.9739601612091064]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4133 [D loss: 0.6496223211288452 | D accuracy: 64.0625] [G loss: 0.9271854162216187]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4134 [D loss: 0.667143702507019 | D accuracy: 54.6875] [G loss: 0.989685595035553]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4135 [D loss: 0.6809060573577881 | D accuracy: 54.6875] [G loss: 0.9548864960670471]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4136 [D loss: 0.6145524382591248 | D accuracy: 67.1875] [G loss: 1.031923532485962]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4137 [D loss: 0.6852586269378662 | D accuracy: 62.5] [G loss: 1.0155686140060425]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4138 [D loss: 0.6179800927639008 | D accuracy: 64.0625] [G loss: 1.0057373046875]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4139 [D loss: 0.6712193489074707 | D accuracy: 59.375] [G loss: 1.0303752422332764]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4140 [D loss: 0.6287993788719177 | D accuracy: 76.5625] [G loss: 0.9704171419143677]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4141 [D loss: 0.625296413898468 | D accuracy: 65.625] [G loss: 1.0029265880584717]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4142 [D loss: 0.5516905188560486 | D accuracy: 71.875] [G loss: 0.9185112714767456]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4143 [D loss: 0.607438862323761 | D accuracy: 60.9375] [G loss: 0.9460273385047913]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4144 [D loss: 0.6479288935661316 | D accuracy: 64.0625] [G loss: 0.9535801410675049]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4145 [D loss: 0.6342682838439941 | D accuracy: 62.5] [G loss: 1.1126675605773926]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4146 [D loss: 0.5685123205184937 | D accuracy: 64.0625] [G loss: 1.1299254894256592]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4147 [D loss: 0.6496419608592987 | D accuracy: 67.1875] [G loss: 1.079399585723877]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4148 [D loss: 0.6239329278469086 | D accuracy: 62.5] [G loss: 0.9524608254432678]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4149 [D loss: 0.5853786170482635 | D accuracy: 67.1875] [G loss: 1.01806640625]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4150 [D loss: 0.6146475672721863 | D accuracy: 67.1875] [G loss: 1.0940303802490234]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4151 [D loss: 0.6521324515342712 | D accuracy: 60.9375] [G loss: 1.008146047592163]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4152 [D loss: 0.64371657371521 | D accuracy: 59.375] [G loss: 1.0828059911727905]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4153 [D loss: 0.5927449762821198 | D accuracy: 67.1875] [G loss: 1.0220693349838257]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4154 [D loss: 0.6344559192657471 | D accuracy: 57.8125] [G loss: 0.9904474020004272]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4155 [D loss: 0.603272020816803 | D accuracy: 67.1875] [G loss: 0.9481366872787476]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4156 [D loss: 0.6544576585292816 | D accuracy: 59.375] [G loss: 0.9781390428543091]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4157 [D loss: 0.5195810198783875 | D accuracy: 78.125] [G loss: 0.9062082767486572]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4158 [D loss: 0.5966842174530029 | D accuracy: 64.0625] [G loss: 1.0516536235809326]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4159 [D loss: 0.5579155683517456 | D accuracy: 75.0] [G loss: 0.9962684512138367]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4160 [D loss: 0.5963422656059265 | D accuracy: 71.875] [G loss: 0.9429831504821777]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4161 [D loss: 0.7248640656471252 | D accuracy: 48.4375] [G loss: 0.9426650404930115]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4162 [D loss: 0.5780392587184906 | D accuracy: 65.625] [G loss: 1.0354195833206177]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4163 [D loss: 0.6128947138786316 | D accuracy: 62.5] [G loss: 1.1034590005874634]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4164 [D loss: 0.704456239938736 | D accuracy: 51.5625] [G loss: 1.0829404592514038]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4165 [D loss: 0.6643114686012268 | D accuracy: 57.8125] [G loss: 1.033376693725586]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4166 [D loss: 0.6272896230220795 | D accuracy: 60.9375] [G loss: 1.0784375667572021]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4167 [D loss: 0.5900223553180695 | D accuracy: 65.625] [G loss: 0.9960470199584961]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4168 [D loss: 0.6838473975658417 | D accuracy: 65.625] [G loss: 1.1697680950164795]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4169 [D loss: 0.6102248430252075 | D accuracy: 62.5] [G loss: 1.0358281135559082]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4170 [D loss: 0.6219270825386047 | D accuracy: 65.625] [G loss: 1.0405168533325195]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4171 [D loss: 0.6434091031551361 | D accuracy: 64.0625] [G loss: 1.0414507389068604]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4172 [D loss: 0.6610570847988129 | D accuracy: 62.5] [G loss: 1.14116632938385]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4173 [D loss: 0.5406076312065125 | D accuracy: 73.4375] [G loss: 1.0181009769439697]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4174 [D loss: 0.6296109855175018 | D accuracy: 65.625] [G loss: 1.0086842775344849]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4175 [D loss: 0.6070716977119446 | D accuracy: 64.0625] [G loss: 1.053954839706421]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4176 [D loss: 0.5843173265457153 | D accuracy: 62.5] [G loss: 1.0544991493225098]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4177 [D loss: 0.6355953812599182 | D accuracy: 70.3125] [G loss: 0.9142665863037109]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4178 [D loss: 0.6210215091705322 | D accuracy: 68.75] [G loss: 0.9169584512710571]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4179 [D loss: 0.6395214200019836 | D accuracy: 59.375] [G loss: 0.9591723680496216]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4180 [D loss: 0.6188734471797943 | D accuracy: 65.625] [G loss: 0.8978227972984314]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4181 [D loss: 0.668975830078125 | D accuracy: 53.125] [G loss: 0.9638087749481201]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4182 [D loss: 0.6380275785923004 | D accuracy: 64.0625] [G loss: 0.9937869906425476]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4183 [D loss: 0.6669273972511292 | D accuracy: 60.9375] [G loss: 0.9676092267036438]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4184 [D loss: 0.6079380512237549 | D accuracy: 67.1875] [G loss: 1.1129223108291626]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4185 [D loss: 0.5480178892612457 | D accuracy: 71.875] [G loss: 1.014184594154358]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4186 [D loss: 0.6050219833850861 | D accuracy: 71.875] [G loss: 1.0376472473144531]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4187 [D loss: 0.6140162944793701 | D accuracy: 56.25] [G loss: 0.9591082334518433]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4188 [D loss: 0.6596803069114685 | D accuracy: 62.5] [G loss: 1.0434635877609253]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "4189 [D loss: 0.673247367143631 | D accuracy: 56.25] [G loss: 0.9904077053070068]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4190 [D loss: 0.616455614566803 | D accuracy: 64.0625] [G loss: 1.0060391426086426]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4191 [D loss: 0.5571267306804657 | D accuracy: 73.4375] [G loss: 0.9393465518951416]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "4192 [D loss: 0.6826668083667755 | D accuracy: 57.8125] [G loss: 1.0311102867126465]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4193 [D loss: 0.6015944480895996 | D accuracy: 57.8125] [G loss: 1.1057136058807373]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4194 [D loss: 0.6217913031578064 | D accuracy: 65.625] [G loss: 1.0530837774276733]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4195 [D loss: 0.628465861082077 | D accuracy: 68.75] [G loss: 1.0949106216430664]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4196 [D loss: 0.6071894764900208 | D accuracy: 70.3125] [G loss: 0.9952667951583862]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4197 [D loss: 0.5958270728588104 | D accuracy: 65.625] [G loss: 1.0266399383544922]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4198 [D loss: 0.6488714516162872 | D accuracy: 60.9375] [G loss: 1.2211956977844238]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4199 [D loss: 0.6232358515262604 | D accuracy: 68.75] [G loss: 1.0301437377929688]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4200 [D loss: 0.5765727162361145 | D accuracy: 75.0] [G loss: 1.0017352104187012]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4201 [D loss: 0.6754586100578308 | D accuracy: 53.125] [G loss: 0.9946876764297485]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4202 [D loss: 0.6531598269939423 | D accuracy: 68.75] [G loss: 0.8949153423309326]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4203 [D loss: 0.6558647453784943 | D accuracy: 56.25] [G loss: 0.951767086982727]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4204 [D loss: 0.6392568945884705 | D accuracy: 59.375] [G loss: 1.080776333808899]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4205 [D loss: 0.5973844230175018 | D accuracy: 67.1875] [G loss: 1.0338975191116333]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4206 [D loss: 0.580238550901413 | D accuracy: 78.125] [G loss: 1.0258398056030273]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4207 [D loss: 0.5918046832084656 | D accuracy: 64.0625] [G loss: 0.9550883769989014]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4208 [D loss: 0.6229015588760376 | D accuracy: 60.9375] [G loss: 1.0039160251617432]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4209 [D loss: 0.5798836350440979 | D accuracy: 68.75] [G loss: 0.9730947017669678]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4210 [D loss: 0.6914624273777008 | D accuracy: 59.375] [G loss: 0.996048092842102]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4211 [D loss: 0.6760903596878052 | D accuracy: 59.375] [G loss: 1.050658106803894]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4212 [D loss: 0.541717916727066 | D accuracy: 76.5625] [G loss: 0.9929964542388916]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4213 [D loss: 0.6322628259658813 | D accuracy: 67.1875] [G loss: 1.0331934690475464]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4214 [D loss: 0.6581242978572845 | D accuracy: 64.0625] [G loss: 0.8949847221374512]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4215 [D loss: 0.6953291296958923 | D accuracy: 57.8125] [G loss: 0.9433188438415527]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4216 [D loss: 0.5786595642566681 | D accuracy: 68.75] [G loss: 0.9976384043693542]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4217 [D loss: 0.6086885929107666 | D accuracy: 71.875] [G loss: 0.8818274736404419]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4218 [D loss: 0.6018038392066956 | D accuracy: 67.1875] [G loss: 0.9251899719238281]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4219 [D loss: 0.5848486125469208 | D accuracy: 75.0] [G loss: 0.9977113008499146]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4220 [D loss: 0.547109454870224 | D accuracy: 70.3125] [G loss: 0.9955109357833862]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4221 [D loss: 0.6033400297164917 | D accuracy: 68.75] [G loss: 0.9825873374938965]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4222 [D loss: 0.6654178202152252 | D accuracy: 64.0625] [G loss: 0.9897247552871704]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4223 [D loss: 0.5714567005634308 | D accuracy: 71.875] [G loss: 1.0550457239151]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4224 [D loss: 0.6238928437232971 | D accuracy: 59.375] [G loss: 1.0490350723266602]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4225 [D loss: 0.6165266931056976 | D accuracy: 65.625] [G loss: 1.0402482748031616]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4226 [D loss: 0.571111649274826 | D accuracy: 70.3125] [G loss: 1.1118838787078857]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4227 [D loss: 0.6518487930297852 | D accuracy: 67.1875] [G loss: 0.9422876834869385]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4228 [D loss: 0.591335654258728 | D accuracy: 70.3125] [G loss: 0.9514743685722351]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4229 [D loss: 0.61922687292099 | D accuracy: 67.1875] [G loss: 0.972415030002594]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4230 [D loss: 0.586532711982727 | D accuracy: 70.3125] [G loss: 1.0886234045028687]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4231 [D loss: 0.6228281855583191 | D accuracy: 59.375] [G loss: 1.0075141191482544]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4232 [D loss: 0.7472992539405823 | D accuracy: 51.5625] [G loss: 0.9620873928070068]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4233 [D loss: 0.5803825259208679 | D accuracy: 68.75] [G loss: 0.967808723449707]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4234 [D loss: 0.6604876518249512 | D accuracy: 56.25] [G loss: 1.0842840671539307]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4235 [D loss: 0.6699879765510559 | D accuracy: 57.8125] [G loss: 1.0660505294799805]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4236 [D loss: 0.5717872977256775 | D accuracy: 70.3125] [G loss: 0.9268468022346497]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4237 [D loss: 0.6238429546356201 | D accuracy: 57.8125] [G loss: 1.046216607093811]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4238 [D loss: 0.5892798900604248 | D accuracy: 70.3125] [G loss: 1.0478581190109253]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4239 [D loss: 0.5892917513847351 | D accuracy: 67.1875] [G loss: 1.0423667430877686]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4240 [D loss: 0.6027840673923492 | D accuracy: 65.625] [G loss: 0.9643693566322327]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4241 [D loss: 0.6846984028816223 | D accuracy: 51.5625] [G loss: 1.0754058361053467]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4242 [D loss: 0.5930825173854828 | D accuracy: 67.1875] [G loss: 0.9847495555877686]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4243 [D loss: 0.5933818519115448 | D accuracy: 78.125] [G loss: 1.0981513261795044]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4244 [D loss: 0.6530709266662598 | D accuracy: 62.5] [G loss: 1.0360994338989258]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4245 [D loss: 0.5978004336357117 | D accuracy: 67.1875] [G loss: 0.9622979164123535]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4246 [D loss: 0.6470110714435577 | D accuracy: 65.625] [G loss: 0.9237110614776611]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4247 [D loss: 0.6121739149093628 | D accuracy: 75.0] [G loss: 1.0238234996795654]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4248 [D loss: 0.6318968832492828 | D accuracy: 57.8125] [G loss: 1.0922883749008179]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4249 [D loss: 0.637955904006958 | D accuracy: 64.0625] [G loss: 0.9217778444290161]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4250 [D loss: 0.5791746079921722 | D accuracy: 73.4375] [G loss: 1.0087840557098389]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4251 [D loss: 0.6005217134952545 | D accuracy: 71.875] [G loss: 1.0532256364822388]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4252 [D loss: 0.6204673945903778 | D accuracy: 62.5] [G loss: 1.0627391338348389]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4253 [D loss: 0.593161016702652 | D accuracy: 60.9375] [G loss: 1.0558034181594849]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4254 [D loss: 0.7243797183036804 | D accuracy: 54.6875] [G loss: 1.125870943069458]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4255 [D loss: 0.6185389161109924 | D accuracy: 70.3125] [G loss: 1.0619890689849854]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4256 [D loss: 0.6277761459350586 | D accuracy: 62.5] [G loss: 1.0138964653015137]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4257 [D loss: 0.6646056175231934 | D accuracy: 64.0625] [G loss: 1.008015751838684]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4258 [D loss: 0.6145857274532318 | D accuracy: 65.625] [G loss: 0.9750570058822632]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4259 [D loss: 0.63578200340271 | D accuracy: 60.9375] [G loss: 0.964268147945404]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4260 [D loss: 0.6330955624580383 | D accuracy: 65.625] [G loss: 0.9916985630989075]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4261 [D loss: 0.6334234774112701 | D accuracy: 57.8125] [G loss: 1.0109649896621704]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "4262 [D loss: 0.562617152929306 | D accuracy: 73.4375] [G loss: 1.0354514122009277]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4263 [D loss: 0.5444948077201843 | D accuracy: 67.1875] [G loss: 1.0258026123046875]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "4264 [D loss: 0.5892308354377747 | D accuracy: 64.0625] [G loss: 1.0117628574371338]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4265 [D loss: 0.5706640481948853 | D accuracy: 73.4375] [G loss: 0.9594871997833252]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4266 [D loss: 0.5892958045005798 | D accuracy: 67.1875] [G loss: 0.8780157566070557]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4267 [D loss: 0.5805802941322327 | D accuracy: 73.4375] [G loss: 1.0449186563491821]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4268 [D loss: 0.5189118832349777 | D accuracy: 73.4375] [G loss: 1.004499912261963]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4269 [D loss: 0.6297902464866638 | D accuracy: 68.75] [G loss: 1.0027470588684082]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4270 [D loss: 0.6192729771137238 | D accuracy: 62.5] [G loss: 1.0819692611694336]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4271 [D loss: 0.5785075128078461 | D accuracy: 68.75] [G loss: 1.0055711269378662]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4272 [D loss: 0.583674281835556 | D accuracy: 71.875] [G loss: 1.0642664432525635]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4273 [D loss: 0.6086265742778778 | D accuracy: 62.5] [G loss: 0.9665945768356323]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4274 [D loss: 0.5987157821655273 | D accuracy: 68.75] [G loss: 1.0768017768859863]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4275 [D loss: 0.6817047297954559 | D accuracy: 56.25] [G loss: 0.9149289727210999]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4276 [D loss: 0.7349098920822144 | D accuracy: 50.0] [G loss: 0.868320107460022]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4277 [D loss: 0.619728296995163 | D accuracy: 65.625] [G loss: 0.9975875020027161]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4278 [D loss: 0.6780622005462646 | D accuracy: 65.625] [G loss: 0.9580295085906982]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4279 [D loss: 0.6159381568431854 | D accuracy: 59.375] [G loss: 0.9650954604148865]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4280 [D loss: 0.6224640011787415 | D accuracy: 67.1875] [G loss: 0.9379315972328186]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4281 [D loss: 0.6059506833553314 | D accuracy: 64.0625] [G loss: 0.9816120862960815]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4282 [D loss: 0.6161982417106628 | D accuracy: 67.1875] [G loss: 0.9642391800880432]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4283 [D loss: 0.6067465245723724 | D accuracy: 67.1875] [G loss: 1.0015398263931274]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4284 [D loss: 0.613304853439331 | D accuracy: 70.3125] [G loss: 0.8689438700675964]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4285 [D loss: 0.5420031547546387 | D accuracy: 76.5625] [G loss: 1.0571866035461426]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4286 [D loss: 0.6238008737564087 | D accuracy: 70.3125] [G loss: 0.9485528469085693]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4287 [D loss: 0.6312032341957092 | D accuracy: 59.375] [G loss: 0.9896411895751953]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4288 [D loss: 0.6144552230834961 | D accuracy: 68.75] [G loss: 1.1095967292785645]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4289 [D loss: 0.6376365721225739 | D accuracy: 60.9375] [G loss: 1.0535943508148193]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4290 [D loss: 0.6377807855606079 | D accuracy: 67.1875] [G loss: 1.132615566253662]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4291 [D loss: 0.6300295293331146 | D accuracy: 56.25] [G loss: 1.0185633897781372]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4292 [D loss: 0.6359653770923615 | D accuracy: 60.9375] [G loss: 1.0476374626159668]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4293 [D loss: 0.6038766205310822 | D accuracy: 67.1875] [G loss: 1.0437445640563965]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4294 [D loss: 0.6042651236057281 | D accuracy: 67.1875] [G loss: 1.0619072914123535]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4295 [D loss: 0.6120270490646362 | D accuracy: 64.0625] [G loss: 1.0418652296066284]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4296 [D loss: 0.5887892842292786 | D accuracy: 64.0625] [G loss: 1.0269689559936523]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4297 [D loss: 0.5627358555793762 | D accuracy: 70.3125] [G loss: 1.0051237344741821]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4298 [D loss: 0.5413284301757812 | D accuracy: 79.6875] [G loss: 0.9615525007247925]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4299 [D loss: 0.5988784432411194 | D accuracy: 67.1875] [G loss: 0.9211219549179077]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4300 [D loss: 0.6269609034061432 | D accuracy: 62.5] [G loss: 0.9822112321853638]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4301 [D loss: 0.5663049817085266 | D accuracy: 73.4375] [G loss: 0.9830451607704163]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4302 [D loss: 0.6855484545230865 | D accuracy: 62.5] [G loss: 0.9760117530822754]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4303 [D loss: 0.5985575318336487 | D accuracy: 70.3125] [G loss: 0.9734833240509033]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4304 [D loss: 0.7173332571983337 | D accuracy: 50.0] [G loss: 0.9647951126098633]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4305 [D loss: 0.6127181351184845 | D accuracy: 70.3125] [G loss: 1.1000607013702393]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4306 [D loss: 0.5779112279415131 | D accuracy: 71.875] [G loss: 1.010571837425232]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4307 [D loss: 0.6161956787109375 | D accuracy: 60.9375] [G loss: 1.0074694156646729]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4308 [D loss: 0.6037880480289459 | D accuracy: 65.625] [G loss: 0.9557839632034302]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4309 [D loss: 0.6789512932300568 | D accuracy: 54.6875] [G loss: 0.975192666053772]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4310 [D loss: 0.582381397485733 | D accuracy: 67.1875] [G loss: 0.9284099340438843]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4311 [D loss: 0.6271952986717224 | D accuracy: 65.625] [G loss: 1.1098397970199585]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4312 [D loss: 0.6348417699337006 | D accuracy: 71.875] [G loss: 0.9851559400558472]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4313 [D loss: 0.6257608234882355 | D accuracy: 59.375] [G loss: 1.0773377418518066]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4314 [D loss: 0.5980442464351654 | D accuracy: 70.3125] [G loss: 1.0583057403564453]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4315 [D loss: 0.6153986752033234 | D accuracy: 65.625] [G loss: 1.074183464050293]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4316 [D loss: 0.6154487431049347 | D accuracy: 68.75] [G loss: 1.0083699226379395]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4317 [D loss: 0.634391725063324 | D accuracy: 60.9375] [G loss: 1.1224942207336426]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4318 [D loss: 0.5656045973300934 | D accuracy: 70.3125] [G loss: 1.051222562789917]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4319 [D loss: 0.629591554403305 | D accuracy: 62.5] [G loss: 0.9586365222930908]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4320 [D loss: 0.6117278635501862 | D accuracy: 59.375] [G loss: 0.9530562162399292]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4321 [D loss: 0.5938493013381958 | D accuracy: 71.875] [G loss: 0.9752212762832642]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4322 [D loss: 0.5648686587810516 | D accuracy: 71.875] [G loss: 0.9887422323226929]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4323 [D loss: 0.6689938604831696 | D accuracy: 60.9375] [G loss: 0.9744113087654114]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4324 [D loss: 0.6171627938747406 | D accuracy: 64.0625] [G loss: 0.9474911689758301]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4325 [D loss: 0.6518741250038147 | D accuracy: 64.0625] [G loss: 0.9724107980728149]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4326 [D loss: 0.5273293554782867 | D accuracy: 79.6875] [G loss: 1.0421886444091797]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4327 [D loss: 0.6464457213878632 | D accuracy: 65.625] [G loss: 1.0310115814208984]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4328 [D loss: 0.608960747718811 | D accuracy: 65.625] [G loss: 1.1383183002471924]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4329 [D loss: 0.6657025218009949 | D accuracy: 60.9375] [G loss: 1.0653495788574219]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4330 [D loss: 0.6301957070827484 | D accuracy: 67.1875] [G loss: 0.9324741363525391]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4331 [D loss: 0.6557653546333313 | D accuracy: 59.375] [G loss: 0.9730528593063354]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4332 [D loss: 0.544357031583786 | D accuracy: 67.1875] [G loss: 1.0483813285827637]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4333 [D loss: 0.6370082497596741 | D accuracy: 57.8125] [G loss: 0.9745973944664001]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4334 [D loss: 0.6354753375053406 | D accuracy: 65.625] [G loss: 0.9836000204086304]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4335 [D loss: 0.5773062407970428 | D accuracy: 68.75] [G loss: 1.0345878601074219]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4336 [D loss: 0.6079090535640717 | D accuracy: 68.75] [G loss: 1.0351557731628418]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4337 [D loss: 0.668229728937149 | D accuracy: 62.5] [G loss: 1.0193954706192017]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4338 [D loss: 0.5652950406074524 | D accuracy: 64.0625] [G loss: 0.9176870584487915]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4339 [D loss: 0.6642864346504211 | D accuracy: 56.25] [G loss: 0.9748021960258484]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4340 [D loss: 0.6413989067077637 | D accuracy: 62.5] [G loss: 0.9639467000961304]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4341 [D loss: 0.6177294254302979 | D accuracy: 59.375] [G loss: 1.0446834564208984]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4342 [D loss: 0.5617786794900894 | D accuracy: 73.4375] [G loss: 1.0130031108856201]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4343 [D loss: 0.6074150800704956 | D accuracy: 65.625] [G loss: 1.057222604751587]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4344 [D loss: 0.5866585373878479 | D accuracy: 67.1875] [G loss: 1.0114874839782715]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4345 [D loss: 0.5971305072307587 | D accuracy: 64.0625] [G loss: 0.9628031253814697]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4346 [D loss: 0.7007214725017548 | D accuracy: 54.6875] [G loss: 1.0066466331481934]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4347 [D loss: 0.6096856892108917 | D accuracy: 57.8125] [G loss: 1.002239465713501]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4348 [D loss: 0.6203241646289825 | D accuracy: 56.25] [G loss: 1.0988484621047974]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4349 [D loss: 0.6673657894134521 | D accuracy: 54.6875] [G loss: 0.9879594445228577]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4350 [D loss: 0.6138323545455933 | D accuracy: 67.1875] [G loss: 0.9984124898910522]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4351 [D loss: 0.621168315410614 | D accuracy: 60.9375] [G loss: 1.067348599433899]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4352 [D loss: 0.6766777634620667 | D accuracy: 59.375] [G loss: 0.9973831176757812]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4353 [D loss: 0.5913379192352295 | D accuracy: 73.4375] [G loss: 1.0164618492126465]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4354 [D loss: 0.5940797626972198 | D accuracy: 71.875] [G loss: 0.9948797225952148]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4355 [D loss: 0.6710943877696991 | D accuracy: 64.0625] [G loss: 0.9974682331085205]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4356 [D loss: 0.6605114042758942 | D accuracy: 57.8125] [G loss: 1.0552973747253418]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4357 [D loss: 0.602667510509491 | D accuracy: 67.1875] [G loss: 1.0362067222595215]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4358 [D loss: 0.6300235390663147 | D accuracy: 64.0625] [G loss: 1.0863182544708252]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4359 [D loss: 0.5901844501495361 | D accuracy: 62.5] [G loss: 1.044847846031189]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4360 [D loss: 0.6857829988002777 | D accuracy: 56.25] [G loss: 1.227239966392517]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4361 [D loss: 0.6192811131477356 | D accuracy: 71.875] [G loss: 0.9881584048271179]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4362 [D loss: 0.5918792486190796 | D accuracy: 70.3125] [G loss: 1.0834028720855713]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4363 [D loss: 0.6394297182559967 | D accuracy: 59.375] [G loss: 1.0690970420837402]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4364 [D loss: 0.6397782266139984 | D accuracy: 64.0625] [G loss: 1.023549199104309]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4365 [D loss: 0.618310958147049 | D accuracy: 65.625] [G loss: 0.964081346988678]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4366 [D loss: 0.6211610734462738 | D accuracy: 62.5] [G loss: 0.9913446307182312]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4367 [D loss: 0.5590730011463165 | D accuracy: 68.75] [G loss: 1.060581088066101]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4368 [D loss: 0.6304802000522614 | D accuracy: 64.0625] [G loss: 0.9499293565750122]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4369 [D loss: 0.6476435363292694 | D accuracy: 68.75] [G loss: 1.10512113571167]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4370 [D loss: 0.6103268265724182 | D accuracy: 64.0625] [G loss: 1.008719801902771]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4371 [D loss: 0.6988058686256409 | D accuracy: 59.375] [G loss: 0.9774848222732544]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4372 [D loss: 0.5590987503528595 | D accuracy: 70.3125] [G loss: 1.0553812980651855]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4373 [D loss: 0.680896520614624 | D accuracy: 50.0] [G loss: 1.0502822399139404]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4374 [D loss: 0.5804831087589264 | D accuracy: 68.75] [G loss: 1.1031773090362549]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4375 [D loss: 0.6119965314865112 | D accuracy: 60.9375] [G loss: 1.0431572198867798]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4376 [D loss: 0.6324165463447571 | D accuracy: 60.9375] [G loss: 1.0474624633789062]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4377 [D loss: 0.6808880567550659 | D accuracy: 62.5] [G loss: 1.124213457107544]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4378 [D loss: 0.625715583562851 | D accuracy: 71.875] [G loss: 1.1438900232315063]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4379 [D loss: 0.6191442608833313 | D accuracy: 67.1875] [G loss: 1.0763437747955322]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4380 [D loss: 0.6808239817619324 | D accuracy: 60.9375] [G loss: 0.9931584000587463]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4381 [D loss: 0.5805416405200958 | D accuracy: 71.875] [G loss: 1.0553796291351318]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4382 [D loss: 0.6252646446228027 | D accuracy: 62.5] [G loss: 1.093029260635376]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4383 [D loss: 0.5688976049423218 | D accuracy: 70.3125] [G loss: 0.9890708327293396]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4384 [D loss: 0.6266975700855255 | D accuracy: 62.5] [G loss: 1.0506384372711182]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4385 [D loss: 0.5936610400676727 | D accuracy: 67.1875] [G loss: 1.0190331935882568]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4386 [D loss: 0.646650493144989 | D accuracy: 60.9375] [G loss: 1.0527770519256592]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4387 [D loss: 0.6066921949386597 | D accuracy: 64.0625] [G loss: 1.0520610809326172]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4388 [D loss: 0.6238021850585938 | D accuracy: 56.25] [G loss: 1.0136982202529907]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4389 [D loss: 0.6465459764003754 | D accuracy: 59.375] [G loss: 0.9080734252929688]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4390 [D loss: 0.6099410951137543 | D accuracy: 67.1875] [G loss: 1.014405369758606]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4391 [D loss: 0.5506940335035324 | D accuracy: 75.0] [G loss: 1.0184605121612549]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4392 [D loss: 0.5923343598842621 | D accuracy: 68.75] [G loss: 1.0445090532302856]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4393 [D loss: 0.571043074131012 | D accuracy: 67.1875] [G loss: 1.0079410076141357]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4394 [D loss: 0.6099822223186493 | D accuracy: 64.0625] [G loss: 0.9746352434158325]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4395 [D loss: 0.6354164779186249 | D accuracy: 57.8125] [G loss: 1.0279089212417603]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4396 [D loss: 0.5431941747665405 | D accuracy: 76.5625] [G loss: 0.9665411710739136]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4397 [D loss: 0.6527716219425201 | D accuracy: 60.9375] [G loss: 1.0669190883636475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4398 [D loss: 0.605308324098587 | D accuracy: 65.625] [G loss: 0.909784197807312]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4399 [D loss: 0.6306527256965637 | D accuracy: 67.1875] [G loss: 0.982414960861206]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4400 [D loss: 0.6271417140960693 | D accuracy: 64.0625] [G loss: 0.9504880905151367]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4401 [D loss: 0.6366994082927704 | D accuracy: 62.5] [G loss: 1.0678774118423462]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4402 [D loss: 0.6253309547901154 | D accuracy: 67.1875] [G loss: 1.0873748064041138]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4403 [D loss: 0.6019647419452667 | D accuracy: 70.3125] [G loss: 0.8889763355255127]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4404 [D loss: 0.6117138862609863 | D accuracy: 64.0625] [G loss: 0.9671438932418823]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4405 [D loss: 0.6158782541751862 | D accuracy: 62.5] [G loss: 1.0414685010910034]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4406 [D loss: 0.6249251961708069 | D accuracy: 67.1875] [G loss: 0.963857889175415]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4407 [D loss: 0.5756355226039886 | D accuracy: 71.875] [G loss: 0.92622971534729]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4408 [D loss: 0.5754662752151489 | D accuracy: 75.0] [G loss: 1.0047028064727783]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4409 [D loss: 0.6140043139457703 | D accuracy: 65.625] [G loss: 1.0564558506011963]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4410 [D loss: 0.6149305999279022 | D accuracy: 60.9375] [G loss: 1.0533939599990845]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4411 [D loss: 0.5613356828689575 | D accuracy: 75.0] [G loss: 1.0452088117599487]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4412 [D loss: 0.5613753199577332 | D accuracy: 73.4375] [G loss: 0.9860642552375793]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4413 [D loss: 0.5637233257293701 | D accuracy: 67.1875] [G loss: 1.0736000537872314]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4414 [D loss: 0.6616919934749603 | D accuracy: 62.5] [G loss: 1.009444236755371]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4415 [D loss: 0.6388324499130249 | D accuracy: 60.9375] [G loss: 1.0270289182662964]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4416 [D loss: 0.6663883030414581 | D accuracy: 57.8125] [G loss: 0.9709022641181946]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4417 [D loss: 0.6186374425888062 | D accuracy: 64.0625] [G loss: 1.0098471641540527]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4418 [D loss: 0.649164080619812 | D accuracy: 60.9375] [G loss: 0.9893423318862915]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4419 [D loss: 0.6149510741233826 | D accuracy: 64.0625] [G loss: 1.04707932472229]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4420 [D loss: 0.5815665423870087 | D accuracy: 67.1875] [G loss: 0.944830060005188]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4421 [D loss: 0.556119829416275 | D accuracy: 73.4375] [G loss: 1.0401251316070557]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4422 [D loss: 0.6554675102233887 | D accuracy: 56.25] [G loss: 0.9961161017417908]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4423 [D loss: 0.6471904218196869 | D accuracy: 60.9375] [G loss: 0.9177428483963013]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4424 [D loss: 0.6178685128688812 | D accuracy: 70.3125] [G loss: 0.95924311876297]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4425 [D loss: 0.632307767868042 | D accuracy: 59.375] [G loss: 0.9958165287971497]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4426 [D loss: 0.5997397601604462 | D accuracy: 59.375] [G loss: 0.976885199546814]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4427 [D loss: 0.6405177116394043 | D accuracy: 57.8125] [G loss: 0.9820484519004822]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4428 [D loss: 0.6190727651119232 | D accuracy: 60.9375] [G loss: 1.0159022808074951]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4429 [D loss: 0.5651825964450836 | D accuracy: 67.1875] [G loss: 1.0490226745605469]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4430 [D loss: 0.6400460004806519 | D accuracy: 70.3125] [G loss: 1.0732733011245728]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4431 [D loss: 0.6588720381259918 | D accuracy: 64.0625] [G loss: 0.9436864256858826]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4432 [D loss: 0.6511320471763611 | D accuracy: 62.5] [G loss: 1.0181965827941895]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4433 [D loss: 0.6052069962024689 | D accuracy: 65.625] [G loss: 0.9508339166641235]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4434 [D loss: 0.6417995989322662 | D accuracy: 65.625] [G loss: 1.0060968399047852]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4435 [D loss: 0.6443075239658356 | D accuracy: 68.75] [G loss: 0.9819992780685425]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4436 [D loss: 0.6298484206199646 | D accuracy: 59.375] [G loss: 1.0784870386123657]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4437 [D loss: 0.6186209321022034 | D accuracy: 67.1875] [G loss: 1.129178524017334]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4438 [D loss: 0.6456462144851685 | D accuracy: 56.25] [G loss: 1.0551762580871582]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4439 [D loss: 0.6186973750591278 | D accuracy: 67.1875] [G loss: 1.025742769241333]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4440 [D loss: 0.5735533833503723 | D accuracy: 60.9375] [G loss: 0.9801347255706787]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4441 [D loss: 0.6323871910572052 | D accuracy: 62.5] [G loss: 0.9492526054382324]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4442 [D loss: 0.5657930374145508 | D accuracy: 67.1875] [G loss: 1.0279581546783447]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4443 [D loss: 0.6085183620452881 | D accuracy: 65.625] [G loss: 0.9519255757331848]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4444 [D loss: 0.5658105313777924 | D accuracy: 71.875] [G loss: 1.0403333902359009]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4445 [D loss: 0.6043505370616913 | D accuracy: 67.1875] [G loss: 0.9886822700500488]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4446 [D loss: 0.6214763820171356 | D accuracy: 64.0625] [G loss: 0.9461451768875122]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4447 [D loss: 0.5701242983341217 | D accuracy: 78.125] [G loss: 0.9556146264076233]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4448 [D loss: 0.6338361501693726 | D accuracy: 62.5] [G loss: 1.0093554258346558]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4449 [D loss: 0.6798597872257233 | D accuracy: 57.8125] [G loss: 1.0210132598876953]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4450 [D loss: 0.5614838004112244 | D accuracy: 68.75] [G loss: 0.9863944053649902]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4451 [D loss: 0.5319768190383911 | D accuracy: 75.0] [G loss: 1.0411359071731567]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4452 [D loss: 0.6064597070217133 | D accuracy: 60.9375] [G loss: 1.0162113904953003]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4453 [D loss: 0.6054131388664246 | D accuracy: 65.625] [G loss: 1.027359127998352]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4454 [D loss: 0.6206340491771698 | D accuracy: 59.375] [G loss: 0.95640629529953]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4455 [D loss: 0.6080531775951385 | D accuracy: 68.75] [G loss: 1.0208674669265747]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4456 [D loss: 0.6947802901268005 | D accuracy: 57.8125] [G loss: 1.084291696548462]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4457 [D loss: 0.6439169645309448 | D accuracy: 62.5] [G loss: 0.9814693927764893]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4458 [D loss: 0.7137681841850281 | D accuracy: 53.125] [G loss: 0.9928567409515381]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4459 [D loss: 0.617443174123764 | D accuracy: 65.625] [G loss: 1.014340877532959]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4460 [D loss: 0.6125026047229767 | D accuracy: 71.875] [G loss: 1.0474880933761597]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4461 [D loss: 0.6023920476436615 | D accuracy: 70.3125] [G loss: 1.004725456237793]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4462 [D loss: 0.6497841477394104 | D accuracy: 60.9375] [G loss: 0.9399368762969971]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4463 [D loss: 0.5890360176563263 | D accuracy: 71.875] [G loss: 0.9123551249504089]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4464 [D loss: 0.5953780710697174 | D accuracy: 71.875] [G loss: 0.9815642833709717]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4465 [D loss: 0.6793713271617889 | D accuracy: 60.9375] [G loss: 1.0275955200195312]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4466 [D loss: 0.6512404680252075 | D accuracy: 60.9375] [G loss: 1.012344241142273]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4467 [D loss: 0.6385016143321991 | D accuracy: 62.5] [G loss: 0.9882841110229492]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4468 [D loss: 0.6281817853450775 | D accuracy: 62.5] [G loss: 0.9298508763313293]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4469 [D loss: 0.589000016450882 | D accuracy: 68.75] [G loss: 0.9668574333190918]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4470 [D loss: 0.6429393887519836 | D accuracy: 53.125] [G loss: 1.0262432098388672]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4471 [D loss: 0.6048623025417328 | D accuracy: 65.625] [G loss: 0.9705716371536255]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4472 [D loss: 0.5510550737380981 | D accuracy: 73.4375] [G loss: 0.9777802228927612]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4473 [D loss: 0.5847759544849396 | D accuracy: 71.875] [G loss: 0.9404817223548889]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4474 [D loss: 0.6089863777160645 | D accuracy: 65.625] [G loss: 0.9213433265686035]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4475 [D loss: 0.6432399749755859 | D accuracy: 59.375] [G loss: 0.9670660495758057]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4476 [D loss: 0.5134329944849014 | D accuracy: 71.875] [G loss: 0.9678552746772766]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4477 [D loss: 0.5658381879329681 | D accuracy: 71.875] [G loss: 0.9475358128547668]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4478 [D loss: 0.6225391030311584 | D accuracy: 60.9375] [G loss: 0.990275502204895]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4479 [D loss: 0.48702090978622437 | D accuracy: 75.0] [G loss: 1.0375584363937378]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4480 [D loss: 0.5717884302139282 | D accuracy: 70.3125] [G loss: 1.0388374328613281]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4481 [D loss: 0.6189922392368317 | D accuracy: 68.75] [G loss: 1.0306802988052368]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4482 [D loss: 0.6379193663597107 | D accuracy: 65.625] [G loss: 0.9795399308204651]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4483 [D loss: 0.6284714639186859 | D accuracy: 65.625] [G loss: 1.0522980690002441]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4484 [D loss: 0.5670970976352692 | D accuracy: 65.625] [G loss: 1.0297856330871582]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4485 [D loss: 0.6205339133739471 | D accuracy: 62.5] [G loss: 1.1492983102798462]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4486 [D loss: 0.6419819891452789 | D accuracy: 64.0625] [G loss: 1.0998814105987549]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4487 [D loss: 0.6300111413002014 | D accuracy: 56.25] [G loss: 0.937995970249176]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4488 [D loss: 0.5982699394226074 | D accuracy: 68.75] [G loss: 1.0019954442977905]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4489 [D loss: 0.6015264987945557 | D accuracy: 65.625] [G loss: 0.9631603956222534]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4490 [D loss: 0.6777556538581848 | D accuracy: 50.0] [G loss: 1.032776117324829]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4491 [D loss: 0.5840069055557251 | D accuracy: 70.3125] [G loss: 0.9961121082305908]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4492 [D loss: 0.6210742294788361 | D accuracy: 62.5] [G loss: 0.9886775016784668]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4493 [D loss: 0.680612713098526 | D accuracy: 54.6875] [G loss: 0.9902814030647278]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4494 [D loss: 0.6565985083580017 | D accuracy: 56.25] [G loss: 1.0671409368515015]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4495 [D loss: 0.5923247933387756 | D accuracy: 65.625] [G loss: 0.9167861938476562]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4496 [D loss: 0.5927062630653381 | D accuracy: 67.1875] [G loss: 0.9880151748657227]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4497 [D loss: 0.588130533695221 | D accuracy: 65.625] [G loss: 1.022328495979309]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "4498 [D loss: 0.6605680584907532 | D accuracy: 59.375] [G loss: 0.953249454498291]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4499 [D loss: 0.652881532907486 | D accuracy: 64.0625] [G loss: 0.9626757502555847]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4500 [D loss: 0.6031765043735504 | D accuracy: 67.1875] [G loss: 1.0264897346496582]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4501 [D loss: 0.5690378546714783 | D accuracy: 71.875] [G loss: 1.1552042961120605]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4502 [D loss: 0.5612380355596542 | D accuracy: 71.875] [G loss: 1.061096429824829]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "4503 [D loss: 0.6593583822250366 | D accuracy: 64.0625] [G loss: 1.0423765182495117]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4504 [D loss: 0.6282627582550049 | D accuracy: 64.0625] [G loss: 0.9636581540107727]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "4505 [D loss: 0.6133027672767639 | D accuracy: 65.625] [G loss: 0.9039530158042908]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4506 [D loss: 0.6101943999528885 | D accuracy: 68.75] [G loss: 1.0220484733581543]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "4507 [D loss: 0.6132709980010986 | D accuracy: 59.375] [G loss: 1.0757695436477661]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4508 [D loss: 0.5912453234195709 | D accuracy: 71.875] [G loss: 1.0098057985305786]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4509 [D loss: 0.5706500113010406 | D accuracy: 67.1875] [G loss: 0.9779273271560669]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4510 [D loss: 0.5483580231666565 | D accuracy: 71.875] [G loss: 1.1221942901611328]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4511 [D loss: 0.6186713576316833 | D accuracy: 70.3125] [G loss: 1.025213360786438]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4512 [D loss: 0.6904550492763519 | D accuracy: 56.25] [G loss: 0.9530321359634399]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4513 [D loss: 0.6494832336902618 | D accuracy: 64.0625] [G loss: 0.9657875299453735]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4514 [D loss: 0.6062878966331482 | D accuracy: 64.0625] [G loss: 0.9892290830612183]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4515 [D loss: 0.6025043427944183 | D accuracy: 67.1875] [G loss: 0.9823746085166931]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4516 [D loss: 0.6202739477157593 | D accuracy: 70.3125] [G loss: 0.9898888468742371]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4517 [D loss: 0.6643433570861816 | D accuracy: 59.375] [G loss: 1.0382603406906128]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4518 [D loss: 0.5816487073898315 | D accuracy: 73.4375] [G loss: 1.0458579063415527]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4519 [D loss: 0.7078972160816193 | D accuracy: 46.875] [G loss: 0.9495513439178467]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4520 [D loss: 0.6147722005844116 | D accuracy: 56.25] [G loss: 0.9767535924911499]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4521 [D loss: 0.6591419279575348 | D accuracy: 64.0625] [G loss: 0.9998592734336853]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4522 [D loss: 0.5237724184989929 | D accuracy: 78.125] [G loss: 1.0106362104415894]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4523 [D loss: 0.6138007640838623 | D accuracy: 67.1875] [G loss: 1.058297872543335]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4524 [D loss: 0.6214456856250763 | D accuracy: 68.75] [G loss: 1.0217876434326172]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4525 [D loss: 0.6423633694648743 | D accuracy: 65.625] [G loss: 0.9521417617797852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4526 [D loss: 0.5967218279838562 | D accuracy: 65.625] [G loss: 0.963649332523346]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4527 [D loss: 0.6993939280509949 | D accuracy: 56.25] [G loss: 1.0735206604003906]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4528 [D loss: 0.6031703948974609 | D accuracy: 62.5] [G loss: 1.0910377502441406]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4529 [D loss: 0.6402073502540588 | D accuracy: 68.75] [G loss: 0.9848675727844238]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4530 [D loss: 0.613651692867279 | D accuracy: 75.0] [G loss: 1.014336347579956]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4531 [D loss: 0.6225584447383881 | D accuracy: 64.0625] [G loss: 0.9861771464347839]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4532 [D loss: 0.5849120318889618 | D accuracy: 60.9375] [G loss: 0.9572317600250244]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4533 [D loss: 0.652533769607544 | D accuracy: 54.6875] [G loss: 1.0993175506591797]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4534 [D loss: 0.5690484046936035 | D accuracy: 67.1875] [G loss: 0.9558942914009094]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4535 [D loss: 0.6794897019863129 | D accuracy: 56.25] [G loss: 1.0142347812652588]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4536 [D loss: 0.5974794924259186 | D accuracy: 64.0625] [G loss: 1.0603786706924438]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4537 [D loss: 0.5966091454029083 | D accuracy: 68.75] [G loss: 1.0188655853271484]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4538 [D loss: 0.58516725897789 | D accuracy: 67.1875] [G loss: 1.0244395732879639]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4539 [D loss: 0.6243196725845337 | D accuracy: 67.1875] [G loss: 1.0052947998046875]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4540 [D loss: 0.6209614276885986 | D accuracy: 60.9375] [G loss: 0.9997676610946655]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4541 [D loss: 0.5902063548564911 | D accuracy: 65.625] [G loss: 1.0062142610549927]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4542 [D loss: 0.5837444961071014 | D accuracy: 67.1875] [G loss: 1.0241129398345947]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4543 [D loss: 0.61257004737854 | D accuracy: 67.1875] [G loss: 1.0678226947784424]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4544 [D loss: 0.6224290132522583 | D accuracy: 68.75] [G loss: 1.031598687171936]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4545 [D loss: 0.579492837190628 | D accuracy: 76.5625] [G loss: 0.9817348122596741]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4546 [D loss: 0.6272837221622467 | D accuracy: 54.6875] [G loss: 0.9258900880813599]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4547 [D loss: 0.5748951137065887 | D accuracy: 71.875] [G loss: 0.9584735631942749]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4548 [D loss: 0.5846377909183502 | D accuracy: 67.1875] [G loss: 1.0199391841888428]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4549 [D loss: 0.5902144014835358 | D accuracy: 70.3125] [G loss: 0.9875035881996155]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4550 [D loss: 0.5803810656070709 | D accuracy: 65.625] [G loss: 1.0560448169708252]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4551 [D loss: 0.6288210451602936 | D accuracy: 62.5] [G loss: 1.0987238883972168]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4552 [D loss: 0.6035446226596832 | D accuracy: 65.625] [G loss: 1.0845569372177124]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4553 [D loss: 0.6195691823959351 | D accuracy: 62.5] [G loss: 1.0162054300308228]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4554 [D loss: 0.6561217308044434 | D accuracy: 62.5] [G loss: 0.9133496284484863]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4555 [D loss: 0.6480195224285126 | D accuracy: 64.0625] [G loss: 0.9474514722824097]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4556 [D loss: 0.6808880269527435 | D accuracy: 54.6875] [G loss: 0.948788583278656]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4557 [D loss: 0.6360486447811127 | D accuracy: 62.5] [G loss: 1.06709623336792]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4558 [D loss: 0.6894831359386444 | D accuracy: 60.9375] [G loss: 0.9292925000190735]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4559 [D loss: 0.6967558860778809 | D accuracy: 56.25] [G loss: 0.9765050411224365]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4560 [D loss: 0.6652844250202179 | D accuracy: 57.8125] [G loss: 0.9124237895011902]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4561 [D loss: 0.5703578293323517 | D accuracy: 65.625] [G loss: 0.9458155632019043]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4562 [D loss: 0.5518178939819336 | D accuracy: 73.4375] [G loss: 0.9574772715568542]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4563 [D loss: 0.674747884273529 | D accuracy: 57.8125] [G loss: 0.9633481502532959]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4564 [D loss: 0.6559063494205475 | D accuracy: 56.25] [G loss: 0.9880682826042175]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4565 [D loss: 0.5974772870540619 | D accuracy: 68.75] [G loss: 0.9245645999908447]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4566 [D loss: 0.6150285005569458 | D accuracy: 62.5] [G loss: 1.0336964130401611]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4567 [D loss: 0.6047393679618835 | D accuracy: 67.1875] [G loss: 0.9411137104034424]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4568 [D loss: 0.7033610343933105 | D accuracy: 57.8125] [G loss: 0.9748296737670898]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4569 [D loss: 0.6351559460163116 | D accuracy: 54.6875] [G loss: 0.9660114645957947]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4570 [D loss: 0.5904726684093475 | D accuracy: 70.3125] [G loss: 0.9604239463806152]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4571 [D loss: 0.6561023592948914 | D accuracy: 68.75] [G loss: 0.9885626435279846]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4572 [D loss: 0.6681022942066193 | D accuracy: 59.375] [G loss: 1.0768063068389893]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4573 [D loss: 0.5796101689338684 | D accuracy: 67.1875] [G loss: 1.015502691268921]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4574 [D loss: 0.6059092581272125 | D accuracy: 71.875] [G loss: 1.0117120742797852]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4575 [D loss: 0.6128374934196472 | D accuracy: 65.625] [G loss: 1.1079421043395996]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4576 [D loss: 0.6019970178604126 | D accuracy: 60.9375] [G loss: 0.9959855675697327]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4577 [D loss: 0.7081704437732697 | D accuracy: 51.5625] [G loss: 0.9593837857246399]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4578 [D loss: 0.5962326526641846 | D accuracy: 62.5] [G loss: 1.0736494064331055]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4579 [D loss: 0.6531915962696075 | D accuracy: 64.0625] [G loss: 1.0835442543029785]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4580 [D loss: 0.6686513423919678 | D accuracy: 59.375] [G loss: 1.0571547746658325]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4581 [D loss: 0.6317075490951538 | D accuracy: 60.9375] [G loss: 0.9343496561050415]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4582 [D loss: 0.6411131024360657 | D accuracy: 62.5] [G loss: 0.9098927974700928]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4583 [D loss: 0.7262524962425232 | D accuracy: 50.0] [G loss: 0.9898544549942017]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4584 [D loss: 0.5389933288097382 | D accuracy: 73.4375] [G loss: 1.054842472076416]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4585 [D loss: 0.6119358837604523 | D accuracy: 67.1875] [G loss: 1.0213868618011475]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4586 [D loss: 0.6115612685680389 | D accuracy: 62.5] [G loss: 1.0498090982437134]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4587 [D loss: 0.6163948774337769 | D accuracy: 64.0625] [G loss: 0.8757014274597168]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4588 [D loss: 0.5717030167579651 | D accuracy: 75.0] [G loss: 0.9582051038742065]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4589 [D loss: 0.5636209547519684 | D accuracy: 70.3125] [G loss: 0.9389474391937256]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "4590 [D loss: 0.573024183511734 | D accuracy: 71.875] [G loss: 0.9605143070220947]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4591 [D loss: 0.5464917123317719 | D accuracy: 71.875] [G loss: 0.9762033820152283]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4592 [D loss: 0.6654651761054993 | D accuracy: 64.0625] [G loss: 0.9902262091636658]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4593 [D loss: 0.6145351231098175 | D accuracy: 68.75] [G loss: 0.8546978235244751]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4594 [D loss: 0.49373021721839905 | D accuracy: 79.6875] [G loss: 1.0247769355773926]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4595 [D loss: 0.6882359683513641 | D accuracy: 59.375] [G loss: 0.9245928525924683]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4596 [D loss: 0.7206973433494568 | D accuracy: 56.25] [G loss: 0.9717667698860168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4597 [D loss: 0.6457809805870056 | D accuracy: 59.375] [G loss: 0.9702968001365662]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4598 [D loss: 0.5762034952640533 | D accuracy: 73.4375] [G loss: 0.877173125743866]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4599 [D loss: 0.6077578067779541 | D accuracy: 64.0625] [G loss: 0.9654372930526733]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4600 [D loss: 0.5514049530029297 | D accuracy: 75.0] [G loss: 0.9366199374198914]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4601 [D loss: 0.610462874174118 | D accuracy: 67.1875] [G loss: 0.9604015946388245]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4602 [D loss: 0.5329249203205109 | D accuracy: 75.0] [G loss: 1.0519338846206665]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4603 [D loss: 0.6088309288024902 | D accuracy: 64.0625] [G loss: 0.9634487628936768]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4604 [D loss: 0.6883243322372437 | D accuracy: 46.875] [G loss: 0.981320858001709]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4605 [D loss: 0.5773021578788757 | D accuracy: 64.0625] [G loss: 1.0315966606140137]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4606 [D loss: 0.6954694986343384 | D accuracy: 56.25] [G loss: 1.034135103225708]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4607 [D loss: 0.5679193735122681 | D accuracy: 73.4375] [G loss: 1.0832346677780151]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4608 [D loss: 0.6712328791618347 | D accuracy: 54.6875] [G loss: 0.9779644012451172]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4609 [D loss: 0.5946160852909088 | D accuracy: 71.875] [G loss: 0.9711461663246155]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4610 [D loss: 0.5995196998119354 | D accuracy: 70.3125] [G loss: 1.0611867904663086]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4611 [D loss: 0.6622878313064575 | D accuracy: 70.3125] [G loss: 0.9421786069869995]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4612 [D loss: 0.6565251350402832 | D accuracy: 60.9375] [G loss: 0.9351100921630859]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4613 [D loss: 0.6360390186309814 | D accuracy: 65.625] [G loss: 1.0984077453613281]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4614 [D loss: 0.5619661211967468 | D accuracy: 70.3125] [G loss: 1.0288400650024414]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4615 [D loss: 0.6326401829719543 | D accuracy: 59.375] [G loss: 1.000958800315857]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4616 [D loss: 0.5542670041322708 | D accuracy: 68.75] [G loss: 0.9656003713607788]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4617 [D loss: 0.5645141005516052 | D accuracy: 67.1875] [G loss: 1.0203382968902588]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4618 [D loss: 0.5983420014381409 | D accuracy: 62.5] [G loss: 1.0019090175628662]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4619 [D loss: 0.6148627996444702 | D accuracy: 68.75] [G loss: 0.9814388751983643]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4620 [D loss: 0.5674358308315277 | D accuracy: 68.75] [G loss: 1.0756804943084717]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4621 [D loss: 0.6868322789669037 | D accuracy: 53.125] [G loss: 1.071256399154663]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4622 [D loss: 0.6479293704032898 | D accuracy: 56.25] [G loss: 0.9583630561828613]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4623 [D loss: 0.575059562921524 | D accuracy: 67.1875] [G loss: 1.0394638776779175]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4624 [D loss: 0.6892173886299133 | D accuracy: 56.25] [G loss: 0.9310267567634583]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4625 [D loss: 0.6001082062721252 | D accuracy: 67.1875] [G loss: 1.0167136192321777]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4626 [D loss: 0.5909499228000641 | D accuracy: 64.0625] [G loss: 0.981969952583313]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4627 [D loss: 0.6218338012695312 | D accuracy: 60.9375] [G loss: 0.9975486993789673]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4628 [D loss: 0.593034416437149 | D accuracy: 65.625] [G loss: 0.9411557912826538]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4629 [D loss: 0.6889074146747589 | D accuracy: 62.5] [G loss: 0.9705933332443237]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4630 [D loss: 0.5430652797222137 | D accuracy: 73.4375] [G loss: 0.8984239101409912]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4631 [D loss: 0.6240860223770142 | D accuracy: 60.9375] [G loss: 0.9510562419891357]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4632 [D loss: 0.5924881100654602 | D accuracy: 65.625] [G loss: 0.9477740526199341]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4633 [D loss: 0.5349952876567841 | D accuracy: 76.5625] [G loss: 0.9720258116722107]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4634 [D loss: 0.5187577605247498 | D accuracy: 82.8125] [G loss: 0.9301027655601501]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4635 [D loss: 0.6699676513671875 | D accuracy: 54.6875] [G loss: 0.9197218418121338]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4636 [D loss: 0.6028990149497986 | D accuracy: 65.625] [G loss: 0.966316282749176]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4637 [D loss: 0.6156459152698517 | D accuracy: 65.625] [G loss: 1.0027722120285034]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4638 [D loss: 0.6031308770179749 | D accuracy: 71.875] [G loss: 1.0029081106185913]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4639 [D loss: 0.5710152089595795 | D accuracy: 70.3125] [G loss: 0.9560773968696594]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4640 [D loss: 0.6040729880332947 | D accuracy: 73.4375] [G loss: 0.968245267868042]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4641 [D loss: 0.5889345407485962 | D accuracy: 75.0] [G loss: 0.993395209312439]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4642 [D loss: 0.5523428618907928 | D accuracy: 71.875] [G loss: 1.0310864448547363]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4643 [D loss: 0.6089375019073486 | D accuracy: 67.1875] [G loss: 0.9991804957389832]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4644 [D loss: 0.5822668373584747 | D accuracy: 68.75] [G loss: 1.0370796918869019]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4645 [D loss: 0.61622154712677 | D accuracy: 67.1875] [G loss: 0.9330006837844849]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4646 [D loss: 0.584351658821106 | D accuracy: 64.0625] [G loss: 1.031128168106079]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4647 [D loss: 0.671288788318634 | D accuracy: 57.8125] [G loss: 0.9765802621841431]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4648 [D loss: 0.661553829908371 | D accuracy: 59.375] [G loss: 0.9743950366973877]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4649 [D loss: 0.6418156027793884 | D accuracy: 57.8125] [G loss: 0.9686813950538635]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4650 [D loss: 0.5816894173622131 | D accuracy: 70.3125] [G loss: 0.9820641279220581]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4651 [D loss: 0.6438843607902527 | D accuracy: 59.375] [G loss: 1.0375012159347534]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4652 [D loss: 0.6123200953006744 | D accuracy: 64.0625] [G loss: 1.0309271812438965]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4653 [D loss: 0.5914661884307861 | D accuracy: 65.625] [G loss: 1.0138554573059082]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4654 [D loss: 0.6132791638374329 | D accuracy: 73.4375] [G loss: 1.024194359779358]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4655 [D loss: 0.5859274566173553 | D accuracy: 68.75] [G loss: 1.027898907661438]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4656 [D loss: 0.5956089496612549 | D accuracy: 70.3125] [G loss: 1.0523395538330078]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4657 [D loss: 0.6679618060588837 | D accuracy: 64.0625] [G loss: 1.1536710262298584]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4658 [D loss: 0.5600278675556183 | D accuracy: 73.4375] [G loss: 1.086266040802002]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4659 [D loss: 0.6493297219276428 | D accuracy: 57.8125] [G loss: 1.0198509693145752]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4660 [D loss: 0.6044331789016724 | D accuracy: 64.0625] [G loss: 0.9262369275093079]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4661 [D loss: 0.6476917266845703 | D accuracy: 57.8125] [G loss: 1.0104846954345703]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "4662 [D loss: 0.6769635081291199 | D accuracy: 54.6875] [G loss: 0.955529510974884]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4663 [D loss: 0.6428214907646179 | D accuracy: 65.625] [G loss: 0.9989830255508423]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4664 [D loss: 0.5813247859477997 | D accuracy: 65.625] [G loss: 0.9727078676223755]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4665 [D loss: 0.5932293236255646 | D accuracy: 68.75] [G loss: 0.9970484375953674]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4666 [D loss: 0.6436754465103149 | D accuracy: 59.375] [G loss: 1.070965051651001]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4667 [D loss: 0.644531786441803 | D accuracy: 57.8125] [G loss: 1.0266820192337036]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4668 [D loss: 0.6169174015522003 | D accuracy: 56.25] [G loss: 0.9824686646461487]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4669 [D loss: 0.6139470934867859 | D accuracy: 67.1875] [G loss: 1.0567268133163452]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4670 [D loss: 0.5249585807323456 | D accuracy: 84.375] [G loss: 0.9930545687675476]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4671 [D loss: 0.6082051694393158 | D accuracy: 70.3125] [G loss: 1.0331838130950928]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "4672 [D loss: 0.5820958316326141 | D accuracy: 64.0625] [G loss: 1.0971314907073975]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4673 [D loss: 0.540412425994873 | D accuracy: 62.5] [G loss: 1.0903005599975586]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4674 [D loss: 0.5989644229412079 | D accuracy: 65.625] [G loss: 0.9531873464584351]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4675 [D loss: 0.6431635618209839 | D accuracy: 71.875] [G loss: 1.1056597232818604]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4676 [D loss: 0.6129404902458191 | D accuracy: 68.75] [G loss: 1.0642396211624146]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4677 [D loss: 0.6238517165184021 | D accuracy: 65.625] [G loss: 0.9572655558586121]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4678 [D loss: 0.6663954854011536 | D accuracy: 57.8125] [G loss: 1.0108520984649658]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4679 [D loss: 0.5838741958141327 | D accuracy: 70.3125] [G loss: 1.0400922298431396]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4680 [D loss: 0.6250925660133362 | D accuracy: 62.5] [G loss: 1.0000056028366089]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4681 [D loss: 0.6158138513565063 | D accuracy: 64.0625] [G loss: 0.9502179622650146]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4682 [D loss: 0.6162294447422028 | D accuracy: 64.0625] [G loss: 1.0470499992370605]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4683 [D loss: 0.691680908203125 | D accuracy: 53.125] [G loss: 0.9319514632225037]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4684 [D loss: 0.5964837670326233 | D accuracy: 60.9375] [G loss: 0.9350736141204834]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4685 [D loss: 0.6415258944034576 | D accuracy: 57.8125] [G loss: 0.9827882647514343]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4686 [D loss: 0.6451895236968994 | D accuracy: 60.9375] [G loss: 0.9955675601959229]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4687 [D loss: 0.5666631758213043 | D accuracy: 68.75] [G loss: 1.0064245462417603]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4688 [D loss: 0.6446806788444519 | D accuracy: 50.0] [G loss: 0.980318546295166]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4689 [D loss: 0.5509154200553894 | D accuracy: 73.4375] [G loss: 0.9796324968338013]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4690 [D loss: 0.6126454770565033 | D accuracy: 65.625] [G loss: 1.088594675064087]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4691 [D loss: 0.6094477772712708 | D accuracy: 62.5] [G loss: 0.9938631057739258]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4692 [D loss: 0.5820173919200897 | D accuracy: 71.875] [G loss: 1.0074923038482666]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4693 [D loss: 0.6034389734268188 | D accuracy: 64.0625] [G loss: 1.0355939865112305]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4694 [D loss: 0.7180334031581879 | D accuracy: 50.0] [G loss: 0.927524745464325]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4695 [D loss: 0.5767267048358917 | D accuracy: 68.75] [G loss: 0.9400595426559448]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4696 [D loss: 0.561002641916275 | D accuracy: 75.0] [G loss: 0.9970850944519043]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4697 [D loss: 0.5950492024421692 | D accuracy: 67.1875] [G loss: 0.9515151977539062]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4698 [D loss: 0.6359871327877045 | D accuracy: 62.5] [G loss: 0.9718769788742065]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4699 [D loss: 0.6370185017585754 | D accuracy: 64.0625] [G loss: 1.0234510898590088]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4700 [D loss: 0.6423946022987366 | D accuracy: 64.0625] [G loss: 1.0332679748535156]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4701 [D loss: 0.5705846548080444 | D accuracy: 70.3125] [G loss: 1.0197242498397827]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "4702 [D loss: 0.6396499276161194 | D accuracy: 60.9375] [G loss: 1.0329556465148926]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4703 [D loss: 0.5778570175170898 | D accuracy: 67.1875] [G loss: 1.0206995010375977]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4704 [D loss: 0.6011696457862854 | D accuracy: 62.5] [G loss: 0.9813522100448608]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4705 [D loss: 0.5868666768074036 | D accuracy: 67.1875] [G loss: 0.9523431062698364]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4706 [D loss: 0.5838529467582703 | D accuracy: 70.3125] [G loss: 0.9120891094207764]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4707 [D loss: 0.6381672024726868 | D accuracy: 67.1875] [G loss: 0.9226043224334717]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4708 [D loss: 0.6342101395130157 | D accuracy: 64.0625] [G loss: 1.0502632856369019]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4709 [D loss: 0.5631353855133057 | D accuracy: 70.3125] [G loss: 1.0445902347564697]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4710 [D loss: 0.601060152053833 | D accuracy: 70.3125] [G loss: 1.0923926830291748]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4711 [D loss: 0.6940193474292755 | D accuracy: 53.125] [G loss: 0.98302161693573]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4712 [D loss: 0.5967479646205902 | D accuracy: 70.3125] [G loss: 0.9646404981613159]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4713 [D loss: 0.5737598836421967 | D accuracy: 73.4375] [G loss: 1.0164567232131958]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4714 [D loss: 0.6491304337978363 | D accuracy: 62.5] [G loss: 0.9936322569847107]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4715 [D loss: 0.579534113407135 | D accuracy: 73.4375] [G loss: 0.9513663649559021]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4716 [D loss: 0.5426745414733887 | D accuracy: 75.0] [G loss: 1.002809762954712]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4717 [D loss: 0.6734287440776825 | D accuracy: 59.375] [G loss: 0.9532660245895386]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4718 [D loss: 0.6251237690448761 | D accuracy: 65.625] [G loss: 1.0464262962341309]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4719 [D loss: 0.6035351753234863 | D accuracy: 68.75] [G loss: 0.9769759178161621]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4720 [D loss: 0.5123394131660461 | D accuracy: 76.5625] [G loss: 1.0112595558166504]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4721 [D loss: 0.621865451335907 | D accuracy: 65.625] [G loss: 1.1351978778839111]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4722 [D loss: 0.5958481431007385 | D accuracy: 64.0625] [G loss: 1.0116572380065918]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4723 [D loss: 0.5795390158891678 | D accuracy: 68.75] [G loss: 0.924466609954834]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4724 [D loss: 0.6245992183685303 | D accuracy: 67.1875] [G loss: 0.9288633465766907]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4725 [D loss: 0.6360839903354645 | D accuracy: 65.625] [G loss: 0.9836324453353882]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4726 [D loss: 0.5815656185150146 | D accuracy: 68.75] [G loss: 0.9144314527511597]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4727 [D loss: 0.6472197771072388 | D accuracy: 60.9375] [G loss: 0.9429560899734497]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4728 [D loss: 0.5653301477432251 | D accuracy: 70.3125] [G loss: 1.0794918537139893]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4729 [D loss: 0.5824613571166992 | D accuracy: 67.1875] [G loss: 1.0934617519378662]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4730 [D loss: 0.6392319202423096 | D accuracy: 64.0625] [G loss: 0.9840315580368042]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4731 [D loss: 0.5434593558311462 | D accuracy: 73.4375] [G loss: 1.0752391815185547]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4732 [D loss: 0.5524620711803436 | D accuracy: 71.875] [G loss: 0.9545738697052002]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4733 [D loss: 0.6123917996883392 | D accuracy: 59.375] [G loss: 0.9424394965171814]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4734 [D loss: 0.5380587577819824 | D accuracy: 75.0] [G loss: 1.01826810836792]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4735 [D loss: 0.6189368963241577 | D accuracy: 64.0625] [G loss: 1.0886585712432861]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4736 [D loss: 0.6141582131385803 | D accuracy: 67.1875] [G loss: 1.0001519918441772]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4737 [D loss: 0.6293148994445801 | D accuracy: 67.1875] [G loss: 1.038774847984314]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4738 [D loss: 0.6605415940284729 | D accuracy: 57.8125] [G loss: 0.9643549919128418]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4739 [D loss: 0.5782632827758789 | D accuracy: 62.5] [G loss: 1.0014004707336426]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4740 [D loss: 0.6239652931690216 | D accuracy: 62.5] [G loss: 0.9310157299041748]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4741 [D loss: 0.6297121942043304 | D accuracy: 67.1875] [G loss: 0.9667192697525024]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4742 [D loss: 0.6216771006584167 | D accuracy: 57.8125] [G loss: 1.0347096920013428]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4743 [D loss: 0.619472086429596 | D accuracy: 68.75] [G loss: 1.060939073562622]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4744 [D loss: 0.6642935574054718 | D accuracy: 67.1875] [G loss: 0.9549371004104614]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4745 [D loss: 0.6106913983821869 | D accuracy: 64.0625] [G loss: 0.9639224410057068]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4746 [D loss: 0.6315872669219971 | D accuracy: 60.9375] [G loss: 0.9596463441848755]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4747 [D loss: 0.6268462836742401 | D accuracy: 64.0625] [G loss: 1.0325087308883667]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4748 [D loss: 0.6632641553878784 | D accuracy: 56.25] [G loss: 0.9577517509460449]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4749 [D loss: 0.6101773083209991 | D accuracy: 62.5] [G loss: 1.0282275676727295]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4750 [D loss: 0.6965207457542419 | D accuracy: 59.375] [G loss: 0.9627110958099365]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4751 [D loss: 0.7158993482589722 | D accuracy: 48.4375] [G loss: 1.092361569404602]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4752 [D loss: 0.6440837383270264 | D accuracy: 65.625] [G loss: 1.042065143585205]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4753 [D loss: 0.6381287574768066 | D accuracy: 57.8125] [G loss: 0.9194540977478027]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4754 [D loss: 0.5910400748252869 | D accuracy: 67.1875] [G loss: 0.9723625779151917]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4755 [D loss: 0.613017350435257 | D accuracy: 62.5] [G loss: 0.9586254954338074]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4756 [D loss: 0.7189783155918121 | D accuracy: 57.8125] [G loss: 1.015018105506897]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4757 [D loss: 0.6116295456886292 | D accuracy: 62.5] [G loss: 1.0576808452606201]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4758 [D loss: 0.6042685508728027 | D accuracy: 59.375] [G loss: 1.0214698314666748]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4759 [D loss: 0.5916699767112732 | D accuracy: 73.4375] [G loss: 1.066954255104065]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4760 [D loss: 0.5522487461566925 | D accuracy: 70.3125] [G loss: 1.0464246273040771]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4761 [D loss: 0.6839976608753204 | D accuracy: 53.125] [G loss: 0.9150584936141968]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4762 [D loss: 0.6588861644268036 | D accuracy: 59.375] [G loss: 0.995773196220398]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4763 [D loss: 0.6175167560577393 | D accuracy: 57.8125] [G loss: 1.0920941829681396]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4764 [D loss: 0.6288785934448242 | D accuracy: 64.0625] [G loss: 0.9269301891326904]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4765 [D loss: 0.6319779753684998 | D accuracy: 65.625] [G loss: 0.9617677330970764]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4766 [D loss: 0.7056013643741608 | D accuracy: 56.25] [G loss: 0.992251992225647]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4767 [D loss: 0.6297319531440735 | D accuracy: 54.6875] [G loss: 0.9659061431884766]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4768 [D loss: 0.6271480321884155 | D accuracy: 62.5] [G loss: 0.886246919631958]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4769 [D loss: 0.5580804646015167 | D accuracy: 73.4375] [G loss: 1.0144848823547363]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4770 [D loss: 0.6148305535316467 | D accuracy: 65.625] [G loss: 0.9593503475189209]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4771 [D loss: 0.6068069040775299 | D accuracy: 62.5] [G loss: 1.031052827835083]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4772 [D loss: 0.5749332904815674 | D accuracy: 73.4375] [G loss: 0.9754397869110107]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4773 [D loss: 0.6824389398097992 | D accuracy: 64.0625] [G loss: 0.994379997253418]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4774 [D loss: 0.5489062070846558 | D accuracy: 76.5625] [G loss: 1.0424038171768188]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4775 [D loss: 0.593096911907196 | D accuracy: 65.625] [G loss: 0.9928352236747742]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4776 [D loss: 0.5661131739616394 | D accuracy: 75.0] [G loss: 1.0129739046096802]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4777 [D loss: 0.5744673013687134 | D accuracy: 64.0625] [G loss: 0.962471067905426]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4778 [D loss: 0.7115948796272278 | D accuracy: 60.9375] [G loss: 0.9819990396499634]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4779 [D loss: 0.6219051480293274 | D accuracy: 65.625] [G loss: 1.0512076616287231]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4780 [D loss: 0.581269383430481 | D accuracy: 65.625] [G loss: 1.03861403465271]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4781 [D loss: 0.6788060963153839 | D accuracy: 56.25] [G loss: 1.0606098175048828]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4782 [D loss: 0.54421466588974 | D accuracy: 71.875] [G loss: 1.0532450675964355]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4783 [D loss: 0.6427804827690125 | D accuracy: 57.8125] [G loss: 1.0209097862243652]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4784 [D loss: 0.6056729555130005 | D accuracy: 68.75] [G loss: 1.009958028793335]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4785 [D loss: 0.576186865568161 | D accuracy: 71.875] [G loss: 0.9507669806480408]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4786 [D loss: 0.5844380259513855 | D accuracy: 68.75] [G loss: 1.046441912651062]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4787 [D loss: 0.6779637336730957 | D accuracy: 60.9375] [G loss: 0.959611177444458]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4788 [D loss: 0.6233173906803131 | D accuracy: 59.375] [G loss: 1.0181899070739746]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4789 [D loss: 0.6072190403938293 | D accuracy: 68.75] [G loss: 1.0487135648727417]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4790 [D loss: 0.6337361931800842 | D accuracy: 59.375] [G loss: 0.9395527839660645]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4791 [D loss: 0.6287014782428741 | D accuracy: 67.1875] [G loss: 1.0493948459625244]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4792 [D loss: 0.5423441827297211 | D accuracy: 65.625] [G loss: 0.9834392070770264]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4793 [D loss: 0.6414535343647003 | D accuracy: 64.0625] [G loss: 1.054938793182373]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4794 [D loss: 0.5772875547409058 | D accuracy: 71.875] [G loss: 0.9742947816848755]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4795 [D loss: 0.6790520250797272 | D accuracy: 57.8125] [G loss: 0.8477057218551636]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4796 [D loss: 0.5596794188022614 | D accuracy: 78.125] [G loss: 1.0349361896514893]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4797 [D loss: 0.6194953918457031 | D accuracy: 64.0625] [G loss: 0.955599844455719]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4798 [D loss: 0.6141736507415771 | D accuracy: 62.5] [G loss: 1.0071046352386475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4799 [D loss: 0.6075444221496582 | D accuracy: 65.625] [G loss: 1.0527217388153076]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4800 [D loss: 0.6040046215057373 | D accuracy: 70.3125] [G loss: 0.987982988357544]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4801 [D loss: 0.619228333234787 | D accuracy: 62.5] [G loss: 1.0439047813415527]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4802 [D loss: 0.6346177160739899 | D accuracy: 71.875] [G loss: 0.9281449317932129]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4803 [D loss: 0.5699918568134308 | D accuracy: 73.4375] [G loss: 1.064794898033142]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4804 [D loss: 0.6448001861572266 | D accuracy: 57.8125] [G loss: 1.0614500045776367]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4805 [D loss: 0.6232183575630188 | D accuracy: 64.0625] [G loss: 0.9851191639900208]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4806 [D loss: 0.589462399482727 | D accuracy: 65.625] [G loss: 1.0019927024841309]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4807 [D loss: 0.6008588373661041 | D accuracy: 62.5] [G loss: 0.938836932182312]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4808 [D loss: 0.6326375603675842 | D accuracy: 60.9375] [G loss: 0.9377827644348145]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4809 [D loss: 0.5577041506767273 | D accuracy: 75.0] [G loss: 0.952777087688446]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4810 [D loss: 0.5900172591209412 | D accuracy: 60.9375] [G loss: 1.0337451696395874]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4811 [D loss: 0.6296549141407013 | D accuracy: 62.5] [G loss: 1.0086207389831543]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4812 [D loss: 0.6894741356372833 | D accuracy: 57.8125] [G loss: 1.003487467765808]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4813 [D loss: 0.6492689847946167 | D accuracy: 59.375] [G loss: 1.0212116241455078]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4814 [D loss: 0.586292028427124 | D accuracy: 65.625] [G loss: 1.0348987579345703]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4815 [D loss: 0.5875448882579803 | D accuracy: 57.8125] [G loss: 1.036356806755066]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4816 [D loss: 0.665172815322876 | D accuracy: 67.1875] [G loss: 0.9955942630767822]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4817 [D loss: 0.5786817669868469 | D accuracy: 70.3125] [G loss: 1.0985349416732788]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4818 [D loss: 0.6189297437667847 | D accuracy: 70.3125] [G loss: 0.9686177968978882]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4819 [D loss: 0.6615630090236664 | D accuracy: 53.125] [G loss: 1.0447101593017578]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4820 [D loss: 0.6834406852722168 | D accuracy: 60.9375] [G loss: 0.9384011626243591]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4821 [D loss: 0.5558128356933594 | D accuracy: 71.875] [G loss: 1.1072407960891724]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4822 [D loss: 0.6351368427276611 | D accuracy: 59.375] [G loss: 1.0013946294784546]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4823 [D loss: 0.6073318719863892 | D accuracy: 64.0625] [G loss: 0.985672116279602]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4824 [D loss: 0.6331718564033508 | D accuracy: 64.0625] [G loss: 1.0258783102035522]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4825 [D loss: 0.6076487302780151 | D accuracy: 64.0625] [G loss: 1.0504283905029297]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4826 [D loss: 0.60040283203125 | D accuracy: 68.75] [G loss: 1.0734003782272339]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4827 [D loss: 0.6263203620910645 | D accuracy: 64.0625] [G loss: 0.9781566262245178]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4828 [D loss: 0.5355943739414215 | D accuracy: 78.125] [G loss: 1.0228384733200073]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4829 [D loss: 0.6370861232280731 | D accuracy: 57.8125] [G loss: 1.0843656063079834]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4830 [D loss: 0.6995150446891785 | D accuracy: 57.8125] [G loss: 1.024878978729248]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "4831 [D loss: 0.6066049337387085 | D accuracy: 65.625] [G loss: 1.1137958765029907]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4832 [D loss: 0.5920054316520691 | D accuracy: 68.75] [G loss: 1.079470157623291]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4833 [D loss: 0.6684488654136658 | D accuracy: 54.6875] [G loss: 0.9990658760070801]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4834 [D loss: 0.5584197342395782 | D accuracy: 64.0625] [G loss: 1.0246353149414062]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4835 [D loss: 0.6107468605041504 | D accuracy: 67.1875] [G loss: 1.0239777565002441]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4836 [D loss: 0.6947338879108429 | D accuracy: 51.5625] [G loss: 1.0291786193847656]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4837 [D loss: 0.6184163689613342 | D accuracy: 68.75] [G loss: 1.019180178642273]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4838 [D loss: 0.5406717658042908 | D accuracy: 68.75] [G loss: 1.0475863218307495]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4839 [D loss: 0.691213071346283 | D accuracy: 59.375] [G loss: 1.0181578397750854]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4840 [D loss: 0.6165718138217926 | D accuracy: 64.0625] [G loss: 1.0459257364273071]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4841 [D loss: 0.6266098916530609 | D accuracy: 68.75] [G loss: 1.0230588912963867]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4842 [D loss: 0.6971907615661621 | D accuracy: 51.5625] [G loss: 1.009103536605835]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4843 [D loss: 0.6586261093616486 | D accuracy: 64.0625] [G loss: 0.9252986311912537]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4844 [D loss: 0.6315430700778961 | D accuracy: 64.0625] [G loss: 0.9550135135650635]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4845 [D loss: 0.6017434895038605 | D accuracy: 62.5] [G loss: 0.9486669898033142]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4846 [D loss: 0.5621284544467926 | D accuracy: 75.0] [G loss: 1.0377380847930908]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4847 [D loss: 0.6433123350143433 | D accuracy: 57.8125] [G loss: 0.9473046660423279]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4848 [D loss: 0.5780314803123474 | D accuracy: 70.3125] [G loss: 0.9437659978866577]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4849 [D loss: 0.6359139382839203 | D accuracy: 57.8125] [G loss: 0.9747323989868164]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4850 [D loss: 0.6135977804660797 | D accuracy: 59.375] [G loss: 0.9385684728622437]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4851 [D loss: 0.6174519658088684 | D accuracy: 67.1875] [G loss: 0.9675084948539734]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4852 [D loss: 0.5541627407073975 | D accuracy: 67.1875] [G loss: 1.0183665752410889]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4853 [D loss: 0.6325232982635498 | D accuracy: 57.8125] [G loss: 1.047821283340454]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "4854 [D loss: 0.5997139811515808 | D accuracy: 60.9375] [G loss: 1.093650460243225]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4855 [D loss: 0.5946750640869141 | D accuracy: 62.5] [G loss: 1.0256924629211426]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4856 [D loss: 0.66068235039711 | D accuracy: 65.625] [G loss: 1.0449347496032715]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4857 [D loss: 0.6732779145240784 | D accuracy: 56.25] [G loss: 0.9553818106651306]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4858 [D loss: 0.6178443133831024 | D accuracy: 64.0625] [G loss: 1.0003948211669922]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4859 [D loss: 0.6249687373638153 | D accuracy: 62.5] [G loss: 0.918830931186676]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4860 [D loss: 0.709911048412323 | D accuracy: 60.9375] [G loss: 0.9507827162742615]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4861 [D loss: 0.5961401164531708 | D accuracy: 67.1875] [G loss: 0.9418066740036011]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4862 [D loss: 0.6555176675319672 | D accuracy: 62.5] [G loss: 0.9426534175872803]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4863 [D loss: 0.602069079875946 | D accuracy: 67.1875] [G loss: 1.0320830345153809]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4864 [D loss: 0.6133562922477722 | D accuracy: 57.8125] [G loss: 1.0290879011154175]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4865 [D loss: 0.6405843794345856 | D accuracy: 62.5] [G loss: 0.927721381187439]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4866 [D loss: 0.6208964735269547 | D accuracy: 57.8125] [G loss: 1.0070563554763794]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4867 [D loss: 0.6481010019779205 | D accuracy: 64.0625] [G loss: 1.0535101890563965]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4868 [D loss: 0.7112892866134644 | D accuracy: 51.5625] [G loss: 1.0059921741485596]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4869 [D loss: 0.6345398426055908 | D accuracy: 68.75] [G loss: 0.9545528292655945]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4870 [D loss: 0.5631237030029297 | D accuracy: 73.4375] [G loss: 0.9991047382354736]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4871 [D loss: 0.6036291122436523 | D accuracy: 68.75] [G loss: 1.037436604499817]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4872 [D loss: 0.6183487176895142 | D accuracy: 62.5] [G loss: 1.0072494745254517]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4873 [D loss: 0.5841404795646667 | D accuracy: 64.0625] [G loss: 1.0148884057998657]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4874 [D loss: 0.5974926054477692 | D accuracy: 67.1875] [G loss: 1.0116653442382812]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4875 [D loss: 0.597895085811615 | D accuracy: 67.1875] [G loss: 1.0677965879440308]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4876 [D loss: 0.6223384439945221 | D accuracy: 64.0625] [G loss: 1.0851068496704102]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4877 [D loss: 0.6174851357936859 | D accuracy: 62.5] [G loss: 1.0616748332977295]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4878 [D loss: 0.6042512655258179 | D accuracy: 64.0625] [G loss: 0.9855849742889404]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4879 [D loss: 0.6588932871818542 | D accuracy: 54.6875] [G loss: 0.9282411336898804]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4880 [D loss: 0.5999131798744202 | D accuracy: 65.625] [G loss: 1.0043972730636597]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4881 [D loss: 0.6754923462867737 | D accuracy: 51.5625] [G loss: 0.863594651222229]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4882 [D loss: 0.6921397745609283 | D accuracy: 54.6875] [G loss: 0.9507685899734497]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4883 [D loss: 0.5927205681800842 | D accuracy: 65.625] [G loss: 0.9780017137527466]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4884 [D loss: 0.6296522319316864 | D accuracy: 62.5] [G loss: 1.027503252029419]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4885 [D loss: 0.5742881298065186 | D accuracy: 70.3125] [G loss: 0.9954805970191956]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4886 [D loss: 0.5641742050647736 | D accuracy: 68.75] [G loss: 1.0605525970458984]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4887 [D loss: 0.6269556879997253 | D accuracy: 56.25] [G loss: 1.0811123847961426]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4888 [D loss: 0.5849904716014862 | D accuracy: 67.1875] [G loss: 1.08061683177948]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4889 [D loss: 0.5611109137535095 | D accuracy: 67.1875] [G loss: 1.014032244682312]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4890 [D loss: 0.633550226688385 | D accuracy: 60.9375] [G loss: 1.1396942138671875]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4891 [D loss: 0.6091413497924805 | D accuracy: 62.5] [G loss: 0.9443252682685852]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4892 [D loss: 0.5604530274868011 | D accuracy: 73.4375] [G loss: 0.9975202083587646]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4893 [D loss: 0.7484272122383118 | D accuracy: 53.125] [G loss: 0.9492579698562622]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4894 [D loss: 0.5897006690502167 | D accuracy: 70.3125] [G loss: 0.9941499829292297]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4895 [D loss: 0.6479397416114807 | D accuracy: 62.5] [G loss: 1.0594534873962402]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4896 [D loss: 0.6070213615894318 | D accuracy: 65.625] [G loss: 0.9552255272865295]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4897 [D loss: 0.6519511342048645 | D accuracy: 62.5] [G loss: 1.0425424575805664]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4898 [D loss: 0.6478339433670044 | D accuracy: 65.625] [G loss: 0.9567510485649109]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4899 [D loss: 0.6141906380653381 | D accuracy: 64.0625] [G loss: 1.015554666519165]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4900 [D loss: 0.6056790947914124 | D accuracy: 68.75] [G loss: 1.078326940536499]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4901 [D loss: 0.566440761089325 | D accuracy: 67.1875] [G loss: 1.0810515880584717]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "4902 [D loss: 0.6624157428741455 | D accuracy: 60.9375] [G loss: 1.079404592514038]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4903 [D loss: 0.6002297699451447 | D accuracy: 64.0625] [G loss: 0.9586024880409241]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4904 [D loss: 0.5518479943275452 | D accuracy: 70.3125] [G loss: 0.8655630946159363]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4905 [D loss: 0.6286046206951141 | D accuracy: 64.0625] [G loss: 0.9040573835372925]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4906 [D loss: 0.6227858364582062 | D accuracy: 59.375] [G loss: 0.9574792385101318]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4907 [D loss: 0.6255166530609131 | D accuracy: 70.3125] [G loss: 0.9189345240592957]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4908 [D loss: 0.5937020182609558 | D accuracy: 73.4375] [G loss: 0.9238353967666626]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "4909 [D loss: 0.642451822757721 | D accuracy: 68.75] [G loss: 0.8657855987548828]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4910 [D loss: 0.5445076525211334 | D accuracy: 75.0] [G loss: 1.0298566818237305]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "4911 [D loss: 0.6243799924850464 | D accuracy: 65.625] [G loss: 0.977289617061615]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4912 [D loss: 0.6472952961921692 | D accuracy: 60.9375] [G loss: 0.9905266761779785]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4913 [D loss: 0.6367520093917847 | D accuracy: 60.9375] [G loss: 0.9845220446586609]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4914 [D loss: 0.6236860156059265 | D accuracy: 59.375] [G loss: 1.0521776676177979]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "4915 [D loss: 0.6012306213378906 | D accuracy: 70.3125] [G loss: 1.0088543891906738]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "4916 [D loss: 0.591372549533844 | D accuracy: 71.875] [G loss: 1.0598974227905273]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4917 [D loss: 0.5552501678466797 | D accuracy: 75.0] [G loss: 1.1904590129852295]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4918 [D loss: 0.6916544735431671 | D accuracy: 56.25] [G loss: 1.0511829853057861]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4919 [D loss: 0.6181111931800842 | D accuracy: 57.8125] [G loss: 1.0592677593231201]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4920 [D loss: 0.6140905022621155 | D accuracy: 70.3125] [G loss: 1.0589585304260254]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4921 [D loss: 0.6620955765247345 | D accuracy: 56.25] [G loss: 1.1120681762695312]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4922 [D loss: 0.6017032116651535 | D accuracy: 68.75] [G loss: 0.9822739362716675]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4923 [D loss: 0.6011019051074982 | D accuracy: 71.875] [G loss: 1.0103191137313843]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4924 [D loss: 0.5871407985687256 | D accuracy: 60.9375] [G loss: 1.0212829113006592]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4925 [D loss: 0.5817738175392151 | D accuracy: 65.625] [G loss: 0.9853905439376831]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4926 [D loss: 0.6029499769210815 | D accuracy: 59.375] [G loss: 0.9901107549667358]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4927 [D loss: 0.5665958225727081 | D accuracy: 67.1875] [G loss: 1.0853691101074219]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4928 [D loss: 0.5913349390029907 | D accuracy: 70.3125] [G loss: 0.9915096759796143]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4929 [D loss: 0.5859828293323517 | D accuracy: 57.8125] [G loss: 1.0208964347839355]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4930 [D loss: 0.6200226247310638 | D accuracy: 71.875] [G loss: 0.967881441116333]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4931 [D loss: 0.6387094259262085 | D accuracy: 64.0625] [G loss: 1.0020103454589844]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4932 [D loss: 0.6388213038444519 | D accuracy: 64.0625] [G loss: 0.9952673316001892]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4933 [D loss: 0.6392235159873962 | D accuracy: 64.0625] [G loss: 1.0500423908233643]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4934 [D loss: 0.49450281262397766 | D accuracy: 78.125] [G loss: 0.9737929701805115]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4935 [D loss: 0.6426537036895752 | D accuracy: 62.5] [G loss: 0.9820420145988464]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4936 [D loss: 0.5957552194595337 | D accuracy: 68.75] [G loss: 1.0796560049057007]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4937 [D loss: 0.5961708128452301 | D accuracy: 67.1875] [G loss: 0.9743521213531494]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4938 [D loss: 0.5591369271278381 | D accuracy: 71.875] [G loss: 1.0055508613586426]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4939 [D loss: 0.6078506708145142 | D accuracy: 75.0] [G loss: 0.9197594523429871]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4940 [D loss: 0.5988613069057465 | D accuracy: 64.0625] [G loss: 1.005478858947754]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4941 [D loss: 0.6179015934467316 | D accuracy: 62.5] [G loss: 0.949797511100769]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4942 [D loss: 0.581940770149231 | D accuracy: 71.875] [G loss: 0.9245820045471191]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4943 [D loss: 0.6352536082267761 | D accuracy: 60.9375] [G loss: 0.9600681066513062]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "4944 [D loss: 0.7108305096626282 | D accuracy: 54.6875] [G loss: 1.0123460292816162]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4945 [D loss: 0.6674306392669678 | D accuracy: 54.6875] [G loss: 1.063860535621643]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4946 [D loss: 0.6382191181182861 | D accuracy: 62.5] [G loss: 1.142887830734253]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4947 [D loss: 0.595351904630661 | D accuracy: 68.75] [G loss: 1.1123756170272827]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4948 [D loss: 0.6914535462856293 | D accuracy: 54.6875] [G loss: 1.066098928451538]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4949 [D loss: 0.6639019250869751 | D accuracy: 60.9375] [G loss: 1.0230505466461182]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4950 [D loss: 0.5894918441772461 | D accuracy: 68.75] [G loss: 0.9957851767539978]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4951 [D loss: 0.6049820482730865 | D accuracy: 70.3125] [G loss: 0.9822248220443726]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4952 [D loss: 0.6020594835281372 | D accuracy: 68.75] [G loss: 0.9567610025405884]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4953 [D loss: 0.5579692423343658 | D accuracy: 71.875] [G loss: 1.0284485816955566]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "4954 [D loss: 0.7249903678894043 | D accuracy: 56.25] [G loss: 0.9921351671218872]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4955 [D loss: 0.5820963084697723 | D accuracy: 67.1875] [G loss: 0.9824446439743042]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "4956 [D loss: 0.5400050729513168 | D accuracy: 75.0] [G loss: 0.9872660636901855]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4957 [D loss: 0.6795248985290527 | D accuracy: 65.625] [G loss: 1.016211748123169]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "4958 [D loss: 0.6799581944942474 | D accuracy: 56.25] [G loss: 0.9547388553619385]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4959 [D loss: 0.6168453693389893 | D accuracy: 65.625] [G loss: 1.0207765102386475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4960 [D loss: 0.5727127492427826 | D accuracy: 65.625] [G loss: 0.9955434799194336]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4961 [D loss: 0.6154187023639679 | D accuracy: 62.5] [G loss: 1.0978293418884277]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4962 [D loss: 0.6055825352668762 | D accuracy: 64.0625] [G loss: 1.0552194118499756]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4963 [D loss: 0.618888258934021 | D accuracy: 70.3125] [G loss: 1.0219824314117432]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4964 [D loss: 0.5249313414096832 | D accuracy: 73.4375] [G loss: 1.0448333024978638]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4965 [D loss: 0.5851967036724091 | D accuracy: 65.625] [G loss: 1.0238921642303467]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4966 [D loss: 0.6070703864097595 | D accuracy: 68.75] [G loss: 1.0681953430175781]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4967 [D loss: 0.6238195896148682 | D accuracy: 65.625] [G loss: 1.0312621593475342]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4968 [D loss: 0.5565626919269562 | D accuracy: 70.3125] [G loss: 0.9805803298950195]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4969 [D loss: 0.7420296370983124 | D accuracy: 54.6875] [G loss: 0.9608771800994873]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "4970 [D loss: 0.5763078927993774 | D accuracy: 76.5625] [G loss: 1.0009915828704834]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4971 [D loss: 0.5802255272865295 | D accuracy: 70.3125] [G loss: 0.9900409579277039]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4972 [D loss: 0.6111621558666229 | D accuracy: 67.1875] [G loss: 1.0295701026916504]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4973 [D loss: 0.5826784372329712 | D accuracy: 68.75] [G loss: 1.014127492904663]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4974 [D loss: 0.5934240818023682 | D accuracy: 64.0625] [G loss: 1.0158228874206543]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4975 [D loss: 0.6346523761749268 | D accuracy: 62.5] [G loss: 1.0207290649414062]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4976 [D loss: 0.5731878280639648 | D accuracy: 68.75] [G loss: 1.0032157897949219]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4977 [D loss: 0.6321278512477875 | D accuracy: 64.0625] [G loss: 1.0144689083099365]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "4978 [D loss: 0.5654052495956421 | D accuracy: 70.3125] [G loss: 1.0710992813110352]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4979 [D loss: 0.6047685146331787 | D accuracy: 64.0625] [G loss: 0.9300218820571899]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "4980 [D loss: 0.5581860542297363 | D accuracy: 60.9375] [G loss: 1.0172480344772339]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4981 [D loss: 0.6147539615631104 | D accuracy: 59.375] [G loss: 1.025442361831665]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4982 [D loss: 0.5940568149089813 | D accuracy: 65.625] [G loss: 1.1637986898422241]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "4983 [D loss: 0.649048238992691 | D accuracy: 60.9375] [G loss: 1.137669563293457]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "4984 [D loss: 0.60117307305336 | D accuracy: 67.1875] [G loss: 1.127104640007019]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "4985 [D loss: 0.6212157905101776 | D accuracy: 70.3125] [G loss: 1.0279910564422607]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4986 [D loss: 0.6198523342609406 | D accuracy: 65.625] [G loss: 0.9664466977119446]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4987 [D loss: 0.6455100774765015 | D accuracy: 65.625] [G loss: 0.9459378123283386]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "4988 [D loss: 0.5595584362745285 | D accuracy: 71.875] [G loss: 1.0579755306243896]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "4989 [D loss: 0.6080512404441833 | D accuracy: 70.3125] [G loss: 1.1157883405685425]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4990 [D loss: 0.6376734375953674 | D accuracy: 64.0625] [G loss: 1.0640439987182617]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "4991 [D loss: 0.5873289108276367 | D accuracy: 64.0625] [G loss: 0.9775880575180054]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "4992 [D loss: 0.6423791348934174 | D accuracy: 56.25] [G loss: 1.1116938591003418]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "4993 [D loss: 0.49740593135356903 | D accuracy: 75.0] [G loss: 1.0654535293579102]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "4994 [D loss: 0.5973629355430603 | D accuracy: 65.625] [G loss: 1.1920809745788574]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4995 [D loss: 0.615595817565918 | D accuracy: 64.0625] [G loss: 1.035083532333374]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "4996 [D loss: 0.5600377023220062 | D accuracy: 68.75] [G loss: 1.0442087650299072]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "4997 [D loss: 0.6023862957954407 | D accuracy: 60.9375] [G loss: 1.0159556865692139]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "4998 [D loss: 0.6410723030567169 | D accuracy: 62.5] [G loss: 0.9605560898780823]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "4999 [D loss: 0.6165725886821747 | D accuracy: 59.375] [G loss: 1.064064621925354]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5000 [D loss: 0.6005933284759521 | D accuracy: 67.1875] [G loss: 1.0740307569503784]\n",
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "5001 [D loss: 0.5954570174217224 | D accuracy: 65.625] [G loss: 1.098480224609375]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5002 [D loss: 0.5985535383224487 | D accuracy: 68.75] [G loss: 0.9507220983505249]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5003 [D loss: 0.6464426517486572 | D accuracy: 60.9375] [G loss: 0.9080117344856262]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5004 [D loss: 0.6279181838035583 | D accuracy: 53.125] [G loss: 0.9523904323577881]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5005 [D loss: 0.5291509330272675 | D accuracy: 71.875] [G loss: 0.9500532150268555]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5006 [D loss: 0.6398449540138245 | D accuracy: 60.9375] [G loss: 1.0566136837005615]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5007 [D loss: 0.6044529974460602 | D accuracy: 67.1875] [G loss: 1.0046426057815552]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5008 [D loss: 0.5779807269573212 | D accuracy: 62.5] [G loss: 1.0217475891113281]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5009 [D loss: 0.6167800724506378 | D accuracy: 64.0625] [G loss: 0.9547863006591797]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5010 [D loss: 0.7087342739105225 | D accuracy: 60.9375] [G loss: 1.101260781288147]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5011 [D loss: 0.5808263421058655 | D accuracy: 76.5625] [G loss: 1.0584800243377686]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5012 [D loss: 0.6146211624145508 | D accuracy: 71.875] [G loss: 0.9952730536460876]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5013 [D loss: 0.5530833601951599 | D accuracy: 71.875] [G loss: 1.1148045063018799]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5014 [D loss: 0.6024454236030579 | D accuracy: 68.75] [G loss: 1.0195724964141846]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5015 [D loss: 0.6577757298946381 | D accuracy: 60.9375] [G loss: 0.9635633230209351]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5016 [D loss: 0.5864067077636719 | D accuracy: 73.4375] [G loss: 1.0962085723876953]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5017 [D loss: 0.7319362759590149 | D accuracy: 50.0] [G loss: 0.9338334798812866]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5018 [D loss: 0.548171728849411 | D accuracy: 73.4375] [G loss: 1.0311206579208374]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5019 [D loss: 0.6136997640132904 | D accuracy: 62.5] [G loss: 1.069758653640747]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5020 [D loss: 0.6741957068443298 | D accuracy: 57.8125] [G loss: 1.0985196828842163]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5021 [D loss: 0.551979124546051 | D accuracy: 67.1875] [G loss: 1.0749928951263428]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5022 [D loss: 0.6305576264858246 | D accuracy: 59.375] [G loss: 1.0683231353759766]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5023 [D loss: 0.6880829334259033 | D accuracy: 53.125] [G loss: 1.0758272409439087]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5024 [D loss: 0.5993753373622894 | D accuracy: 59.375] [G loss: 0.9324740767478943]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5025 [D loss: 0.5705827474594116 | D accuracy: 75.0] [G loss: 0.9435704350471497]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5026 [D loss: 0.6252983212471008 | D accuracy: 62.5] [G loss: 1.0303115844726562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5027 [D loss: 0.6326758563518524 | D accuracy: 70.3125] [G loss: 0.969714879989624]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5028 [D loss: 0.6615205705165863 | D accuracy: 59.375] [G loss: 0.9892354607582092]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5029 [D loss: 0.5413759052753448 | D accuracy: 71.875] [G loss: 0.9865587949752808]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5030 [D loss: 0.6620290875434875 | D accuracy: 68.75] [G loss: 0.9583883285522461]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5031 [D loss: 0.6263698637485504 | D accuracy: 65.625] [G loss: 0.9962263107299805]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5032 [D loss: 0.6222390532493591 | D accuracy: 65.625] [G loss: 0.9407234787940979]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5033 [D loss: 0.5727804005146027 | D accuracy: 71.875] [G loss: 0.9470136761665344]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5034 [D loss: 0.6300613582134247 | D accuracy: 59.375] [G loss: 0.9621037244796753]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5035 [D loss: 0.6233544051647186 | D accuracy: 65.625] [G loss: 1.0620150566101074]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5036 [D loss: 0.6597112119197845 | D accuracy: 59.375] [G loss: 0.9653087258338928]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5037 [D loss: 0.6075676083564758 | D accuracy: 62.5] [G loss: 0.9921715259552002]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5038 [D loss: 0.5483946204185486 | D accuracy: 73.4375] [G loss: 1.0139155387878418]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5039 [D loss: 0.6272857189178467 | D accuracy: 60.9375] [G loss: 0.9157838225364685]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5040 [D loss: 0.5892424881458282 | D accuracy: 67.1875] [G loss: 1.0087171792984009]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5041 [D loss: 0.6883001625537872 | D accuracy: 54.6875] [G loss: 0.9918438792228699]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5042 [D loss: 0.5831953287124634 | D accuracy: 60.9375] [G loss: 0.9625929594039917]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5043 [D loss: 0.5696648061275482 | D accuracy: 70.3125] [G loss: 0.9803012609481812]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5044 [D loss: 0.5788963139057159 | D accuracy: 68.75] [G loss: 1.0366123914718628]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5045 [D loss: 0.663728654384613 | D accuracy: 57.8125] [G loss: 1.0479828119277954]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5046 [D loss: 0.5773897767066956 | D accuracy: 75.0] [G loss: 1.1039540767669678]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5047 [D loss: 0.5872046649456024 | D accuracy: 73.4375] [G loss: 0.9686235189437866]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5048 [D loss: 0.6408547759056091 | D accuracy: 62.5] [G loss: 0.9617704153060913]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5049 [D loss: 0.596917062997818 | D accuracy: 65.625] [G loss: 0.9688551425933838]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5050 [D loss: 0.5709826946258545 | D accuracy: 68.75] [G loss: 1.0468679666519165]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5051 [D loss: 0.6234650611877441 | D accuracy: 57.8125] [G loss: 0.9066394567489624]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5052 [D loss: 0.5933469533920288 | D accuracy: 68.75] [G loss: 0.9980607032775879]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5053 [D loss: 0.6840251088142395 | D accuracy: 59.375] [G loss: 0.9409970045089722]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5054 [D loss: 0.5933208763599396 | D accuracy: 65.625] [G loss: 0.995733916759491]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5055 [D loss: 0.6820063889026642 | D accuracy: 62.5] [G loss: 0.9904249310493469]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5056 [D loss: 0.6500387191772461 | D accuracy: 64.0625] [G loss: 1.03303062915802]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5057 [D loss: 0.5654867589473724 | D accuracy: 73.4375] [G loss: 1.0549514293670654]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5058 [D loss: 0.6221418082714081 | D accuracy: 65.625] [G loss: 1.0154755115509033]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5059 [D loss: 0.5821708738803864 | D accuracy: 65.625] [G loss: 1.0665580034255981]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5060 [D loss: 0.6110004186630249 | D accuracy: 65.625] [G loss: 0.9783141613006592]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5061 [D loss: 0.57953941822052 | D accuracy: 75.0] [G loss: 1.009631633758545]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5062 [D loss: 0.6408856809139252 | D accuracy: 59.375] [G loss: 0.9651962518692017]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5063 [D loss: 0.5990360379219055 | D accuracy: 64.0625] [G loss: 0.9858726859092712]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "5064 [D loss: 0.6555497348308563 | D accuracy: 70.3125] [G loss: 1.0380992889404297]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "5065 [D loss: 0.6345871388912201 | D accuracy: 59.375] [G loss: 1.0032247304916382]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5066 [D loss: 0.594224363565445 | D accuracy: 68.75] [G loss: 0.9111971855163574]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5067 [D loss: 0.6021896004676819 | D accuracy: 65.625] [G loss: 1.0347570180892944]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "5068 [D loss: 0.5117834061384201 | D accuracy: 75.0] [G loss: 1.0642180442810059]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5069 [D loss: 0.6933839321136475 | D accuracy: 54.6875] [G loss: 1.017916202545166]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "5070 [D loss: 0.5956708192825317 | D accuracy: 71.875] [G loss: 1.0682957172393799]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "5071 [D loss: 0.6125689744949341 | D accuracy: 71.875] [G loss: 0.9957587122917175]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5072 [D loss: 0.6091972589492798 | D accuracy: 62.5] [G loss: 0.9987512230873108]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5073 [D loss: 0.6319758892059326 | D accuracy: 56.25] [G loss: 0.9200822710990906]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5074 [D loss: 0.6069009900093079 | D accuracy: 60.9375] [G loss: 0.9405654668807983]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5075 [D loss: 0.6098662912845612 | D accuracy: 68.75] [G loss: 0.9854969382286072]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5076 [D loss: 0.6288071274757385 | D accuracy: 62.5] [G loss: 1.0118892192840576]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5077 [D loss: 0.6169033050537109 | D accuracy: 59.375] [G loss: 1.1060696840286255]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5078 [D loss: 0.5926603674888611 | D accuracy: 68.75] [G loss: 1.000530481338501]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5079 [D loss: 0.5840083956718445 | D accuracy: 64.0625] [G loss: 0.9584930539131165]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5080 [D loss: 0.5987729728221893 | D accuracy: 68.75] [G loss: 1.0892665386199951]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5081 [D loss: 0.6189016103744507 | D accuracy: 60.9375] [G loss: 0.9823608994483948]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5082 [D loss: 0.5869774520397186 | D accuracy: 65.625] [G loss: 1.0868136882781982]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5083 [D loss: 0.6209866106510162 | D accuracy: 64.0625] [G loss: 1.0034936666488647]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5084 [D loss: 0.6847427189350128 | D accuracy: 51.5625] [G loss: 1.073564052581787]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5085 [D loss: 0.6305901110172272 | D accuracy: 62.5] [G loss: 0.9983360767364502]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5086 [D loss: 0.5972097218036652 | D accuracy: 65.625] [G loss: 0.9646468758583069]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5087 [D loss: 0.5504777133464813 | D accuracy: 71.875] [G loss: 0.9986833930015564]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5088 [D loss: 0.5943345725536346 | D accuracy: 59.375] [G loss: 1.0038940906524658]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5089 [D loss: 0.544069916009903 | D accuracy: 70.3125] [G loss: 0.9089645147323608]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5090 [D loss: 0.7005723416805267 | D accuracy: 60.9375] [G loss: 0.9622465372085571]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5091 [D loss: 0.6255704760551453 | D accuracy: 64.0625] [G loss: 1.0453145503997803]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5092 [D loss: 0.5905383229255676 | D accuracy: 64.0625] [G loss: 1.0242722034454346]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5093 [D loss: 0.5981029868125916 | D accuracy: 71.875] [G loss: 0.9406018257141113]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5094 [D loss: 0.6542275846004486 | D accuracy: 57.8125] [G loss: 0.9030688405036926]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5095 [D loss: 0.6077471077442169 | D accuracy: 75.0] [G loss: 0.9957160949707031]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5096 [D loss: 0.6236995756626129 | D accuracy: 67.1875] [G loss: 0.9979996681213379]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5097 [D loss: 0.6230069994926453 | D accuracy: 67.1875] [G loss: 0.9888957142829895]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5098 [D loss: 0.6687977612018585 | D accuracy: 62.5] [G loss: 1.0470600128173828]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5099 [D loss: 0.561076819896698 | D accuracy: 70.3125] [G loss: 0.9530714750289917]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5100 [D loss: 0.6285978257656097 | D accuracy: 68.75] [G loss: 1.0107536315917969]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5101 [D loss: 0.6301711797714233 | D accuracy: 67.1875] [G loss: 0.9988739490509033]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5102 [D loss: 0.5975661277770996 | D accuracy: 68.75] [G loss: 1.0193101167678833]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5103 [D loss: 0.7187833786010742 | D accuracy: 51.5625] [G loss: 1.046383261680603]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5104 [D loss: 0.5768077969551086 | D accuracy: 70.3125] [G loss: 1.0152978897094727]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5105 [D loss: 0.6134554445743561 | D accuracy: 65.625] [G loss: 1.1078755855560303]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5106 [D loss: 0.5985995531082153 | D accuracy: 67.1875] [G loss: 0.9525328278541565]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5107 [D loss: 0.6610889732837677 | D accuracy: 59.375] [G loss: 1.0766801834106445]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5108 [D loss: 0.6884063184261322 | D accuracy: 57.8125] [G loss: 0.9863806366920471]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5109 [D loss: 0.5988506376743317 | D accuracy: 65.625] [G loss: 0.9619873762130737]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5110 [D loss: 0.5828212797641754 | D accuracy: 59.375] [G loss: 1.0911591053009033]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5111 [D loss: 0.6492772400379181 | D accuracy: 64.0625] [G loss: 0.977291464805603]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5112 [D loss: 0.6102521419525146 | D accuracy: 65.625] [G loss: 1.0313267707824707]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5113 [D loss: 0.6014162302017212 | D accuracy: 62.5] [G loss: 1.0455427169799805]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5114 [D loss: 0.5947018265724182 | D accuracy: 70.3125] [G loss: 1.0170643329620361]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5115 [D loss: 0.6322768330574036 | D accuracy: 59.375] [G loss: 0.9945127964019775]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5116 [D loss: 0.5567852556705475 | D accuracy: 67.1875] [G loss: 0.9964215159416199]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5117 [D loss: 0.6145836114883423 | D accuracy: 65.625] [G loss: 0.8831642866134644]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5118 [D loss: 0.5644710958003998 | D accuracy: 75.0] [G loss: 1.032305121421814]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5119 [D loss: 0.594571590423584 | D accuracy: 65.625] [G loss: 0.9839447736740112]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "5120 [D loss: 0.5869672894477844 | D accuracy: 76.5625] [G loss: 0.9922065138816833]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5121 [D loss: 0.5634512305259705 | D accuracy: 79.6875] [G loss: 1.0234171152114868]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5122 [D loss: 0.5512050092220306 | D accuracy: 73.4375] [G loss: 0.9785832762718201]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5123 [D loss: 0.6201334595680237 | D accuracy: 62.5] [G loss: 1.0073477029800415]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5124 [D loss: 0.5866619050502777 | D accuracy: 71.875] [G loss: 1.0384769439697266]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5125 [D loss: 0.6081277430057526 | D accuracy: 64.0625] [G loss: 1.006145715713501]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5126 [D loss: 0.6464766263961792 | D accuracy: 64.0625] [G loss: 1.0703330039978027]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5127 [D loss: 0.6629055738449097 | D accuracy: 56.25] [G loss: 1.0252282619476318]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5128 [D loss: 0.5578774213790894 | D accuracy: 70.3125] [G loss: 1.0452117919921875]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5129 [D loss: 0.6449703276157379 | D accuracy: 59.375] [G loss: 1.0047909021377563]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5130 [D loss: 0.5365307331085205 | D accuracy: 71.875] [G loss: 0.9488788843154907]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5131 [D loss: 0.5994603931903839 | D accuracy: 64.0625] [G loss: 0.9931100010871887]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5132 [D loss: 0.6214281320571899 | D accuracy: 62.5] [G loss: 0.9019361734390259]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5133 [D loss: 0.6609770059585571 | D accuracy: 59.375] [G loss: 0.9603604674339294]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5134 [D loss: 0.5376408696174622 | D accuracy: 75.0] [G loss: 1.0568740367889404]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5135 [D loss: 0.6194656193256378 | D accuracy: 68.75] [G loss: 1.0008604526519775]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5136 [D loss: 0.6902952194213867 | D accuracy: 54.6875] [G loss: 1.0093915462493896]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "5137 [D loss: 0.5907499492168427 | D accuracy: 62.5] [G loss: 1.034684181213379]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5138 [D loss: 0.5655467510223389 | D accuracy: 73.4375] [G loss: 1.0025700330734253]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5139 [D loss: 0.5961884260177612 | D accuracy: 70.3125] [G loss: 0.9067840576171875]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5140 [D loss: 0.7050940096378326 | D accuracy: 62.5] [G loss: 1.0047838687896729]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5141 [D loss: 0.5847682058811188 | D accuracy: 65.625] [G loss: 1.014500379562378]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5142 [D loss: 0.5554096102714539 | D accuracy: 71.875] [G loss: 1.027529239654541]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "5143 [D loss: 0.5592087209224701 | D accuracy: 75.0] [G loss: 1.0023963451385498]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5144 [D loss: 0.591387003660202 | D accuracy: 68.75] [G loss: 1.0856581926345825]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "5145 [D loss: 0.6048501431941986 | D accuracy: 65.625] [G loss: 1.0655040740966797]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "5146 [D loss: 0.5780248939990997 | D accuracy: 68.75] [G loss: 1.1564850807189941]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5147 [D loss: 0.6585667133331299 | D accuracy: 62.5] [G loss: 1.1350746154785156]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5148 [D loss: 0.7115336060523987 | D accuracy: 57.8125] [G loss: 1.0565719604492188]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5149 [D loss: 0.6561096608638763 | D accuracy: 65.625] [G loss: 1.0490143299102783]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5150 [D loss: 0.5543196797370911 | D accuracy: 73.4375] [G loss: 1.001089096069336]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5151 [D loss: 0.6322047412395477 | D accuracy: 68.75] [G loss: 0.9862213730812073]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5152 [D loss: 0.6682439744472504 | D accuracy: 50.0] [G loss: 1.0439157485961914]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5153 [D loss: 0.5505702197551727 | D accuracy: 76.5625] [G loss: 1.0200949907302856]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5154 [D loss: 0.7032677531242371 | D accuracy: 53.125] [G loss: 0.9363334774971008]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5155 [D loss: 0.5406056940555573 | D accuracy: 75.0] [G loss: 0.933491587638855]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5156 [D loss: 0.6194452345371246 | D accuracy: 62.5] [G loss: 0.946370005607605]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5157 [D loss: 0.5345257520675659 | D accuracy: 73.4375] [G loss: 1.021719217300415]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5158 [D loss: 0.5105198323726654 | D accuracy: 78.125] [G loss: 0.996967613697052]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5159 [D loss: 0.5878989994525909 | D accuracy: 71.875] [G loss: 0.9408453106880188]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5160 [D loss: 0.597761332988739 | D accuracy: 65.625] [G loss: 1.0383206605911255]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5161 [D loss: 0.5980857014656067 | D accuracy: 68.75] [G loss: 1.0206725597381592]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5162 [D loss: 0.6061254739761353 | D accuracy: 65.625] [G loss: 1.0630247592926025]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5163 [D loss: 0.6309484839439392 | D accuracy: 62.5] [G loss: 1.0568273067474365]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5164 [D loss: 0.628768116235733 | D accuracy: 65.625] [G loss: 1.000518798828125]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5165 [D loss: 0.6316525936126709 | D accuracy: 59.375] [G loss: 1.0029230117797852]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5166 [D loss: 0.5556019842624664 | D accuracy: 75.0] [G loss: 1.0352888107299805]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5167 [D loss: 0.5893170237541199 | D accuracy: 71.875] [G loss: 1.0420234203338623]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5168 [D loss: 0.6335395574569702 | D accuracy: 62.5] [G loss: 1.0789674520492554]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5169 [D loss: 0.6763031184673309 | D accuracy: 53.125] [G loss: 1.0236769914627075]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5170 [D loss: 0.6048573851585388 | D accuracy: 68.75] [G loss: 1.0378243923187256]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5171 [D loss: 0.5893062949180603 | D accuracy: 68.75] [G loss: 0.9977638721466064]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5172 [D loss: 0.5654613077640533 | D accuracy: 65.625] [G loss: 1.0917840003967285]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5173 [D loss: 0.6735620200634003 | D accuracy: 57.8125] [G loss: 1.0046751499176025]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5174 [D loss: 0.6885003745555878 | D accuracy: 56.25] [G loss: 1.0404181480407715]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5175 [D loss: 0.5724847912788391 | D accuracy: 70.3125] [G loss: 0.959939181804657]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5176 [D loss: 0.5794949531555176 | D accuracy: 68.75] [G loss: 0.9923250675201416]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5177 [D loss: 0.6166524291038513 | D accuracy: 62.5] [G loss: 0.9551874399185181]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5178 [D loss: 0.7007853090763092 | D accuracy: 53.125] [G loss: 0.9571770429611206]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5179 [D loss: 0.559242844581604 | D accuracy: 70.3125] [G loss: 0.9380793571472168]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5180 [D loss: 0.6096487641334534 | D accuracy: 62.5] [G loss: 0.9401575922966003]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5181 [D loss: 0.6014841198921204 | D accuracy: 71.875] [G loss: 0.9227732419967651]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5182 [D loss: 0.5790304243564606 | D accuracy: 73.4375] [G loss: 1.0590741634368896]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5183 [D loss: 0.6212135553359985 | D accuracy: 70.3125] [G loss: 1.018006682395935]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5184 [D loss: 0.6197769045829773 | D accuracy: 62.5] [G loss: 0.984882116317749]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5185 [D loss: 0.6499002873897552 | D accuracy: 56.25] [G loss: 1.1077479124069214]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5186 [D loss: 0.6310897767543793 | D accuracy: 67.1875] [G loss: 1.0399771928787231]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5187 [D loss: 0.7070158421993256 | D accuracy: 60.9375] [G loss: 1.068220853805542]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5188 [D loss: 0.5936746001243591 | D accuracy: 68.75] [G loss: 1.0879124402999878]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5189 [D loss: 0.597028374671936 | D accuracy: 68.75] [G loss: 1.0621113777160645]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5190 [D loss: 0.542116641998291 | D accuracy: 71.875] [G loss: 1.0117610692977905]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5191 [D loss: 0.4942272901535034 | D accuracy: 82.8125] [G loss: 1.027510166168213]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5192 [D loss: 0.5284907817840576 | D accuracy: 68.75] [G loss: 1.038591742515564]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5193 [D loss: 0.6536092758178711 | D accuracy: 57.8125] [G loss: 1.0397650003433228]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5194 [D loss: 0.5964329838752747 | D accuracy: 67.1875] [G loss: 0.9040791392326355]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5195 [D loss: 0.5624740719795227 | D accuracy: 68.75] [G loss: 0.9583237171173096]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "5196 [D loss: 0.591315895318985 | D accuracy: 64.0625] [G loss: 0.9503589272499084]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5197 [D loss: 0.5929179191589355 | D accuracy: 64.0625] [G loss: 0.9393976926803589]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5198 [D loss: 0.5532275438308716 | D accuracy: 75.0] [G loss: 0.9445603489875793]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5199 [D loss: 0.6765077412128448 | D accuracy: 53.125] [G loss: 1.0257773399353027]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5200 [D loss: 0.5816007852554321 | D accuracy: 67.1875] [G loss: 1.0160856246948242]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5201 [D loss: 0.6050123870372772 | D accuracy: 70.3125] [G loss: 1.0574133396148682]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5202 [D loss: 0.6040106415748596 | D accuracy: 67.1875] [G loss: 1.0035111904144287]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5203 [D loss: 0.6292645037174225 | D accuracy: 60.9375] [G loss: 1.00275719165802]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5204 [D loss: 0.6930016577243805 | D accuracy: 64.0625] [G loss: 1.0265097618103027]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5205 [D loss: 0.7241313755512238 | D accuracy: 50.0] [G loss: 0.9933701753616333]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5206 [D loss: 0.6602832973003387 | D accuracy: 59.375] [G loss: 0.9316569566726685]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5207 [D loss: 0.536904901266098 | D accuracy: 79.6875] [G loss: 1.0077521800994873]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5208 [D loss: 0.6398727595806122 | D accuracy: 62.5] [G loss: 0.968123197555542]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5209 [D loss: 0.6371677815914154 | D accuracy: 60.9375] [G loss: 0.9331046342849731]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5210 [D loss: 0.5876946449279785 | D accuracy: 65.625] [G loss: 1.0146549940109253]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5211 [D loss: 0.5600007772445679 | D accuracy: 73.4375] [G loss: 1.0338413715362549]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5212 [D loss: 0.6238375008106232 | D accuracy: 64.0625] [G loss: 0.9140555262565613]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5213 [D loss: 0.7466399371623993 | D accuracy: 50.0] [G loss: 0.9617957472801208]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5214 [D loss: 0.603421151638031 | D accuracy: 64.0625] [G loss: 1.1292152404785156]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5215 [D loss: 0.6348971426486969 | D accuracy: 60.9375] [G loss: 1.0309370756149292]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5216 [D loss: 0.6090627908706665 | D accuracy: 67.1875] [G loss: 1.0055372714996338]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5217 [D loss: 0.6504287123680115 | D accuracy: 59.375] [G loss: 1.0272523164749146]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5218 [D loss: 0.5664407312870026 | D accuracy: 73.4375] [G loss: 1.0154274702072144]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5219 [D loss: 0.563721239566803 | D accuracy: 67.1875] [G loss: 1.012420654296875]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5220 [D loss: 0.6381199955940247 | D accuracy: 57.8125] [G loss: 1.0014615058898926]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "5221 [D loss: 0.6302647590637207 | D accuracy: 54.6875] [G loss: 0.9426143169403076]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5222 [D loss: 0.5949577987194061 | D accuracy: 64.0625] [G loss: 0.9957993626594543]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5223 [D loss: 0.5824048221111298 | D accuracy: 73.4375] [G loss: 1.006224274635315]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5224 [D loss: 0.6042917370796204 | D accuracy: 65.625] [G loss: 0.9295297265052795]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "5225 [D loss: 0.5945518314838409 | D accuracy: 67.1875] [G loss: 1.0052053928375244]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "5226 [D loss: 0.6702912449836731 | D accuracy: 64.0625] [G loss: 0.9947446584701538]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5227 [D loss: 0.5688868761062622 | D accuracy: 71.875] [G loss: 1.0232645273208618]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "5228 [D loss: 0.6390843987464905 | D accuracy: 53.125] [G loss: 0.9189338684082031]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5229 [D loss: 0.7135568857192993 | D accuracy: 46.875] [G loss: 0.9300369024276733]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5230 [D loss: 0.5099704563617706 | D accuracy: 78.125] [G loss: 0.9433615803718567]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5231 [D loss: 0.5135177969932556 | D accuracy: 73.4375] [G loss: 1.0658421516418457]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5232 [D loss: 0.6824933290481567 | D accuracy: 54.6875] [G loss: 0.9907814264297485]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5233 [D loss: 0.614803820848465 | D accuracy: 64.0625] [G loss: 0.988599956035614]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5234 [D loss: 0.6550374031066895 | D accuracy: 56.25] [G loss: 1.0358765125274658]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5235 [D loss: 0.6473519504070282 | D accuracy: 51.5625] [G loss: 0.9808052778244019]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5236 [D loss: 0.6080673336982727 | D accuracy: 67.1875] [G loss: 1.0184990167617798]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5237 [D loss: 0.5920476317405701 | D accuracy: 64.0625] [G loss: 0.9819382429122925]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5238 [D loss: 0.6278187036514282 | D accuracy: 59.375] [G loss: 1.011232852935791]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5239 [D loss: 0.6282438933849335 | D accuracy: 60.9375] [G loss: 0.9199918508529663]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5240 [D loss: 0.6596640944480896 | D accuracy: 59.375] [G loss: 0.9170655012130737]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5241 [D loss: 0.6195337474346161 | D accuracy: 65.625] [G loss: 0.9811456203460693]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5242 [D loss: 0.6195449233055115 | D accuracy: 67.1875] [G loss: 0.9169885516166687]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5243 [D loss: 0.6964552998542786 | D accuracy: 42.1875] [G loss: 1.0027196407318115]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5244 [D loss: 0.5278648436069489 | D accuracy: 78.125] [G loss: 1.0407356023788452]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5245 [D loss: 0.5567840933799744 | D accuracy: 73.4375] [G loss: 0.9612881541252136]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5246 [D loss: 0.5732534527778625 | D accuracy: 67.1875] [G loss: 0.9617617726325989]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5247 [D loss: 0.6584945321083069 | D accuracy: 60.9375] [G loss: 0.960315465927124]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5248 [D loss: 0.645000547170639 | D accuracy: 64.0625] [G loss: 0.9839020371437073]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5249 [D loss: 0.7000602781772614 | D accuracy: 57.8125] [G loss: 0.9975827932357788]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5250 [D loss: 0.6757820844650269 | D accuracy: 54.6875] [G loss: 1.1414647102355957]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5251 [D loss: 0.60545215010643 | D accuracy: 62.5] [G loss: 1.1156542301177979]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5252 [D loss: 0.587164044380188 | D accuracy: 60.9375] [G loss: 0.9430223107337952]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5253 [D loss: 0.6177093684673309 | D accuracy: 68.75] [G loss: 1.0547595024108887]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5254 [D loss: 0.5681086182594299 | D accuracy: 71.875] [G loss: 1.0004615783691406]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5255 [D loss: 0.5814619660377502 | D accuracy: 70.3125] [G loss: 0.9340130090713501]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5256 [D loss: 0.5585503131151199 | D accuracy: 71.875] [G loss: 0.980273425579071]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5257 [D loss: 0.5406156331300735 | D accuracy: 75.0] [G loss: 0.9945690035820007]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5258 [D loss: 0.6637228727340698 | D accuracy: 54.6875] [G loss: 1.0623180866241455]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5259 [D loss: 0.6239063739776611 | D accuracy: 64.0625] [G loss: 1.0022563934326172]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5260 [D loss: 0.6875417232513428 | D accuracy: 59.375] [G loss: 0.9457502365112305]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5261 [D loss: 0.545201987028122 | D accuracy: 71.875] [G loss: 0.9374242424964905]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5262 [D loss: 0.7229577600955963 | D accuracy: 50.0] [G loss: 0.9416053295135498]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5263 [D loss: 0.6144726276397705 | D accuracy: 65.625] [G loss: 0.9800305962562561]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5264 [D loss: 0.6342818439006805 | D accuracy: 64.0625] [G loss: 0.9718452095985413]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5265 [D loss: 0.5968430042266846 | D accuracy: 70.3125] [G loss: 0.9446104764938354]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5266 [D loss: 0.6048317849636078 | D accuracy: 64.0625] [G loss: 1.0628821849822998]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5267 [D loss: 0.5544474422931671 | D accuracy: 76.5625] [G loss: 1.0433850288391113]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5268 [D loss: 0.626393586397171 | D accuracy: 62.5] [G loss: 1.0440351963043213]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5269 [D loss: 0.6724538505077362 | D accuracy: 62.5] [G loss: 0.9604911804199219]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5270 [D loss: 0.6575417816638947 | D accuracy: 62.5] [G loss: 0.9283530712127686]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5271 [D loss: 0.6022538542747498 | D accuracy: 68.75] [G loss: 1.0529375076293945]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5272 [D loss: 0.6415230631828308 | D accuracy: 59.375] [G loss: 1.0905838012695312]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5273 [D loss: 0.5849829316139221 | D accuracy: 68.75] [G loss: 0.9247440099716187]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5274 [D loss: 0.6542962193489075 | D accuracy: 67.1875] [G loss: 0.9322975873947144]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5275 [D loss: 0.6538224220275879 | D accuracy: 60.9375] [G loss: 1.0498008728027344]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5276 [D loss: 0.6134936511516571 | D accuracy: 68.75] [G loss: 0.8879168033599854]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5277 [D loss: 0.6334014236927032 | D accuracy: 64.0625] [G loss: 0.9279776811599731]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5278 [D loss: 0.5560164749622345 | D accuracy: 79.6875] [G loss: 0.9213096499443054]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5279 [D loss: 0.641079306602478 | D accuracy: 54.6875] [G loss: 0.9827377796173096]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5280 [D loss: 0.5305845141410828 | D accuracy: 78.125] [G loss: 1.034421682357788]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5281 [D loss: 0.5943582653999329 | D accuracy: 73.4375] [G loss: 1.0400865077972412]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5282 [D loss: 0.7100090384483337 | D accuracy: 60.9375] [G loss: 0.9862664341926575]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5283 [D loss: 0.5914057195186615 | D accuracy: 68.75] [G loss: 0.9337985515594482]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5284 [D loss: 0.6514606773853302 | D accuracy: 59.375] [G loss: 0.9818052649497986]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5288 [D loss: 0.6064796149730682 | D accuracy: 60.9375] [G loss: 1.0156168937683105]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5289 [D loss: 0.5710472464561462 | D accuracy: 70.3125] [G loss: 0.965906023979187]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5290 [D loss: 0.5995840728282928 | D accuracy: 70.3125] [G loss: 0.9548577070236206]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5291 [D loss: 0.6230442225933075 | D accuracy: 64.0625] [G loss: 0.9347184896469116]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5292 [D loss: 0.5923694670200348 | D accuracy: 62.5] [G loss: 0.9371739625930786]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5293 [D loss: 0.6156661212444305 | D accuracy: 68.75] [G loss: 1.0233532190322876]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5294 [D loss: 0.5720769762992859 | D accuracy: 68.75] [G loss: 1.0252125263214111]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5295 [D loss: 0.6319873929023743 | D accuracy: 65.625] [G loss: 0.9950536489486694]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5296 [D loss: 0.6004064381122589 | D accuracy: 65.625] [G loss: 0.9988038539886475]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5297 [D loss: 0.6487141847610474 | D accuracy: 62.5] [G loss: 0.9718597531318665]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5298 [D loss: 0.5923840701580048 | D accuracy: 67.1875] [G loss: 0.9756700992584229]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5299 [D loss: 0.6360257863998413 | D accuracy: 56.25] [G loss: 0.8698229789733887]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5300 [D loss: 0.6506304144859314 | D accuracy: 62.5] [G loss: 0.9601043462753296]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5301 [D loss: 0.5803145468235016 | D accuracy: 65.625] [G loss: 1.0368094444274902]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "5302 [D loss: 0.5536967515945435 | D accuracy: 75.0] [G loss: 1.0437698364257812]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "5303 [D loss: 0.5834100246429443 | D accuracy: 64.0625] [G loss: 0.9088094830513]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5304 [D loss: 0.5623565018177032 | D accuracy: 70.3125] [G loss: 0.8057125806808472]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "5305 [D loss: 0.6536824405193329 | D accuracy: 65.625] [G loss: 0.993804395198822]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5306 [D loss: 0.6162053346633911 | D accuracy: 62.5] [G loss: 0.9455341100692749]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "5307 [D loss: 0.6467942595481873 | D accuracy: 62.5] [G loss: 1.0907933712005615]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5308 [D loss: 0.5739379525184631 | D accuracy: 64.0625] [G loss: 0.9790780544281006]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5309 [D loss: 0.6871948838233948 | D accuracy: 53.125] [G loss: 1.0069458484649658]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5310 [D loss: 0.6092483997344971 | D accuracy: 60.9375] [G loss: 1.0178132057189941]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5311 [D loss: 0.6544217467308044 | D accuracy: 65.625] [G loss: 0.9992578029632568]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5312 [D loss: 0.6068086326122284 | D accuracy: 57.8125] [G loss: 0.961520791053772]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5313 [D loss: 0.580053836107254 | D accuracy: 71.875] [G loss: 0.9317225813865662]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5314 [D loss: 0.5505200028419495 | D accuracy: 73.4375] [G loss: 1.1078945398330688]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5315 [D loss: 0.6939156651496887 | D accuracy: 46.875] [G loss: 1.0483955144882202]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5316 [D loss: 0.6756822466850281 | D accuracy: 60.9375] [G loss: 0.9329531192779541]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5317 [D loss: 0.6427237093448639 | D accuracy: 60.9375] [G loss: 0.9588284492492676]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5318 [D loss: 0.6404086649417877 | D accuracy: 60.9375] [G loss: 1.019864797592163]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5319 [D loss: 0.6103043854236603 | D accuracy: 67.1875] [G loss: 0.926406979560852]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5320 [D loss: 0.589736133813858 | D accuracy: 71.875] [G loss: 1.0409104824066162]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5321 [D loss: 0.6219027936458588 | D accuracy: 60.9375] [G loss: 1.0385456085205078]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5322 [D loss: 0.6336806416511536 | D accuracy: 59.375] [G loss: 0.9465566873550415]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5323 [D loss: 0.6420271098613739 | D accuracy: 65.625] [G loss: 1.0257866382598877]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5324 [D loss: 0.5389253199100494 | D accuracy: 73.4375] [G loss: 1.0587689876556396]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5325 [D loss: 0.6276546716690063 | D accuracy: 59.375] [G loss: 1.1240575313568115]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5326 [D loss: 0.582140177488327 | D accuracy: 65.625] [G loss: 1.0676321983337402]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5327 [D loss: 0.5540288090705872 | D accuracy: 70.3125] [G loss: 1.0854392051696777]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5328 [D loss: 0.5940512120723724 | D accuracy: 67.1875] [G loss: 0.9892089366912842]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5329 [D loss: 0.6639348268508911 | D accuracy: 60.9375] [G loss: 0.9141538739204407]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5330 [D loss: 0.5890207290649414 | D accuracy: 70.3125] [G loss: 1.034358024597168]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5331 [D loss: 0.6285277903079987 | D accuracy: 59.375] [G loss: 0.9300128221511841]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5332 [D loss: 0.5874993205070496 | D accuracy: 65.625] [G loss: 0.959923267364502]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5333 [D loss: 0.6126487255096436 | D accuracy: 70.3125] [G loss: 0.9694315195083618]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5334 [D loss: 0.5627911388874054 | D accuracy: 65.625] [G loss: 0.8824030160903931]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5335 [D loss: 0.6091691255569458 | D accuracy: 65.625] [G loss: 0.9830795526504517]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5336 [D loss: 0.587873786687851 | D accuracy: 67.1875] [G loss: 0.9534465670585632]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5337 [D loss: 0.6119015514850616 | D accuracy: 67.1875] [G loss: 1.0482604503631592]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5338 [D loss: 0.6256199777126312 | D accuracy: 64.0625] [G loss: 0.9643763899803162]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5339 [D loss: 0.6124525964260101 | D accuracy: 64.0625] [G loss: 0.9877464771270752]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5340 [D loss: 0.6160722970962524 | D accuracy: 65.625] [G loss: 1.082789421081543]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5341 [D loss: 0.5869375467300415 | D accuracy: 68.75] [G loss: 0.9897047281265259]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5342 [D loss: 0.5525258183479309 | D accuracy: 67.1875] [G loss: 1.105879545211792]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5343 [D loss: 0.6752046048641205 | D accuracy: 56.25] [G loss: 0.9643003940582275]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5344 [D loss: 0.6120156645774841 | D accuracy: 71.875] [G loss: 0.9828342199325562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5345 [D loss: 0.5834233164787292 | D accuracy: 65.625] [G loss: 0.9589155912399292]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5346 [D loss: 0.5593994855880737 | D accuracy: 71.875] [G loss: 1.0074433088302612]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5347 [D loss: 0.5552926361560822 | D accuracy: 76.5625] [G loss: 0.9561797380447388]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5348 [D loss: 0.6455323100090027 | D accuracy: 65.625] [G loss: 0.9614375829696655]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5349 [D loss: 0.62687748670578 | D accuracy: 64.0625] [G loss: 1.014190673828125]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5350 [D loss: 0.5960200130939484 | D accuracy: 64.0625] [G loss: 0.9583094716072083]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5351 [D loss: 0.71674844622612 | D accuracy: 43.75] [G loss: 0.9997638463973999]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5352 [D loss: 0.642408698797226 | D accuracy: 57.8125] [G loss: 0.9853461980819702]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5353 [D loss: 0.615666389465332 | D accuracy: 68.75] [G loss: 1.017500400543213]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5354 [D loss: 0.6040127873420715 | D accuracy: 68.75] [G loss: 1.0226752758026123]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5355 [D loss: 0.6906384825706482 | D accuracy: 57.8125] [G loss: 1.09894597530365]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5356 [D loss: 0.5258685052394867 | D accuracy: 76.5625] [G loss: 1.0325677394866943]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5357 [D loss: 0.596487820148468 | D accuracy: 71.875] [G loss: 1.0598046779632568]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5358 [D loss: 0.5833229124546051 | D accuracy: 76.5625] [G loss: 1.0236459970474243]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5359 [D loss: 0.620505303144455 | D accuracy: 60.9375] [G loss: 0.920699954032898]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5360 [D loss: 0.5604282021522522 | D accuracy: 71.875] [G loss: 0.9568437933921814]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5361 [D loss: 0.5512021481990814 | D accuracy: 71.875] [G loss: 1.0636920928955078]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5362 [D loss: 0.6255140006542206 | D accuracy: 67.1875] [G loss: 1.077944278717041]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5363 [D loss: 0.6114314496517181 | D accuracy: 67.1875] [G loss: 1.0010091066360474]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5364 [D loss: 0.6398425698280334 | D accuracy: 64.0625] [G loss: 1.0357509851455688]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5365 [D loss: 0.5965111255645752 | D accuracy: 64.0625] [G loss: 0.9597364664077759]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5366 [D loss: 0.6083699762821198 | D accuracy: 65.625] [G loss: 0.9860237836837769]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5367 [D loss: 0.6697571575641632 | D accuracy: 59.375] [G loss: 0.9533792734146118]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5368 [D loss: 0.5277784913778305 | D accuracy: 73.4375] [G loss: 1.0336227416992188]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5369 [D loss: 0.663318395614624 | D accuracy: 56.25] [G loss: 0.9905391931533813]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5370 [D loss: 0.5894679427146912 | D accuracy: 64.0625] [G loss: 1.0185343027114868]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5371 [D loss: 0.641907811164856 | D accuracy: 64.0625] [G loss: 1.0225777626037598]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5372 [D loss: 0.5964103043079376 | D accuracy: 73.4375] [G loss: 0.9360950589179993]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5373 [D loss: 0.6291538178920746 | D accuracy: 56.25] [G loss: 0.9772027134895325]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5374 [D loss: 0.6526439189910889 | D accuracy: 64.0625] [G loss: 1.023360252380371]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5375 [D loss: 0.5504580438137054 | D accuracy: 75.0] [G loss: 1.0059220790863037]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5376 [D loss: 0.6450949907302856 | D accuracy: 57.8125] [G loss: 1.1362375020980835]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5377 [D loss: 0.6219897866249084 | D accuracy: 64.0625] [G loss: 1.099687099456787]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5378 [D loss: 0.6494137644767761 | D accuracy: 64.0625] [G loss: 1.0465974807739258]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5379 [D loss: 0.5595238506793976 | D accuracy: 71.875] [G loss: 1.0351471900939941]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5380 [D loss: 0.5866626501083374 | D accuracy: 62.5] [G loss: 1.0257558822631836]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5381 [D loss: 0.5583377480506897 | D accuracy: 75.0] [G loss: 0.9202762842178345]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5382 [D loss: 0.615917980670929 | D accuracy: 67.1875] [G loss: 0.9218670129776001]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5383 [D loss: 0.5994343459606171 | D accuracy: 64.0625] [G loss: 1.0385509729385376]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5384 [D loss: 0.6173782348632812 | D accuracy: 64.0625] [G loss: 0.9641025066375732]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5385 [D loss: 0.6565138697624207 | D accuracy: 59.375] [G loss: 0.9811812043190002]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5386 [D loss: 0.6090586185455322 | D accuracy: 65.625] [G loss: 0.994206428527832]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "5387 [D loss: 0.5643573105335236 | D accuracy: 64.0625] [G loss: 1.1049449443817139]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5388 [D loss: 0.6454175710678101 | D accuracy: 57.8125] [G loss: 0.9762618541717529]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5389 [D loss: 0.6197960674762726 | D accuracy: 70.3125] [G loss: 1.0214141607284546]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5390 [D loss: 0.587104469537735 | D accuracy: 65.625] [G loss: 1.0371557474136353]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5391 [D loss: 0.5810525119304657 | D accuracy: 67.1875] [G loss: 0.9785584211349487]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5392 [D loss: 0.6580090522766113 | D accuracy: 64.0625] [G loss: 0.9267863035202026]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5393 [D loss: 0.6505705714225769 | D accuracy: 60.9375] [G loss: 0.9126405119895935]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5394 [D loss: 0.6474945545196533 | D accuracy: 57.8125] [G loss: 1.0136775970458984]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5395 [D loss: 0.6306651830673218 | D accuracy: 62.5] [G loss: 0.9742096662521362]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5396 [D loss: 0.6413484811782837 | D accuracy: 64.0625] [G loss: 0.9851986169815063]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5397 [D loss: 0.5947777628898621 | D accuracy: 60.9375] [G loss: 1.0819411277770996]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5398 [D loss: 0.5745052099227905 | D accuracy: 67.1875] [G loss: 1.077659010887146]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5399 [D loss: 0.5601593554019928 | D accuracy: 73.4375] [G loss: 0.9751737117767334]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "5400 [D loss: 0.6143170297145844 | D accuracy: 65.625] [G loss: 1.0238111019134521]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5401 [D loss: 0.6262378096580505 | D accuracy: 56.25] [G loss: 0.936884880065918]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5402 [D loss: 0.6058715879917145 | D accuracy: 62.5] [G loss: 1.0038620233535767]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5403 [D loss: 0.5734458863735199 | D accuracy: 76.5625] [G loss: 0.9567748308181763]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5404 [D loss: 0.6726715564727783 | D accuracy: 59.375] [G loss: 1.0621980428695679]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5405 [D loss: 0.5482814013957977 | D accuracy: 76.5625] [G loss: 1.0131891965866089]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5406 [D loss: 0.6763388514518738 | D accuracy: 59.375] [G loss: 1.0423641204833984]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5407 [D loss: 0.5463622510433197 | D accuracy: 76.5625] [G loss: 1.0394479036331177]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5408 [D loss: 0.5979160368442535 | D accuracy: 67.1875] [G loss: 1.0005552768707275]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5409 [D loss: 0.6168312430381775 | D accuracy: 67.1875] [G loss: 1.133597731590271]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5410 [D loss: 0.600983202457428 | D accuracy: 70.3125] [G loss: 1.097084641456604]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5411 [D loss: 0.6299096345901489 | D accuracy: 64.0625] [G loss: 0.9532510042190552]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5412 [D loss: 0.5986120998859406 | D accuracy: 67.1875] [G loss: 1.0043973922729492]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5413 [D loss: 0.6376130878925323 | D accuracy: 64.0625] [G loss: 0.948236346244812]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5414 [D loss: 0.5633740723133087 | D accuracy: 67.1875] [G loss: 0.9394084215164185]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5415 [D loss: 0.6323776543140411 | D accuracy: 54.6875] [G loss: 0.9912102222442627]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5416 [D loss: 0.5998001396656036 | D accuracy: 62.5] [G loss: 0.9980244636535645]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5417 [D loss: 0.5757027268409729 | D accuracy: 67.1875] [G loss: 1.1475857496261597]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5418 [D loss: 0.6126313209533691 | D accuracy: 64.0625] [G loss: 0.956680178642273]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5419 [D loss: 0.5614306032657623 | D accuracy: 68.75] [G loss: 0.9871338605880737]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5420 [D loss: 0.6959657669067383 | D accuracy: 57.8125] [G loss: 0.9682642221450806]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5421 [D loss: 0.6036273539066315 | D accuracy: 70.3125] [G loss: 1.0909017324447632]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5422 [D loss: 0.6485094130039215 | D accuracy: 67.1875] [G loss: 1.022098422050476]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5423 [D loss: 0.5768856108188629 | D accuracy: 73.4375] [G loss: 0.9928771257400513]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5424 [D loss: 0.6541208028793335 | D accuracy: 62.5] [G loss: 1.1310875415802002]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5425 [D loss: 0.6032479852437973 | D accuracy: 67.1875] [G loss: 0.9947522878646851]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5426 [D loss: 0.6077739596366882 | D accuracy: 64.0625] [G loss: 0.9948316216468811]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5427 [D loss: 0.6154333055019379 | D accuracy: 65.625] [G loss: 1.0089752674102783]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5428 [D loss: 0.6636338829994202 | D accuracy: 62.5] [G loss: 1.0912129878997803]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5429 [D loss: 0.6372823119163513 | D accuracy: 59.375] [G loss: 1.0426182746887207]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5430 [D loss: 0.6995304822921753 | D accuracy: 48.4375] [G loss: 1.0085532665252686]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5431 [D loss: 0.5963424146175385 | D accuracy: 75.0] [G loss: 1.0002083778381348]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5432 [D loss: 0.5331615209579468 | D accuracy: 73.4375] [G loss: 0.9777186512947083]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5433 [D loss: 0.6338621079921722 | D accuracy: 57.8125] [G loss: 0.8989220857620239]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5434 [D loss: 0.5328792035579681 | D accuracy: 78.125] [G loss: 0.9476151466369629]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5435 [D loss: 0.6274838149547577 | D accuracy: 60.9375] [G loss: 0.9219441413879395]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5436 [D loss: 0.6161740720272064 | D accuracy: 70.3125] [G loss: 0.945277988910675]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5437 [D loss: 0.6464019119739532 | D accuracy: 51.5625] [G loss: 0.9186252951622009]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5438 [D loss: 0.590361088514328 | D accuracy: 64.0625] [G loss: 0.9233663082122803]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5439 [D loss: 0.6152230799198151 | D accuracy: 67.1875] [G loss: 1.0216577053070068]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5440 [D loss: 0.5279858112335205 | D accuracy: 78.125] [G loss: 1.069432258605957]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5441 [D loss: 0.6324511468410492 | D accuracy: 54.6875] [G loss: 1.023207664489746]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5442 [D loss: 0.5209626704454422 | D accuracy: 82.8125] [G loss: 1.0303603410720825]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5443 [D loss: 0.5572633147239685 | D accuracy: 71.875] [G loss: 1.0161536931991577]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5444 [D loss: 0.5517522990703583 | D accuracy: 76.5625] [G loss: 1.0256654024124146]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5445 [D loss: 0.6124610602855682 | D accuracy: 73.4375] [G loss: 1.0069777965545654]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5446 [D loss: 0.6444852352142334 | D accuracy: 65.625] [G loss: 1.023813247680664]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5447 [D loss: 0.7004739344120026 | D accuracy: 53.125] [G loss: 1.0779500007629395]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5448 [D loss: 0.6288447380065918 | D accuracy: 60.9375] [G loss: 0.9398084282875061]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5449 [D loss: 0.6582936644554138 | D accuracy: 59.375] [G loss: 1.0173625946044922]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5450 [D loss: 0.6621699929237366 | D accuracy: 64.0625] [G loss: 0.9807278513908386]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5451 [D loss: 0.5507395267486572 | D accuracy: 75.0] [G loss: 0.9764801263809204]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5452 [D loss: 0.6760722100734711 | D accuracy: 54.6875] [G loss: 1.0018486976623535]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5453 [D loss: 0.5615772902965546 | D accuracy: 65.625] [G loss: 0.9588570594787598]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5454 [D loss: 0.6079491674900055 | D accuracy: 67.1875] [G loss: 1.0614877939224243]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5455 [D loss: 0.6296093165874481 | D accuracy: 60.9375] [G loss: 1.0267406702041626]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5456 [D loss: 0.698284924030304 | D accuracy: 59.375] [G loss: 1.0459035634994507]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5457 [D loss: 0.6297491192817688 | D accuracy: 64.0625] [G loss: 1.0410836935043335]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5458 [D loss: 0.6512753963470459 | D accuracy: 56.25] [G loss: 1.1153686046600342]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5459 [D loss: 0.6452130079269409 | D accuracy: 60.9375] [G loss: 1.0489084720611572]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5460 [D loss: 0.5468871295452118 | D accuracy: 71.875] [G loss: 1.084211826324463]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5461 [D loss: 0.6077536046504974 | D accuracy: 65.625] [G loss: 1.0261330604553223]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5462 [D loss: 0.6700217723846436 | D accuracy: 57.8125] [G loss: 0.9421367645263672]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5463 [D loss: 0.5652388334274292 | D accuracy: 70.3125] [G loss: 1.0397083759307861]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5464 [D loss: 0.6401395499706268 | D accuracy: 60.9375] [G loss: 1.0622133016586304]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "5465 [D loss: 0.680996835231781 | D accuracy: 56.25] [G loss: 1.0115574598312378]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5466 [D loss: 0.6496436893939972 | D accuracy: 64.0625] [G loss: 1.0726395845413208]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5467 [D loss: 0.5877358615398407 | D accuracy: 70.3125] [G loss: 1.0371735095977783]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5468 [D loss: 0.5739921480417252 | D accuracy: 71.875] [G loss: 1.0601508617401123]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5469 [D loss: 0.6610702276229858 | D accuracy: 64.0625] [G loss: 0.9635486602783203]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "5470 [D loss: 0.6227700114250183 | D accuracy: 65.625] [G loss: 0.9416074752807617]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5471 [D loss: 0.6103769540786743 | D accuracy: 71.875] [G loss: 0.8821808695793152]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5472 [D loss: 0.6035544872283936 | D accuracy: 59.375] [G loss: 0.950919508934021]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "5473 [D loss: 0.609639436006546 | D accuracy: 65.625] [G loss: 0.9467253684997559]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5474 [D loss: 0.5997554063796997 | D accuracy: 70.3125] [G loss: 0.8486095666885376]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5475 [D loss: 0.6738816201686859 | D accuracy: 62.5] [G loss: 1.0170073509216309]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5476 [D loss: 0.550379604101181 | D accuracy: 70.3125] [G loss: 1.017845869064331]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5477 [D loss: 0.5917114913463593 | D accuracy: 68.75] [G loss: 0.9061335325241089]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5478 [D loss: 0.5890160202980042 | D accuracy: 62.5] [G loss: 0.9865888357162476]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5479 [D loss: 0.5896562337875366 | D accuracy: 73.4375] [G loss: 1.0008293390274048]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5480 [D loss: 0.5703893154859543 | D accuracy: 78.125] [G loss: 1.0426498651504517]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5481 [D loss: 0.575782060623169 | D accuracy: 70.3125] [G loss: 1.0114719867706299]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5482 [D loss: 0.6314913034439087 | D accuracy: 56.25] [G loss: 0.9765545725822449]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5483 [D loss: 0.6776410043239594 | D accuracy: 50.0] [G loss: 0.9548341035842896]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5484 [D loss: 0.5319495499134064 | D accuracy: 76.5625] [G loss: 0.9763491153717041]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5485 [D loss: 0.5921667516231537 | D accuracy: 67.1875] [G loss: 1.0187475681304932]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5486 [D loss: 0.6735200881958008 | D accuracy: 57.8125] [G loss: 0.9667888283729553]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5487 [D loss: 0.6148464679718018 | D accuracy: 60.9375] [G loss: 0.8589247465133667]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5488 [D loss: 0.6428959667682648 | D accuracy: 60.9375] [G loss: 1.0197944641113281]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5489 [D loss: 0.632688969373703 | D accuracy: 62.5] [G loss: 1.0023434162139893]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5490 [D loss: 0.5878771841526031 | D accuracy: 67.1875] [G loss: 0.967366099357605]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5491 [D loss: 0.6375758945941925 | D accuracy: 57.8125] [G loss: 1.0706802606582642]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5492 [D loss: 0.6537218689918518 | D accuracy: 68.75] [G loss: 1.0203897953033447]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5493 [D loss: 0.6152786612510681 | D accuracy: 65.625] [G loss: 1.0095982551574707]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5494 [D loss: 0.5770459473133087 | D accuracy: 67.1875] [G loss: 0.9330207705497742]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5495 [D loss: 0.6408475637435913 | D accuracy: 62.5] [G loss: 0.9721287488937378]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5496 [D loss: 0.6449953019618988 | D accuracy: 68.75] [G loss: 0.9522560834884644]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5497 [D loss: 0.6577656269073486 | D accuracy: 60.9375] [G loss: 0.9464402198791504]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5498 [D loss: 0.6053696274757385 | D accuracy: 60.9375] [G loss: 0.9764930605888367]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5499 [D loss: 0.6454688906669617 | D accuracy: 60.9375] [G loss: 0.9210387468338013]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5500 [D loss: 0.6378685534000397 | D accuracy: 64.0625] [G loss: 0.9868409633636475]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5501 [D loss: 0.7113083600997925 | D accuracy: 54.6875] [G loss: 0.9216872453689575]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5502 [D loss: 0.6257778108119965 | D accuracy: 62.5] [G loss: 0.9219615459442139]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5503 [D loss: 0.6772486865520477 | D accuracy: 62.5] [G loss: 0.9575602412223816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5504 [D loss: 0.675622969865799 | D accuracy: 57.8125] [G loss: 0.956832766532898]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5505 [D loss: 0.6250123679637909 | D accuracy: 60.9375] [G loss: 1.0052781105041504]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5506 [D loss: 0.5922471582889557 | D accuracy: 68.75] [G loss: 0.9634089469909668]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5507 [D loss: 0.6554380059242249 | D accuracy: 57.8125] [G loss: 0.9484349489212036]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5508 [D loss: 0.5623470544815063 | D accuracy: 71.875] [G loss: 1.041219711303711]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5509 [D loss: 0.6228283643722534 | D accuracy: 71.875] [G loss: 0.9544458389282227]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5510 [D loss: 0.702860027551651 | D accuracy: 54.6875] [G loss: 0.9920634031295776]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5511 [D loss: 0.5394999086856842 | D accuracy: 71.875] [G loss: 1.0701956748962402]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5512 [D loss: 0.5527731776237488 | D accuracy: 70.3125] [G loss: 0.980789303779602]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5513 [D loss: 0.5652045011520386 | D accuracy: 71.875] [G loss: 1.0416589975357056]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5514 [D loss: 0.5414307713508606 | D accuracy: 73.4375] [G loss: 1.0349388122558594]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5515 [D loss: 0.6175130009651184 | D accuracy: 68.75] [G loss: 1.0226829051971436]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5516 [D loss: 0.5731627941131592 | D accuracy: 73.4375] [G loss: 1.072737455368042]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5517 [D loss: 0.5785952806472778 | D accuracy: 71.875] [G loss: 1.1363328695297241]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5518 [D loss: 0.5788841992616653 | D accuracy: 64.0625] [G loss: 1.0704699754714966]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5519 [D loss: 0.618493527173996 | D accuracy: 65.625] [G loss: 1.0502383708953857]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5520 [D loss: 0.5689097940921783 | D accuracy: 68.75] [G loss: 0.9682886004447937]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5521 [D loss: 0.5647343993186951 | D accuracy: 71.875] [G loss: 1.0042011737823486]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5522 [D loss: 0.6449846625328064 | D accuracy: 59.375] [G loss: 1.076022982597351]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5523 [D loss: 0.6761510968208313 | D accuracy: 51.5625] [G loss: 1.0716780424118042]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5524 [D loss: 0.6617647409439087 | D accuracy: 64.0625] [G loss: 0.9925197958946228]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5525 [D loss: 0.5799310803413391 | D accuracy: 68.75] [G loss: 0.9916930198669434]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5526 [D loss: 0.5841885507106781 | D accuracy: 65.625] [G loss: 0.9784795045852661]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5527 [D loss: 0.6435504257678986 | D accuracy: 60.9375] [G loss: 0.9470762610435486]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5528 [D loss: 0.5185045599937439 | D accuracy: 73.4375] [G loss: 1.077056884765625]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5529 [D loss: 0.6865499019622803 | D accuracy: 59.375] [G loss: 1.0133854150772095]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5530 [D loss: 0.6014115214347839 | D accuracy: 65.625] [G loss: 0.9983673095703125]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5531 [D loss: 0.5901484787464142 | D accuracy: 70.3125] [G loss: 1.0118498802185059]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5532 [D loss: 0.6434486508369446 | D accuracy: 60.9375] [G loss: 1.006044626235962]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5533 [D loss: 0.6705634891986847 | D accuracy: 59.375] [G loss: 1.0021023750305176]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5534 [D loss: 0.6119623482227325 | D accuracy: 70.3125] [G loss: 0.9886506199836731]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5535 [D loss: 0.6581268906593323 | D accuracy: 56.25] [G loss: 1.015918254852295]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5536 [D loss: 0.5779906511306763 | D accuracy: 70.3125] [G loss: 0.9901195168495178]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5537 [D loss: 0.6108196079730988 | D accuracy: 65.625] [G loss: 1.0495308637619019]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5538 [D loss: 0.6093692481517792 | D accuracy: 60.9375] [G loss: 0.9825524091720581]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5539 [D loss: 0.5454007387161255 | D accuracy: 76.5625] [G loss: 0.9840598106384277]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5540 [D loss: 0.6521515548229218 | D accuracy: 60.9375] [G loss: 1.0045281648635864]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5541 [D loss: 0.6462149322032928 | D accuracy: 67.1875] [G loss: 0.9911103248596191]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5542 [D loss: 0.5911968946456909 | D accuracy: 71.875] [G loss: 0.9200408458709717]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5543 [D loss: 0.6118857264518738 | D accuracy: 67.1875] [G loss: 1.056044101715088]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5544 [D loss: 0.5685088038444519 | D accuracy: 73.4375] [G loss: 1.0047446489334106]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5545 [D loss: 0.6160382628440857 | D accuracy: 62.5] [G loss: 0.9199621677398682]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5546 [D loss: 0.6088180840015411 | D accuracy: 62.5] [G loss: 0.9808065891265869]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5547 [D loss: 0.6429896354675293 | D accuracy: 59.375] [G loss: 1.0115022659301758]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5548 [D loss: 0.7113412022590637 | D accuracy: 60.9375] [G loss: 0.9648487567901611]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "5549 [D loss: 0.5978580117225647 | D accuracy: 70.3125] [G loss: 1.0009818077087402]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5550 [D loss: 0.6254740953445435 | D accuracy: 65.625] [G loss: 1.0793211460113525]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5551 [D loss: 0.576166570186615 | D accuracy: 71.875] [G loss: 0.9366323947906494]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5552 [D loss: 0.598430722951889 | D accuracy: 73.4375] [G loss: 1.0018880367279053]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5553 [D loss: 0.6188147664070129 | D accuracy: 57.8125] [G loss: 1.055755615234375]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5554 [D loss: 0.6246578991413116 | D accuracy: 59.375] [G loss: 1.0667155981063843]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5555 [D loss: 0.618837296962738 | D accuracy: 64.0625] [G loss: 1.0114414691925049]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5556 [D loss: 0.6414337754249573 | D accuracy: 60.9375] [G loss: 0.9411466717720032]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5557 [D loss: 0.6921201646327972 | D accuracy: 56.25] [G loss: 0.9633262157440186]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5558 [D loss: 0.6256745755672455 | D accuracy: 60.9375] [G loss: 1.0444896221160889]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5559 [D loss: 0.600383460521698 | D accuracy: 73.4375] [G loss: 0.9849162101745605]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5560 [D loss: 0.565140962600708 | D accuracy: 71.875] [G loss: 1.010297417640686]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5561 [D loss: 0.5883048474788666 | D accuracy: 68.75] [G loss: 0.9947326183319092]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5562 [D loss: 0.5956606268882751 | D accuracy: 67.1875] [G loss: 1.026777982711792]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5563 [D loss: 0.5517700910568237 | D accuracy: 73.4375] [G loss: 0.9772853851318359]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5564 [D loss: 0.6157240271568298 | D accuracy: 65.625] [G loss: 1.0876085758209229]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5565 [D loss: 0.6510571539402008 | D accuracy: 64.0625] [G loss: 0.9876806735992432]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5566 [D loss: 0.6279341578483582 | D accuracy: 59.375] [G loss: 1.1106599569320679]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5567 [D loss: 0.5982882678508759 | D accuracy: 68.75] [G loss: 0.9806622266769409]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5568 [D loss: 0.550180047750473 | D accuracy: 70.3125] [G loss: 1.0167278051376343]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5569 [D loss: 0.6280543804168701 | D accuracy: 57.8125] [G loss: 1.0234932899475098]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5570 [D loss: 0.6486530005931854 | D accuracy: 67.1875] [G loss: 1.0388847589492798]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5571 [D loss: 0.6101889908313751 | D accuracy: 64.0625] [G loss: 0.987637996673584]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5572 [D loss: 0.5912221968173981 | D accuracy: 71.875] [G loss: 0.9199208617210388]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5573 [D loss: 0.6003403961658478 | D accuracy: 73.4375] [G loss: 1.0214043855667114]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5574 [D loss: 0.6588291823863983 | D accuracy: 56.25] [G loss: 1.0405683517456055]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5575 [D loss: 0.6082144975662231 | D accuracy: 65.625] [G loss: 1.0755139589309692]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5576 [D loss: 0.6254547834396362 | D accuracy: 56.25] [G loss: 0.9618927836418152]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5577 [D loss: 0.6565215289592743 | D accuracy: 65.625] [G loss: 0.944846510887146]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5578 [D loss: 0.6164556741714478 | D accuracy: 68.75] [G loss: 0.9887348413467407]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5579 [D loss: 0.5926586985588074 | D accuracy: 68.75] [G loss: 0.9438233375549316]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5580 [D loss: 0.6519375741481781 | D accuracy: 65.625] [G loss: 0.8779392242431641]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5581 [D loss: 0.5657460391521454 | D accuracy: 67.1875] [G loss: 0.9919900298118591]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5582 [D loss: 0.6299308836460114 | D accuracy: 59.375] [G loss: 1.1031079292297363]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5583 [D loss: 0.6348898708820343 | D accuracy: 65.625] [G loss: 1.015192985534668]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5584 [D loss: 0.5652861893177032 | D accuracy: 71.875] [G loss: 1.0207972526550293]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5585 [D loss: 0.6386484801769257 | D accuracy: 60.9375] [G loss: 0.9146053194999695]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5586 [D loss: 0.6552386581897736 | D accuracy: 59.375] [G loss: 1.0547809600830078]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5587 [D loss: 0.6596863865852356 | D accuracy: 57.8125] [G loss: 1.0400124788284302]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5588 [D loss: 0.6364039778709412 | D accuracy: 60.9375] [G loss: 1.081669807434082]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5589 [D loss: 0.5973629653453827 | D accuracy: 68.75] [G loss: 0.9834219217300415]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5590 [D loss: 0.6147084832191467 | D accuracy: 64.0625] [G loss: 1.032278060913086]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5591 [D loss: 0.5240417420864105 | D accuracy: 76.5625] [G loss: 1.0260355472564697]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5592 [D loss: 0.6257261335849762 | D accuracy: 70.3125] [G loss: 1.1719601154327393]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5593 [D loss: 0.6263319849967957 | D accuracy: 64.0625] [G loss: 1.0510294437408447]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5594 [D loss: 0.5598970651626587 | D accuracy: 76.5625] [G loss: 1.0789282321929932]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5595 [D loss: 0.6448843777179718 | D accuracy: 60.9375] [G loss: 1.039416790008545]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5596 [D loss: 0.589062362909317 | D accuracy: 71.875] [G loss: 0.9739964008331299]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5597 [D loss: 0.5820139646530151 | D accuracy: 68.75] [G loss: 0.9823920726776123]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5598 [D loss: 0.5357433557510376 | D accuracy: 70.3125] [G loss: 0.9609045386314392]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5599 [D loss: 0.7023767530918121 | D accuracy: 54.6875] [G loss: 0.9875501990318298]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5600 [D loss: 0.6209639608860016 | D accuracy: 64.0625] [G loss: 0.9808480143547058]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5601 [D loss: 0.6284146308898926 | D accuracy: 68.75] [G loss: 0.9885368347167969]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5602 [D loss: 0.6444877982139587 | D accuracy: 62.5] [G loss: 0.9445732831954956]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5603 [D loss: 0.5430367887020111 | D accuracy: 71.875] [G loss: 1.1234935522079468]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5604 [D loss: 0.6950843930244446 | D accuracy: 62.5] [G loss: 0.9218025207519531]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5605 [D loss: 0.5687835514545441 | D accuracy: 70.3125] [G loss: 0.9557201862335205]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5606 [D loss: 0.5701524913311005 | D accuracy: 75.0] [G loss: 1.0155762434005737]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5607 [D loss: 0.5791248977184296 | D accuracy: 70.3125] [G loss: 1.0068343877792358]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5608 [D loss: 0.5804330706596375 | D accuracy: 70.3125] [G loss: 0.9519553184509277]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5609 [D loss: 0.5846928358078003 | D accuracy: 67.1875] [G loss: 1.0209474563598633]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5610 [D loss: 0.5620095431804657 | D accuracy: 70.3125] [G loss: 1.0125796794891357]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5611 [D loss: 0.5795086920261383 | D accuracy: 70.3125] [G loss: 1.012159824371338]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5612 [D loss: 0.5736127495765686 | D accuracy: 68.75] [G loss: 0.989867627620697]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5613 [D loss: 0.5321149379014969 | D accuracy: 75.0] [G loss: 1.037818431854248]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5614 [D loss: 0.6162669956684113 | D accuracy: 62.5] [G loss: 1.0389902591705322]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5615 [D loss: 0.5502414107322693 | D accuracy: 76.5625] [G loss: 1.0312042236328125]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5616 [D loss: 0.5968139469623566 | D accuracy: 73.4375] [G loss: 0.973242998123169]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5617 [D loss: 0.5999240279197693 | D accuracy: 62.5] [G loss: 1.0532972812652588]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5618 [D loss: 0.5763868987560272 | D accuracy: 68.75] [G loss: 0.9860334396362305]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5619 [D loss: 0.6618621349334717 | D accuracy: 56.25] [G loss: 1.0416136980056763]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5620 [D loss: 0.6632538735866547 | D accuracy: 67.1875] [G loss: 0.9297618269920349]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5621 [D loss: 0.6602954268455505 | D accuracy: 60.9375] [G loss: 1.0117931365966797]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "5622 [D loss: 0.6309303641319275 | D accuracy: 60.9375] [G loss: 1.0424327850341797]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5623 [D loss: 0.6278398633003235 | D accuracy: 59.375] [G loss: 1.0055341720581055]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5624 [D loss: 0.5438401103019714 | D accuracy: 68.75] [G loss: 1.0048812627792358]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5625 [D loss: 0.5636802613735199 | D accuracy: 68.75] [G loss: 1.0213041305541992]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5626 [D loss: 0.6230155527591705 | D accuracy: 60.9375] [G loss: 0.9883434772491455]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "5627 [D loss: 0.5691241919994354 | D accuracy: 70.3125] [G loss: 1.0597255229949951]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5628 [D loss: 0.6566343903541565 | D accuracy: 59.375] [G loss: 0.9852922558784485]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5629 [D loss: 0.6154185831546783 | D accuracy: 67.1875] [G loss: 1.0707476139068604]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5630 [D loss: 0.5583074986934662 | D accuracy: 73.4375] [G loss: 1.0809011459350586]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5631 [D loss: 0.536083847284317 | D accuracy: 70.3125] [G loss: 1.0634015798568726]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5632 [D loss: 0.592952311038971 | D accuracy: 68.75] [G loss: 1.0767422914505005]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5633 [D loss: 0.5857994556427002 | D accuracy: 68.75] [G loss: 1.041062593460083]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5634 [D loss: 0.5916610956192017 | D accuracy: 64.0625] [G loss: 0.9319429397583008]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5635 [D loss: 0.6386052370071411 | D accuracy: 65.625] [G loss: 1.0396841764450073]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5636 [D loss: 0.654746949672699 | D accuracy: 57.8125] [G loss: 0.9779127240180969]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5637 [D loss: 0.5723264217376709 | D accuracy: 68.75] [G loss: 1.0507681369781494]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5638 [D loss: 0.5723560750484467 | D accuracy: 75.0] [G loss: 1.0459600687026978]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5639 [D loss: 0.6446698307991028 | D accuracy: 60.9375] [G loss: 1.0383708477020264]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5640 [D loss: 0.5630614459514618 | D accuracy: 65.625] [G loss: 0.9876132011413574]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5641 [D loss: 0.5415607392787933 | D accuracy: 79.6875] [G loss: 1.0363595485687256]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5642 [D loss: 0.531412199139595 | D accuracy: 70.3125] [G loss: 1.0064327716827393]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5643 [D loss: 0.6644584536552429 | D accuracy: 64.0625] [G loss: 0.9292008876800537]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5644 [D loss: 0.6505207717418671 | D accuracy: 60.9375] [G loss: 0.9887838363647461]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5645 [D loss: 0.6329212188720703 | D accuracy: 60.9375] [G loss: 1.139686107635498]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5646 [D loss: 0.6482507586479187 | D accuracy: 62.5] [G loss: 1.1134437322616577]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5647 [D loss: 0.65597003698349 | D accuracy: 65.625] [G loss: 1.0282835960388184]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5648 [D loss: 0.5971372127532959 | D accuracy: 70.3125] [G loss: 1.0659594535827637]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5649 [D loss: 0.5882900059223175 | D accuracy: 68.75] [G loss: 0.9821773767471313]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5650 [D loss: 0.7106953263282776 | D accuracy: 46.875] [G loss: 0.9701075553894043]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5651 [D loss: 0.6565174758434296 | D accuracy: 53.125] [G loss: 1.0231727361679077]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5652 [D loss: 0.5864754319190979 | D accuracy: 67.1875] [G loss: 1.056572437286377]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5653 [D loss: 0.5830399096012115 | D accuracy: 68.75] [G loss: 0.9946212768554688]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5654 [D loss: 0.6662538051605225 | D accuracy: 59.375] [G loss: 1.056982398033142]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5655 [D loss: 0.6041238605976105 | D accuracy: 68.75] [G loss: 0.9829387664794922]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5656 [D loss: 0.5050502121448517 | D accuracy: 79.6875] [G loss: 1.008676290512085]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5657 [D loss: 0.595736563205719 | D accuracy: 62.5] [G loss: 0.974010169506073]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5658 [D loss: 0.6076198518276215 | D accuracy: 64.0625] [G loss: 1.0317519903182983]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5659 [D loss: 0.6262339651584625 | D accuracy: 65.625] [G loss: 0.9638397097587585]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5660 [D loss: 0.7139498293399811 | D accuracy: 59.375] [G loss: 0.9375988245010376]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5661 [D loss: 0.5922343730926514 | D accuracy: 73.4375] [G loss: 0.9364169836044312]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5662 [D loss: 0.6043111979961395 | D accuracy: 65.625] [G loss: 0.9625725150108337]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5663 [D loss: 0.5764371156692505 | D accuracy: 73.4375] [G loss: 0.9951229095458984]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5664 [D loss: 0.6946319937705994 | D accuracy: 51.5625] [G loss: 1.043624758720398]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5665 [D loss: 0.583703488111496 | D accuracy: 73.4375] [G loss: 1.021009087562561]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5666 [D loss: 0.5226631164550781 | D accuracy: 75.0] [G loss: 1.0740246772766113]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5667 [D loss: 0.5746556520462036 | D accuracy: 70.3125] [G loss: 1.057588815689087]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5668 [D loss: 0.5940439701080322 | D accuracy: 65.625] [G loss: 0.9567955732345581]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5669 [D loss: 0.49336016178131104 | D accuracy: 73.4375] [G loss: 1.098002314567566]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5670 [D loss: 0.6694829165935516 | D accuracy: 57.8125] [G loss: 1.0434513092041016]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5671 [D loss: 0.5516312420368195 | D accuracy: 73.4375] [G loss: 1.039284110069275]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5672 [D loss: 0.6246650815010071 | D accuracy: 59.375] [G loss: 1.0108428001403809]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5673 [D loss: 0.6393758654594421 | D accuracy: 57.8125] [G loss: 1.0208964347839355]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5674 [D loss: 0.6225024461746216 | D accuracy: 65.625] [G loss: 0.978977382183075]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5675 [D loss: 0.6569410562515259 | D accuracy: 56.25] [G loss: 0.9414968490600586]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5676 [D loss: 0.6033296883106232 | D accuracy: 65.625] [G loss: 0.9636871814727783]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5677 [D loss: 0.6065756678581238 | D accuracy: 65.625] [G loss: 0.8994089961051941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5678 [D loss: 0.5852962136268616 | D accuracy: 67.1875] [G loss: 0.9653142690658569]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5679 [D loss: 0.5786189138889313 | D accuracy: 75.0] [G loss: 1.0158758163452148]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5680 [D loss: 0.6769697964191437 | D accuracy: 57.8125] [G loss: 1.0384807586669922]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5681 [D loss: 0.5929681956768036 | D accuracy: 71.875] [G loss: 1.0041532516479492]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5682 [D loss: 0.5880098640918732 | D accuracy: 68.75] [G loss: 1.027016282081604]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5683 [D loss: 0.5799737274646759 | D accuracy: 70.3125] [G loss: 1.0108287334442139]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5684 [D loss: 0.6490321159362793 | D accuracy: 62.5] [G loss: 1.1063618659973145]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5685 [D loss: 0.5682098865509033 | D accuracy: 71.875] [G loss: 0.9385401010513306]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5686 [D loss: 0.49267910420894623 | D accuracy: 79.6875] [G loss: 1.1007826328277588]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5687 [D loss: 0.5947944521903992 | D accuracy: 64.0625] [G loss: 1.1464420557022095]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5688 [D loss: 0.5871410369873047 | D accuracy: 62.5] [G loss: 1.0114349126815796]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5689 [D loss: 0.672741174697876 | D accuracy: 53.125] [G loss: 1.0521941184997559]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5690 [D loss: 0.6283542215824127 | D accuracy: 64.0625] [G loss: 0.9833234548568726]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5691 [D loss: 0.6269260346889496 | D accuracy: 62.5] [G loss: 0.9736396670341492]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5692 [D loss: 0.698773205280304 | D accuracy: 54.6875] [G loss: 0.9483412504196167]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5693 [D loss: 0.6044509708881378 | D accuracy: 68.75] [G loss: 1.0067805051803589]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5694 [D loss: 0.6260316669940948 | D accuracy: 60.9375] [G loss: 1.0086272954940796]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5695 [D loss: 0.6033116281032562 | D accuracy: 67.1875] [G loss: 1.0055296421051025]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5696 [D loss: 0.5123470425605774 | D accuracy: 71.875] [G loss: 1.1112523078918457]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5697 [D loss: 0.6529845893383026 | D accuracy: 65.625] [G loss: 0.9462377429008484]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5698 [D loss: 0.5808396935462952 | D accuracy: 64.0625] [G loss: 0.9808554649353027]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5699 [D loss: 0.6056485176086426 | D accuracy: 68.75] [G loss: 1.0382652282714844]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5700 [D loss: 0.5602219700813293 | D accuracy: 71.875] [G loss: 1.0108237266540527]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5701 [D loss: 0.6003995537757874 | D accuracy: 67.1875] [G loss: 0.8915872573852539]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5702 [D loss: 0.5868763029575348 | D accuracy: 64.0625] [G loss: 0.9793636202812195]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5703 [D loss: 0.6152006983757019 | D accuracy: 60.9375] [G loss: 0.9593330025672913]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5704 [D loss: 0.5640047490596771 | D accuracy: 65.625] [G loss: 1.0101404190063477]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5705 [D loss: 0.6609419584274292 | D accuracy: 57.8125] [G loss: 0.9970721006393433]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5706 [D loss: 0.615160346031189 | D accuracy: 70.3125] [G loss: 1.1071579456329346]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5707 [D loss: 0.6389999985694885 | D accuracy: 67.1875] [G loss: 1.0911407470703125]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5708 [D loss: 0.653080552816391 | D accuracy: 65.625] [G loss: 0.9491222500801086]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5709 [D loss: 0.5988274216651917 | D accuracy: 60.9375] [G loss: 0.9914318323135376]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5710 [D loss: 0.6570101976394653 | D accuracy: 53.125] [G loss: 0.9962972402572632]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5711 [D loss: 0.6166908144950867 | D accuracy: 60.9375] [G loss: 0.9434242248535156]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "5712 [D loss: 0.5511666238307953 | D accuracy: 73.4375] [G loss: 0.9729292392730713]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5713 [D loss: 0.6136282682418823 | D accuracy: 71.875] [G loss: 0.9221641421318054]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5714 [D loss: 0.6418506503105164 | D accuracy: 59.375] [G loss: 0.9362144470214844]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5715 [D loss: 0.5546046495437622 | D accuracy: 68.75] [G loss: 1.0184441804885864]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5716 [D loss: 0.5965186357498169 | D accuracy: 70.3125] [G loss: 1.020736575126648]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5717 [D loss: 0.5756588578224182 | D accuracy: 65.625] [G loss: 1.0254604816436768]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5718 [D loss: 0.5837704837322235 | D accuracy: 70.3125] [G loss: 1.0783838033676147]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "5719 [D loss: 0.6345759928226471 | D accuracy: 62.5] [G loss: 0.9957475066184998]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5720 [D loss: 0.6224579215049744 | D accuracy: 59.375] [G loss: 1.1716123819351196]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5721 [D loss: 0.6487963497638702 | D accuracy: 62.5] [G loss: 1.2429230213165283]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5722 [D loss: 0.6266582906246185 | D accuracy: 60.9375] [G loss: 1.184576153755188]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5723 [D loss: 0.6410250961780548 | D accuracy: 62.5] [G loss: 0.9129980802536011]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5724 [D loss: 0.6368275284767151 | D accuracy: 62.5] [G loss: 0.9147046208381653]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5725 [D loss: 0.625598818063736 | D accuracy: 65.625] [G loss: 1.0204453468322754]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5726 [D loss: 0.5489169359207153 | D accuracy: 70.3125] [G loss: 0.967653751373291]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5727 [D loss: 0.5785948038101196 | D accuracy: 67.1875] [G loss: 0.9779844284057617]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5728 [D loss: 0.5740172863006592 | D accuracy: 71.875] [G loss: 1.0619447231292725]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5729 [D loss: 0.589429646730423 | D accuracy: 60.9375] [G loss: 0.9914537668228149]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5730 [D loss: 0.5765974819660187 | D accuracy: 73.4375] [G loss: 1.096442699432373]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5731 [D loss: 0.5891416966915131 | D accuracy: 67.1875] [G loss: 0.9273974895477295]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5732 [D loss: 0.5740638673305511 | D accuracy: 75.0] [G loss: 1.0353585481643677]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5733 [D loss: 0.6084466576576233 | D accuracy: 64.0625] [G loss: 1.0087018013000488]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5734 [D loss: 0.5495314002037048 | D accuracy: 76.5625] [G loss: 1.0313489437103271]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5735 [D loss: 0.6080508828163147 | D accuracy: 68.75] [G loss: 1.0407922267913818]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5736 [D loss: 0.5603763461112976 | D accuracy: 73.4375] [G loss: 0.9878270626068115]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5737 [D loss: 0.6399904787540436 | D accuracy: 62.5] [G loss: 1.0201457738876343]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5738 [D loss: 0.6020433008670807 | D accuracy: 64.0625] [G loss: 0.9528299570083618]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5739 [D loss: 0.6394674777984619 | D accuracy: 62.5] [G loss: 0.9629461765289307]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5740 [D loss: 0.6036462187767029 | D accuracy: 67.1875] [G loss: 0.9425365924835205]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5741 [D loss: 0.5879563689231873 | D accuracy: 70.3125] [G loss: 0.9712278842926025]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5742 [D loss: 0.5827983617782593 | D accuracy: 65.625] [G loss: 1.0317391157150269]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5743 [D loss: 0.5984767079353333 | D accuracy: 62.5] [G loss: 1.0956107378005981]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5744 [D loss: 0.6317262947559357 | D accuracy: 64.0625] [G loss: 0.9939534664154053]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5745 [D loss: 0.5709967017173767 | D accuracy: 70.3125] [G loss: 1.0558632612228394]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5746 [D loss: 0.6181467175483704 | D accuracy: 64.0625] [G loss: 1.1119714975357056]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5747 [D loss: 0.5248089283704758 | D accuracy: 73.4375] [G loss: 1.0770289897918701]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5748 [D loss: 0.6769527494907379 | D accuracy: 57.8125] [G loss: 1.1214334964752197]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5749 [D loss: 0.6019967794418335 | D accuracy: 70.3125] [G loss: 1.0387897491455078]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5750 [D loss: 0.6595833897590637 | D accuracy: 56.25] [G loss: 1.0057365894317627]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5751 [D loss: 0.6160528063774109 | D accuracy: 67.1875] [G loss: 1.0199373960494995]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5752 [D loss: 0.6144499778747559 | D accuracy: 60.9375] [G loss: 0.979465126991272]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5753 [D loss: 0.6121972501277924 | D accuracy: 70.3125] [G loss: 0.9670906066894531]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5754 [D loss: 0.6187663674354553 | D accuracy: 65.625] [G loss: 0.951691746711731]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5755 [D loss: 0.5673700571060181 | D accuracy: 70.3125] [G loss: 1.0489801168441772]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5756 [D loss: 0.5780037641525269 | D accuracy: 65.625] [G loss: 0.9998334050178528]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5757 [D loss: 0.6337043941020966 | D accuracy: 67.1875] [G loss: 1.005733847618103]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5758 [D loss: 0.6342298090457916 | D accuracy: 64.0625] [G loss: 1.007418155670166]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5759 [D loss: 0.6231760382652283 | D accuracy: 64.0625] [G loss: 1.0124266147613525]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5760 [D loss: 0.7139790654182434 | D accuracy: 50.0] [G loss: 0.9934362173080444]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5761 [D loss: 0.6303870677947998 | D accuracy: 64.0625] [G loss: 0.9085520505905151]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5762 [D loss: 0.5091912597417831 | D accuracy: 78.125] [G loss: 1.0704845190048218]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5763 [D loss: 0.6560027301311493 | D accuracy: 59.375] [G loss: 1.05979323387146]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5764 [D loss: 0.5940015614032745 | D accuracy: 67.1875] [G loss: 1.0393893718719482]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5765 [D loss: 0.5909497141838074 | D accuracy: 64.0625] [G loss: 0.9854564666748047]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5766 [D loss: 0.6719001829624176 | D accuracy: 59.375] [G loss: 0.9798542857170105]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5767 [D loss: 0.6904779374599457 | D accuracy: 57.8125] [G loss: 1.0286850929260254]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5768 [D loss: 0.583090603351593 | D accuracy: 65.625] [G loss: 1.011683702468872]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5769 [D loss: 0.645356684923172 | D accuracy: 59.375] [G loss: 1.072746753692627]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5770 [D loss: 0.6318261623382568 | D accuracy: 70.3125] [G loss: 1.017477035522461]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5771 [D loss: 0.695044070482254 | D accuracy: 53.125] [G loss: 0.9489201903343201]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5772 [D loss: 0.5633251070976257 | D accuracy: 71.875] [G loss: 1.0240424871444702]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5773 [D loss: 0.6189741492271423 | D accuracy: 64.0625] [G loss: 1.1213276386260986]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5774 [D loss: 0.5960907340049744 | D accuracy: 62.5] [G loss: 0.9863899946212769]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5775 [D loss: 0.5960905849933624 | D accuracy: 64.0625] [G loss: 1.0681898593902588]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5776 [D loss: 0.5991957783699036 | D accuracy: 64.0625] [G loss: 1.0908257961273193]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5777 [D loss: 0.6682859659194946 | D accuracy: 53.125] [G loss: 0.9620057940483093]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5778 [D loss: 0.5589137077331543 | D accuracy: 65.625] [G loss: 1.0342540740966797]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5779 [D loss: 0.5894511938095093 | D accuracy: 70.3125] [G loss: 1.057685375213623]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5780 [D loss: 0.5658389627933502 | D accuracy: 71.875] [G loss: 1.043459415435791]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5781 [D loss: 0.6698285341262817 | D accuracy: 60.9375] [G loss: 1.1004767417907715]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5782 [D loss: 0.6326071321964264 | D accuracy: 62.5] [G loss: 1.0505273342132568]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5783 [D loss: 0.6118965744972229 | D accuracy: 67.1875] [G loss: 1.0346637964248657]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5784 [D loss: 0.529771015048027 | D accuracy: 68.75] [G loss: 1.0044269561767578]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5785 [D loss: 0.6310896277427673 | D accuracy: 65.625] [G loss: 0.9812523126602173]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5786 [D loss: 0.6112888157367706 | D accuracy: 71.875] [G loss: 1.1213855743408203]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5787 [D loss: 0.5877133011817932 | D accuracy: 73.4375] [G loss: 1.082385540008545]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5788 [D loss: 0.5925239324569702 | D accuracy: 65.625] [G loss: 1.009576439857483]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5789 [D loss: 0.5719678103923798 | D accuracy: 70.3125] [G loss: 0.9794690012931824]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5790 [D loss: 0.5577943027019501 | D accuracy: 70.3125] [G loss: 0.981214165687561]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5791 [D loss: 0.5475972890853882 | D accuracy: 68.75] [G loss: 1.07570481300354]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5792 [D loss: 0.5723612308502197 | D accuracy: 75.0] [G loss: 1.0483758449554443]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5793 [D loss: 0.6809344291687012 | D accuracy: 50.0] [G loss: 0.9632643461227417]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "5794 [D loss: 0.5892630219459534 | D accuracy: 67.1875] [G loss: 1.0521557331085205]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5795 [D loss: 0.6219556331634521 | D accuracy: 60.9375] [G loss: 1.0836701393127441]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "5796 [D loss: 0.5809789597988129 | D accuracy: 64.0625] [G loss: 1.0401430130004883]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "5797 [D loss: 0.6109254956245422 | D accuracy: 68.75] [G loss: 0.9129111766815186]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "5798 [D loss: 0.6293752789497375 | D accuracy: 64.0625] [G loss: 0.9096355438232422]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5799 [D loss: 0.6120675206184387 | D accuracy: 62.5] [G loss: 1.1030951738357544]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "5800 [D loss: 0.5853753089904785 | D accuracy: 70.3125] [G loss: 0.9874216318130493]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "5801 [D loss: 0.5325154364109039 | D accuracy: 68.75] [G loss: 0.9529659748077393]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5802 [D loss: 0.5913006663322449 | D accuracy: 70.3125] [G loss: 0.9964251518249512]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5803 [D loss: 0.6454060077667236 | D accuracy: 59.375] [G loss: 1.074628472328186]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "5804 [D loss: 0.6781288683414459 | D accuracy: 50.0] [G loss: 0.9470614790916443]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5805 [D loss: 0.5605820715427399 | D accuracy: 65.625] [G loss: 1.0288140773773193]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5806 [D loss: 0.6194482147693634 | D accuracy: 64.0625] [G loss: 1.0259348154067993]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5807 [D loss: 0.633402556180954 | D accuracy: 59.375] [G loss: 0.9969059228897095]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5808 [D loss: 0.5992844998836517 | D accuracy: 65.625] [G loss: 1.1257246732711792]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5809 [D loss: 0.5841419994831085 | D accuracy: 71.875] [G loss: 1.0078867673873901]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5810 [D loss: 0.6021888852119446 | D accuracy: 65.625] [G loss: 1.0298702716827393]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5811 [D loss: 0.5577487945556641 | D accuracy: 71.875] [G loss: 1.0071501731872559]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5812 [D loss: 0.619314581155777 | D accuracy: 64.0625] [G loss: 1.0473116636276245]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5813 [D loss: 0.6719880104064941 | D accuracy: 62.5] [G loss: 0.9904769062995911]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5814 [D loss: 0.6094985902309418 | D accuracy: 60.9375] [G loss: 1.0561091899871826]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5815 [D loss: 0.6515646278858185 | D accuracy: 57.8125] [G loss: 0.9048123359680176]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5816 [D loss: 0.6006673276424408 | D accuracy: 70.3125] [G loss: 1.0631687641143799]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5817 [D loss: 0.5532708466053009 | D accuracy: 71.875] [G loss: 1.0310263633728027]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5818 [D loss: 0.6544609665870667 | D accuracy: 60.9375] [G loss: 1.0811285972595215]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5819 [D loss: 0.6550033688545227 | D accuracy: 59.375] [G loss: 1.1019970178604126]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5820 [D loss: 0.5743496417999268 | D accuracy: 70.3125] [G loss: 1.104154109954834]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5821 [D loss: 0.6340352892875671 | D accuracy: 65.625] [G loss: 1.0472660064697266]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5822 [D loss: 0.6620854139328003 | D accuracy: 59.375] [G loss: 1.0427144765853882]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5823 [D loss: 0.5282350182533264 | D accuracy: 73.4375] [G loss: 1.0561928749084473]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5824 [D loss: 0.6144451200962067 | D accuracy: 68.75] [G loss: 1.0761770009994507]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5825 [D loss: 0.6312364935874939 | D accuracy: 60.9375] [G loss: 1.0364298820495605]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5826 [D loss: 0.5168753117322922 | D accuracy: 73.4375] [G loss: 1.0166735649108887]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5827 [D loss: 0.5939330458641052 | D accuracy: 71.875] [G loss: 1.041279911994934]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5828 [D loss: 0.5786265730857849 | D accuracy: 70.3125] [G loss: 1.0731794834136963]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5829 [D loss: 0.5378345251083374 | D accuracy: 75.0] [G loss: 1.053159236907959]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5830 [D loss: 0.6859518885612488 | D accuracy: 57.8125] [G loss: 1.0054166316986084]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5831 [D loss: 0.6055749654769897 | D accuracy: 62.5] [G loss: 0.9675493240356445]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5832 [D loss: 0.6112487018108368 | D accuracy: 62.5] [G loss: 0.9510438442230225]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5833 [D loss: 0.6166602373123169 | D accuracy: 70.3125] [G loss: 0.9938112497329712]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5834 [D loss: 0.604863166809082 | D accuracy: 64.0625] [G loss: 0.9868793487548828]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5835 [D loss: 0.6189926564693451 | D accuracy: 54.6875] [G loss: 0.9151820540428162]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5836 [D loss: 0.6697746217250824 | D accuracy: 62.5] [G loss: 0.9783021807670593]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5837 [D loss: 0.6454399228096008 | D accuracy: 62.5] [G loss: 1.062481164932251]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5838 [D loss: 0.5682616233825684 | D accuracy: 67.1875] [G loss: 1.0112202167510986]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5839 [D loss: 0.5915541648864746 | D accuracy: 64.0625] [G loss: 1.0466458797454834]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5840 [D loss: 0.5764367878437042 | D accuracy: 68.75] [G loss: 1.0543750524520874]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5841 [D loss: 0.6162965893745422 | D accuracy: 65.625] [G loss: 0.8687141537666321]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5842 [D loss: 0.6029964685440063 | D accuracy: 62.5] [G loss: 0.9993066191673279]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5843 [D loss: 0.6254095137119293 | D accuracy: 64.0625] [G loss: 0.9655685424804688]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5844 [D loss: 0.5928180515766144 | D accuracy: 70.3125] [G loss: 0.9269816875457764]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5845 [D loss: 0.618359386920929 | D accuracy: 68.75] [G loss: 0.9551283121109009]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5846 [D loss: 0.6259552538394928 | D accuracy: 62.5] [G loss: 1.0108866691589355]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5847 [D loss: 0.726042777299881 | D accuracy: 50.0] [G loss: 1.0126968622207642]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5848 [D loss: 0.6664928197860718 | D accuracy: 60.9375] [G loss: 0.9393556118011475]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5849 [D loss: 0.6253128945827484 | D accuracy: 59.375] [G loss: 1.0312161445617676]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5850 [D loss: 0.6026410460472107 | D accuracy: 57.8125] [G loss: 0.9608677625656128]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5851 [D loss: 0.6091422140598297 | D accuracy: 68.75] [G loss: 1.0051519870758057]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5852 [D loss: 0.655101090669632 | D accuracy: 53.125] [G loss: 1.0040943622589111]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5853 [D loss: 0.5873458981513977 | D accuracy: 65.625] [G loss: 0.9860378503799438]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5854 [D loss: 0.5994379818439484 | D accuracy: 73.4375] [G loss: 0.9336788058280945]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5855 [D loss: 0.6482785940170288 | D accuracy: 67.1875] [G loss: 0.9860509037971497]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5856 [D loss: 0.5992351174354553 | D accuracy: 70.3125] [G loss: 0.9138739109039307]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5857 [D loss: 0.5981023907661438 | D accuracy: 70.3125] [G loss: 1.0024442672729492]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "5858 [D loss: 0.5717069506645203 | D accuracy: 70.3125] [G loss: 1.0519511699676514]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5859 [D loss: 0.7060455679893494 | D accuracy: 54.6875] [G loss: 1.0677827596664429]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5860 [D loss: 0.6828261017799377 | D accuracy: 53.125] [G loss: 1.022676944732666]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5861 [D loss: 0.5689296126365662 | D accuracy: 68.75] [G loss: 1.0634856224060059]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5862 [D loss: 0.6082290410995483 | D accuracy: 62.5] [G loss: 1.0842732191085815]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5863 [D loss: 0.52889284491539 | D accuracy: 81.25] [G loss: 1.0265593528747559]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5864 [D loss: 0.6199311316013336 | D accuracy: 59.375] [G loss: 1.0283253192901611]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5865 [D loss: 0.6000730097293854 | D accuracy: 62.5] [G loss: 1.0013420581817627]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5866 [D loss: 0.6420914828777313 | D accuracy: 68.75] [G loss: 1.09975266456604]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5867 [D loss: 0.6178163886070251 | D accuracy: 68.75] [G loss: 0.9390146732330322]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5868 [D loss: 0.5722458958625793 | D accuracy: 79.6875] [G loss: 0.9447511434555054]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5869 [D loss: 0.6212886571884155 | D accuracy: 57.8125] [G loss: 0.9572610855102539]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5870 [D loss: 0.6507489383220673 | D accuracy: 62.5] [G loss: 1.0573570728302002]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5871 [D loss: 0.6255711317062378 | D accuracy: 64.0625] [G loss: 0.9742671847343445]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5872 [D loss: 0.5473089516162872 | D accuracy: 68.75] [G loss: 1.1556990146636963]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5873 [D loss: 0.6640692353248596 | D accuracy: 67.1875] [G loss: 1.077535629272461]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5874 [D loss: 0.6052578687667847 | D accuracy: 67.1875] [G loss: 1.0205594301223755]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5875 [D loss: 0.5760621130466461 | D accuracy: 64.0625] [G loss: 0.9618051052093506]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5876 [D loss: 0.6806541979312897 | D accuracy: 60.9375] [G loss: 1.0891661643981934]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5877 [D loss: 0.6332976222038269 | D accuracy: 62.5] [G loss: 1.0487087965011597]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5878 [D loss: 0.5509881973266602 | D accuracy: 71.875] [G loss: 1.0656278133392334]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5879 [D loss: 0.6328755617141724 | D accuracy: 67.1875] [G loss: 0.9629775881767273]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5880 [D loss: 0.5277110934257507 | D accuracy: 76.5625] [G loss: 1.0340811014175415]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "5881 [D loss: 0.5568472594022751 | D accuracy: 71.875] [G loss: 1.0670359134674072]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "5882 [D loss: 0.5252655446529388 | D accuracy: 78.125] [G loss: 1.002882480621338]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5883 [D loss: 0.644198089838028 | D accuracy: 65.625] [G loss: 1.0425087213516235]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5884 [D loss: 0.4926556944847107 | D accuracy: 78.125] [G loss: 1.1449508666992188]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "5885 [D loss: 0.6307514905929565 | D accuracy: 60.9375] [G loss: 1.1329177618026733]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5886 [D loss: 0.6036601066589355 | D accuracy: 68.75] [G loss: 1.0301352739334106]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "5887 [D loss: 0.6462981104850769 | D accuracy: 59.375] [G loss: 1.0034785270690918]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5888 [D loss: 0.6343337297439575 | D accuracy: 65.625] [G loss: 1.022789478302002]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5889 [D loss: 0.544489175081253 | D accuracy: 76.5625] [G loss: 1.065451979637146]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5890 [D loss: 0.5727197825908661 | D accuracy: 65.625] [G loss: 1.0449423789978027]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5891 [D loss: 0.6144624650478363 | D accuracy: 68.75] [G loss: 0.9536394476890564]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5892 [D loss: 0.6456283926963806 | D accuracy: 59.375] [G loss: 1.0192605257034302]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5893 [D loss: 0.6705178022384644 | D accuracy: 53.125] [G loss: 1.0309007167816162]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5894 [D loss: 0.6396268606185913 | D accuracy: 56.25] [G loss: 1.0863920450210571]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5895 [D loss: 0.6373265385627747 | D accuracy: 56.25] [G loss: 1.0846524238586426]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5896 [D loss: 0.6396136581897736 | D accuracy: 65.625] [G loss: 1.0425257682800293]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5897 [D loss: 0.6833992898464203 | D accuracy: 60.9375] [G loss: 0.9742564558982849]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5898 [D loss: 0.6558420062065125 | D accuracy: 54.6875] [G loss: 1.059082269668579]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5899 [D loss: 0.6127841472625732 | D accuracy: 67.1875] [G loss: 1.0588443279266357]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5900 [D loss: 0.6347148418426514 | D accuracy: 60.9375] [G loss: 0.9578883647918701]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5901 [D loss: 0.6483119428157806 | D accuracy: 57.8125] [G loss: 1.0412379503250122]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5902 [D loss: 0.6380866467952728 | D accuracy: 60.9375] [G loss: 0.9729281663894653]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5903 [D loss: 0.6050852239131927 | D accuracy: 68.75] [G loss: 0.9419416785240173]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5904 [D loss: 0.6516180634498596 | D accuracy: 60.9375] [G loss: 1.0341984033584595]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5905 [D loss: 0.5823417007923126 | D accuracy: 70.3125] [G loss: 1.0676072835922241]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5906 [D loss: 0.6858222186565399 | D accuracy: 57.8125] [G loss: 0.9856530427932739]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5907 [D loss: 0.534641832113266 | D accuracy: 71.875] [G loss: 1.0078554153442383]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5908 [D loss: 0.524961918592453 | D accuracy: 73.4375] [G loss: 1.0026763677597046]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5909 [D loss: 0.6325180232524872 | D accuracy: 60.9375] [G loss: 0.9829349517822266]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5910 [D loss: 0.5905545353889465 | D accuracy: 68.75] [G loss: 1.0031211376190186]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5911 [D loss: 0.5775167047977448 | D accuracy: 71.875] [G loss: 0.9716836810112]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5912 [D loss: 0.643411248922348 | D accuracy: 56.25] [G loss: 0.9419170022010803]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5913 [D loss: 0.5616190433502197 | D accuracy: 71.875] [G loss: 0.9660471081733704]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5914 [D loss: 0.6095830798149109 | D accuracy: 68.75] [G loss: 0.9530062079429626]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5915 [D loss: 0.587521880865097 | D accuracy: 71.875] [G loss: 0.9320238828659058]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5916 [D loss: 0.6307633221149445 | D accuracy: 65.625] [G loss: 1.048430323600769]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5917 [D loss: 0.6175233721733093 | D accuracy: 67.1875] [G loss: 1.0064754486083984]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5918 [D loss: 0.6323423981666565 | D accuracy: 60.9375] [G loss: 0.9042785167694092]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5919 [D loss: 0.6333667635917664 | D accuracy: 59.375] [G loss: 0.9452725052833557]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5920 [D loss: 0.5960970818996429 | D accuracy: 70.3125] [G loss: 1.0135531425476074]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5921 [D loss: 0.6437392830848694 | D accuracy: 62.5] [G loss: 0.9164132475852966]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5922 [D loss: 0.5740947723388672 | D accuracy: 65.625] [G loss: 0.977352499961853]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5923 [D loss: 0.5571852028369904 | D accuracy: 67.1875] [G loss: 1.026841402053833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5924 [D loss: 0.5096346437931061 | D accuracy: 82.8125] [G loss: 1.0185638666152954]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5925 [D loss: 0.6361764073371887 | D accuracy: 65.625] [G loss: 0.9985239505767822]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5926 [D loss: 0.6545723080635071 | D accuracy: 60.9375] [G loss: 1.0174833536148071]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5927 [D loss: 0.6265310049057007 | D accuracy: 65.625] [G loss: 0.9520484209060669]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5928 [D loss: 0.570906788110733 | D accuracy: 65.625] [G loss: 1.025722622871399]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5929 [D loss: 0.5583522915840149 | D accuracy: 75.0] [G loss: 1.0475832223892212]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5930 [D loss: 0.5823360085487366 | D accuracy: 73.4375] [G loss: 1.0126593112945557]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5931 [D loss: 0.5258417725563049 | D accuracy: 73.4375] [G loss: 1.055289626121521]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5932 [D loss: 0.6860267519950867 | D accuracy: 57.8125] [G loss: 0.9865854978561401]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5933 [D loss: 0.585881382226944 | D accuracy: 73.4375] [G loss: 0.9805077910423279]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5934 [D loss: 0.5803147852420807 | D accuracy: 65.625] [G loss: 1.0066592693328857]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5935 [D loss: 0.610023021697998 | D accuracy: 67.1875] [G loss: 0.9912347197532654]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5936 [D loss: 0.5975647568702698 | D accuracy: 62.5] [G loss: 1.0038247108459473]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5937 [D loss: 0.565709263086319 | D accuracy: 70.3125] [G loss: 1.1156352758407593]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5938 [D loss: 0.6121811866760254 | D accuracy: 68.75] [G loss: 0.9550669193267822]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5939 [D loss: 0.6347222626209259 | D accuracy: 62.5] [G loss: 0.9388164281845093]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5940 [D loss: 0.6429959237575531 | D accuracy: 56.25] [G loss: 1.0535094738006592]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5941 [D loss: 0.54008549451828 | D accuracy: 71.875] [G loss: 1.0827488899230957]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5942 [D loss: 0.5939522385597229 | D accuracy: 59.375] [G loss: 1.0733850002288818]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5943 [D loss: 0.6189586222171783 | D accuracy: 62.5] [G loss: 1.1177583932876587]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5944 [D loss: 0.6072713136672974 | D accuracy: 60.9375] [G loss: 1.0380810499191284]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5945 [D loss: 0.5823192000389099 | D accuracy: 65.625] [G loss: 1.0901744365692139]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5946 [D loss: 0.652759313583374 | D accuracy: 56.25] [G loss: 1.0075554847717285]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "5947 [D loss: 0.6484113931655884 | D accuracy: 64.0625] [G loss: 1.0140410661697388]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5948 [D loss: 0.6154144704341888 | D accuracy: 57.8125] [G loss: 0.9537579417228699]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5949 [D loss: 0.6143795251846313 | D accuracy: 68.75] [G loss: 0.9717269539833069]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5950 [D loss: 0.595387876033783 | D accuracy: 62.5] [G loss: 0.9855757355690002]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5951 [D loss: 0.6278041303157806 | D accuracy: 59.375] [G loss: 1.029608964920044]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5952 [D loss: 0.6104587316513062 | D accuracy: 64.0625] [G loss: 1.0289885997772217]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5953 [D loss: 0.5668075084686279 | D accuracy: 76.5625] [G loss: 1.0486156940460205]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5954 [D loss: 0.5984066426753998 | D accuracy: 70.3125] [G loss: 1.0284295082092285]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5955 [D loss: 0.6138089001178741 | D accuracy: 57.8125] [G loss: 0.9401941299438477]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "5956 [D loss: 0.5390105843544006 | D accuracy: 68.75] [G loss: 0.9601629376411438]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5957 [D loss: 0.5546039342880249 | D accuracy: 73.4375] [G loss: 1.0254212617874146]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5958 [D loss: 0.6478831768035889 | D accuracy: 65.625] [G loss: 1.065746784210205]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5959 [D loss: 0.5811675786972046 | D accuracy: 65.625] [G loss: 0.9480283856391907]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5960 [D loss: 0.6216161251068115 | D accuracy: 65.625] [G loss: 0.9567552208900452]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5961 [D loss: 0.6079741418361664 | D accuracy: 64.0625] [G loss: 0.9905010461807251]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5962 [D loss: 0.5457776784896851 | D accuracy: 65.625] [G loss: 0.9652630090713501]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5963 [D loss: 0.6929697394371033 | D accuracy: 51.5625] [G loss: 1.0160977840423584]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "5964 [D loss: 0.6439761519432068 | D accuracy: 62.5] [G loss: 0.9675785303115845]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "5965 [D loss: 0.6350045800209045 | D accuracy: 56.25] [G loss: 1.0627217292785645]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5966 [D loss: 0.5565826296806335 | D accuracy: 75.0] [G loss: 0.9667499661445618]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "5967 [D loss: 0.7110904157161713 | D accuracy: 51.5625] [G loss: 1.0568122863769531]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "5968 [D loss: 0.5378324091434479 | D accuracy: 76.5625] [G loss: 0.9362878799438477]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5969 [D loss: 0.6157548129558563 | D accuracy: 65.625] [G loss: 1.0395475625991821]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "5970 [D loss: 0.5775609612464905 | D accuracy: 70.3125] [G loss: 0.9679583311080933]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "5971 [D loss: 0.5741568505764008 | D accuracy: 71.875] [G loss: 1.0628688335418701]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "5972 [D loss: 0.5735589563846588 | D accuracy: 71.875] [G loss: 1.0447287559509277]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5973 [D loss: 0.5407314002513885 | D accuracy: 73.4375] [G loss: 1.0506155490875244]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "5974 [D loss: 0.6272662878036499 | D accuracy: 64.0625] [G loss: 1.0812606811523438]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5975 [D loss: 0.5772716104984283 | D accuracy: 65.625] [G loss: 1.1343563795089722]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5976 [D loss: 0.6809463798999786 | D accuracy: 54.6875] [G loss: 1.0927402973175049]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5977 [D loss: 0.6502714157104492 | D accuracy: 62.5] [G loss: 1.0457377433776855]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5978 [D loss: 0.6747762858867645 | D accuracy: 60.9375] [G loss: 1.1772903203964233]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5979 [D loss: 0.6264299750328064 | D accuracy: 62.5] [G loss: 1.0022608041763306]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5980 [D loss: 0.6153838634490967 | D accuracy: 62.5] [G loss: 1.0666306018829346]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "5981 [D loss: 0.5323159694671631 | D accuracy: 85.9375] [G loss: 1.138373613357544]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5982 [D loss: 0.5955168902873993 | D accuracy: 70.3125] [G loss: 1.0195298194885254]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "5983 [D loss: 0.6443438231945038 | D accuracy: 57.8125] [G loss: 1.0285816192626953]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5984 [D loss: 0.6480963230133057 | D accuracy: 60.9375] [G loss: 1.0348963737487793]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5985 [D loss: 0.5794053226709366 | D accuracy: 75.0] [G loss: 1.0682873725891113]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5986 [D loss: 0.5842618346214294 | D accuracy: 67.1875] [G loss: 0.9021497964859009]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "5987 [D loss: 0.5937366783618927 | D accuracy: 64.0625] [G loss: 1.0266222953796387]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5988 [D loss: 0.5895246863365173 | D accuracy: 67.1875] [G loss: 0.883499026298523]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "5989 [D loss: 0.5671260058879852 | D accuracy: 67.1875] [G loss: 1.10072660446167]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5990 [D loss: 0.6331469416618347 | D accuracy: 59.375] [G loss: 1.0244872570037842]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "5991 [D loss: 0.5904519557952881 | D accuracy: 64.0625] [G loss: 1.0317941904067993]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5992 [D loss: 0.5765625238418579 | D accuracy: 73.4375] [G loss: 1.0324413776397705]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5993 [D loss: 0.5357718467712402 | D accuracy: 73.4375] [G loss: 0.9204940795898438]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "5994 [D loss: 0.604638010263443 | D accuracy: 67.1875] [G loss: 1.0050252676010132]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "5995 [D loss: 0.6335796415805817 | D accuracy: 56.25] [G loss: 0.9393818974494934]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "5996 [D loss: 0.5266092121601105 | D accuracy: 75.0] [G loss: 0.9661017656326294]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "5997 [D loss: 0.5990548133850098 | D accuracy: 71.875] [G loss: 1.041280746459961]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "5998 [D loss: 0.5905146896839142 | D accuracy: 60.9375] [G loss: 1.0143053531646729]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "5999 [D loss: 0.5560570955276489 | D accuracy: 65.625] [G loss: 1.0596095323562622]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6000 [D loss: 0.5637774467468262 | D accuracy: 71.875] [G loss: 1.0427809953689575]\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "6001 [D loss: 0.6083514094352722 | D accuracy: 64.0625] [G loss: 1.0517048835754395]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6002 [D loss: 0.5881626009941101 | D accuracy: 65.625] [G loss: 0.9134794473648071]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6003 [D loss: 0.6215618252754211 | D accuracy: 65.625] [G loss: 0.9177294969558716]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6004 [D loss: 0.675763338804245 | D accuracy: 53.125] [G loss: 1.030627965927124]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6005 [D loss: 0.514678955078125 | D accuracy: 76.5625] [G loss: 1.0284024477005005]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6006 [D loss: 0.6485317945480347 | D accuracy: 56.25] [G loss: 0.9715368747711182]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6007 [D loss: 0.5916186571121216 | D accuracy: 71.875] [G loss: 0.9712370038032532]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6008 [D loss: 0.5813592374324799 | D accuracy: 73.4375] [G loss: 1.0679395198822021]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6009 [D loss: 0.5269466936588287 | D accuracy: 78.125] [G loss: 1.0912952423095703]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6010 [D loss: 0.5526396036148071 | D accuracy: 73.4375] [G loss: 1.060392141342163]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6011 [D loss: 0.5809106528759003 | D accuracy: 70.3125] [G loss: 1.025132417678833]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6012 [D loss: 0.6630750298500061 | D accuracy: 60.9375] [G loss: 1.0088887214660645]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6013 [D loss: 0.565748929977417 | D accuracy: 73.4375] [G loss: 0.9348329305648804]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6014 [D loss: 0.6058770418167114 | D accuracy: 62.5] [G loss: 1.0152851343154907]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6015 [D loss: 0.6524212658405304 | D accuracy: 57.8125] [G loss: 0.9762210845947266]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6016 [D loss: 0.6137393414974213 | D accuracy: 62.5] [G loss: 1.0183870792388916]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6017 [D loss: 0.6113816797733307 | D accuracy: 73.4375] [G loss: 1.0694949626922607]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6018 [D loss: 0.5759503543376923 | D accuracy: 68.75] [G loss: 0.9718576669692993]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6019 [D loss: 0.5451994836330414 | D accuracy: 76.5625] [G loss: 1.1028388738632202]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6020 [D loss: 0.6329134404659271 | D accuracy: 57.8125] [G loss: 0.9804878830909729]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6021 [D loss: 0.5559422373771667 | D accuracy: 70.3125] [G loss: 1.1269397735595703]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6022 [D loss: 0.5653577446937561 | D accuracy: 70.3125] [G loss: 0.988892674446106]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6023 [D loss: 0.6280111968517303 | D accuracy: 65.625] [G loss: 1.0525624752044678]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6024 [D loss: 0.5879396498203278 | D accuracy: 70.3125] [G loss: 0.9827322363853455]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6025 [D loss: 0.5779627561569214 | D accuracy: 73.4375] [G loss: 0.9259896278381348]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6026 [D loss: 0.6045817136764526 | D accuracy: 62.5] [G loss: 0.9488463401794434]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6027 [D loss: 0.6385821104049683 | D accuracy: 54.6875] [G loss: 1.002100944519043]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6028 [D loss: 0.5586005449295044 | D accuracy: 70.3125] [G loss: 0.9810367226600647]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6029 [D loss: 0.5493819415569305 | D accuracy: 70.3125] [G loss: 0.9665611386299133]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6030 [D loss: 0.5399979054927826 | D accuracy: 75.0] [G loss: 0.9190070629119873]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6031 [D loss: 0.5779244899749756 | D accuracy: 70.3125] [G loss: 1.0009706020355225]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6032 [D loss: 0.6266440749168396 | D accuracy: 56.25] [G loss: 0.9875290393829346]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6033 [D loss: 0.5731861889362335 | D accuracy: 73.4375] [G loss: 1.0220685005187988]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6034 [D loss: 0.618548572063446 | D accuracy: 65.625] [G loss: 0.9577587246894836]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "6035 [D loss: 0.5591483116149902 | D accuracy: 71.875] [G loss: 1.0714682340621948]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6036 [D loss: 0.5385090708732605 | D accuracy: 68.75] [G loss: 1.003584861755371]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6037 [D loss: 0.6332703828811646 | D accuracy: 60.9375] [G loss: 1.0715011358261108]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6038 [D loss: 0.5983253121376038 | D accuracy: 73.4375] [G loss: 1.1058571338653564]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6039 [D loss: 0.6088172197341919 | D accuracy: 65.625] [G loss: 1.0932819843292236]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6040 [D loss: 0.720014750957489 | D accuracy: 54.6875] [G loss: 1.087585210800171]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "6041 [D loss: 0.6470291018486023 | D accuracy: 65.625] [G loss: 0.9928381443023682]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "6042 [D loss: 0.5623201727867126 | D accuracy: 73.4375] [G loss: 0.9718599915504456]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6043 [D loss: 0.6188644766807556 | D accuracy: 70.3125] [G loss: 0.9959139823913574]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6044 [D loss: 0.6274825632572174 | D accuracy: 60.9375] [G loss: 1.006152629852295]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6045 [D loss: 0.5820442736148834 | D accuracy: 68.75] [G loss: 0.9588117599487305]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6046 [D loss: 0.5403205305337906 | D accuracy: 79.6875] [G loss: 0.9242435693740845]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6047 [D loss: 0.6832770109176636 | D accuracy: 59.375] [G loss: 0.9796277284622192]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6048 [D loss: 0.5575871169567108 | D accuracy: 68.75] [G loss: 1.084177851676941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6049 [D loss: 0.6208308339118958 | D accuracy: 65.625] [G loss: 1.04318368434906]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6050 [D loss: 0.5660931468009949 | D accuracy: 65.625] [G loss: 0.9422141909599304]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6051 [D loss: 0.6005323231220245 | D accuracy: 70.3125] [G loss: 0.9717472791671753]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6052 [D loss: 0.5692525804042816 | D accuracy: 73.4375] [G loss: 1.001082420349121]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6053 [D loss: 0.6441167891025543 | D accuracy: 54.6875] [G loss: 1.035792589187622]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6054 [D loss: 0.5881010591983795 | D accuracy: 67.1875] [G loss: 0.9594737887382507]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6055 [D loss: 0.6992099285125732 | D accuracy: 53.125] [G loss: 1.026962399482727]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6056 [D loss: 0.5583323240280151 | D accuracy: 73.4375] [G loss: 0.9716824889183044]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6057 [D loss: 0.553870677947998 | D accuracy: 75.0] [G loss: 1.052895426750183]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6058 [D loss: 0.5461624562740326 | D accuracy: 70.3125] [G loss: 1.006441593170166]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6059 [D loss: 0.5733354389667511 | D accuracy: 73.4375] [G loss: 0.9730326533317566]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6060 [D loss: 0.5711917579174042 | D accuracy: 75.0] [G loss: 1.022876501083374]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6061 [D loss: 0.6178991794586182 | D accuracy: 60.9375] [G loss: 1.0129435062408447]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6062 [D loss: 0.5770009160041809 | D accuracy: 70.3125] [G loss: 0.9493992924690247]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6063 [D loss: 0.6327767372131348 | D accuracy: 64.0625] [G loss: 1.0931410789489746]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6064 [D loss: 0.48077332973480225 | D accuracy: 84.375] [G loss: 1.134871482849121]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6065 [D loss: 0.6547933220863342 | D accuracy: 62.5] [G loss: 0.9207008481025696]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6066 [D loss: 0.648152083158493 | D accuracy: 60.9375] [G loss: 0.9863904118537903]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6067 [D loss: 0.6372764110565186 | D accuracy: 57.8125] [G loss: 1.0396180152893066]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6068 [D loss: 0.5651454627513885 | D accuracy: 70.3125] [G loss: 1.0217454433441162]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6069 [D loss: 0.652312695980072 | D accuracy: 56.25] [G loss: 1.122368574142456]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6070 [D loss: 0.5793935060501099 | D accuracy: 71.875] [G loss: 0.9891337752342224]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6071 [D loss: 0.5822141766548157 | D accuracy: 70.3125] [G loss: 0.9651376605033875]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6072 [D loss: 0.516213983297348 | D accuracy: 76.5625] [G loss: 0.9089480638504028]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6073 [D loss: 0.55733922123909 | D accuracy: 76.5625] [G loss: 1.0302181243896484]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6074 [D loss: 0.6358162760734558 | D accuracy: 62.5] [G loss: 0.9587163925170898]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6075 [D loss: 0.6650211215019226 | D accuracy: 62.5] [G loss: 1.001816749572754]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6076 [D loss: 0.5365397036075592 | D accuracy: 75.0] [G loss: 0.9970628023147583]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6077 [D loss: 0.6042248904705048 | D accuracy: 62.5] [G loss: 1.0734443664550781]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6078 [D loss: 0.5799726843833923 | D accuracy: 65.625] [G loss: 0.8914389610290527]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6079 [D loss: 0.5883709192276001 | D accuracy: 68.75] [G loss: 1.0725351572036743]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6080 [D loss: 0.6781895160675049 | D accuracy: 56.25] [G loss: 1.11360502243042]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6081 [D loss: 0.5898621678352356 | D accuracy: 64.0625] [G loss: 1.068796157836914]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6082 [D loss: 0.568587988615036 | D accuracy: 73.4375] [G loss: 1.1535029411315918]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6083 [D loss: 0.5814570188522339 | D accuracy: 73.4375] [G loss: 1.0206940174102783]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6084 [D loss: 0.5968964397907257 | D accuracy: 65.625] [G loss: 1.1449003219604492]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6085 [D loss: 0.6202124953269958 | D accuracy: 64.0625] [G loss: 1.017162561416626]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6086 [D loss: 0.5553886890411377 | D accuracy: 71.875] [G loss: 1.0604112148284912]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6087 [D loss: 0.6398440301418304 | D accuracy: 57.8125] [G loss: 1.029977560043335]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6088 [D loss: 0.627709299325943 | D accuracy: 64.0625] [G loss: 1.0254321098327637]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6089 [D loss: 0.5618315041065216 | D accuracy: 75.0] [G loss: 1.0486993789672852]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6090 [D loss: 0.6497146487236023 | D accuracy: 59.375] [G loss: 1.2023096084594727]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6091 [D loss: 0.5894328355789185 | D accuracy: 67.1875] [G loss: 1.015235185623169]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6092 [D loss: 0.5949323773384094 | D accuracy: 65.625] [G loss: 1.0511419773101807]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6093 [D loss: 0.6084003448486328 | D accuracy: 62.5] [G loss: 1.0280866622924805]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6094 [D loss: 0.6473971009254456 | D accuracy: 62.5] [G loss: 0.9431500434875488]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6095 [D loss: 0.6083943545818329 | D accuracy: 65.625] [G loss: 0.945504367351532]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6096 [D loss: 0.6217354238033295 | D accuracy: 67.1875] [G loss: 0.9860219955444336]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6097 [D loss: 0.538512796163559 | D accuracy: 76.5625] [G loss: 0.9712086915969849]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6098 [D loss: 0.5799467861652374 | D accuracy: 71.875] [G loss: 0.9863564372062683]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6099 [D loss: 0.6531279683113098 | D accuracy: 56.25] [G loss: 1.0342302322387695]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6100 [D loss: 0.6511643528938293 | D accuracy: 60.9375] [G loss: 1.0032607316970825]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6101 [D loss: 0.5786571800708771 | D accuracy: 64.0625] [G loss: 1.075711727142334]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6102 [D loss: 0.6198536157608032 | D accuracy: 60.9375] [G loss: 1.15629243850708]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6103 [D loss: 0.6326651573181152 | D accuracy: 65.625] [G loss: 1.0473237037658691]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6104 [D loss: 0.5577578544616699 | D accuracy: 71.875] [G loss: 0.9811492562294006]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6105 [D loss: 0.6251291036605835 | D accuracy: 62.5] [G loss: 1.008592963218689]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6106 [D loss: 0.6090113818645477 | D accuracy: 57.8125] [G loss: 0.9582164287567139]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6107 [D loss: 0.6208455562591553 | D accuracy: 60.9375] [G loss: 0.9849271774291992]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6108 [D loss: 0.6585170924663544 | D accuracy: 56.25] [G loss: 1.0649323463439941]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6109 [D loss: 0.5715050101280212 | D accuracy: 70.3125] [G loss: 1.0215734243392944]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6110 [D loss: 0.6356512904167175 | D accuracy: 67.1875] [G loss: 1.0676687955856323]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6111 [D loss: 0.6539273262023926 | D accuracy: 54.6875] [G loss: 0.9673088788986206]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6112 [D loss: 0.643541008234024 | D accuracy: 60.9375] [G loss: 1.0020842552185059]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "6113 [D loss: 0.6427874565124512 | D accuracy: 59.375] [G loss: 1.0545419454574585]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "6114 [D loss: 0.6249058544635773 | D accuracy: 64.0625] [G loss: 0.9582802057266235]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6115 [D loss: 0.6201251149177551 | D accuracy: 64.0625] [G loss: 1.0399378538131714]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6116 [D loss: 0.6421094238758087 | D accuracy: 57.8125] [G loss: 0.9866310358047485]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6117 [D loss: 0.5708920359611511 | D accuracy: 67.1875] [G loss: 1.1112477779388428]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6118 [D loss: 0.5999309122562408 | D accuracy: 68.75] [G loss: 1.0284619331359863]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6119 [D loss: 0.6355106830596924 | D accuracy: 59.375] [G loss: 1.08418869972229]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "6120 [D loss: 0.590913861989975 | D accuracy: 65.625] [G loss: 1.0445003509521484]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6121 [D loss: 0.6374439299106598 | D accuracy: 67.1875] [G loss: 1.061924934387207]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "6122 [D loss: 0.6156514585018158 | D accuracy: 60.9375] [G loss: 0.9745005369186401]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6123 [D loss: 0.6499963998794556 | D accuracy: 59.375] [G loss: 1.0709714889526367]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6124 [D loss: 0.6175795793533325 | D accuracy: 68.75] [G loss: 0.9351279139518738]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6125 [D loss: 0.5903249084949493 | D accuracy: 70.3125] [G loss: 0.9645301103591919]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6126 [D loss: 0.6134454905986786 | D accuracy: 64.0625] [G loss: 0.9703971147537231]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6127 [D loss: 0.6591271162033081 | D accuracy: 57.8125] [G loss: 0.9246505498886108]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6128 [D loss: 0.535800576210022 | D accuracy: 75.0] [G loss: 0.9728097915649414]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6129 [D loss: 0.5669918358325958 | D accuracy: 70.3125] [G loss: 1.010961651802063]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6130 [D loss: 0.5673334300518036 | D accuracy: 68.75] [G loss: 1.1023074388504028]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6131 [D loss: 0.5571950376033783 | D accuracy: 64.0625] [G loss: 1.0876299142837524]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6132 [D loss: 0.6318061947822571 | D accuracy: 65.625] [G loss: 1.054880142211914]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6133 [D loss: 0.6299581229686737 | D accuracy: 65.625] [G loss: 1.1082708835601807]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6134 [D loss: 0.6841025352478027 | D accuracy: 56.25] [G loss: 1.0027391910552979]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6135 [D loss: 0.5497353971004486 | D accuracy: 78.125] [G loss: 1.08541738986969]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6136 [D loss: 0.6481129229068756 | D accuracy: 56.25] [G loss: 1.0278160572052002]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6137 [D loss: 0.6637161076068878 | D accuracy: 54.6875] [G loss: 1.0270204544067383]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6138 [D loss: 0.5904313027858734 | D accuracy: 73.4375] [G loss: 0.9848217368125916]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6139 [D loss: 0.6237644553184509 | D accuracy: 67.1875] [G loss: 1.1137516498565674]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6140 [D loss: 0.6143232882022858 | D accuracy: 64.0625] [G loss: 1.082399845123291]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6141 [D loss: 0.6982913911342621 | D accuracy: 60.9375] [G loss: 0.979464590549469]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6142 [D loss: 0.5585951209068298 | D accuracy: 76.5625] [G loss: 1.036064863204956]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6143 [D loss: 0.6825713813304901 | D accuracy: 51.5625] [G loss: 1.0224547386169434]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6144 [D loss: 0.5324824452400208 | D accuracy: 67.1875] [G loss: 1.0746135711669922]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6145 [D loss: 0.5528779029846191 | D accuracy: 76.5625] [G loss: 1.0784530639648438]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6146 [D loss: 0.5884791612625122 | D accuracy: 65.625] [G loss: 0.9852182865142822]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6147 [D loss: 0.562428891658783 | D accuracy: 64.0625] [G loss: 1.104877233505249]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6148 [D loss: 0.6188533306121826 | D accuracy: 65.625] [G loss: 1.0196956396102905]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6149 [D loss: 0.597061812877655 | D accuracy: 65.625] [G loss: 1.06768798828125]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6150 [D loss: 0.6378932297229767 | D accuracy: 59.375] [G loss: 1.1003988981246948]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6151 [D loss: 0.6278260350227356 | D accuracy: 64.0625] [G loss: 1.002251386642456]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6152 [D loss: 0.6029604077339172 | D accuracy: 68.75] [G loss: 0.9817265272140503]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6153 [D loss: 0.5875080227851868 | D accuracy: 67.1875] [G loss: 0.9992595314979553]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6154 [D loss: 0.5876126885414124 | D accuracy: 65.625] [G loss: 0.9593828916549683]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6155 [D loss: 0.6367828249931335 | D accuracy: 62.5] [G loss: 0.9368972778320312]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6156 [D loss: 0.6247680187225342 | D accuracy: 59.375] [G loss: 0.980231761932373]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6157 [D loss: 0.5733575820922852 | D accuracy: 68.75] [G loss: 1.0544865131378174]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6158 [D loss: 0.6070653200149536 | D accuracy: 65.625] [G loss: 0.998180627822876]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6159 [D loss: 0.6337146461009979 | D accuracy: 60.9375] [G loss: 1.0961108207702637]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6160 [D loss: 0.5927846878767014 | D accuracy: 67.1875] [G loss: 0.9896353483200073]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6161 [D loss: 0.5762568712234497 | D accuracy: 70.3125] [G loss: 1.0053997039794922]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6162 [D loss: 0.6125737428665161 | D accuracy: 70.3125] [G loss: 0.9492387771606445]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6163 [D loss: 0.5439429581165314 | D accuracy: 71.875] [G loss: 0.9927846193313599]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6164 [D loss: 0.6111299097537994 | D accuracy: 59.375] [G loss: 1.006951093673706]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6165 [D loss: 0.6415044665336609 | D accuracy: 60.9375] [G loss: 1.050441861152649]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6166 [D loss: 0.6636382639408112 | D accuracy: 56.25] [G loss: 1.0293731689453125]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6167 [D loss: 0.6081814169883728 | D accuracy: 71.875] [G loss: 1.150045394897461]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6168 [D loss: 0.6240709125995636 | D accuracy: 68.75] [G loss: 1.0752606391906738]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6169 [D loss: 0.625684529542923 | D accuracy: 64.0625] [G loss: 1.0243644714355469]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6170 [D loss: 0.6270658671855927 | D accuracy: 62.5] [G loss: 1.0726591348648071]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6171 [D loss: 0.5635511577129364 | D accuracy: 68.75] [G loss: 0.9792357683181763]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6172 [D loss: 0.6325205564498901 | D accuracy: 56.25] [G loss: 1.021601915359497]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6173 [D loss: 0.5775660574436188 | D accuracy: 62.5] [G loss: 1.0445480346679688]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6174 [D loss: 0.6325292587280273 | D accuracy: 62.5] [G loss: 0.9617323875427246]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6175 [D loss: 0.5543322563171387 | D accuracy: 70.3125] [G loss: 1.044551134109497]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6176 [D loss: 0.6663736999034882 | D accuracy: 56.25] [G loss: 0.960436224937439]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6177 [D loss: 0.5822301506996155 | D accuracy: 68.75] [G loss: 1.0790834426879883]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6178 [D loss: 0.5734505653381348 | D accuracy: 68.75] [G loss: 1.1295511722564697]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6179 [D loss: 0.7231526374816895 | D accuracy: 62.5] [G loss: 1.0271658897399902]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6180 [D loss: 0.5864962339401245 | D accuracy: 62.5] [G loss: 1.002943992614746]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6181 [D loss: 0.5609791278839111 | D accuracy: 75.0] [G loss: 1.0186761617660522]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6182 [D loss: 0.6084447801113129 | D accuracy: 67.1875] [G loss: 0.9367431998252869]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6183 [D loss: 0.6458337306976318 | D accuracy: 54.6875] [G loss: 0.9885785579681396]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6184 [D loss: 0.6010182797908783 | D accuracy: 68.75] [G loss: 0.962229311466217]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6185 [D loss: 0.6091759204864502 | D accuracy: 68.75] [G loss: 0.9173784255981445]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6186 [D loss: 0.5925486087799072 | D accuracy: 71.875] [G loss: 1.0061876773834229]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6187 [D loss: 0.6306509673595428 | D accuracy: 57.8125] [G loss: 1.0636272430419922]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "6188 [D loss: 0.6007844805717468 | D accuracy: 65.625] [G loss: 0.9786187410354614]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6189 [D loss: 0.7003722786903381 | D accuracy: 51.5625] [G loss: 0.941766619682312]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "6190 [D loss: 0.5872658789157867 | D accuracy: 65.625] [G loss: 1.0438580513000488]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6191 [D loss: 0.5749593675136566 | D accuracy: 68.75] [G loss: 1.0617910623550415]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6192 [D loss: 0.6169699132442474 | D accuracy: 62.5] [G loss: 1.1027162075042725]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6193 [D loss: 0.5866357982158661 | D accuracy: 67.1875] [G loss: 1.002974510192871]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6194 [D loss: 0.6446103453636169 | D accuracy: 64.0625] [G loss: 1.0252113342285156]\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "6195 [D loss: 0.4858988970518112 | D accuracy: 75.0] [G loss: 0.976803183555603]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6196 [D loss: 0.5764477550983429 | D accuracy: 70.3125] [G loss: 0.9749113321304321]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "6197 [D loss: 0.6110815405845642 | D accuracy: 68.75] [G loss: 1.1515839099884033]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6198 [D loss: 0.5607752799987793 | D accuracy: 73.4375] [G loss: 0.9804526567459106]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6199 [D loss: 0.6077775359153748 | D accuracy: 65.625] [G loss: 0.9793920516967773]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "6200 [D loss: 0.5978880524635315 | D accuracy: 67.1875] [G loss: 0.8912190198898315]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6201 [D loss: 0.6206865310668945 | D accuracy: 67.1875] [G loss: 0.9984554052352905]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6202 [D loss: 0.5454806387424469 | D accuracy: 73.4375] [G loss: 0.9697965979576111]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6203 [D loss: 0.6216756105422974 | D accuracy: 67.1875] [G loss: 0.9808093309402466]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6204 [D loss: 0.64313805103302 | D accuracy: 67.1875] [G loss: 1.0970804691314697]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6205 [D loss: 0.6092494428157806 | D accuracy: 73.4375] [G loss: 0.9960832595825195]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6206 [D loss: 0.6108722388744354 | D accuracy: 68.75] [G loss: 1.0697214603424072]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6207 [D loss: 0.6065076887607574 | D accuracy: 68.75] [G loss: 0.9992972612380981]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6208 [D loss: 0.628341555595398 | D accuracy: 70.3125] [G loss: 0.9847760200500488]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6209 [D loss: 0.6046157479286194 | D accuracy: 67.1875] [G loss: 1.0913265943527222]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6210 [D loss: 0.6248700022697449 | D accuracy: 54.6875] [G loss: 1.081298589706421]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6211 [D loss: 0.6963373124599457 | D accuracy: 57.8125] [G loss: 1.0996360778808594]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6212 [D loss: 0.6028648018836975 | D accuracy: 62.5] [G loss: 1.0727698802947998]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6213 [D loss: 0.5799274742603302 | D accuracy: 73.4375] [G loss: 0.9877310991287231]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6214 [D loss: 0.6087736487388611 | D accuracy: 62.5] [G loss: 0.9760454893112183]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6215 [D loss: 0.6100350618362427 | D accuracy: 65.625] [G loss: 1.0541759729385376]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6216 [D loss: 0.6032376289367676 | D accuracy: 59.375] [G loss: 0.984417736530304]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6217 [D loss: 0.5586877167224884 | D accuracy: 75.0] [G loss: 0.9881306886672974]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6218 [D loss: 0.6237235963344574 | D accuracy: 56.25] [G loss: 1.0366294384002686]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6219 [D loss: 0.6758533418178558 | D accuracy: 56.25] [G loss: 0.9714601039886475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6220 [D loss: 0.5644656419754028 | D accuracy: 73.4375] [G loss: 1.0362428426742554]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6221 [D loss: 0.5577566027641296 | D accuracy: 67.1875] [G loss: 0.9859903454780579]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6222 [D loss: 0.6842310130596161 | D accuracy: 54.6875] [G loss: 1.0138719081878662]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6223 [D loss: 0.5886851847171783 | D accuracy: 70.3125] [G loss: 1.0347208976745605]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6224 [D loss: 0.6722408831119537 | D accuracy: 62.5] [G loss: 1.0071847438812256]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6225 [D loss: 0.6302334666252136 | D accuracy: 68.75] [G loss: 0.9866198301315308]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6226 [D loss: 0.5679801106452942 | D accuracy: 62.5] [G loss: 0.9725435972213745]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6227 [D loss: 0.5809876024723053 | D accuracy: 73.4375] [G loss: 0.9152741432189941]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6228 [D loss: 0.5916813015937805 | D accuracy: 67.1875] [G loss: 0.8940856456756592]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6229 [D loss: 0.6011570394039154 | D accuracy: 65.625] [G loss: 0.9911936521530151]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6230 [D loss: 0.6311559081077576 | D accuracy: 60.9375] [G loss: 1.0538986921310425]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6231 [D loss: 0.578373372554779 | D accuracy: 73.4375] [G loss: 0.9842071533203125]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6232 [D loss: 0.6339772641658783 | D accuracy: 60.9375] [G loss: 0.9986120462417603]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6233 [D loss: 0.6609340310096741 | D accuracy: 65.625] [G loss: 1.0339152812957764]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6234 [D loss: 0.56037238240242 | D accuracy: 71.875] [G loss: 0.9979711174964905]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6235 [D loss: 0.5472434461116791 | D accuracy: 73.4375] [G loss: 1.0349993705749512]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6236 [D loss: 0.6276951730251312 | D accuracy: 57.8125] [G loss: 0.9943332672119141]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6237 [D loss: 0.659184604883194 | D accuracy: 56.25] [G loss: 1.0922038555145264]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6238 [D loss: 0.6457145512104034 | D accuracy: 67.1875] [G loss: 1.0641623735427856]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6239 [D loss: 0.6098470985889435 | D accuracy: 65.625] [G loss: 1.040313959121704]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6240 [D loss: 0.6406533718109131 | D accuracy: 65.625] [G loss: 1.085577130317688]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6241 [D loss: 0.5967646837234497 | D accuracy: 64.0625] [G loss: 1.0127534866333008]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6242 [D loss: 0.654952347278595 | D accuracy: 60.9375] [G loss: 1.0065655708312988]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6243 [D loss: 0.548689603805542 | D accuracy: 76.5625] [G loss: 0.9837924838066101]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6244 [D loss: 0.5832235813140869 | D accuracy: 68.75] [G loss: 0.9992563128471375]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6245 [D loss: 0.5739697813987732 | D accuracy: 75.0] [G loss: 1.026808261871338]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6246 [D loss: 0.5567406117916107 | D accuracy: 75.0] [G loss: 1.038804292678833]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6247 [D loss: 0.6679022312164307 | D accuracy: 59.375] [G loss: 1.03822922706604]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6248 [D loss: 0.6991993188858032 | D accuracy: 60.9375] [G loss: 0.9328274726867676]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6249 [D loss: 0.5091778039932251 | D accuracy: 82.8125] [G loss: 1.0686594247817993]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6250 [D loss: 0.6500208377838135 | D accuracy: 59.375] [G loss: 0.8970096707344055]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6251 [D loss: 0.6454399228096008 | D accuracy: 59.375] [G loss: 0.9691795110702515]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6252 [D loss: 0.5668731927871704 | D accuracy: 65.625] [G loss: 1.0279090404510498]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6253 [D loss: 0.6346769332885742 | D accuracy: 67.1875] [G loss: 0.8931376934051514]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6254 [D loss: 0.6152371764183044 | D accuracy: 64.0625] [G loss: 0.8946806192398071]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6255 [D loss: 0.6104516685009003 | D accuracy: 68.75] [G loss: 0.9126206636428833]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6256 [D loss: 0.6907179057598114 | D accuracy: 56.25] [G loss: 1.021988868713379]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6257 [D loss: 0.6035830974578857 | D accuracy: 68.75] [G loss: 1.0325706005096436]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6258 [D loss: 0.6170262694358826 | D accuracy: 60.9375] [G loss: 1.0337560176849365]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6259 [D loss: 0.642955482006073 | D accuracy: 59.375] [G loss: 0.9524387121200562]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6260 [D loss: 0.6273117065429688 | D accuracy: 62.5] [G loss: 1.0102698802947998]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6261 [D loss: 0.5765273571014404 | D accuracy: 67.1875] [G loss: 0.9681422114372253]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6262 [D loss: 0.5695313215255737 | D accuracy: 70.3125] [G loss: 1.0338234901428223]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6263 [D loss: 0.5726935267448425 | D accuracy: 73.4375] [G loss: 1.0830166339874268]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6264 [D loss: 0.6352255940437317 | D accuracy: 59.375] [G loss: 1.0868943929672241]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6265 [D loss: 0.568053662776947 | D accuracy: 71.875] [G loss: 0.9679396748542786]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6266 [D loss: 0.6413963139057159 | D accuracy: 59.375] [G loss: 0.9510399699211121]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6267 [D loss: 0.5591962337493896 | D accuracy: 71.875] [G loss: 1.0469627380371094]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "6268 [D loss: 0.5906222462654114 | D accuracy: 70.3125] [G loss: 1.1145589351654053]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6269 [D loss: 0.5484613478183746 | D accuracy: 67.1875] [G loss: 1.1146042346954346]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6270 [D loss: 0.6250901520252228 | D accuracy: 64.0625] [G loss: 0.9649192094802856]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6271 [D loss: 0.6336525082588196 | D accuracy: 64.0625] [G loss: 0.945111095905304]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6272 [D loss: 0.6017439663410187 | D accuracy: 68.75] [G loss: 0.9699844121932983]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6273 [D loss: 0.5771833658218384 | D accuracy: 75.0] [G loss: 1.0714101791381836]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6274 [D loss: 0.5620050132274628 | D accuracy: 67.1875] [G loss: 1.0953096151351929]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6275 [D loss: 0.5681750923395157 | D accuracy: 68.75] [G loss: 1.1441149711608887]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6276 [D loss: 0.608878493309021 | D accuracy: 64.0625] [G loss: 0.9662178754806519]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6277 [D loss: 0.6142219603061676 | D accuracy: 67.1875] [G loss: 1.0100431442260742]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6278 [D loss: 0.7021267414093018 | D accuracy: 54.6875] [G loss: 0.9448354840278625]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6279 [D loss: 0.6173217594623566 | D accuracy: 60.9375] [G loss: 1.116396188735962]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "6280 [D loss: 0.6452808380126953 | D accuracy: 64.0625] [G loss: 0.908821702003479]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6281 [D loss: 0.5377155989408493 | D accuracy: 70.3125] [G loss: 0.9750926494598389]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6282 [D loss: 0.6103142201900482 | D accuracy: 68.75] [G loss: 0.97328782081604]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6283 [D loss: 0.6025587320327759 | D accuracy: 64.0625] [G loss: 1.0085961818695068]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6284 [D loss: 0.5741281509399414 | D accuracy: 64.0625] [G loss: 1.1242165565490723]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6285 [D loss: 0.5915979892015457 | D accuracy: 70.3125] [G loss: 1.083355188369751]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6286 [D loss: 0.5679122507572174 | D accuracy: 75.0] [G loss: 0.990894615650177]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6287 [D loss: 0.6645612716674805 | D accuracy: 59.375] [G loss: 1.0753920078277588]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6288 [D loss: 0.5912617444992065 | D accuracy: 67.1875] [G loss: 0.8942857384681702]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6289 [D loss: 0.6492179036140442 | D accuracy: 59.375] [G loss: 0.9518139958381653]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6290 [D loss: 0.6228591799736023 | D accuracy: 62.5] [G loss: 0.982904314994812]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6291 [D loss: 0.6539388298988342 | D accuracy: 64.0625] [G loss: 1.0222151279449463]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6292 [D loss: 0.5290742814540863 | D accuracy: 70.3125] [G loss: 1.1015864610671997]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6293 [D loss: 0.5735336244106293 | D accuracy: 73.4375] [G loss: 0.97679603099823]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6294 [D loss: 0.5624964833259583 | D accuracy: 71.875] [G loss: 1.0608413219451904]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6295 [D loss: 0.5124415755271912 | D accuracy: 76.5625] [G loss: 1.0060073137283325]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6296 [D loss: 0.624496579170227 | D accuracy: 64.0625] [G loss: 0.9771431684494019]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6297 [D loss: 0.6371191143989563 | D accuracy: 62.5] [G loss: 1.0245808362960815]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6298 [D loss: 0.6454560458660126 | D accuracy: 60.9375] [G loss: 1.035869836807251]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6299 [D loss: 0.6009502708911896 | D accuracy: 60.9375] [G loss: 1.0431740283966064]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6300 [D loss: 0.5908781588077545 | D accuracy: 64.0625] [G loss: 1.0207136869430542]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6301 [D loss: 0.6329622864723206 | D accuracy: 59.375] [G loss: 0.9968298673629761]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6302 [D loss: 0.6090764999389648 | D accuracy: 71.875] [G loss: 1.0543088912963867]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6303 [D loss: 0.6206580400466919 | D accuracy: 65.625] [G loss: 0.9704060554504395]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6304 [D loss: 0.6325951814651489 | D accuracy: 59.375] [G loss: 0.9941211938858032]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6305 [D loss: 0.5531311631202698 | D accuracy: 62.5] [G loss: 1.099837303161621]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6306 [D loss: 0.6275793313980103 | D accuracy: 64.0625] [G loss: 1.0235751867294312]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6307 [D loss: 0.5598810017108917 | D accuracy: 71.875] [G loss: 0.9962558150291443]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6308 [D loss: 0.6106120944023132 | D accuracy: 65.625] [G loss: 0.9888020157814026]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6309 [D loss: 0.5825500786304474 | D accuracy: 65.625] [G loss: 0.9022611379623413]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6310 [D loss: 0.5851415395736694 | D accuracy: 70.3125] [G loss: 0.9559259414672852]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6311 [D loss: 0.5655218362808228 | D accuracy: 68.75] [G loss: 1.0110890865325928]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6312 [D loss: 0.618133157491684 | D accuracy: 60.9375] [G loss: 0.959671676158905]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6313 [D loss: 0.678830087184906 | D accuracy: 59.375] [G loss: 1.0837055444717407]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6314 [D loss: 0.651524156332016 | D accuracy: 53.125] [G loss: 1.0713211297988892]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6315 [D loss: 0.5820163488388062 | D accuracy: 65.625] [G loss: 1.0618702173233032]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6316 [D loss: 0.5673241764307022 | D accuracy: 75.0] [G loss: 1.120737075805664]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6317 [D loss: 0.6084921061992645 | D accuracy: 64.0625] [G loss: 0.9380007982254028]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6318 [D loss: 0.5977419018745422 | D accuracy: 64.0625] [G loss: 1.01908278465271]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6319 [D loss: 0.6291382908821106 | D accuracy: 64.0625] [G loss: 1.0737621784210205]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6320 [D loss: 0.5625477433204651 | D accuracy: 71.875] [G loss: 1.0904500484466553]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6321 [D loss: 0.6013687551021576 | D accuracy: 68.75] [G loss: 1.0020685195922852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6322 [D loss: 0.6647775769233704 | D accuracy: 57.8125] [G loss: 1.0338457822799683]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6323 [D loss: 0.5887210071086884 | D accuracy: 64.0625] [G loss: 0.9516554474830627]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6324 [D loss: 0.5345963835716248 | D accuracy: 71.875] [G loss: 1.0334806442260742]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6325 [D loss: 0.5834109485149384 | D accuracy: 67.1875] [G loss: 0.9927300810813904]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6326 [D loss: 0.629100501537323 | D accuracy: 62.5] [G loss: 0.9716774821281433]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6327 [D loss: 0.6466609835624695 | D accuracy: 60.9375] [G loss: 0.9426708817481995]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6328 [D loss: 0.6989538669586182 | D accuracy: 60.9375] [G loss: 1.040095567703247]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6329 [D loss: 0.6169537603855133 | D accuracy: 67.1875] [G loss: 1.0609378814697266]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6330 [D loss: 0.5904606580734253 | D accuracy: 68.75] [G loss: 1.0199240446090698]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6331 [D loss: 0.583048015832901 | D accuracy: 67.1875] [G loss: 1.0306403636932373]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6332 [D loss: 0.610802561044693 | D accuracy: 59.375] [G loss: 0.9926913976669312]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6333 [D loss: 0.5823413133621216 | D accuracy: 73.4375] [G loss: 0.967126190662384]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6334 [D loss: 0.561629444360733 | D accuracy: 67.1875] [G loss: 1.0477254390716553]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6335 [D loss: 0.5452908873558044 | D accuracy: 75.0] [G loss: 0.978824257850647]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6336 [D loss: 0.5909416079521179 | D accuracy: 65.625] [G loss: 0.956177830696106]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6337 [D loss: 0.6187012493610382 | D accuracy: 62.5] [G loss: 1.0040210485458374]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6338 [D loss: 0.6779295206069946 | D accuracy: 60.9375] [G loss: 0.984744131565094]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6339 [D loss: 0.6571685969829559 | D accuracy: 59.375] [G loss: 1.1242520809173584]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6340 [D loss: 0.5899722874164581 | D accuracy: 65.625] [G loss: 0.9946619272232056]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6341 [D loss: 0.6006664037704468 | D accuracy: 70.3125] [G loss: 1.0596532821655273]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6342 [D loss: 0.6500461101531982 | D accuracy: 57.8125] [G loss: 0.9648503661155701]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6343 [D loss: 0.6496943831443787 | D accuracy: 51.5625] [G loss: 0.9082083106040955]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6344 [D loss: 0.6044137477874756 | D accuracy: 67.1875] [G loss: 0.9851824641227722]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6345 [D loss: 0.6169554591178894 | D accuracy: 62.5] [G loss: 0.9690734148025513]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6346 [D loss: 0.7031696438789368 | D accuracy: 54.6875] [G loss: 0.9077828526496887]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6347 [D loss: 0.6040481328964233 | D accuracy: 71.875] [G loss: 0.989575207233429]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6348 [D loss: 0.633635401725769 | D accuracy: 59.375] [G loss: 0.9993621110916138]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6349 [D loss: 0.6541551351547241 | D accuracy: 56.25] [G loss: 0.9865578413009644]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6350 [D loss: 0.555410847067833 | D accuracy: 71.875] [G loss: 0.985421359539032]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6351 [D loss: 0.5739826261997223 | D accuracy: 71.875] [G loss: 0.9470802545547485]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6352 [D loss: 0.5978276133537292 | D accuracy: 60.9375] [G loss: 0.9808675050735474]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6353 [D loss: 0.5056359469890594 | D accuracy: 81.25] [G loss: 1.0942893028259277]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6354 [D loss: 0.6169441044330597 | D accuracy: 67.1875] [G loss: 0.9652189016342163]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6355 [D loss: 0.5916908085346222 | D accuracy: 68.75] [G loss: 0.9938527345657349]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6356 [D loss: 0.6323097944259644 | D accuracy: 62.5] [G loss: 1.0432735681533813]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6357 [D loss: 0.5796737372875214 | D accuracy: 70.3125] [G loss: 1.0038038492202759]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6358 [D loss: 0.620841920375824 | D accuracy: 67.1875] [G loss: 1.0991580486297607]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6359 [D loss: 0.5748619735240936 | D accuracy: 68.75] [G loss: 1.0118811130523682]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6360 [D loss: 0.5676447451114655 | D accuracy: 65.625] [G loss: 0.953281044960022]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6361 [D loss: 0.5582698881626129 | D accuracy: 75.0] [G loss: 0.9058759212493896]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6362 [D loss: 0.5601383745670319 | D accuracy: 64.0625] [G loss: 0.9473705291748047]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6363 [D loss: 0.6197384297847748 | D accuracy: 65.625] [G loss: 1.0590457916259766]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6364 [D loss: 0.602239340543747 | D accuracy: 70.3125] [G loss: 1.0257110595703125]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6365 [D loss: 0.5784325003623962 | D accuracy: 70.3125] [G loss: 0.9889016151428223]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6366 [D loss: 0.5917683243751526 | D accuracy: 65.625] [G loss: 0.8877816200256348]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6367 [D loss: 0.533957302570343 | D accuracy: 78.125] [G loss: 0.919583261013031]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6368 [D loss: 0.5801242291927338 | D accuracy: 65.625] [G loss: 1.0000702142715454]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6369 [D loss: 0.5414542257785797 | D accuracy: 78.125] [G loss: 1.0729684829711914]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6370 [D loss: 0.5617809593677521 | D accuracy: 76.5625] [G loss: 0.943711519241333]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6371 [D loss: 0.5759828090667725 | D accuracy: 70.3125] [G loss: 0.9497156739234924]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6372 [D loss: 0.6849523484706879 | D accuracy: 56.25] [G loss: 1.0189049243927002]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6373 [D loss: 0.593469649553299 | D accuracy: 70.3125] [G loss: 1.0650938749313354]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6374 [D loss: 0.575441837310791 | D accuracy: 71.875] [G loss: 1.0318373441696167]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6375 [D loss: 0.5992809534072876 | D accuracy: 68.75] [G loss: 1.041719913482666]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6376 [D loss: 0.5698516368865967 | D accuracy: 67.1875] [G loss: 1.0878126621246338]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6377 [D loss: 0.5813745558261871 | D accuracy: 70.3125] [G loss: 1.1187760829925537]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6378 [D loss: 0.6274071931838989 | D accuracy: 64.0625] [G loss: 1.0567675828933716]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6379 [D loss: 0.5938090682029724 | D accuracy: 67.1875] [G loss: 1.0897784233093262]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6380 [D loss: 0.5994710922241211 | D accuracy: 62.5] [G loss: 1.0633236169815063]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6381 [D loss: 0.5573418438434601 | D accuracy: 67.1875] [G loss: 1.074053406715393]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6382 [D loss: 0.565236508846283 | D accuracy: 71.875] [G loss: 1.0432904958724976]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6383 [D loss: 0.6613191366195679 | D accuracy: 59.375] [G loss: 1.0276157855987549]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6384 [D loss: 0.6214016675949097 | D accuracy: 59.375] [G loss: 1.1454377174377441]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6385 [D loss: 0.6744042932987213 | D accuracy: 60.9375] [G loss: 1.0978612899780273]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6386 [D loss: 0.557459145784378 | D accuracy: 70.3125] [G loss: 1.1247398853302002]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6387 [D loss: 0.5963467359542847 | D accuracy: 67.1875] [G loss: 1.1042819023132324]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6388 [D loss: 0.6702986359596252 | D accuracy: 51.5625] [G loss: 1.0245100259780884]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6389 [D loss: 0.6750336289405823 | D accuracy: 57.8125] [G loss: 1.0216933488845825]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6390 [D loss: 0.5642801523208618 | D accuracy: 65.625] [G loss: 0.9710568785667419]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6391 [D loss: 0.6281479299068451 | D accuracy: 62.5] [G loss: 0.9807799458503723]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6392 [D loss: 0.5993887186050415 | D accuracy: 68.75] [G loss: 1.1207165718078613]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6393 [D loss: 0.586879163980484 | D accuracy: 65.625] [G loss: 0.9069212675094604]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6394 [D loss: 0.5652692019939423 | D accuracy: 68.75] [G loss: 0.9695950746536255]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6395 [D loss: 0.5439033955335617 | D accuracy: 70.3125] [G loss: 0.9945169687271118]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6396 [D loss: 0.6631931662559509 | D accuracy: 62.5] [G loss: 1.062512993812561]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6397 [D loss: 0.5423833131790161 | D accuracy: 68.75] [G loss: 1.0761888027191162]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6398 [D loss: 0.589943528175354 | D accuracy: 60.9375] [G loss: 1.0315837860107422]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6399 [D loss: 0.6083793044090271 | D accuracy: 59.375] [G loss: 0.9988459348678589]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6400 [D loss: 0.5861685276031494 | D accuracy: 59.375] [G loss: 1.0708664655685425]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6401 [D loss: 0.6061645746231079 | D accuracy: 67.1875] [G loss: 0.9428653717041016]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6402 [D loss: 0.6669318377971649 | D accuracy: 56.25] [G loss: 0.9983198046684265]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6403 [D loss: 0.5728430151939392 | D accuracy: 73.4375] [G loss: 0.9590107202529907]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6404 [D loss: 0.557614266872406 | D accuracy: 68.75] [G loss: 0.9851844906806946]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6405 [D loss: 0.5522649586200714 | D accuracy: 71.875] [G loss: 1.019916296005249]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6406 [D loss: 0.5984084010124207 | D accuracy: 67.1875] [G loss: 1.1726484298706055]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6407 [D loss: 0.5719034075737 | D accuracy: 68.75] [G loss: 1.1386241912841797]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6408 [D loss: 0.5821719765663147 | D accuracy: 71.875] [G loss: 1.0299677848815918]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6409 [D loss: 0.6405327320098877 | D accuracy: 62.5] [G loss: 1.0729410648345947]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6410 [D loss: 0.5533783733844757 | D accuracy: 71.875] [G loss: 1.087607979774475]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6411 [D loss: 0.601156622171402 | D accuracy: 62.5] [G loss: 0.9609503149986267]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6412 [D loss: 0.5824092924594879 | D accuracy: 73.4375] [G loss: 1.1341450214385986]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6413 [D loss: 0.542184054851532 | D accuracy: 70.3125] [G loss: 1.0355784893035889]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6414 [D loss: 0.5545690953731537 | D accuracy: 71.875] [G loss: 0.9852103590965271]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6415 [D loss: 0.6067352890968323 | D accuracy: 64.0625] [G loss: 1.1058385372161865]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6416 [D loss: 0.6160010993480682 | D accuracy: 60.9375] [G loss: 1.05708909034729]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6417 [D loss: 0.587541401386261 | D accuracy: 62.5] [G loss: 1.077623963356018]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6418 [D loss: 0.591033548116684 | D accuracy: 60.9375] [G loss: 1.0482409000396729]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6419 [D loss: 0.5071944147348404 | D accuracy: 71.875] [G loss: 1.015609622001648]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6420 [D loss: 0.5647238790988922 | D accuracy: 68.75] [G loss: 1.0206966400146484]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6421 [D loss: 0.6279667913913727 | D accuracy: 67.1875] [G loss: 1.073242425918579]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6422 [D loss: 0.6003196239471436 | D accuracy: 64.0625] [G loss: 1.0453726053237915]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6423 [D loss: 0.5852466225624084 | D accuracy: 62.5] [G loss: 1.1590917110443115]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6424 [D loss: 0.6491524577140808 | D accuracy: 51.5625] [G loss: 1.0586402416229248]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6425 [D loss: 0.5481977164745331 | D accuracy: 75.0] [G loss: 1.077406644821167]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6426 [D loss: 0.6327977776527405 | D accuracy: 64.0625] [G loss: 1.049257516860962]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6427 [D loss: 0.5925677120685577 | D accuracy: 60.9375] [G loss: 1.0380343198776245]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6428 [D loss: 0.5801554620265961 | D accuracy: 70.3125] [G loss: 1.0033347606658936]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6429 [D loss: 0.5863932371139526 | D accuracy: 71.875] [G loss: 1.0658001899719238]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6430 [D loss: 0.5761753022670746 | D accuracy: 67.1875] [G loss: 1.0118049383163452]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "6431 [D loss: 0.6053103506565094 | D accuracy: 73.4375] [G loss: 1.0278489589691162]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "6432 [D loss: 0.5817594528198242 | D accuracy: 73.4375] [G loss: 1.0249202251434326]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6433 [D loss: 0.5924346446990967 | D accuracy: 68.75] [G loss: 0.9194328784942627]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6434 [D loss: 0.605403482913971 | D accuracy: 64.0625] [G loss: 1.0244696140289307]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6435 [D loss: 0.6182271242141724 | D accuracy: 60.9375] [G loss: 1.058324933052063]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "6436 [D loss: 0.6304840445518494 | D accuracy: 64.0625] [G loss: 1.0942527055740356]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6437 [D loss: 0.5981054306030273 | D accuracy: 68.75] [G loss: 1.0241881608963013]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6438 [D loss: 0.6334191560745239 | D accuracy: 60.9375] [G loss: 1.0431503057479858]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "6439 [D loss: 0.590447336435318 | D accuracy: 68.75] [G loss: 1.0532902479171753]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6440 [D loss: 0.6152938008308411 | D accuracy: 62.5] [G loss: 1.1859941482543945]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6441 [D loss: 0.6342004835605621 | D accuracy: 57.8125] [G loss: 1.1321171522140503]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6442 [D loss: 0.55235955119133 | D accuracy: 68.75] [G loss: 1.1568049192428589]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6443 [D loss: 0.624159961938858 | D accuracy: 60.9375] [G loss: 1.0193402767181396]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6444 [D loss: 0.6213257312774658 | D accuracy: 59.375] [G loss: 1.129734992980957]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6445 [D loss: 0.6398405432701111 | D accuracy: 57.8125] [G loss: 1.0794976949691772]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6446 [D loss: 0.6400706171989441 | D accuracy: 56.25] [G loss: 1.0830013751983643]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6447 [D loss: 0.6243897676467896 | D accuracy: 59.375] [G loss: 1.0835497379302979]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6448 [D loss: 0.685669481754303 | D accuracy: 65.625] [G loss: 0.985306441783905]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6449 [D loss: 0.535708874464035 | D accuracy: 75.0] [G loss: 1.0669801235198975]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6450 [D loss: 0.6377932727336884 | D accuracy: 64.0625] [G loss: 1.075232744216919]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6451 [D loss: 0.5847242176532745 | D accuracy: 71.875] [G loss: 0.9495807886123657]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6452 [D loss: 0.6498507261276245 | D accuracy: 62.5] [G loss: 1.0229699611663818]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6453 [D loss: 0.5904490351676941 | D accuracy: 67.1875] [G loss: 0.9928543567657471]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6454 [D loss: 0.5913614630699158 | D accuracy: 70.3125] [G loss: 1.03517746925354]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6455 [D loss: 0.6972631812095642 | D accuracy: 59.375] [G loss: 1.0734196901321411]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6456 [D loss: 0.5947359800338745 | D accuracy: 65.625] [G loss: 0.9776948690414429]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6457 [D loss: 0.6044847667217255 | D accuracy: 68.75] [G loss: 1.0343120098114014]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6458 [D loss: 0.55266073346138 | D accuracy: 68.75] [G loss: 1.0901637077331543]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6459 [D loss: 0.5535343587398529 | D accuracy: 70.3125] [G loss: 0.9977885484695435]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6460 [D loss: 0.659532368183136 | D accuracy: 60.9375] [G loss: 1.0690569877624512]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6461 [D loss: 0.5830835998058319 | D accuracy: 71.875] [G loss: 1.0625977516174316]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6462 [D loss: 0.6129759252071381 | D accuracy: 64.0625] [G loss: 1.027017593383789]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6463 [D loss: 0.5312684774398804 | D accuracy: 71.875] [G loss: 1.0196350812911987]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6464 [D loss: 0.5564559698104858 | D accuracy: 75.0] [G loss: 0.9724390506744385]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6465 [D loss: 0.5988239347934723 | D accuracy: 67.1875] [G loss: 0.9594601988792419]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6466 [D loss: 0.584422767162323 | D accuracy: 70.3125] [G loss: 0.9058330059051514]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6467 [D loss: 0.6024210900068283 | D accuracy: 64.0625] [G loss: 0.9050495028495789]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6468 [D loss: 0.5500703454017639 | D accuracy: 71.875] [G loss: 1.0657098293304443]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6469 [D loss: 0.5878977477550507 | D accuracy: 70.3125] [G loss: 1.0276308059692383]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6470 [D loss: 0.6187312006950378 | D accuracy: 59.375] [G loss: 1.096498727798462]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6471 [D loss: 0.6114235818386078 | D accuracy: 60.9375] [G loss: 0.9977550506591797]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6472 [D loss: 0.6223045885562897 | D accuracy: 59.375] [G loss: 1.0446226596832275]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6473 [D loss: 0.6232266426086426 | D accuracy: 68.75] [G loss: 1.1275348663330078]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6474 [D loss: 0.5549038350582123 | D accuracy: 70.3125] [G loss: 0.9991071224212646]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6475 [D loss: 0.624139130115509 | D accuracy: 64.0625] [G loss: 1.0545217990875244]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6476 [D loss: 0.5942317247390747 | D accuracy: 62.5] [G loss: 1.1505097150802612]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6477 [D loss: 0.6093992292881012 | D accuracy: 59.375] [G loss: 1.0874220132827759]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6478 [D loss: 0.5279943346977234 | D accuracy: 76.5625] [G loss: 1.0760877132415771]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6479 [D loss: 0.5936493277549744 | D accuracy: 65.625] [G loss: 1.082099437713623]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6480 [D loss: 0.5535293519496918 | D accuracy: 75.0] [G loss: 1.0230211019515991]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6481 [D loss: 0.6311590671539307 | D accuracy: 62.5] [G loss: 0.8857924938201904]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6482 [D loss: 0.5640391111373901 | D accuracy: 65.625] [G loss: 0.9995205998420715]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6483 [D loss: 0.6369697153568268 | D accuracy: 64.0625] [G loss: 0.9330501556396484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6484 [D loss: 0.5277281105518341 | D accuracy: 71.875] [G loss: 1.1772220134735107]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6485 [D loss: 0.574988067150116 | D accuracy: 71.875] [G loss: 1.0757017135620117]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6486 [D loss: 0.6168010830879211 | D accuracy: 62.5] [G loss: 0.987494707107544]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6487 [D loss: 0.5566813349723816 | D accuracy: 67.1875] [G loss: 0.9808241724967957]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6488 [D loss: 0.6407445669174194 | D accuracy: 57.8125] [G loss: 1.1004951000213623]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6489 [D loss: 0.5927625894546509 | D accuracy: 67.1875] [G loss: 0.9500402212142944]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6490 [D loss: 0.5865117311477661 | D accuracy: 67.1875] [G loss: 0.9809187650680542]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6491 [D loss: 0.5541667342185974 | D accuracy: 70.3125] [G loss: 1.0599913597106934]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6492 [D loss: 0.5972152352333069 | D accuracy: 70.3125] [G loss: 1.0263057947158813]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6493 [D loss: 0.5430217534303665 | D accuracy: 75.0] [G loss: 0.9990217685699463]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6494 [D loss: 0.5576425194740295 | D accuracy: 70.3125] [G loss: 1.0782573223114014]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6495 [D loss: 0.6597501635551453 | D accuracy: 60.9375] [G loss: 1.0059326887130737]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6496 [D loss: 0.6163390874862671 | D accuracy: 60.9375] [G loss: 1.0597386360168457]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6497 [D loss: 0.5161998867988586 | D accuracy: 81.25] [G loss: 1.0207781791687012]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6498 [D loss: 0.566389411687851 | D accuracy: 75.0] [G loss: 0.9838199615478516]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6499 [D loss: 0.701637476682663 | D accuracy: 60.9375] [G loss: 1.0588634014129639]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6500 [D loss: 0.6255286633968353 | D accuracy: 65.625] [G loss: 0.9504439830780029]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6501 [D loss: 0.5781781673431396 | D accuracy: 68.75] [G loss: 1.0649440288543701]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6502 [D loss: 0.643329381942749 | D accuracy: 51.5625] [G loss: 1.1015565395355225]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6503 [D loss: 0.6434647738933563 | D accuracy: 67.1875] [G loss: 1.037409782409668]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6504 [D loss: 0.6294997036457062 | D accuracy: 56.25] [G loss: 1.0406577587127686]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6505 [D loss: 0.6120093464851379 | D accuracy: 62.5] [G loss: 1.0298736095428467]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6506 [D loss: 0.6190059185028076 | D accuracy: 68.75] [G loss: 1.0149568319320679]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6507 [D loss: 0.6091956794261932 | D accuracy: 64.0625] [G loss: 1.1068824529647827]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6508 [D loss: 0.5243877917528152 | D accuracy: 78.125] [G loss: 1.0476289987564087]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6509 [D loss: 0.5433007776737213 | D accuracy: 68.75] [G loss: 0.9743631482124329]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6510 [D loss: 0.5679277181625366 | D accuracy: 73.4375] [G loss: 1.003342628479004]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6511 [D loss: 0.6191590428352356 | D accuracy: 67.1875] [G loss: 1.0053987503051758]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6512 [D loss: 0.5882783234119415 | D accuracy: 70.3125] [G loss: 1.0260847806930542]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6513 [D loss: 0.6601234674453735 | D accuracy: 64.0625] [G loss: 0.9401581287384033]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6514 [D loss: 0.5608353614807129 | D accuracy: 73.4375] [G loss: 1.0510518550872803]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6515 [D loss: 0.6447899341583252 | D accuracy: 59.375] [G loss: 1.0035473108291626]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6516 [D loss: 0.6008706986904144 | D accuracy: 70.3125] [G loss: 1.11095130443573]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6517 [D loss: 0.6632733345031738 | D accuracy: 56.25] [G loss: 0.9376881122589111]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6518 [D loss: 0.5995954275131226 | D accuracy: 67.1875] [G loss: 1.0437198877334595]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6519 [D loss: 0.6199537217617035 | D accuracy: 62.5] [G loss: 0.9536614418029785]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6520 [D loss: 0.6241198480129242 | D accuracy: 62.5] [G loss: 1.0334535837173462]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6521 [D loss: 0.5721407830715179 | D accuracy: 67.1875] [G loss: 0.8705881834030151]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6522 [D loss: 0.6040630340576172 | D accuracy: 60.9375] [G loss: 0.9212912917137146]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6523 [D loss: 0.5373193621635437 | D accuracy: 76.5625] [G loss: 0.9628221392631531]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6524 [D loss: 0.5574041306972504 | D accuracy: 71.875] [G loss: 1.0986629724502563]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6525 [D loss: 0.5847216248512268 | D accuracy: 67.1875] [G loss: 1.033700704574585]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6526 [D loss: 0.642647922039032 | D accuracy: 60.9375] [G loss: 0.9967846274375916]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6527 [D loss: 0.6460840404033661 | D accuracy: 59.375] [G loss: 0.8789353370666504]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6528 [D loss: 0.598609209060669 | D accuracy: 65.625] [G loss: 1.0331395864486694]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6529 [D loss: 0.6546228528022766 | D accuracy: 62.5] [G loss: 0.9624320864677429]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6530 [D loss: 0.6067773103713989 | D accuracy: 59.375] [G loss: 1.0829691886901855]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6531 [D loss: 0.5632646679878235 | D accuracy: 71.875] [G loss: 1.0694876909255981]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6532 [D loss: 0.5981874763965607 | D accuracy: 68.75] [G loss: 1.014327883720398]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6533 [D loss: 0.6105457246303558 | D accuracy: 60.9375] [G loss: 0.9508689641952515]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6534 [D loss: 0.6176393628120422 | D accuracy: 67.1875] [G loss: 1.0182089805603027]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6535 [D loss: 0.6271184086799622 | D accuracy: 64.0625] [G loss: 0.9383130073547363]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6536 [D loss: 0.5444821417331696 | D accuracy: 79.6875] [G loss: 0.9449039697647095]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6537 [D loss: 0.5780552625656128 | D accuracy: 75.0] [G loss: 0.9571386575698853]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6538 [D loss: 0.5997008383274078 | D accuracy: 70.3125] [G loss: 1.090623140335083]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6539 [D loss: 0.5924170315265656 | D accuracy: 67.1875] [G loss: 0.9178120493888855]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6540 [D loss: 0.6150383651256561 | D accuracy: 54.6875] [G loss: 1.0413873195648193]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6541 [D loss: 0.5851117968559265 | D accuracy: 70.3125] [G loss: 1.1268401145935059]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6542 [D loss: 0.5699303448200226 | D accuracy: 70.3125] [G loss: 1.009303331375122]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6543 [D loss: 0.6370416879653931 | D accuracy: 53.125] [G loss: 1.0479947328567505]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6544 [D loss: 0.645735114812851 | D accuracy: 64.0625] [G loss: 1.0717651844024658]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6545 [D loss: 0.7239740788936615 | D accuracy: 53.125] [G loss: 0.9993632435798645]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6546 [D loss: 0.5435948669910431 | D accuracy: 65.625] [G loss: 1.1492600440979004]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6547 [D loss: 0.6077982783317566 | D accuracy: 68.75] [G loss: 1.0691120624542236]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6548 [D loss: 0.6137479543685913 | D accuracy: 62.5] [G loss: 1.0372310876846313]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6549 [D loss: 0.5777844190597534 | D accuracy: 75.0] [G loss: 0.9934511184692383]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6550 [D loss: 0.5429672598838806 | D accuracy: 70.3125] [G loss: 1.010382890701294]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6551 [D loss: 0.6271374225616455 | D accuracy: 60.9375] [G loss: 0.9965109825134277]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6552 [D loss: 0.6011243164539337 | D accuracy: 64.0625] [G loss: 1.0770267248153687]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6553 [D loss: 0.5702846050262451 | D accuracy: 70.3125] [G loss: 1.0345561504364014]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6554 [D loss: 0.5538080930709839 | D accuracy: 73.4375] [G loss: 1.07949697971344]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6555 [D loss: 0.5336286723613739 | D accuracy: 71.875] [G loss: 1.164428949356079]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6556 [D loss: 0.5486843585968018 | D accuracy: 73.4375] [G loss: 1.0966359376907349]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6557 [D loss: 0.523630291223526 | D accuracy: 67.1875] [G loss: 0.9401264190673828]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6558 [D loss: 0.5227989554405212 | D accuracy: 75.0] [G loss: 0.9355852007865906]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6559 [D loss: 0.5884854197502136 | D accuracy: 67.1875] [G loss: 1.1008610725402832]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6560 [D loss: 0.5434996783733368 | D accuracy: 65.625] [G loss: 1.1388680934906006]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6561 [D loss: 0.6008101105690002 | D accuracy: 67.1875] [G loss: 1.096881628036499]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6562 [D loss: 0.5746390223503113 | D accuracy: 70.3125] [G loss: 1.0618791580200195]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6563 [D loss: 0.5969217419624329 | D accuracy: 64.0625] [G loss: 0.9620023965835571]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6564 [D loss: 0.5577618777751923 | D accuracy: 71.875] [G loss: 0.9903862476348877]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6565 [D loss: 0.5803260505199432 | D accuracy: 70.3125] [G loss: 1.001997470855713]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6566 [D loss: 0.6311404407024384 | D accuracy: 67.1875] [G loss: 0.9554120302200317]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6567 [D loss: 0.6013934016227722 | D accuracy: 65.625] [G loss: 0.9385576248168945]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6568 [D loss: 0.4860881567001343 | D accuracy: 76.5625] [G loss: 1.1629728078842163]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6569 [D loss: 0.665399819612503 | D accuracy: 59.375] [G loss: 1.064965009689331]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6570 [D loss: 0.707484245300293 | D accuracy: 59.375] [G loss: 1.0871975421905518]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6571 [D loss: 0.6334424018859863 | D accuracy: 59.375] [G loss: 0.9972923994064331]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6572 [D loss: 0.6582421958446503 | D accuracy: 57.8125] [G loss: 1.1523221731185913]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6573 [D loss: 0.5466465353965759 | D accuracy: 68.75] [G loss: 1.0624713897705078]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6574 [D loss: 0.6570257544517517 | D accuracy: 65.625] [G loss: 0.9937712550163269]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6575 [D loss: 0.6363788843154907 | D accuracy: 64.0625] [G loss: 1.0192699432373047]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6576 [D loss: 0.580129474401474 | D accuracy: 73.4375] [G loss: 1.0512585639953613]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6577 [D loss: 0.6426954567432404 | D accuracy: 62.5] [G loss: 1.0042402744293213]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6578 [D loss: 0.45086923241615295 | D accuracy: 81.25] [G loss: 0.9716054201126099]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6579 [D loss: 0.5606589913368225 | D accuracy: 75.0] [G loss: 1.0477726459503174]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6580 [D loss: 0.5734167397022247 | D accuracy: 65.625] [G loss: 1.065469741821289]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6581 [D loss: 0.5909456610679626 | D accuracy: 68.75] [G loss: 1.0493412017822266]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6582 [D loss: 0.5657766461372375 | D accuracy: 71.875] [G loss: 1.1031219959259033]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6583 [D loss: 0.5885311961174011 | D accuracy: 62.5] [G loss: 1.1721320152282715]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6584 [D loss: 0.5876131653785706 | D accuracy: 68.75] [G loss: 1.0685462951660156]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6585 [D loss: 0.6341591477394104 | D accuracy: 64.0625] [G loss: 1.0852432250976562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6586 [D loss: 0.6060104072093964 | D accuracy: 64.0625] [G loss: 1.0756776332855225]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6587 [D loss: 0.6027902662754059 | D accuracy: 64.0625] [G loss: 0.966086745262146]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6588 [D loss: 0.6487889289855957 | D accuracy: 62.5] [G loss: 0.9769098162651062]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6589 [D loss: 0.5564124882221222 | D accuracy: 68.75] [G loss: 1.0751805305480957]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6590 [D loss: 0.6732309460639954 | D accuracy: 56.25] [G loss: 0.9434466361999512]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6591 [D loss: 0.6181091666221619 | D accuracy: 62.5] [G loss: 1.0848960876464844]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6592 [D loss: 0.5343683809041977 | D accuracy: 70.3125] [G loss: 1.1093754768371582]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6593 [D loss: 0.5663920640945435 | D accuracy: 70.3125] [G loss: 1.1054694652557373]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6594 [D loss: 0.5407897531986237 | D accuracy: 75.0] [G loss: 1.2010141611099243]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6595 [D loss: 0.6280875205993652 | D accuracy: 70.3125] [G loss: 0.9839380979537964]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "6596 [D loss: 0.5819831788539886 | D accuracy: 75.0] [G loss: 1.0560994148254395]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6597 [D loss: 0.6447368860244751 | D accuracy: 59.375] [G loss: 1.151902198791504]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "6598 [D loss: 0.6021865606307983 | D accuracy: 62.5] [G loss: 0.9845480918884277]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6599 [D loss: 0.612989068031311 | D accuracy: 71.875] [G loss: 1.0088329315185547]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6600 [D loss: 0.6377660036087036 | D accuracy: 60.9375] [G loss: 0.9794508814811707]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6601 [D loss: 0.6308443546295166 | D accuracy: 62.5] [G loss: 1.1174566745758057]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6602 [D loss: 0.6659868657588959 | D accuracy: 59.375] [G loss: 1.0506134033203125]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6603 [D loss: 0.5999059975147247 | D accuracy: 71.875] [G loss: 1.0025534629821777]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6604 [D loss: 0.64140984416008 | D accuracy: 59.375] [G loss: 1.0533124208450317]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "6605 [D loss: 0.6061666309833527 | D accuracy: 64.0625] [G loss: 1.0526230335235596]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6606 [D loss: 0.644563764333725 | D accuracy: 62.5] [G loss: 0.984829843044281]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "6607 [D loss: 0.6015728712081909 | D accuracy: 64.0625] [G loss: 0.9465792179107666]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6608 [D loss: 0.6003067493438721 | D accuracy: 75.0] [G loss: 0.9794005155563354]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6609 [D loss: 0.6150758266448975 | D accuracy: 67.1875] [G loss: 1.0031030178070068]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6610 [D loss: 0.6172716915607452 | D accuracy: 75.0] [G loss: 0.9465442895889282]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6611 [D loss: 0.6144680976867676 | D accuracy: 70.3125] [G loss: 1.0424827337265015]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6612 [D loss: 0.5522006750106812 | D accuracy: 70.3125] [G loss: 0.9563846588134766]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6613 [D loss: 0.6579186022281647 | D accuracy: 65.625] [G loss: 0.9851130247116089]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6614 [D loss: 0.5950045883655548 | D accuracy: 65.625] [G loss: 0.9419350624084473]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6615 [D loss: 0.6395896971225739 | D accuracy: 59.375] [G loss: 1.0201525688171387]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6616 [D loss: 0.5434450805187225 | D accuracy: 68.75] [G loss: 1.063557505607605]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6617 [D loss: 0.5448487997055054 | D accuracy: 73.4375] [G loss: 1.0990620851516724]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6618 [D loss: 0.5742200016975403 | D accuracy: 67.1875] [G loss: 1.0367927551269531]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6619 [D loss: 0.6155952513217926 | D accuracy: 64.0625] [G loss: 1.0622854232788086]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6620 [D loss: 0.5155787914991379 | D accuracy: 79.6875] [G loss: 1.0574883222579956]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6621 [D loss: 0.5512793958187103 | D accuracy: 71.875] [G loss: 1.0330748558044434]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6622 [D loss: 0.6649422645568848 | D accuracy: 54.6875] [G loss: 1.0850110054016113]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6623 [D loss: 0.6247172057628632 | D accuracy: 65.625] [G loss: 1.0324852466583252]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6624 [D loss: 0.5850153267383575 | D accuracy: 67.1875] [G loss: 1.0451054573059082]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6625 [D loss: 0.5573520064353943 | D accuracy: 70.3125] [G loss: 1.0599582195281982]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6626 [D loss: 0.5727887749671936 | D accuracy: 73.4375] [G loss: 1.014245629310608]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6627 [D loss: 0.5797108113765717 | D accuracy: 71.875] [G loss: 1.0510562658309937]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6628 [D loss: 0.6160097122192383 | D accuracy: 71.875] [G loss: 1.0379023551940918]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6629 [D loss: 0.6419309377670288 | D accuracy: 64.0625] [G loss: 1.0785119533538818]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6630 [D loss: 0.6884047389030457 | D accuracy: 57.8125] [G loss: 1.0331093072891235]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6631 [D loss: 0.6453944742679596 | D accuracy: 65.625] [G loss: 1.093807339668274]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6632 [D loss: 0.5960335731506348 | D accuracy: 64.0625] [G loss: 1.0082539319992065]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6633 [D loss: 0.6045296788215637 | D accuracy: 62.5] [G loss: 1.138595700263977]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6634 [D loss: 0.5835996866226196 | D accuracy: 71.875] [G loss: 1.0247855186462402]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6635 [D loss: 0.50394606590271 | D accuracy: 71.875] [G loss: 1.068446159362793]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6636 [D loss: 0.5828056335449219 | D accuracy: 68.75] [G loss: 1.0969822406768799]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6637 [D loss: 0.5590414702892303 | D accuracy: 75.0] [G loss: 0.9922635555267334]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6638 [D loss: 0.5704554915428162 | D accuracy: 70.3125] [G loss: 1.009371280670166]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6639 [D loss: 0.6007831692695618 | D accuracy: 65.625] [G loss: 1.0515553951263428]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6640 [D loss: 0.6377222537994385 | D accuracy: 56.25] [G loss: 1.0294443368911743]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6641 [D loss: 0.5719304531812668 | D accuracy: 70.3125] [G loss: 1.093049168586731]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6642 [D loss: 0.6385911405086517 | D accuracy: 60.9375] [G loss: 1.1492855548858643]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6643 [D loss: 0.5956353545188904 | D accuracy: 68.75] [G loss: 1.1235568523406982]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6644 [D loss: 0.6289496123790741 | D accuracy: 59.375] [G loss: 1.0058220624923706]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6645 [D loss: 0.5667498707771301 | D accuracy: 65.625] [G loss: 1.1015195846557617]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6646 [D loss: 0.6381163895130157 | D accuracy: 57.8125] [G loss: 1.0024908781051636]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6647 [D loss: 0.6257822811603546 | D accuracy: 68.75] [G loss: 1.0344996452331543]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6648 [D loss: 0.578911304473877 | D accuracy: 73.4375] [G loss: 1.0025776624679565]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6649 [D loss: 0.6761863529682159 | D accuracy: 59.375] [G loss: 1.0720338821411133]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6650 [D loss: 0.5607017576694489 | D accuracy: 67.1875] [G loss: 1.012113332748413]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6651 [D loss: 0.5322716534137726 | D accuracy: 76.5625] [G loss: 0.987776517868042]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6652 [D loss: 0.6204030513763428 | D accuracy: 59.375] [G loss: 0.9714723825454712]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6653 [D loss: 0.6527116596698761 | D accuracy: 59.375] [G loss: 0.9946250915527344]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6654 [D loss: 0.6168404817581177 | D accuracy: 59.375] [G loss: 0.9999489188194275]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6655 [D loss: 0.6160105466842651 | D accuracy: 68.75] [G loss: 1.077392339706421]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6656 [D loss: 0.5489133894443512 | D accuracy: 78.125] [G loss: 1.0755687952041626]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6657 [D loss: 0.5940518975257874 | D accuracy: 75.0] [G loss: 1.1287106275558472]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6658 [D loss: 0.5857526063919067 | D accuracy: 67.1875] [G loss: 1.0394717454910278]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6659 [D loss: 0.618840366601944 | D accuracy: 60.9375] [G loss: 1.111975908279419]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6660 [D loss: 0.6224250197410583 | D accuracy: 71.875] [G loss: 1.045883297920227]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6661 [D loss: 0.6554802358150482 | D accuracy: 57.8125] [G loss: 0.9888619184494019]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6662 [D loss: 0.6068502068519592 | D accuracy: 79.6875] [G loss: 1.168637990951538]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6663 [D loss: 0.6192694902420044 | D accuracy: 60.9375] [G loss: 1.0230859518051147]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6664 [D loss: 0.5607825517654419 | D accuracy: 71.875] [G loss: 1.0775134563446045]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6665 [D loss: 0.5949094891548157 | D accuracy: 65.625] [G loss: 1.0241166353225708]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6666 [D loss: 0.5893802046775818 | D accuracy: 73.4375] [G loss: 0.965725839138031]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6667 [D loss: 0.577981173992157 | D accuracy: 76.5625] [G loss: 0.9610373973846436]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6668 [D loss: 0.5273522734642029 | D accuracy: 70.3125] [G loss: 0.9835902452468872]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6669 [D loss: 0.554894208908081 | D accuracy: 70.3125] [G loss: 0.9911403656005859]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6670 [D loss: 0.6617644429206848 | D accuracy: 65.625] [G loss: 1.1133646965026855]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6671 [D loss: 0.6883256733417511 | D accuracy: 54.6875] [G loss: 1.0668048858642578]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6672 [D loss: 0.6037689447402954 | D accuracy: 60.9375] [G loss: 1.0075504779815674]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6673 [D loss: 0.5348728001117706 | D accuracy: 76.5625] [G loss: 0.9797849655151367]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6674 [D loss: 0.5778408646583557 | D accuracy: 71.875] [G loss: 1.0273903608322144]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6675 [D loss: 0.5148004740476608 | D accuracy: 75.0] [G loss: 1.007657527923584]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6676 [D loss: 0.6187766790390015 | D accuracy: 59.375] [G loss: 0.9844987392425537]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6677 [D loss: 0.6487429141998291 | D accuracy: 57.8125] [G loss: 1.0687602758407593]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6678 [D loss: 0.5510693490505219 | D accuracy: 70.3125] [G loss: 1.0957226753234863]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6679 [D loss: 0.5513047277927399 | D accuracy: 75.0] [G loss: 1.0520765781402588]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6680 [D loss: 0.6217040866613388 | D accuracy: 68.75] [G loss: 1.0469443798065186]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6681 [D loss: 0.6143141686916351 | D accuracy: 59.375] [G loss: 0.9975215196609497]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6682 [D loss: 0.5969655811786652 | D accuracy: 62.5] [G loss: 1.0177658796310425]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6683 [D loss: 0.5857609510421753 | D accuracy: 68.75] [G loss: 1.0882625579833984]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6684 [D loss: 0.5601159334182739 | D accuracy: 68.75] [G loss: 1.0099819898605347]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6685 [D loss: 0.5575614869594574 | D accuracy: 70.3125] [G loss: 1.044827938079834]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6686 [D loss: 0.6113978922367096 | D accuracy: 67.1875] [G loss: 0.9615476131439209]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6687 [D loss: 0.5699063539505005 | D accuracy: 68.75] [G loss: 1.0248188972473145]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6688 [D loss: 0.5129689574241638 | D accuracy: 73.4375] [G loss: 1.107548713684082]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6689 [D loss: 0.6094585061073303 | D accuracy: 60.9375] [G loss: 1.0449702739715576]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6690 [D loss: 0.5873681902885437 | D accuracy: 70.3125] [G loss: 1.080729603767395]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6691 [D loss: 0.653139054775238 | D accuracy: 64.0625] [G loss: 1.046589970588684]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6692 [D loss: 0.5106886029243469 | D accuracy: 76.5625] [G loss: 0.9540523290634155]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6693 [D loss: 0.5113760679960251 | D accuracy: 76.5625] [G loss: 1.048449993133545]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6694 [D loss: 0.5863605439662933 | D accuracy: 68.75] [G loss: 1.1823484897613525]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6695 [D loss: 0.5907785892486572 | D accuracy: 68.75] [G loss: 1.037390947341919]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6696 [D loss: 0.5787451565265656 | D accuracy: 67.1875] [G loss: 1.0415624380111694]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6697 [D loss: 0.5476170778274536 | D accuracy: 70.3125] [G loss: 1.0082532167434692]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6698 [D loss: 0.5014950633049011 | D accuracy: 78.125] [G loss: 0.9357267618179321]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6699 [D loss: 0.5799277126789093 | D accuracy: 67.1875] [G loss: 1.0057146549224854]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6700 [D loss: 0.5912503302097321 | D accuracy: 64.0625] [G loss: 1.0697295665740967]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6701 [D loss: 0.5376035869121552 | D accuracy: 76.5625] [G loss: 1.0797877311706543]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6702 [D loss: 0.5687574744224548 | D accuracy: 76.5625] [G loss: 1.1527003049850464]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6703 [D loss: 0.5969932973384857 | D accuracy: 64.0625] [G loss: 1.096125841140747]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6704 [D loss: 0.5961190462112427 | D accuracy: 67.1875] [G loss: 1.0161051750183105]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6705 [D loss: 0.5936835408210754 | D accuracy: 64.0625] [G loss: 1.0517503023147583]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6706 [D loss: 0.6253772079944611 | D accuracy: 60.9375] [G loss: 1.0458204746246338]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6707 [D loss: 0.6177252233028412 | D accuracy: 59.375] [G loss: 1.1251994371414185]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6708 [D loss: 0.6699097752571106 | D accuracy: 65.625] [G loss: 1.002925992012024]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6709 [D loss: 0.5871100425720215 | D accuracy: 67.1875] [G loss: 0.9805407524108887]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6710 [D loss: 0.5238915979862213 | D accuracy: 71.875] [G loss: 1.0388544797897339]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6711 [D loss: 0.6264317333698273 | D accuracy: 64.0625] [G loss: 1.0232975482940674]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6712 [D loss: 0.5091111958026886 | D accuracy: 71.875] [G loss: 1.0351996421813965]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6713 [D loss: 0.7015625834465027 | D accuracy: 59.375] [G loss: 0.9871607422828674]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6714 [D loss: 0.5976909697055817 | D accuracy: 68.75] [G loss: 1.0951699018478394]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6715 [D loss: 0.6200087070465088 | D accuracy: 67.1875] [G loss: 0.9812092781066895]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6716 [D loss: 0.6062709093093872 | D accuracy: 68.75] [G loss: 1.1014512777328491]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6717 [D loss: 0.6083919703960419 | D accuracy: 62.5] [G loss: 1.1113440990447998]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "6718 [D loss: 0.5617997944355011 | D accuracy: 71.875] [G loss: 1.0040817260742188]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6719 [D loss: 0.6419719755649567 | D accuracy: 65.625] [G loss: 1.0362801551818848]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6720 [D loss: 0.5877654254436493 | D accuracy: 68.75] [G loss: 1.1578701734542847]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6721 [D loss: 0.6082721948623657 | D accuracy: 68.75] [G loss: 1.2002902030944824]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6722 [D loss: 0.6133431792259216 | D accuracy: 75.0] [G loss: 1.1236029863357544]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6723 [D loss: 0.6023675799369812 | D accuracy: 68.75] [G loss: 1.0364859104156494]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6724 [D loss: 0.6554927229881287 | D accuracy: 56.25] [G loss: 1.0490705966949463]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6725 [D loss: 0.6151393055915833 | D accuracy: 57.8125] [G loss: 1.0203919410705566]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6726 [D loss: 0.6224670708179474 | D accuracy: 64.0625] [G loss: 1.0598626136779785]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6727 [D loss: 0.5563580542802811 | D accuracy: 75.0] [G loss: 1.129953145980835]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6728 [D loss: 0.6533110439777374 | D accuracy: 67.1875] [G loss: 1.0450623035430908]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6729 [D loss: 0.5630116760730743 | D accuracy: 71.875] [G loss: 1.0793509483337402]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6730 [D loss: 0.613028883934021 | D accuracy: 64.0625] [G loss: 1.008836269378662]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6731 [D loss: 0.5704641044139862 | D accuracy: 67.1875] [G loss: 0.9714797735214233]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6732 [D loss: 0.5311371684074402 | D accuracy: 70.3125] [G loss: 1.0522311925888062]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6733 [D loss: 0.6535453498363495 | D accuracy: 57.8125] [G loss: 1.0731074810028076]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6734 [D loss: 0.6528981626033783 | D accuracy: 67.1875] [G loss: 1.0324187278747559]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6735 [D loss: 0.5701955556869507 | D accuracy: 64.0625] [G loss: 0.9539673924446106]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6736 [D loss: 0.6199620366096497 | D accuracy: 56.25] [G loss: 1.1067273616790771]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6737 [D loss: 0.6920851469039917 | D accuracy: 51.5625] [G loss: 0.8705859780311584]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6738 [D loss: 0.5880039930343628 | D accuracy: 68.75] [G loss: 1.0174531936645508]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6739 [D loss: 0.5475418865680695 | D accuracy: 76.5625] [G loss: 1.1390490531921387]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6740 [D loss: 0.6689744293689728 | D accuracy: 57.8125] [G loss: 1.1107009649276733]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6741 [D loss: 0.6087904870510101 | D accuracy: 64.0625] [G loss: 0.9906684756278992]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6742 [D loss: 0.6644163727760315 | D accuracy: 59.375] [G loss: 1.018315076828003]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6743 [D loss: 0.5822858512401581 | D accuracy: 65.625] [G loss: 1.0660849809646606]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6744 [D loss: 0.6120571494102478 | D accuracy: 64.0625] [G loss: 1.0758275985717773]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6745 [D loss: 0.6702952682971954 | D accuracy: 59.375] [G loss: 1.0557564496994019]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6746 [D loss: 0.6000199615955353 | D accuracy: 68.75] [G loss: 0.9928025007247925]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6747 [D loss: 0.622389554977417 | D accuracy: 65.625] [G loss: 1.0027350187301636]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6748 [D loss: 0.6004624366760254 | D accuracy: 65.625] [G loss: 1.1109933853149414]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6749 [D loss: 0.6889399886131287 | D accuracy: 54.6875] [G loss: 0.9678332209587097]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6750 [D loss: 0.5754902958869934 | D accuracy: 67.1875] [G loss: 0.9832491874694824]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6751 [D loss: 0.6228862702846527 | D accuracy: 68.75] [G loss: 1.024945616722107]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6752 [D loss: 0.5586653351783752 | D accuracy: 65.625] [G loss: 1.027878999710083]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6753 [D loss: 0.5587723255157471 | D accuracy: 70.3125] [G loss: 0.9824123382568359]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "6754 [D loss: 0.5203285962343216 | D accuracy: 78.125] [G loss: 1.1004940271377563]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6755 [D loss: 0.5859341025352478 | D accuracy: 64.0625] [G loss: 1.0701406002044678]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6756 [D loss: 0.5380339026451111 | D accuracy: 76.5625] [G loss: 1.0683331489562988]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6757 [D loss: 0.6982588469982147 | D accuracy: 59.375] [G loss: 1.070834994316101]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6758 [D loss: 0.5975755453109741 | D accuracy: 65.625] [G loss: 1.1064156293869019]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6759 [D loss: 0.5825003385543823 | D accuracy: 64.0625] [G loss: 1.0286600589752197]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6760 [D loss: 0.5900225043296814 | D accuracy: 67.1875] [G loss: 1.021296739578247]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6761 [D loss: 0.6015662848949432 | D accuracy: 67.1875] [G loss: 1.0456657409667969]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6762 [D loss: 0.5564053058624268 | D accuracy: 71.875] [G loss: 1.0444501638412476]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6763 [D loss: 0.5311841070652008 | D accuracy: 73.4375] [G loss: 1.0706894397735596]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6764 [D loss: 0.5514045059680939 | D accuracy: 73.4375] [G loss: 1.0124714374542236]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6765 [D loss: 0.590997040271759 | D accuracy: 59.375] [G loss: 1.0679421424865723]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6766 [D loss: 0.6280121058225632 | D accuracy: 68.75] [G loss: 1.0236728191375732]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6767 [D loss: 0.5896918475627899 | D accuracy: 67.1875] [G loss: 1.0250695943832397]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6768 [D loss: 0.581185519695282 | D accuracy: 65.625] [G loss: 1.0316379070281982]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6769 [D loss: 0.5816400349140167 | D accuracy: 62.5] [G loss: 1.0492818355560303]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6770 [D loss: 0.5948194265365601 | D accuracy: 68.75] [G loss: 1.083046793937683]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6771 [D loss: 0.6111816167831421 | D accuracy: 60.9375] [G loss: 0.9614107608795166]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6772 [D loss: 0.6019467711448669 | D accuracy: 68.75] [G loss: 0.975217342376709]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6773 [D loss: 0.6499123871326447 | D accuracy: 70.3125] [G loss: 1.1011266708374023]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6774 [D loss: 0.640947699546814 | D accuracy: 62.5] [G loss: 1.0819907188415527]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6775 [D loss: 0.5782278180122375 | D accuracy: 70.3125] [G loss: 1.0805739164352417]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6776 [D loss: 0.6286086440086365 | D accuracy: 65.625] [G loss: 1.0276529788970947]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6777 [D loss: 0.6399681866168976 | D accuracy: 70.3125] [G loss: 0.9651246070861816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6778 [D loss: 0.6592737436294556 | D accuracy: 64.0625] [G loss: 0.8807865381240845]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6779 [D loss: 0.5149779617786407 | D accuracy: 78.125] [G loss: 0.9987527132034302]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6780 [D loss: 0.5333282947540283 | D accuracy: 73.4375] [G loss: 1.0877902507781982]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6781 [D loss: 0.5919620990753174 | D accuracy: 68.75] [G loss: 1.077765703201294]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6782 [D loss: 0.5908641815185547 | D accuracy: 64.0625] [G loss: 1.0589759349822998]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6783 [D loss: 0.6020857989788055 | D accuracy: 60.9375] [G loss: 1.1474077701568604]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6784 [D loss: 0.5828040540218353 | D accuracy: 62.5] [G loss: 1.1109373569488525]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6785 [D loss: 0.47619107365608215 | D accuracy: 78.125] [G loss: 1.1713874340057373]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6786 [D loss: 0.593554675579071 | D accuracy: 67.1875] [G loss: 1.1145371198654175]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6787 [D loss: 0.662035197019577 | D accuracy: 60.9375] [G loss: 0.9819148778915405]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6788 [D loss: 0.606645405292511 | D accuracy: 68.75] [G loss: 1.0931596755981445]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6789 [D loss: 0.5942995548248291 | D accuracy: 65.625] [G loss: 1.085477352142334]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6790 [D loss: 0.6542756855487823 | D accuracy: 57.8125] [G loss: 0.9873579144477844]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6791 [D loss: 0.5586473941802979 | D accuracy: 65.625] [G loss: 1.0394988059997559]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6792 [D loss: 0.5261454582214355 | D accuracy: 70.3125] [G loss: 1.0967010259628296]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6793 [D loss: 0.5112107992172241 | D accuracy: 76.5625] [G loss: 1.0682706832885742]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6794 [D loss: 0.5951205790042877 | D accuracy: 68.75] [G loss: 1.0953716039657593]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6795 [D loss: 0.5210780501365662 | D accuracy: 75.0] [G loss: 1.086597204208374]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6796 [D loss: 0.5598972737789154 | D accuracy: 64.0625] [G loss: 1.036159634590149]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6797 [D loss: 0.6443639099597931 | D accuracy: 57.8125] [G loss: 1.0265799760818481]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6798 [D loss: 0.6310882866382599 | D accuracy: 65.625] [G loss: 1.0162608623504639]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6799 [D loss: 0.5907659530639648 | D accuracy: 68.75] [G loss: 1.0638147592544556]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6800 [D loss: 0.5578425526618958 | D accuracy: 71.875] [G loss: 1.0189789533615112]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6801 [D loss: 0.5517792999744415 | D accuracy: 73.4375] [G loss: 0.9670373201370239]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6802 [D loss: 0.5651260018348694 | D accuracy: 65.625] [G loss: 1.075364589691162]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6803 [D loss: 0.5966568291187286 | D accuracy: 65.625] [G loss: 1.0596134662628174]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6804 [D loss: 0.5301354825496674 | D accuracy: 75.0] [G loss: 1.032529354095459]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6805 [D loss: 0.5872986316680908 | D accuracy: 60.9375] [G loss: 1.1228071451187134]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6806 [D loss: 0.58381187915802 | D accuracy: 68.75] [G loss: 1.03477144241333]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6807 [D loss: 0.6238021850585938 | D accuracy: 70.3125] [G loss: 1.0369452238082886]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6808 [D loss: 0.5605431199073792 | D accuracy: 65.625] [G loss: 1.0378525257110596]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6809 [D loss: 0.5404510796070099 | D accuracy: 76.5625] [G loss: 1.0297340154647827]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6810 [D loss: 0.6589362323284149 | D accuracy: 59.375] [G loss: 1.0512627363204956]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6811 [D loss: 0.5198367238044739 | D accuracy: 78.125] [G loss: 1.0270488262176514]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6812 [D loss: 0.611965000629425 | D accuracy: 62.5] [G loss: 0.991105318069458]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6813 [D loss: 0.6049626767635345 | D accuracy: 68.75] [G loss: 1.0166064500808716]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6814 [D loss: 0.5845021307468414 | D accuracy: 64.0625] [G loss: 1.1651246547698975]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6815 [D loss: 0.6227821111679077 | D accuracy: 64.0625] [G loss: 1.1794748306274414]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6816 [D loss: 0.5313805043697357 | D accuracy: 73.4375] [G loss: 1.040150761604309]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6817 [D loss: 0.6022283732891083 | D accuracy: 65.625] [G loss: 1.0412309169769287]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6818 [D loss: 0.5700497627258301 | D accuracy: 68.75] [G loss: 1.0810221433639526]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6819 [D loss: 0.6448641717433929 | D accuracy: 56.25] [G loss: 0.9092890024185181]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6820 [D loss: 0.5570622682571411 | D accuracy: 70.3125] [G loss: 0.9391520023345947]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6821 [D loss: 0.6792898178100586 | D accuracy: 59.375] [G loss: 1.0635364055633545]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6822 [D loss: 0.5247493386268616 | D accuracy: 78.125] [G loss: 1.0936064720153809]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6823 [D loss: 0.5680564045906067 | D accuracy: 75.0] [G loss: 1.1215672492980957]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6824 [D loss: 0.498453825712204 | D accuracy: 70.3125] [G loss: 1.0723836421966553]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6825 [D loss: 0.5542682260274887 | D accuracy: 70.3125] [G loss: 0.957612931728363]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6826 [D loss: 0.4850621223449707 | D accuracy: 81.25] [G loss: 1.163779616355896]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6827 [D loss: 0.6091322004795074 | D accuracy: 67.1875] [G loss: 1.0143346786499023]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6828 [D loss: 0.6143372058868408 | D accuracy: 64.0625] [G loss: 1.0769925117492676]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6829 [D loss: 0.6271643042564392 | D accuracy: 59.375] [G loss: 1.121497392654419]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6830 [D loss: 0.5653775334358215 | D accuracy: 71.875] [G loss: 1.248518943786621]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6831 [D loss: 0.5843693017959595 | D accuracy: 65.625] [G loss: 1.0376901626586914]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "6832 [D loss: 0.5400337278842926 | D accuracy: 67.1875] [G loss: 1.0371088981628418]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "6833 [D loss: 0.5415492951869965 | D accuracy: 73.4375] [G loss: 0.9889413118362427]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6834 [D loss: 0.5522244572639465 | D accuracy: 79.6875] [G loss: 1.0133134126663208]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "6835 [D loss: 0.65153968334198 | D accuracy: 57.8125] [G loss: 1.0693864822387695]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6836 [D loss: 0.5682927966117859 | D accuracy: 73.4375] [G loss: 1.0994293689727783]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "6837 [D loss: 0.5943326354026794 | D accuracy: 65.625] [G loss: 1.1411585807800293]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6838 [D loss: 0.5719338059425354 | D accuracy: 71.875] [G loss: 1.0894029140472412]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6839 [D loss: 0.5497866272926331 | D accuracy: 73.4375] [G loss: 1.0642471313476562]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6840 [D loss: 0.6225276589393616 | D accuracy: 65.625] [G loss: 1.0477280616760254]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6841 [D loss: 0.664160966873169 | D accuracy: 59.375] [G loss: 1.0492215156555176]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6842 [D loss: 0.6701518297195435 | D accuracy: 67.1875] [G loss: 1.0331993103027344]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "6843 [D loss: 0.5000580698251724 | D accuracy: 79.6875] [G loss: 1.1772687435150146]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "6844 [D loss: 0.561120331287384 | D accuracy: 70.3125] [G loss: 1.1936757564544678]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6845 [D loss: 0.6383010745048523 | D accuracy: 60.9375] [G loss: 1.046204924583435]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "6846 [D loss: 0.5399258136749268 | D accuracy: 75.0] [G loss: 1.0745922327041626]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6847 [D loss: 0.5889128148555756 | D accuracy: 75.0] [G loss: 0.9982291460037231]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6848 [D loss: 0.5720320343971252 | D accuracy: 68.75] [G loss: 1.0431108474731445]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6849 [D loss: 0.6781482100486755 | D accuracy: 57.8125] [G loss: 1.0294746160507202]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6850 [D loss: 0.6616005003452301 | D accuracy: 57.8125] [G loss: 1.0317553281784058]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6851 [D loss: 0.5402852296829224 | D accuracy: 71.875] [G loss: 1.0037100315093994]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6852 [D loss: 0.5976165533065796 | D accuracy: 60.9375] [G loss: 1.034758448600769]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6853 [D loss: 0.58622807264328 | D accuracy: 67.1875] [G loss: 0.9573838710784912]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6854 [D loss: 0.5658556222915649 | D accuracy: 75.0] [G loss: 1.0326883792877197]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6855 [D loss: 0.5723732113838196 | D accuracy: 70.3125] [G loss: 1.0495244264602661]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6856 [D loss: 0.5822232663631439 | D accuracy: 64.0625] [G loss: 1.1699590682983398]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6857 [D loss: 0.6467718183994293 | D accuracy: 60.9375] [G loss: 1.1579055786132812]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6858 [D loss: 0.5706832110881805 | D accuracy: 67.1875] [G loss: 1.0974267721176147]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6859 [D loss: 0.6321097016334534 | D accuracy: 57.8125] [G loss: 1.104980707168579]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6860 [D loss: 0.5739511251449585 | D accuracy: 73.4375] [G loss: 0.9985613822937012]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6861 [D loss: 0.5966164469718933 | D accuracy: 64.0625] [G loss: 1.0819569826126099]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6862 [D loss: 0.6313142478466034 | D accuracy: 65.625] [G loss: 1.0584285259246826]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6863 [D loss: 0.6046052575111389 | D accuracy: 60.9375] [G loss: 1.0412838459014893]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6864 [D loss: 0.6144917905330658 | D accuracy: 65.625] [G loss: 0.9761971235275269]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6865 [D loss: 0.6307105720043182 | D accuracy: 62.5] [G loss: 0.9683769941329956]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6866 [D loss: 0.5879228711128235 | D accuracy: 71.875] [G loss: 0.986156702041626]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6867 [D loss: 0.5298705995082855 | D accuracy: 73.4375] [G loss: 1.0862164497375488]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6868 [D loss: 0.6136492490768433 | D accuracy: 60.9375] [G loss: 1.0060291290283203]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6869 [D loss: 0.5705478489398956 | D accuracy: 70.3125] [G loss: 1.0527513027191162]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6870 [D loss: 0.5862676203250885 | D accuracy: 73.4375] [G loss: 0.9749836921691895]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6871 [D loss: 0.5813325047492981 | D accuracy: 73.4375] [G loss: 1.1142607927322388]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6872 [D loss: 0.5527306497097015 | D accuracy: 71.875] [G loss: 1.039675235748291]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6873 [D loss: 0.6342118382453918 | D accuracy: 60.9375] [G loss: 1.0733203887939453]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6874 [D loss: 0.520329624414444 | D accuracy: 70.3125] [G loss: 1.0432686805725098]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6875 [D loss: 0.5746964812278748 | D accuracy: 71.875] [G loss: 1.055614948272705]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6876 [D loss: 0.6276439428329468 | D accuracy: 68.75] [G loss: 1.1006596088409424]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6877 [D loss: 0.6622615456581116 | D accuracy: 60.9375] [G loss: 1.0271661281585693]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6878 [D loss: 0.6010987162590027 | D accuracy: 67.1875] [G loss: 1.0920042991638184]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6879 [D loss: 0.5429590344429016 | D accuracy: 75.0] [G loss: 1.0762145519256592]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6880 [D loss: 0.5397515892982483 | D accuracy: 75.0] [G loss: 1.0248866081237793]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6881 [D loss: 0.5714884102344513 | D accuracy: 68.75] [G loss: 1.0191411972045898]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6882 [D loss: 0.549415335059166 | D accuracy: 71.875] [G loss: 1.086172342300415]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6883 [D loss: 0.5580385625362396 | D accuracy: 67.1875] [G loss: 1.0436818599700928]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6884 [D loss: 0.6601396799087524 | D accuracy: 64.0625] [G loss: 1.0189952850341797]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6885 [D loss: 0.650499016046524 | D accuracy: 62.5] [G loss: 1.0113492012023926]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6886 [D loss: 0.5767372250556946 | D accuracy: 73.4375] [G loss: 0.9983292818069458]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6887 [D loss: 0.5859251916408539 | D accuracy: 67.1875] [G loss: 0.9441156983375549]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6888 [D loss: 0.6369413435459137 | D accuracy: 60.9375] [G loss: 0.9970777630805969]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6889 [D loss: 0.6256624460220337 | D accuracy: 62.5] [G loss: 0.934145987033844]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6890 [D loss: 0.5906801521778107 | D accuracy: 64.0625] [G loss: 0.9639511108398438]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6891 [D loss: 0.5192341506481171 | D accuracy: 78.125] [G loss: 0.9733286499977112]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6892 [D loss: 0.5390408337116241 | D accuracy: 71.875] [G loss: 1.0208017826080322]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6893 [D loss: 0.5281387567520142 | D accuracy: 78.125] [G loss: 1.0705831050872803]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6894 [D loss: 0.5610139071941376 | D accuracy: 65.625] [G loss: 1.1638375520706177]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6895 [D loss: 0.5862769484519958 | D accuracy: 73.4375] [G loss: 1.073799967765808]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6896 [D loss: 0.5133928954601288 | D accuracy: 76.5625] [G loss: 1.0721654891967773]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6897 [D loss: 0.5956517159938812 | D accuracy: 75.0] [G loss: 1.0393850803375244]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6898 [D loss: 0.6036057472229004 | D accuracy: 65.625] [G loss: 1.0246201753616333]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6899 [D loss: 0.5808878540992737 | D accuracy: 64.0625] [G loss: 0.9845592379570007]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6900 [D loss: 0.5718844830989838 | D accuracy: 65.625] [G loss: 0.9846333265304565]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6901 [D loss: 0.6681362092494965 | D accuracy: 56.25] [G loss: 0.9868388772010803]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6902 [D loss: 0.6353577971458435 | D accuracy: 64.0625] [G loss: 1.0584187507629395]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6903 [D loss: 0.5645577311515808 | D accuracy: 67.1875] [G loss: 1.0523242950439453]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6904 [D loss: 0.6251707673072815 | D accuracy: 53.125] [G loss: 0.9309057593345642]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6905 [D loss: 0.6878230273723602 | D accuracy: 64.0625] [G loss: 1.0907357931137085]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6906 [D loss: 0.591585636138916 | D accuracy: 71.875] [G loss: 0.9627993106842041]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6907 [D loss: 0.673488587141037 | D accuracy: 62.5] [G loss: 1.140047550201416]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6908 [D loss: 0.6131521463394165 | D accuracy: 71.875] [G loss: 1.0762933492660522]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6909 [D loss: 0.6094128489494324 | D accuracy: 68.75] [G loss: 1.1591570377349854]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6910 [D loss: 0.6080286204814911 | D accuracy: 68.75] [G loss: 1.0001705884933472]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6911 [D loss: 0.6625296473503113 | D accuracy: 54.6875] [G loss: 0.9915201663970947]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "6912 [D loss: 0.5748032629489899 | D accuracy: 68.75] [G loss: 0.9601016640663147]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "6913 [D loss: 0.639030933380127 | D accuracy: 59.375] [G loss: 0.9790579080581665]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "6914 [D loss: 0.5773160755634308 | D accuracy: 64.0625] [G loss: 1.0814106464385986]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6915 [D loss: 0.5371606051921844 | D accuracy: 70.3125] [G loss: 1.0143992900848389]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "6916 [D loss: 0.5395582765340805 | D accuracy: 71.875] [G loss: 1.0566331148147583]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6917 [D loss: 0.5718237161636353 | D accuracy: 71.875] [G loss: 1.0519464015960693]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "6918 [D loss: 0.5723336338996887 | D accuracy: 65.625] [G loss: 0.9890033006668091]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "6919 [D loss: 0.5833092927932739 | D accuracy: 67.1875] [G loss: 1.0735721588134766]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "6920 [D loss: 0.632127195596695 | D accuracy: 62.5] [G loss: 1.002772569656372]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6921 [D loss: 0.5595112144947052 | D accuracy: 65.625] [G loss: 1.0912914276123047]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "6922 [D loss: 0.5865124464035034 | D accuracy: 68.75] [G loss: 1.0324705839157104]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6923 [D loss: 0.6268435120582581 | D accuracy: 64.0625] [G loss: 0.9774589538574219]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6924 [D loss: 0.6086221635341644 | D accuracy: 60.9375] [G loss: 1.0347299575805664]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6925 [D loss: 0.6804347336292267 | D accuracy: 53.125] [G loss: 1.115719199180603]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6926 [D loss: 0.5106738209724426 | D accuracy: 75.0] [G loss: 1.1427760124206543]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6927 [D loss: 0.655242383480072 | D accuracy: 62.5] [G loss: 1.1079277992248535]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6928 [D loss: 0.5207324028015137 | D accuracy: 78.125] [G loss: 1.0155755281448364]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6929 [D loss: 0.5497563630342484 | D accuracy: 73.4375] [G loss: 1.0124094486236572]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6930 [D loss: 0.6515394747257233 | D accuracy: 57.8125] [G loss: 1.0319100618362427]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6931 [D loss: 0.57377889752388 | D accuracy: 73.4375] [G loss: 1.0184476375579834]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6932 [D loss: 0.541849821805954 | D accuracy: 73.4375] [G loss: 1.2564432621002197]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6933 [D loss: 0.6073010265827179 | D accuracy: 70.3125] [G loss: 1.1495378017425537]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6934 [D loss: 0.6040183305740356 | D accuracy: 64.0625] [G loss: 1.0375173091888428]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6935 [D loss: 0.6185121536254883 | D accuracy: 70.3125] [G loss: 1.0461617708206177]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6936 [D loss: 0.5898335576057434 | D accuracy: 67.1875] [G loss: 1.0568339824676514]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6937 [D loss: 0.6621721386909485 | D accuracy: 51.5625] [G loss: 0.9696422219276428]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6938 [D loss: 0.5883837044239044 | D accuracy: 65.625] [G loss: 1.0076707601547241]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6939 [D loss: 0.5897067189216614 | D accuracy: 68.75] [G loss: 1.0473785400390625]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6940 [D loss: 0.5721016228199005 | D accuracy: 65.625] [G loss: 1.087943434715271]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6941 [D loss: 0.5725228190422058 | D accuracy: 73.4375] [G loss: 1.0535811185836792]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6942 [D loss: 0.6200283169746399 | D accuracy: 68.75] [G loss: 1.0065339803695679]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6943 [D loss: 0.6320458352565765 | D accuracy: 59.375] [G loss: 1.0299526453018188]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6944 [D loss: 0.621158242225647 | D accuracy: 62.5] [G loss: 0.9907900094985962]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6945 [D loss: 0.5631678700447083 | D accuracy: 68.75] [G loss: 1.109686017036438]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6946 [D loss: 0.6123442053794861 | D accuracy: 60.9375] [G loss: 0.9801194071769714]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6947 [D loss: 0.6979476809501648 | D accuracy: 54.6875] [G loss: 0.9302334785461426]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6948 [D loss: 0.6084127724170685 | D accuracy: 68.75] [G loss: 1.013725757598877]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6949 [D loss: 0.5379211902618408 | D accuracy: 78.125] [G loss: 0.8991222977638245]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6950 [D loss: 0.5648072361946106 | D accuracy: 70.3125] [G loss: 1.120833396911621]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6951 [D loss: 0.5372020304203033 | D accuracy: 75.0] [G loss: 1.0418572425842285]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6952 [D loss: 0.5242676436901093 | D accuracy: 78.125] [G loss: 1.0310745239257812]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6953 [D loss: 0.5329873263835907 | D accuracy: 68.75] [G loss: 1.027489185333252]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6954 [D loss: 0.6305752992630005 | D accuracy: 62.5] [G loss: 0.9862558245658875]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6955 [D loss: 0.6086802780628204 | D accuracy: 71.875] [G loss: 1.11391019821167]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6956 [D loss: 0.5355696827173233 | D accuracy: 73.4375] [G loss: 1.1863926649093628]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6957 [D loss: 0.5479372441768646 | D accuracy: 65.625] [G loss: 1.120783805847168]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6958 [D loss: 0.6281006634235382 | D accuracy: 57.8125] [G loss: 1.0128892660140991]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6959 [D loss: 0.5545603930950165 | D accuracy: 70.3125] [G loss: 1.1581536531448364]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6960 [D loss: 0.5580358803272247 | D accuracy: 67.1875] [G loss: 1.1490275859832764]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "6961 [D loss: 0.5625985562801361 | D accuracy: 65.625] [G loss: 1.074535608291626]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6962 [D loss: 0.6023108661174774 | D accuracy: 67.1875] [G loss: 1.0415513515472412]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6963 [D loss: 0.5730170905590057 | D accuracy: 65.625] [G loss: 1.0514081716537476]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6964 [D loss: 0.5850543975830078 | D accuracy: 65.625] [G loss: 1.01352059841156]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6965 [D loss: 0.6072162091732025 | D accuracy: 73.4375] [G loss: 1.08990478515625]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6966 [D loss: 0.612369030714035 | D accuracy: 75.0] [G loss: 1.0844677686691284]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6967 [D loss: 0.49920816719532013 | D accuracy: 79.6875] [G loss: 1.0954867601394653]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6968 [D loss: 0.5514282286167145 | D accuracy: 70.3125] [G loss: 1.0176053047180176]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6969 [D loss: 0.5797722935676575 | D accuracy: 67.1875] [G loss: 1.1433944702148438]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6970 [D loss: 0.6738443970680237 | D accuracy: 60.9375] [G loss: 0.9166556596755981]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6971 [D loss: 0.5316298604011536 | D accuracy: 78.125] [G loss: 0.9869902729988098]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "6972 [D loss: 0.5810627043247223 | D accuracy: 68.75] [G loss: 1.0735059976577759]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6973 [D loss: 0.6356816589832306 | D accuracy: 62.5] [G loss: 1.1636781692504883]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6974 [D loss: 0.5914722979068756 | D accuracy: 62.5] [G loss: 1.1164836883544922]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "6975 [D loss: 0.580607533454895 | D accuracy: 62.5] [G loss: 1.0329629182815552]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "6976 [D loss: 0.599663257598877 | D accuracy: 60.9375] [G loss: 1.054443597793579]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6977 [D loss: 0.6586160659790039 | D accuracy: 54.6875] [G loss: 1.010296106338501]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6978 [D loss: 0.5338153541088104 | D accuracy: 73.4375] [G loss: 1.1567291021347046]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "6979 [D loss: 0.6124144792556763 | D accuracy: 67.1875] [G loss: 1.010101079940796]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "6980 [D loss: 0.5686241984367371 | D accuracy: 73.4375] [G loss: 1.0244197845458984]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "6981 [D loss: 0.6718129813671112 | D accuracy: 57.8125] [G loss: 1.0822876691818237]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "6982 [D loss: 0.6403760313987732 | D accuracy: 62.5] [G loss: 1.0087852478027344]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "6983 [D loss: 0.5891765356063843 | D accuracy: 75.0] [G loss: 1.011325478553772]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "6984 [D loss: 0.6206651926040649 | D accuracy: 60.9375] [G loss: 0.9797420501708984]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "6985 [D loss: 0.5771937370300293 | D accuracy: 68.75] [G loss: 0.9258648157119751]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "6986 [D loss: 0.6480271816253662 | D accuracy: 68.75] [G loss: 0.9531219005584717]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "6987 [D loss: 0.5717257261276245 | D accuracy: 68.75] [G loss: 1.1435192823410034]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "6988 [D loss: 0.6024266481399536 | D accuracy: 67.1875] [G loss: 0.992527425289154]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "6989 [D loss: 0.5820624828338623 | D accuracy: 71.875] [G loss: 0.9784694910049438]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "6990 [D loss: 0.5954561233520508 | D accuracy: 65.625] [G loss: 0.9580098390579224]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "6991 [D loss: 0.6148055195808411 | D accuracy: 62.5] [G loss: 1.0584688186645508]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "6992 [D loss: 0.6467278897762299 | D accuracy: 65.625] [G loss: 0.9838936924934387]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "6993 [D loss: 0.5889951586723328 | D accuracy: 64.0625] [G loss: 1.084610104560852]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "6994 [D loss: 0.5368862152099609 | D accuracy: 73.4375] [G loss: 1.1210284233093262]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "6995 [D loss: 0.5597794055938721 | D accuracy: 75.0] [G loss: 1.070910096168518]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "6996 [D loss: 0.5291204154491425 | D accuracy: 73.4375] [G loss: 0.9603583812713623]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "6997 [D loss: 0.584247350692749 | D accuracy: 65.625] [G loss: 1.0927083492279053]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "6998 [D loss: 0.6560788452625275 | D accuracy: 59.375] [G loss: 0.9918000102043152]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "6999 [D loss: 0.5937343835830688 | D accuracy: 70.3125] [G loss: 0.9889260530471802]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7000 [D loss: 0.49332332611083984 | D accuracy: 81.25] [G loss: 1.098233699798584]\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "7001 [D loss: 0.531361848115921 | D accuracy: 78.125] [G loss: 1.029341459274292]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7002 [D loss: 0.5835525393486023 | D accuracy: 67.1875] [G loss: 1.0645477771759033]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7003 [D loss: 0.6568328142166138 | D accuracy: 56.25] [G loss: 0.9914678931236267]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7004 [D loss: 0.5485314428806305 | D accuracy: 76.5625] [G loss: 1.0435292720794678]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7005 [D loss: 0.6105828285217285 | D accuracy: 64.0625] [G loss: 1.0959608554840088]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7006 [D loss: 0.6534215211868286 | D accuracy: 54.6875] [G loss: 1.1386058330535889]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7007 [D loss: 0.5743148624897003 | D accuracy: 75.0] [G loss: 1.037414789199829]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7008 [D loss: 0.5988276600837708 | D accuracy: 67.1875] [G loss: 1.1689528226852417]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7009 [D loss: 0.5455778241157532 | D accuracy: 73.4375] [G loss: 1.068709373474121]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7010 [D loss: 0.6024259328842163 | D accuracy: 64.0625] [G loss: 1.0835518836975098]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7011 [D loss: 0.5546732097864151 | D accuracy: 70.3125] [G loss: 1.037864327430725]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7012 [D loss: 0.5898360311985016 | D accuracy: 67.1875] [G loss: 1.0131086111068726]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7013 [D loss: 0.5291105806827545 | D accuracy: 76.5625] [G loss: 1.0418567657470703]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7014 [D loss: 0.5179053992033005 | D accuracy: 75.0] [G loss: 1.0019035339355469]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7015 [D loss: 0.6888046860694885 | D accuracy: 60.9375] [G loss: 0.9736039638519287]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7016 [D loss: 0.5709885954856873 | D accuracy: 71.875] [G loss: 1.1001821756362915]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7017 [D loss: 0.5718665719032288 | D accuracy: 70.3125] [G loss: 1.0930862426757812]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7018 [D loss: 0.620042622089386 | D accuracy: 62.5] [G loss: 1.157677173614502]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7019 [D loss: 0.5912820398807526 | D accuracy: 60.9375] [G loss: 1.1376041173934937]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7020 [D loss: 0.5785723924636841 | D accuracy: 67.1875] [G loss: 0.9918935298919678]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7021 [D loss: 0.6650798916816711 | D accuracy: 54.6875] [G loss: 1.0248286724090576]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7022 [D loss: 0.5531173944473267 | D accuracy: 76.5625] [G loss: 1.0754101276397705]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7023 [D loss: 0.6323973834514618 | D accuracy: 59.375] [G loss: 1.1611943244934082]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7024 [D loss: 0.5769070386886597 | D accuracy: 62.5] [G loss: 1.086143970489502]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7025 [D loss: 0.5672155916690826 | D accuracy: 70.3125] [G loss: 1.0458056926727295]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7026 [D loss: 0.5990667343139648 | D accuracy: 70.3125] [G loss: 1.0538814067840576]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7027 [D loss: 0.6272083818912506 | D accuracy: 68.75] [G loss: 1.1097335815429688]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7028 [D loss: 0.7086424827575684 | D accuracy: 53.125] [G loss: 0.975265622138977]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7029 [D loss: 0.5330617427825928 | D accuracy: 76.5625] [G loss: 1.1648783683776855]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7030 [D loss: 0.6267992258071899 | D accuracy: 57.8125] [G loss: 0.9597358703613281]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7031 [D loss: 0.5764634013175964 | D accuracy: 65.625] [G loss: 0.9811151623725891]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7032 [D loss: 0.6117734909057617 | D accuracy: 65.625] [G loss: 1.136460304260254]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7033 [D loss: 0.5550882816314697 | D accuracy: 71.875] [G loss: 1.0965969562530518]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7034 [D loss: 0.6025359034538269 | D accuracy: 68.75] [G loss: 0.9873331785202026]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7035 [D loss: 0.6270793676376343 | D accuracy: 62.5] [G loss: 1.0777088403701782]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7036 [D loss: 0.5740559697151184 | D accuracy: 68.75] [G loss: 0.9631518721580505]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7037 [D loss: 0.6047693192958832 | D accuracy: 71.875] [G loss: 0.9696521759033203]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7038 [D loss: 0.6030523478984833 | D accuracy: 64.0625] [G loss: 1.1007051467895508]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7039 [D loss: 0.5808379948139191 | D accuracy: 70.3125] [G loss: 1.0513012409210205]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7040 [D loss: 0.635104775428772 | D accuracy: 57.8125] [G loss: 0.9927037954330444]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7041 [D loss: 0.6210823059082031 | D accuracy: 68.75] [G loss: 1.0713039636611938]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7042 [D loss: 0.5361599326133728 | D accuracy: 70.3125] [G loss: 1.176953673362732]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7043 [D loss: 0.638296365737915 | D accuracy: 60.9375] [G loss: 1.1849253177642822]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7044 [D loss: 0.6035954654216766 | D accuracy: 65.625] [G loss: 1.1244395971298218]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7045 [D loss: 0.5425766706466675 | D accuracy: 73.4375] [G loss: 1.1284873485565186]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7046 [D loss: 0.5650828182697296 | D accuracy: 75.0] [G loss: 1.14699387550354]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7047 [D loss: 0.6118872463703156 | D accuracy: 60.9375] [G loss: 0.9915242791175842]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7048 [D loss: 0.5682562589645386 | D accuracy: 70.3125] [G loss: 0.994200587272644]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7049 [D loss: 0.5144564807415009 | D accuracy: 70.3125] [G loss: 1.133912444114685]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7050 [D loss: 0.5654870867729187 | D accuracy: 65.625] [G loss: 1.0754714012145996]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7051 [D loss: 0.6549972891807556 | D accuracy: 57.8125] [G loss: 1.131094217300415]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7052 [D loss: 0.5795224010944366 | D accuracy: 64.0625] [G loss: 1.0725057125091553]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7053 [D loss: 0.5376884043216705 | D accuracy: 67.1875] [G loss: 1.198312520980835]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7054 [D loss: 0.6219397187232971 | D accuracy: 59.375] [G loss: 1.1134757995605469]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7055 [D loss: 0.629097044467926 | D accuracy: 65.625] [G loss: 1.102931022644043]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7056 [D loss: 0.4701310843229294 | D accuracy: 82.8125] [G loss: 1.198521614074707]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7057 [D loss: 0.5796498656272888 | D accuracy: 68.75] [G loss: 1.1330512762069702]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7058 [D loss: 0.6109106540679932 | D accuracy: 56.25] [G loss: 1.1204159259796143]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7059 [D loss: 0.5189238488674164 | D accuracy: 87.5] [G loss: 1.1015098094940186]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7060 [D loss: 0.6427817344665527 | D accuracy: 59.375] [G loss: 0.9805701971054077]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7061 [D loss: 0.668641209602356 | D accuracy: 59.375] [G loss: 1.0505143404006958]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7062 [D loss: 0.568693071603775 | D accuracy: 73.4375] [G loss: 0.9892104864120483]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7063 [D loss: 0.6119110584259033 | D accuracy: 60.9375] [G loss: 0.9852604866027832]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7064 [D loss: 0.6082859933376312 | D accuracy: 60.9375] [G loss: 1.0353538990020752]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "7065 [D loss: 0.5085912048816681 | D accuracy: 68.75] [G loss: 1.1127469539642334]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7066 [D loss: 0.5719723701477051 | D accuracy: 68.75] [G loss: 1.0908269882202148]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7067 [D loss: 0.5429510325193405 | D accuracy: 70.3125] [G loss: 1.0997810363769531]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7068 [D loss: 0.6764191389083862 | D accuracy: 53.125] [G loss: 1.0724503993988037]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7069 [D loss: 0.5802773535251617 | D accuracy: 68.75] [G loss: 0.9743542671203613]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7070 [D loss: 0.6008402109146118 | D accuracy: 62.5] [G loss: 1.0307793617248535]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7071 [D loss: 0.5662451386451721 | D accuracy: 70.3125] [G loss: 1.0815790891647339]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7072 [D loss: 0.6050690412521362 | D accuracy: 62.5] [G loss: 0.9208914041519165]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "7073 [D loss: 0.6815630793571472 | D accuracy: 54.6875] [G loss: 1.0412418842315674]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7074 [D loss: 0.5827837586402893 | D accuracy: 68.75] [G loss: 1.0803810358047485]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7075 [D loss: 0.5738072991371155 | D accuracy: 65.625] [G loss: 1.0390154123306274]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7076 [D loss: 0.6609071791172028 | D accuracy: 56.25] [G loss: 1.1103904247283936]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7077 [D loss: 0.588835746049881 | D accuracy: 68.75] [G loss: 1.007042646408081]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7078 [D loss: 0.5985984206199646 | D accuracy: 67.1875] [G loss: 1.006940245628357]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7079 [D loss: 0.6573933959007263 | D accuracy: 65.625] [G loss: 1.0628607273101807]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7080 [D loss: 0.6016810387372971 | D accuracy: 65.625] [G loss: 1.0678656101226807]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7081 [D loss: 0.5386766493320465 | D accuracy: 75.0] [G loss: 1.0090715885162354]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7082 [D loss: 0.6415948569774628 | D accuracy: 64.0625] [G loss: 1.0935413837432861]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7083 [D loss: 0.49673521518707275 | D accuracy: 78.125] [G loss: 1.0695486068725586]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7084 [D loss: 0.5755958259105682 | D accuracy: 65.625] [G loss: 1.169453501701355]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7085 [D loss: 0.6825892925262451 | D accuracy: 60.9375] [G loss: 1.030118465423584]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7086 [D loss: 0.5601632297039032 | D accuracy: 68.75] [G loss: 1.0410432815551758]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7087 [D loss: 0.6223370730876923 | D accuracy: 60.9375] [G loss: 1.0090259313583374]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7088 [D loss: 0.5847136676311493 | D accuracy: 68.75] [G loss: 0.9486367702484131]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7089 [D loss: 0.6394961774349213 | D accuracy: 70.3125] [G loss: 1.0091402530670166]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7090 [D loss: 0.5618865191936493 | D accuracy: 75.0] [G loss: 1.078688144683838]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7091 [D loss: 0.6555691957473755 | D accuracy: 54.6875] [G loss: 0.9699959754943848]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7092 [D loss: 0.5646693408489227 | D accuracy: 71.875] [G loss: 1.0458095073699951]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7093 [D loss: 0.618513286113739 | D accuracy: 65.625] [G loss: 0.9072870016098022]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7094 [D loss: 0.6063674092292786 | D accuracy: 60.9375] [G loss: 1.141057014465332]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7095 [D loss: 0.6169984936714172 | D accuracy: 67.1875] [G loss: 1.0208576917648315]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7096 [D loss: 0.564425528049469 | D accuracy: 75.0] [G loss: 1.0321941375732422]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7097 [D loss: 0.5777288675308228 | D accuracy: 71.875] [G loss: 1.0695476531982422]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7098 [D loss: 0.6631224155426025 | D accuracy: 57.8125] [G loss: 1.0274631977081299]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7099 [D loss: 0.5175184905529022 | D accuracy: 78.125] [G loss: 1.076186180114746]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7100 [D loss: 0.5569577664136887 | D accuracy: 73.4375] [G loss: 1.1153433322906494]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7101 [D loss: 0.5061997771263123 | D accuracy: 73.4375] [G loss: 1.0502970218658447]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7102 [D loss: 0.5945380628108978 | D accuracy: 70.3125] [G loss: 1.0449542999267578]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7103 [D loss: 0.5702486038208008 | D accuracy: 68.75] [G loss: 1.0883231163024902]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7104 [D loss: 0.5950098931789398 | D accuracy: 70.3125] [G loss: 1.0038138628005981]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7105 [D loss: 0.6475222706794739 | D accuracy: 53.125] [G loss: 1.0312854051589966]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7106 [D loss: 0.545534610748291 | D accuracy: 67.1875] [G loss: 0.9942048788070679]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7107 [D loss: 0.5323170125484467 | D accuracy: 76.5625] [G loss: 1.1857891082763672]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7108 [D loss: 0.5902201235294342 | D accuracy: 70.3125] [G loss: 1.0723592042922974]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7109 [D loss: 0.5645455718040466 | D accuracy: 70.3125] [G loss: 1.2271814346313477]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7110 [D loss: 0.6188972592353821 | D accuracy: 67.1875] [G loss: 1.148895025253296]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7111 [D loss: 0.5902479588985443 | D accuracy: 68.75] [G loss: 1.0392541885375977]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7112 [D loss: 0.6084693074226379 | D accuracy: 65.625] [G loss: 0.9718807935714722]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7113 [D loss: 0.5663448572158813 | D accuracy: 67.1875] [G loss: 1.0046987533569336]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7114 [D loss: 0.5350263714790344 | D accuracy: 79.6875] [G loss: 0.9578078985214233]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7115 [D loss: 0.6156696677207947 | D accuracy: 71.875] [G loss: 1.010152816772461]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7116 [D loss: 0.6761794686317444 | D accuracy: 56.25] [G loss: 0.9900126457214355]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7117 [D loss: 0.6360369920730591 | D accuracy: 64.0625] [G loss: 1.0968255996704102]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7118 [D loss: 0.5765392482280731 | D accuracy: 73.4375] [G loss: 1.0798029899597168]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7119 [D loss: 0.5840898156166077 | D accuracy: 70.3125] [G loss: 0.9855710864067078]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7120 [D loss: 0.5868822634220123 | D accuracy: 70.3125] [G loss: 1.0092637538909912]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7121 [D loss: 0.6587895452976227 | D accuracy: 70.3125] [G loss: 1.0850343704223633]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7122 [D loss: 0.565807044506073 | D accuracy: 71.875] [G loss: 1.1940267086029053]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7123 [D loss: 0.6050684750080109 | D accuracy: 67.1875] [G loss: 1.0272982120513916]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7124 [D loss: 0.6433123648166656 | D accuracy: 65.625] [G loss: 0.9951750040054321]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7125 [D loss: 0.5939095616340637 | D accuracy: 64.0625] [G loss: 0.9717510342597961]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7126 [D loss: 0.49990084767341614 | D accuracy: 78.125] [G loss: 1.0934035778045654]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7127 [D loss: 0.6496108174324036 | D accuracy: 56.25] [G loss: 1.030953049659729]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7128 [D loss: 0.5917081832885742 | D accuracy: 70.3125] [G loss: 0.9591889381408691]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7129 [D loss: 0.6149052083492279 | D accuracy: 64.0625] [G loss: 0.9974682927131653]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7130 [D loss: 0.5582020878791809 | D accuracy: 65.625] [G loss: 1.1382944583892822]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7131 [D loss: 0.5970669090747833 | D accuracy: 70.3125] [G loss: 0.9691005945205688]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7132 [D loss: 0.6084950566291809 | D accuracy: 67.1875] [G loss: 1.0510671138763428]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7133 [D loss: 0.5482088923454285 | D accuracy: 73.4375] [G loss: 1.102696180343628]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7134 [D loss: 0.5784477293491364 | D accuracy: 70.3125] [G loss: 1.192222237586975]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7135 [D loss: 0.6017668545246124 | D accuracy: 57.8125] [G loss: 1.0648903846740723]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7136 [D loss: 0.6047110557556152 | D accuracy: 64.0625] [G loss: 1.0158017873764038]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7137 [D loss: 0.5866927206516266 | D accuracy: 68.75] [G loss: 0.9293982982635498]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7138 [D loss: 0.5546408891677856 | D accuracy: 70.3125] [G loss: 1.023405909538269]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "7139 [D loss: 0.46716582775115967 | D accuracy: 81.25] [G loss: 1.0599157810211182]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "7140 [D loss: 0.561905175447464 | D accuracy: 75.0] [G loss: 1.0684549808502197]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7141 [D loss: 0.6073728799819946 | D accuracy: 68.75] [G loss: 1.070566177368164]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7142 [D loss: 0.48934128880500793 | D accuracy: 78.125] [G loss: 1.0373215675354004]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7143 [D loss: 0.6013964712619781 | D accuracy: 65.625] [G loss: 1.001430630683899]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7144 [D loss: 0.6568908393383026 | D accuracy: 54.6875] [G loss: 0.9443806409835815]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7145 [D loss: 0.5631558895111084 | D accuracy: 71.875] [G loss: 1.1031179428100586]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "7146 [D loss: 0.6207379102706909 | D accuracy: 64.0625] [G loss: 1.0453307628631592]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "7147 [D loss: 0.683775395154953 | D accuracy: 59.375] [G loss: 1.0650619268417358]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7148 [D loss: 0.6480298638343811 | D accuracy: 57.8125] [G loss: 0.9926716089248657]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7149 [D loss: 0.4958222806453705 | D accuracy: 76.5625] [G loss: 1.1254969835281372]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7150 [D loss: 0.5557337403297424 | D accuracy: 76.5625] [G loss: 1.065121054649353]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7151 [D loss: 0.6020506322383881 | D accuracy: 67.1875] [G loss: 1.1160651445388794]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7152 [D loss: 0.6598676443099976 | D accuracy: 56.25] [G loss: 1.162476897239685]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7153 [D loss: 0.5649701058864594 | D accuracy: 73.4375] [G loss: 1.0867908000946045]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7154 [D loss: 0.5807594656944275 | D accuracy: 70.3125] [G loss: 1.0918407440185547]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7155 [D loss: 0.5251252949237823 | D accuracy: 71.875] [G loss: 1.057845950126648]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7156 [D loss: 0.6835695505142212 | D accuracy: 60.9375] [G loss: 1.0264711380004883]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7157 [D loss: 0.540367841720581 | D accuracy: 73.4375] [G loss: 1.0831445455551147]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7158 [D loss: 0.4866277128458023 | D accuracy: 75.0] [G loss: 0.9974566698074341]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7159 [D loss: 0.5803742706775665 | D accuracy: 70.3125] [G loss: 1.082834005355835]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7160 [D loss: 0.6036221086978912 | D accuracy: 71.875] [G loss: 1.0286483764648438]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7161 [D loss: 0.607652872800827 | D accuracy: 60.9375] [G loss: 1.0855746269226074]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7162 [D loss: 0.6177102327346802 | D accuracy: 76.5625] [G loss: 0.9915883541107178]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7163 [D loss: 0.7077633440494537 | D accuracy: 57.8125] [G loss: 1.122352123260498]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7164 [D loss: 0.5898003578186035 | D accuracy: 70.3125] [G loss: 1.0832736492156982]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7165 [D loss: 0.5749940574169159 | D accuracy: 70.3125] [G loss: 1.0914480686187744]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7166 [D loss: 0.5265502482652664 | D accuracy: 73.4375] [G loss: 1.0977258682250977]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7167 [D loss: 0.6044340431690216 | D accuracy: 68.75] [G loss: 1.0372142791748047]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7168 [D loss: 0.5304246544837952 | D accuracy: 73.4375] [G loss: 1.1136335134506226]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7169 [D loss: 0.5551236867904663 | D accuracy: 70.3125] [G loss: 1.021756887435913]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7170 [D loss: 0.6127845644950867 | D accuracy: 65.625] [G loss: 1.0212973356246948]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7171 [D loss: 0.584401935338974 | D accuracy: 70.3125] [G loss: 1.0493974685668945]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7172 [D loss: 0.6238501667976379 | D accuracy: 62.5] [G loss: 1.1999956369400024]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7173 [D loss: 0.6296630501747131 | D accuracy: 57.8125] [G loss: 1.0551518201828003]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7174 [D loss: 0.5645877122879028 | D accuracy: 70.3125] [G loss: 1.127683162689209]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7175 [D loss: 0.5444646179676056 | D accuracy: 67.1875] [G loss: 1.105266809463501]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7176 [D loss: 0.6402004957199097 | D accuracy: 65.625] [G loss: 1.0588030815124512]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7177 [D loss: 0.6179912090301514 | D accuracy: 68.75] [G loss: 1.1626620292663574]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7178 [D loss: 0.5193060636520386 | D accuracy: 78.125] [G loss: 1.1010005474090576]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7179 [D loss: 0.6558450758457184 | D accuracy: 64.0625] [G loss: 1.1155498027801514]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7180 [D loss: 0.6173223257064819 | D accuracy: 65.625] [G loss: 1.0768561363220215]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7181 [D loss: 0.666327178478241 | D accuracy: 65.625] [G loss: 1.0161503553390503]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7182 [D loss: 0.5192759186029434 | D accuracy: 76.5625] [G loss: 1.157571792602539]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7183 [D loss: 0.6002190709114075 | D accuracy: 67.1875] [G loss: 1.079050064086914]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7184 [D loss: 0.5734024941921234 | D accuracy: 70.3125] [G loss: 1.1032981872558594]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7185 [D loss: 0.672947883605957 | D accuracy: 57.8125] [G loss: 1.027083158493042]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7186 [D loss: 0.5172582119703293 | D accuracy: 79.6875] [G loss: 1.1355891227722168]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7187 [D loss: 0.5430681705474854 | D accuracy: 70.3125] [G loss: 0.997310996055603]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7188 [D loss: 0.6166985630989075 | D accuracy: 62.5] [G loss: 1.0454885959625244]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7189 [D loss: 0.5278564691543579 | D accuracy: 75.0] [G loss: 1.1452476978302002]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7190 [D loss: 0.6709925830364227 | D accuracy: 60.9375] [G loss: 0.981754720211029]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7191 [D loss: 0.5938572287559509 | D accuracy: 70.3125] [G loss: 0.9609516859054565]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7192 [D loss: 0.5365475416183472 | D accuracy: 79.6875] [G loss: 1.0328387022018433]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7193 [D loss: 0.5359981060028076 | D accuracy: 75.0] [G loss: 1.0967824459075928]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7194 [D loss: 0.579685389995575 | D accuracy: 70.3125] [G loss: 1.0720973014831543]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7195 [D loss: 0.6386223137378693 | D accuracy: 62.5] [G loss: 1.1220186948776245]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7196 [D loss: 0.553769052028656 | D accuracy: 68.75] [G loss: 1.0458860397338867]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7197 [D loss: 0.618626058101654 | D accuracy: 62.5] [G loss: 1.0300753116607666]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7198 [D loss: 0.580071210861206 | D accuracy: 70.3125] [G loss: 1.0939743518829346]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7199 [D loss: 0.5768675208091736 | D accuracy: 73.4375] [G loss: 1.0790575742721558]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7200 [D loss: 0.4957953244447708 | D accuracy: 73.4375] [G loss: 1.131528615951538]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7201 [D loss: 0.5410610735416412 | D accuracy: 76.5625] [G loss: 0.9911782145500183]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7202 [D loss: 0.48598602414131165 | D accuracy: 81.25] [G loss: 1.1168177127838135]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7203 [D loss: 0.5183060765266418 | D accuracy: 71.875] [G loss: 0.9576653838157654]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7204 [D loss: 0.5383694469928741 | D accuracy: 71.875] [G loss: 1.069340705871582]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7205 [D loss: 0.5527409911155701 | D accuracy: 67.1875] [G loss: 1.0051562786102295]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7206 [D loss: 0.6125365495681763 | D accuracy: 59.375] [G loss: 0.970420777797699]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7207 [D loss: 0.6351037621498108 | D accuracy: 59.375] [G loss: 0.9848703145980835]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7208 [D loss: 0.5305664837360382 | D accuracy: 71.875] [G loss: 1.0428485870361328]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7209 [D loss: 0.5164452791213989 | D accuracy: 79.6875] [G loss: 1.1060807704925537]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7210 [D loss: 0.58768031001091 | D accuracy: 71.875] [G loss: 1.0621092319488525]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7211 [D loss: 0.6704409718513489 | D accuracy: 60.9375] [G loss: 1.026043176651001]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7212 [D loss: 0.6253526508808136 | D accuracy: 59.375] [G loss: 0.981167733669281]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7213 [D loss: 0.525878369808197 | D accuracy: 71.875] [G loss: 1.0678491592407227]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7214 [D loss: 0.5893021523952484 | D accuracy: 67.1875] [G loss: 1.0530933141708374]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7215 [D loss: 0.6273166835308075 | D accuracy: 56.25] [G loss: 1.1141873598098755]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7216 [D loss: 0.6137507557868958 | D accuracy: 64.0625] [G loss: 1.0878925323486328]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7217 [D loss: 0.5959540009498596 | D accuracy: 68.75] [G loss: 1.0057406425476074]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7218 [D loss: 0.5505461990833282 | D accuracy: 73.4375] [G loss: 1.028184413909912]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "7219 [D loss: 0.6257094442844391 | D accuracy: 62.5] [G loss: 1.0919808149337769]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7220 [D loss: 0.5864409804344177 | D accuracy: 70.3125] [G loss: 1.1389319896697998]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7221 [D loss: 0.5472851991653442 | D accuracy: 71.875] [G loss: 1.10858154296875]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7222 [D loss: 0.5766643583774567 | D accuracy: 70.3125] [G loss: 1.0542508363723755]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7223 [D loss: 0.6018684506416321 | D accuracy: 68.75] [G loss: 1.1764616966247559]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7224 [D loss: 0.6116745471954346 | D accuracy: 67.1875] [G loss: 1.129683256149292]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7225 [D loss: 0.5438583493232727 | D accuracy: 65.625] [G loss: 1.0535697937011719]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7226 [D loss: 0.5694263279438019 | D accuracy: 71.875] [G loss: 1.1291394233703613]\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "7227 [D loss: 0.5498465001583099 | D accuracy: 68.75] [G loss: 0.9977200627326965]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "7228 [D loss: 0.5567314624786377 | D accuracy: 65.625] [G loss: 0.9948695302009583]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7229 [D loss: 0.531999945640564 | D accuracy: 62.5] [G loss: 0.9989084005355835]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7230 [D loss: 0.5563163906335831 | D accuracy: 70.3125] [G loss: 1.171968936920166]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7231 [D loss: 0.6298621594905853 | D accuracy: 64.0625] [G loss: 1.0302627086639404]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7232 [D loss: 0.6962192356586456 | D accuracy: 57.8125] [G loss: 1.0850008726119995]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7233 [D loss: 0.4712951183319092 | D accuracy: 79.6875] [G loss: 1.1638139486312866]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7234 [D loss: 0.6128520667552948 | D accuracy: 59.375] [G loss: 1.153122901916504]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7235 [D loss: 0.5969365835189819 | D accuracy: 65.625] [G loss: 1.065970778465271]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7236 [D loss: 0.5445087552070618 | D accuracy: 71.875] [G loss: 1.0919452905654907]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7237 [D loss: 0.5446717441082001 | D accuracy: 73.4375] [G loss: 1.0515432357788086]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7238 [D loss: 0.6477287113666534 | D accuracy: 54.6875] [G loss: 1.143648386001587]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7239 [D loss: 0.6285403072834015 | D accuracy: 65.625] [G loss: 1.088263988494873]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7240 [D loss: 0.5747067332267761 | D accuracy: 67.1875] [G loss: 1.0970929861068726]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7241 [D loss: 0.6553373634815216 | D accuracy: 71.875] [G loss: 1.0940001010894775]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7242 [D loss: 0.5476447343826294 | D accuracy: 70.3125] [G loss: 1.0445477962493896]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7243 [D loss: 0.5624504387378693 | D accuracy: 71.875] [G loss: 1.0144377946853638]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7244 [D loss: 0.5465327203273773 | D accuracy: 71.875] [G loss: 0.9521376490592957]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7245 [D loss: 0.5840433537960052 | D accuracy: 70.3125] [G loss: 1.0414906740188599]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7246 [D loss: 0.5685433745384216 | D accuracy: 70.3125] [G loss: 0.9461668729782104]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7247 [D loss: 0.6537874042987823 | D accuracy: 60.9375] [G loss: 1.1677806377410889]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7248 [D loss: 0.6605134606361389 | D accuracy: 64.0625] [G loss: 1.0567224025726318]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7249 [D loss: 0.5838108956813812 | D accuracy: 73.4375] [G loss: 1.0331743955612183]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7250 [D loss: 0.5361694693565369 | D accuracy: 67.1875] [G loss: 1.0899670124053955]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7251 [D loss: 0.5106903463602066 | D accuracy: 78.125] [G loss: 1.163478970527649]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7252 [D loss: 0.5926713645458221 | D accuracy: 71.875] [G loss: 1.0232486724853516]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7253 [D loss: 0.590838223695755 | D accuracy: 64.0625] [G loss: 1.1219176054000854]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7254 [D loss: 0.5682340562343597 | D accuracy: 64.0625] [G loss: 1.0809826850891113]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7255 [D loss: 0.6539827883243561 | D accuracy: 65.625] [G loss: 1.1106529235839844]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7256 [D loss: 0.6039255857467651 | D accuracy: 67.1875] [G loss: 1.0815194845199585]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7257 [D loss: 0.5944479703903198 | D accuracy: 62.5] [G loss: 1.1234962940216064]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7258 [D loss: 0.5963160693645477 | D accuracy: 64.0625] [G loss: 1.0335203409194946]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7259 [D loss: 0.5225209891796112 | D accuracy: 73.4375] [G loss: 1.1550341844558716]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7260 [D loss: 0.5070378333330154 | D accuracy: 78.125] [G loss: 1.0681501626968384]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7261 [D loss: 0.5978810489177704 | D accuracy: 68.75] [G loss: 1.0295815467834473]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7262 [D loss: 0.6229666769504547 | D accuracy: 64.0625] [G loss: 1.0050199031829834]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7263 [D loss: 0.5313458144664764 | D accuracy: 75.0] [G loss: 0.9667353630065918]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7264 [D loss: 0.6369159817695618 | D accuracy: 62.5] [G loss: 0.9591765403747559]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "7265 [D loss: 0.5560360252857208 | D accuracy: 76.5625] [G loss: 1.0658576488494873]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7266 [D loss: 0.5975117087364197 | D accuracy: 65.625] [G loss: 1.0741302967071533]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7267 [D loss: 0.6254670023918152 | D accuracy: 65.625] [G loss: 1.1166373491287231]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7268 [D loss: 0.6197161674499512 | D accuracy: 64.0625] [G loss: 1.1651597023010254]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7269 [D loss: 0.6325950622558594 | D accuracy: 60.9375] [G loss: 1.0389180183410645]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7270 [D loss: 0.5488240718841553 | D accuracy: 73.4375] [G loss: 1.1072969436645508]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7271 [D loss: 0.585761308670044 | D accuracy: 62.5] [G loss: 1.104151964187622]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7272 [D loss: 0.5614670217037201 | D accuracy: 67.1875] [G loss: 1.0902023315429688]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7273 [D loss: 0.5682568252086639 | D accuracy: 65.625] [G loss: 1.0366438627243042]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7274 [D loss: 0.6152266263961792 | D accuracy: 67.1875] [G loss: 0.9980703592300415]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7275 [D loss: 0.6121246218681335 | D accuracy: 64.0625] [G loss: 1.0736225843429565]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7276 [D loss: 0.6285222172737122 | D accuracy: 71.875] [G loss: 1.1213328838348389]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7277 [D loss: 0.6107807755470276 | D accuracy: 60.9375] [G loss: 1.1301993131637573]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7278 [D loss: 0.5116693675518036 | D accuracy: 75.0] [G loss: 1.0764471292495728]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7279 [D loss: 0.5442293584346771 | D accuracy: 70.3125] [G loss: 1.0168018341064453]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7280 [D loss: 0.6568161249160767 | D accuracy: 56.25] [G loss: 1.0798476934432983]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7281 [D loss: 0.6063098907470703 | D accuracy: 68.75] [G loss: 1.1183289289474487]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7282 [D loss: 0.5412372946739197 | D accuracy: 75.0] [G loss: 1.0656144618988037]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7283 [D loss: 0.5484001040458679 | D accuracy: 73.4375] [G loss: 1.2117207050323486]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7284 [D loss: 0.5360112488269806 | D accuracy: 73.4375] [G loss: 1.0123250484466553]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7285 [D loss: 0.6128291338682175 | D accuracy: 67.1875] [G loss: 1.1657055616378784]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7286 [D loss: 0.6808538138866425 | D accuracy: 56.25] [G loss: 1.058145523071289]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7287 [D loss: 0.5705356597900391 | D accuracy: 70.3125] [G loss: 1.0326980352401733]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7288 [D loss: 0.6875744462013245 | D accuracy: 57.8125] [G loss: 1.0959129333496094]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7289 [D loss: 0.578083336353302 | D accuracy: 71.875] [G loss: 1.0480612516403198]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7290 [D loss: 0.5206035524606705 | D accuracy: 78.125] [G loss: 1.12698233127594]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7291 [D loss: 0.6021051704883575 | D accuracy: 68.75] [G loss: 1.1177213191986084]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7292 [D loss: 0.5885043442249298 | D accuracy: 68.75] [G loss: 0.9480258226394653]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7293 [D loss: 0.5568260550498962 | D accuracy: 67.1875] [G loss: 1.060276746749878]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7294 [D loss: 0.5930209755897522 | D accuracy: 57.8125] [G loss: 1.0050228834152222]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7295 [D loss: 0.6249038577079773 | D accuracy: 60.9375] [G loss: 1.1441073417663574]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7296 [D loss: 0.6158370673656464 | D accuracy: 59.375] [G loss: 1.0732065439224243]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7297 [D loss: 0.5570683479309082 | D accuracy: 73.4375] [G loss: 1.1587908267974854]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7298 [D loss: 0.5741291046142578 | D accuracy: 65.625] [G loss: 1.2156774997711182]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7299 [D loss: 0.5944204032421112 | D accuracy: 65.625] [G loss: 1.1675169467926025]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7300 [D loss: 0.6358709335327148 | D accuracy: 57.8125] [G loss: 1.0801864862442017]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7301 [D loss: 0.6264533698558807 | D accuracy: 54.6875] [G loss: 1.0987169742584229]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7302 [D loss: 0.5775399208068848 | D accuracy: 68.75] [G loss: 1.1691557168960571]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7303 [D loss: 0.5758475065231323 | D accuracy: 70.3125] [G loss: 1.1010360717773438]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7304 [D loss: 0.5336157977581024 | D accuracy: 79.6875] [G loss: 1.1382100582122803]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7305 [D loss: 0.6096208691596985 | D accuracy: 64.0625] [G loss: 1.119645118713379]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7306 [D loss: 0.6928280591964722 | D accuracy: 57.8125] [G loss: 1.211611032485962]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7307 [D loss: 0.5998376607894897 | D accuracy: 65.625] [G loss: 1.120990514755249]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7308 [D loss: 0.5750239193439484 | D accuracy: 73.4375] [G loss: 1.1141502857208252]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "7309 [D loss: 0.5537740290164948 | D accuracy: 65.625] [G loss: 1.109851360321045]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7310 [D loss: 0.6143947243690491 | D accuracy: 65.625] [G loss: 1.0166127681732178]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7311 [D loss: 0.5405589640140533 | D accuracy: 70.3125] [G loss: 1.0843605995178223]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7312 [D loss: 0.6087235808372498 | D accuracy: 68.75] [G loss: 1.0377612113952637]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7313 [D loss: 0.5663042664527893 | D accuracy: 68.75] [G loss: 1.078287124633789]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7314 [D loss: 0.5990718603134155 | D accuracy: 64.0625] [G loss: 0.9685932397842407]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7315 [D loss: 0.6213039755821228 | D accuracy: 67.1875] [G loss: 0.9801722168922424]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7316 [D loss: 0.539440780878067 | D accuracy: 71.875] [G loss: 0.991379976272583]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7317 [D loss: 0.5579022467136383 | D accuracy: 71.875] [G loss: 0.9964793920516968]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7318 [D loss: 0.520182877779007 | D accuracy: 73.4375] [G loss: 0.9859943389892578]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7319 [D loss: 0.5310682058334351 | D accuracy: 68.75] [G loss: 0.976773738861084]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7320 [D loss: 0.5736290216445923 | D accuracy: 71.875] [G loss: 1.0292561054229736]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7321 [D loss: 0.5108993649482727 | D accuracy: 78.125] [G loss: 1.1242862939834595]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7322 [D loss: 0.5950080454349518 | D accuracy: 70.3125] [G loss: 1.0974072217941284]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7323 [D loss: 0.5610041320323944 | D accuracy: 68.75] [G loss: 1.1414337158203125]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7324 [D loss: 0.5745240747928619 | D accuracy: 71.875] [G loss: 1.1196558475494385]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7325 [D loss: 0.5601223409175873 | D accuracy: 65.625] [G loss: 1.0653908252716064]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7326 [D loss: 0.6828427314758301 | D accuracy: 60.9375] [G loss: 1.1898021697998047]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7327 [D loss: 0.5585914850234985 | D accuracy: 70.3125] [G loss: 1.1457176208496094]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7328 [D loss: 0.6126008033752441 | D accuracy: 60.9375] [G loss: 1.12287175655365]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7329 [D loss: 0.5285514891147614 | D accuracy: 78.125] [G loss: 1.0775728225708008]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7330 [D loss: 0.6067820489406586 | D accuracy: 70.3125] [G loss: 1.107551097869873]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7331 [D loss: 0.5392954647541046 | D accuracy: 70.3125] [G loss: 1.1214025020599365]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7332 [D loss: 0.6429358124732971 | D accuracy: 59.375] [G loss: 1.0839166641235352]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7333 [D loss: 0.5480188429355621 | D accuracy: 73.4375] [G loss: 1.1684454679489136]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7334 [D loss: 0.5789397060871124 | D accuracy: 67.1875] [G loss: 1.0823403596878052]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7335 [D loss: 0.5842544436454773 | D accuracy: 68.75] [G loss: 1.0738728046417236]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7336 [D loss: 0.6723421812057495 | D accuracy: 60.9375] [G loss: 1.0561413764953613]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7337 [D loss: 0.4911433905363083 | D accuracy: 78.125] [G loss: 0.9672604203224182]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7338 [D loss: 0.5811381042003632 | D accuracy: 62.5] [G loss: 1.2154542207717896]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7339 [D loss: 0.5811030864715576 | D accuracy: 71.875] [G loss: 1.1480000019073486]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7340 [D loss: 0.6046014130115509 | D accuracy: 62.5] [G loss: 0.9403703212738037]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7341 [D loss: 0.6420912742614746 | D accuracy: 62.5] [G loss: 1.0430731773376465]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7342 [D loss: 0.6179858148097992 | D accuracy: 68.75] [G loss: 1.0659053325653076]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7343 [D loss: 0.5635054707527161 | D accuracy: 81.25] [G loss: 1.0773916244506836]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7344 [D loss: 0.6153010725975037 | D accuracy: 57.8125] [G loss: 1.0854461193084717]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7345 [D loss: 0.6596860587596893 | D accuracy: 59.375] [G loss: 1.1332519054412842]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7346 [D loss: 0.67784783244133 | D accuracy: 59.375] [G loss: 1.193230152130127]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7347 [D loss: 0.5420437455177307 | D accuracy: 71.875] [G loss: 1.15309476852417]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7348 [D loss: 0.5984636843204498 | D accuracy: 60.9375] [G loss: 1.1731719970703125]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7349 [D loss: 0.616759717464447 | D accuracy: 60.9375] [G loss: 1.0976208448410034]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7350 [D loss: 0.5140590667724609 | D accuracy: 71.875] [G loss: 1.0803698301315308]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7351 [D loss: 0.5280806720256805 | D accuracy: 76.5625] [G loss: 1.2018933296203613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7352 [D loss: 0.5807420015335083 | D accuracy: 64.0625] [G loss: 1.2162556648254395]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7353 [D loss: 0.5695833265781403 | D accuracy: 64.0625] [G loss: 1.1839933395385742]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7354 [D loss: 0.5817379951477051 | D accuracy: 65.625] [G loss: 1.04239821434021]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7355 [D loss: 0.5041809976100922 | D accuracy: 75.0] [G loss: 1.1416335105895996]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7356 [D loss: 0.6437717974185944 | D accuracy: 62.5] [G loss: 1.1449732780456543]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7357 [D loss: 0.5846751630306244 | D accuracy: 70.3125] [G loss: 1.0718896389007568]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7358 [D loss: 0.6186115145683289 | D accuracy: 59.375] [G loss: 1.0991567373275757]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7359 [D loss: 0.5093593895435333 | D accuracy: 78.125] [G loss: 1.0332447290420532]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7360 [D loss: 0.5611524879932404 | D accuracy: 73.4375] [G loss: 0.9954006671905518]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7361 [D loss: 0.5771792531013489 | D accuracy: 68.75] [G loss: 1.0924042463302612]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7362 [D loss: 0.5468274056911469 | D accuracy: 76.5625] [G loss: 0.9465539455413818]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7363 [D loss: 0.4813431203365326 | D accuracy: 76.5625] [G loss: 1.110996127128601]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7364 [D loss: 0.5759796500205994 | D accuracy: 73.4375] [G loss: 1.035356879234314]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7365 [D loss: 0.591803640127182 | D accuracy: 62.5] [G loss: 1.0465079545974731]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7366 [D loss: 0.4888507127761841 | D accuracy: 78.125] [G loss: 1.1315288543701172]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7367 [D loss: 0.6885387599468231 | D accuracy: 57.8125] [G loss: 1.118699073791504]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7368 [D loss: 0.5842652916908264 | D accuracy: 70.3125] [G loss: 1.0871994495391846]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7369 [D loss: 0.6047066748142242 | D accuracy: 64.0625] [G loss: 1.0377748012542725]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7370 [D loss: 0.5036096721887589 | D accuracy: 79.6875] [G loss: 0.952968955039978]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7371 [D loss: 0.5857565999031067 | D accuracy: 62.5] [G loss: 1.104889988899231]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7372 [D loss: 0.5975774526596069 | D accuracy: 68.75] [G loss: 1.0234631299972534]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7373 [D loss: 0.6615138053894043 | D accuracy: 59.375] [G loss: 1.0691885948181152]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7374 [D loss: 0.5642553269863129 | D accuracy: 71.875] [G loss: 1.085921049118042]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7375 [D loss: 0.5758288502693176 | D accuracy: 71.875] [G loss: 0.9659490585327148]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7376 [D loss: 0.5839932858943939 | D accuracy: 65.625] [G loss: 1.0833566188812256]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7377 [D loss: 0.5099772810935974 | D accuracy: 78.125] [G loss: 1.0524988174438477]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7378 [D loss: 0.5474099814891815 | D accuracy: 70.3125] [G loss: 1.0366986989974976]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7379 [D loss: 0.5686714053153992 | D accuracy: 73.4375] [G loss: 1.0425105094909668]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7380 [D loss: 0.6222504675388336 | D accuracy: 68.75] [G loss: 1.082136869430542]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "7381 [D loss: 0.5371922552585602 | D accuracy: 81.25] [G loss: 1.0257585048675537]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7382 [D loss: 0.6400362551212311 | D accuracy: 60.9375] [G loss: 1.1196019649505615]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7383 [D loss: 0.6445935964584351 | D accuracy: 56.25] [G loss: 1.0358047485351562]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7384 [D loss: 0.5018057823181152 | D accuracy: 76.5625] [G loss: 1.1153477430343628]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7385 [D loss: 0.640143096446991 | D accuracy: 67.1875] [G loss: 1.0996670722961426]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7386 [D loss: 0.586308479309082 | D accuracy: 65.625] [G loss: 1.077420711517334]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "7387 [D loss: 0.6308948695659637 | D accuracy: 62.5] [G loss: 1.0363743305206299]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7388 [D loss: 0.5289586335420609 | D accuracy: 78.125] [G loss: 1.082885980606079]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7389 [D loss: 0.5895764231681824 | D accuracy: 65.625] [G loss: 1.0792580842971802]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7390 [D loss: 0.6063245832920074 | D accuracy: 67.1875] [G loss: 1.138869047164917]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7391 [D loss: 0.5455231964588165 | D accuracy: 75.0] [G loss: 1.1269521713256836]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "7392 [D loss: 0.5565885603427887 | D accuracy: 68.75] [G loss: 1.109557867050171]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7393 [D loss: 0.5288071930408478 | D accuracy: 70.3125] [G loss: 1.0908069610595703]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7394 [D loss: 0.5431739091873169 | D accuracy: 73.4375] [G loss: 1.1544086933135986]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7395 [D loss: 0.6135931313037872 | D accuracy: 62.5] [G loss: 1.0504953861236572]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7396 [D loss: 0.6231715679168701 | D accuracy: 62.5] [G loss: 1.0567548274993896]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7397 [D loss: 0.545703798532486 | D accuracy: 76.5625] [G loss: 1.055849552154541]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7398 [D loss: 0.5866483747959137 | D accuracy: 64.0625] [G loss: 1.0093295574188232]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7399 [D loss: 0.5714380443096161 | D accuracy: 75.0] [G loss: 1.0970189571380615]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7400 [D loss: 0.5481320917606354 | D accuracy: 71.875] [G loss: 1.0662717819213867]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7401 [D loss: 0.5703849494457245 | D accuracy: 65.625] [G loss: 1.0857723951339722]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7402 [D loss: 0.5671733617782593 | D accuracy: 68.75] [G loss: 1.0853053331375122]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7403 [D loss: 0.5832211375236511 | D accuracy: 70.3125] [G loss: 1.1027696132659912]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7404 [D loss: 0.68293896317482 | D accuracy: 59.375] [G loss: 1.0005403757095337]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7405 [D loss: 0.5932109951972961 | D accuracy: 71.875] [G loss: 1.12898588180542]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7406 [D loss: 0.595831960439682 | D accuracy: 75.0] [G loss: 1.1447563171386719]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7407 [D loss: 0.5146363079547882 | D accuracy: 73.4375] [G loss: 1.2522395849227905]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7408 [D loss: 0.5901954770088196 | D accuracy: 65.625] [G loss: 1.180667757987976]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7409 [D loss: 0.5542948544025421 | D accuracy: 73.4375] [G loss: 1.1418871879577637]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7410 [D loss: 0.6195593476295471 | D accuracy: 64.0625] [G loss: 1.073206901550293]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7411 [D loss: 0.5781370997428894 | D accuracy: 71.875] [G loss: 1.0963311195373535]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7412 [D loss: 0.5591725409030914 | D accuracy: 75.0] [G loss: 1.0906054973602295]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7413 [D loss: 0.5933636724948883 | D accuracy: 64.0625] [G loss: 1.0921292304992676]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7414 [D loss: 0.5912973582744598 | D accuracy: 60.9375] [G loss: 1.1718143224716187]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7415 [D loss: 0.5239946693181992 | D accuracy: 78.125] [G loss: 1.096102237701416]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7416 [D loss: 0.5252788662910461 | D accuracy: 71.875] [G loss: 1.1133599281311035]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7417 [D loss: 0.6341781616210938 | D accuracy: 64.0625] [G loss: 1.1147253513336182]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7418 [D loss: 0.5416972935199738 | D accuracy: 67.1875] [G loss: 1.2429783344268799]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7419 [D loss: 0.6651656627655029 | D accuracy: 56.25] [G loss: 1.2523934841156006]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7420 [D loss: 0.5910699218511581 | D accuracy: 65.625] [G loss: 1.109136939048767]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7421 [D loss: 0.49331730604171753 | D accuracy: 75.0] [G loss: 1.1339778900146484]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7422 [D loss: 0.5652336478233337 | D accuracy: 67.1875] [G loss: 1.1013259887695312]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7423 [D loss: 0.5512194335460663 | D accuracy: 71.875] [G loss: 1.0447505712509155]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7424 [D loss: 0.5537733435630798 | D accuracy: 65.625] [G loss: 0.9825526475906372]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7425 [D loss: 0.5936062037944794 | D accuracy: 65.625] [G loss: 1.0927438735961914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7426 [D loss: 0.6063499748706818 | D accuracy: 68.75] [G loss: 1.0868347883224487]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7427 [D loss: 0.5779799222946167 | D accuracy: 70.3125] [G loss: 1.0881309509277344]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7428 [D loss: 0.624216765165329 | D accuracy: 67.1875] [G loss: 1.0464224815368652]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7429 [D loss: 0.5207900702953339 | D accuracy: 70.3125] [G loss: 1.0436490774154663]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7430 [D loss: 0.625721275806427 | D accuracy: 60.9375] [G loss: 1.0438159704208374]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7431 [D loss: 0.626724898815155 | D accuracy: 62.5] [G loss: 1.124172568321228]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7432 [D loss: 0.6011910736560822 | D accuracy: 71.875] [G loss: 1.2076895236968994]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7433 [D loss: 0.5753242671489716 | D accuracy: 71.875] [G loss: 1.1295459270477295]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7434 [D loss: 0.5909017622470856 | D accuracy: 68.75] [G loss: 1.1339976787567139]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7435 [D loss: 0.5996094942092896 | D accuracy: 64.0625] [G loss: 1.0405272245407104]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7436 [D loss: 0.5502102077007294 | D accuracy: 73.4375] [G loss: 1.0136795043945312]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7437 [D loss: 0.682258129119873 | D accuracy: 57.8125] [G loss: 1.1937757730484009]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7438 [D loss: 0.6430788636207581 | D accuracy: 67.1875] [G loss: 1.1697773933410645]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7439 [D loss: 0.568879246711731 | D accuracy: 73.4375] [G loss: 1.0857129096984863]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7440 [D loss: 0.5044113844633102 | D accuracy: 76.5625] [G loss: 1.0853075981140137]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7441 [D loss: 0.5159978866577148 | D accuracy: 68.75] [G loss: 1.106716275215149]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7442 [D loss: 0.5812345147132874 | D accuracy: 67.1875] [G loss: 1.0796250104904175]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7443 [D loss: 0.6690906286239624 | D accuracy: 59.375] [G loss: 1.0610766410827637]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7444 [D loss: 0.5697193443775177 | D accuracy: 67.1875] [G loss: 1.0184531211853027]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7445 [D loss: 0.5654394328594208 | D accuracy: 70.3125] [G loss: 1.0064337253570557]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7446 [D loss: 0.5509688854217529 | D accuracy: 75.0] [G loss: 1.0528937578201294]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7447 [D loss: 0.59818035364151 | D accuracy: 71.875] [G loss: 1.0638383626937866]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7448 [D loss: 0.5866262316703796 | D accuracy: 62.5] [G loss: 0.8510114550590515]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7449 [D loss: 0.5618543922901154 | D accuracy: 62.5] [G loss: 0.9361817836761475]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7450 [D loss: 0.5743078589439392 | D accuracy: 70.3125] [G loss: 1.03041672706604]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7451 [D loss: 0.5027480125427246 | D accuracy: 81.25] [G loss: 0.9900379180908203]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7452 [D loss: 0.5435228049755096 | D accuracy: 75.0] [G loss: 1.076960563659668]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7453 [D loss: 0.6042732000350952 | D accuracy: 60.9375] [G loss: 0.9817408323287964]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7454 [D loss: 0.526271641254425 | D accuracy: 75.0] [G loss: 1.0013890266418457]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7455 [D loss: 0.5155835151672363 | D accuracy: 78.125] [G loss: 1.124455451965332]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7456 [D loss: 0.5453292280435562 | D accuracy: 71.875] [G loss: 1.1229774951934814]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7457 [D loss: 0.49599240720272064 | D accuracy: 76.5625] [G loss: 1.0472270250320435]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7458 [D loss: 0.6589555740356445 | D accuracy: 56.25] [G loss: 1.1228952407836914]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7459 [D loss: 0.5569606125354767 | D accuracy: 75.0] [G loss: 1.0364139080047607]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7460 [D loss: 0.662040650844574 | D accuracy: 62.5] [G loss: 1.1246352195739746]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "7461 [D loss: 0.71494922041893 | D accuracy: 59.375] [G loss: 1.276848316192627]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7462 [D loss: 0.6005586683750153 | D accuracy: 67.1875] [G loss: 1.1257939338684082]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7463 [D loss: 0.5936155319213867 | D accuracy: 67.1875] [G loss: 1.0370588302612305]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7464 [D loss: 0.5049401670694351 | D accuracy: 75.0] [G loss: 1.1111174821853638]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7465 [D loss: 0.6616165041923523 | D accuracy: 65.625] [G loss: 1.141311764717102]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7466 [D loss: 0.5799537599086761 | D accuracy: 64.0625] [G loss: 1.1621500253677368]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7467 [D loss: 0.6173389256000519 | D accuracy: 73.4375] [G loss: 1.117539644241333]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7468 [D loss: 0.5582704842090607 | D accuracy: 70.3125] [G loss: 1.1537988185882568]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7469 [D loss: 0.6011547148227692 | D accuracy: 60.9375] [G loss: 1.1108393669128418]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7470 [D loss: 0.5478008389472961 | D accuracy: 73.4375] [G loss: 1.1160552501678467]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7471 [D loss: 0.5680120587348938 | D accuracy: 70.3125] [G loss: 1.1382677555084229]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "7472 [D loss: 0.5632086992263794 | D accuracy: 68.75] [G loss: 1.1167755126953125]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7473 [D loss: 0.5938543081283569 | D accuracy: 62.5] [G loss: 1.0281420946121216]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7474 [D loss: 0.5750846862792969 | D accuracy: 62.5] [G loss: 1.082066535949707]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7475 [D loss: 0.6747801303863525 | D accuracy: 62.5] [G loss: 1.070326328277588]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7476 [D loss: 0.5211052894592285 | D accuracy: 71.875] [G loss: 1.071040153503418]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7477 [D loss: 0.5254973322153091 | D accuracy: 70.3125] [G loss: 1.0178016424179077]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7478 [D loss: 0.610336184501648 | D accuracy: 64.0625] [G loss: 1.0365781784057617]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7479 [D loss: 0.5559605956077576 | D accuracy: 67.1875] [G loss: 1.095707893371582]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7480 [D loss: 0.6657124161720276 | D accuracy: 67.1875] [G loss: 1.0810840129852295]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7481 [D loss: 0.6012878119945526 | D accuracy: 64.0625] [G loss: 1.0865089893341064]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7482 [D loss: 0.6193785071372986 | D accuracy: 64.0625] [G loss: 1.074967384338379]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7483 [D loss: 0.5887302160263062 | D accuracy: 68.75] [G loss: 1.070521593093872]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7484 [D loss: 0.5666071474552155 | D accuracy: 75.0] [G loss: 1.0483078956604004]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7485 [D loss: 0.5500282645225525 | D accuracy: 68.75] [G loss: 1.0446135997772217]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7486 [D loss: 0.592363566160202 | D accuracy: 70.3125] [G loss: 1.110321283340454]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7487 [D loss: 0.6179421842098236 | D accuracy: 64.0625] [G loss: 1.103626012802124]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7488 [D loss: 0.5579337179660797 | D accuracy: 68.75] [G loss: 1.1307034492492676]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7489 [D loss: 0.59078449010849 | D accuracy: 70.3125] [G loss: 1.0057131052017212]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7490 [D loss: 0.6099836826324463 | D accuracy: 67.1875] [G loss: 1.1237314939498901]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7491 [D loss: 0.6583902537822723 | D accuracy: 56.25] [G loss: 1.0880043506622314]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7492 [D loss: 0.5472414791584015 | D accuracy: 68.75] [G loss: 1.0683714151382446]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7493 [D loss: 0.5414802730083466 | D accuracy: 76.5625] [G loss: 1.1391971111297607]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7494 [D loss: 0.5676787197589874 | D accuracy: 75.0] [G loss: 1.1379806995391846]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7495 [D loss: 0.5390430986881256 | D accuracy: 68.75] [G loss: 0.9975677132606506]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7496 [D loss: 0.5706153512001038 | D accuracy: 73.4375] [G loss: 1.0554031133651733]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7497 [D loss: 0.5298390686511993 | D accuracy: 70.3125] [G loss: 1.1020110845565796]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7498 [D loss: 0.52503702044487 | D accuracy: 73.4375] [G loss: 1.1097259521484375]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7499 [D loss: 0.5665207505226135 | D accuracy: 70.3125] [G loss: 1.1090378761291504]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7500 [D loss: 0.6332057118415833 | D accuracy: 59.375] [G loss: 1.1234865188598633]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7501 [D loss: 0.6093985736370087 | D accuracy: 65.625] [G loss: 1.0648629665374756]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7502 [D loss: 0.6661255359649658 | D accuracy: 57.8125] [G loss: 0.99242103099823]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7503 [D loss: 0.5445296764373779 | D accuracy: 70.3125] [G loss: 0.9698383808135986]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7504 [D loss: 0.5860758125782013 | D accuracy: 65.625] [G loss: 1.103245735168457]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7505 [D loss: 0.6736244559288025 | D accuracy: 50.0] [G loss: 1.0651967525482178]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7506 [D loss: 0.6940417885780334 | D accuracy: 48.4375] [G loss: 1.0176386833190918]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7507 [D loss: 0.5450189113616943 | D accuracy: 68.75] [G loss: 1.1786960363388062]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7508 [D loss: 0.6047767698764801 | D accuracy: 59.375] [G loss: 1.0323262214660645]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7509 [D loss: 0.6065857708454132 | D accuracy: 62.5] [G loss: 0.9788601994514465]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7510 [D loss: 0.5452419519424438 | D accuracy: 67.1875] [G loss: 0.980951726436615]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7511 [D loss: 0.5553757101297379 | D accuracy: 73.4375] [G loss: 1.093855381011963]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7512 [D loss: 0.6015757322311401 | D accuracy: 67.1875] [G loss: 1.0888290405273438]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7513 [D loss: 0.5676898658275604 | D accuracy: 67.1875] [G loss: 1.1208887100219727]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7514 [D loss: 0.5886115431785583 | D accuracy: 73.4375] [G loss: 1.189180850982666]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7515 [D loss: 0.5839496552944183 | D accuracy: 62.5] [G loss: 1.0913209915161133]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7516 [D loss: 0.6079567670822144 | D accuracy: 70.3125] [G loss: 1.0507521629333496]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7517 [D loss: 0.6098335087299347 | D accuracy: 64.0625] [G loss: 0.9673548936843872]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7518 [D loss: 0.679233580827713 | D accuracy: 62.5] [G loss: 0.9609960317611694]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7519 [D loss: 0.56654492020607 | D accuracy: 71.875] [G loss: 1.069810152053833]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7520 [D loss: 0.6312887668609619 | D accuracy: 54.6875] [G loss: 1.080402135848999]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "7521 [D loss: 0.5895019173622131 | D accuracy: 67.1875] [G loss: 1.0357229709625244]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "7522 [D loss: 0.6160350143909454 | D accuracy: 68.75] [G loss: 1.1079610586166382]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "7523 [D loss: 0.5629414021968842 | D accuracy: 68.75] [G loss: 1.1035816669464111]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7524 [D loss: 0.6468425095081329 | D accuracy: 68.75] [G loss: 1.1042442321777344]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7525 [D loss: 0.6272566318511963 | D accuracy: 64.0625] [G loss: 1.1730324029922485]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7526 [D loss: 0.5210161358118057 | D accuracy: 75.0] [G loss: 1.0374507904052734]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7527 [D loss: 0.4977090358734131 | D accuracy: 78.125] [G loss: 1.1444220542907715]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7528 [D loss: 0.5163195133209229 | D accuracy: 71.875] [G loss: 1.1026571989059448]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7529 [D loss: 0.5524582862854004 | D accuracy: 73.4375] [G loss: 1.1238019466400146]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7530 [D loss: 0.5993637442588806 | D accuracy: 65.625] [G loss: 1.2223212718963623]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7531 [D loss: 0.5245649218559265 | D accuracy: 71.875] [G loss: 1.1443870067596436]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7532 [D loss: 0.5607288926839828 | D accuracy: 65.625] [G loss: 1.1697875261306763]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7533 [D loss: 0.6235661804676056 | D accuracy: 67.1875] [G loss: 1.004580020904541]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7534 [D loss: 0.6258212924003601 | D accuracy: 60.9375] [G loss: 1.0415457487106323]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7535 [D loss: 0.658918023109436 | D accuracy: 51.5625] [G loss: 1.0822033882141113]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7536 [D loss: 0.5777261555194855 | D accuracy: 67.1875] [G loss: 1.0682787895202637]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7537 [D loss: 0.5790195465087891 | D accuracy: 73.4375] [G loss: 1.0506305694580078]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7538 [D loss: 0.5546675324440002 | D accuracy: 73.4375] [G loss: 1.052066683769226]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7539 [D loss: 0.5034198760986328 | D accuracy: 78.125] [G loss: 1.0235008001327515]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7540 [D loss: 0.6335761845111847 | D accuracy: 56.25] [G loss: 1.0956209897994995]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7541 [D loss: 0.653819352388382 | D accuracy: 65.625] [G loss: 1.0672653913497925]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7542 [D loss: 0.5141236037015915 | D accuracy: 75.0] [G loss: 1.087784767150879]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7543 [D loss: 0.5998416244983673 | D accuracy: 68.75] [G loss: 1.1160223484039307]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7544 [D loss: 0.5218964517116547 | D accuracy: 75.0] [G loss: 1.0870838165283203]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7545 [D loss: 0.5625480711460114 | D accuracy: 68.75] [G loss: 1.0662727355957031]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7546 [D loss: 0.5509259700775146 | D accuracy: 70.3125] [G loss: 1.107900857925415]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7547 [D loss: 0.6245940327644348 | D accuracy: 64.0625] [G loss: 0.9979805946350098]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7548 [D loss: 0.5788744390010834 | D accuracy: 76.5625] [G loss: 1.0991359949111938]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7549 [D loss: 0.6050513386726379 | D accuracy: 67.1875] [G loss: 1.0487539768218994]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7550 [D loss: 0.5866324305534363 | D accuracy: 65.625] [G loss: 1.0577694177627563]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7551 [D loss: 0.577343761920929 | D accuracy: 70.3125] [G loss: 1.108862280845642]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "7552 [D loss: 0.5637591183185577 | D accuracy: 68.75] [G loss: 1.0869529247283936]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7553 [D loss: 0.5284598171710968 | D accuracy: 70.3125] [G loss: 1.1516237258911133]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7554 [D loss: 0.6683791875839233 | D accuracy: 62.5] [G loss: 1.0943046808242798]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7555 [D loss: 0.5175815671682358 | D accuracy: 78.125] [G loss: 1.0581220388412476]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7556 [D loss: 0.5985438227653503 | D accuracy: 65.625] [G loss: 1.114577293395996]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7557 [D loss: 0.5544578433036804 | D accuracy: 65.625] [G loss: 1.0871281623840332]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7558 [D loss: 0.513055831193924 | D accuracy: 76.5625] [G loss: 1.1119282245635986]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7559 [D loss: 0.5832354128360748 | D accuracy: 71.875] [G loss: 1.1135048866271973]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7560 [D loss: 0.7130605280399323 | D accuracy: 56.25] [G loss: 1.0868141651153564]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7561 [D loss: 0.4944622665643692 | D accuracy: 78.125] [G loss: 1.1638481616973877]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7562 [D loss: 0.5636436343193054 | D accuracy: 71.875] [G loss: 1.1188747882843018]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7563 [D loss: 0.5561370849609375 | D accuracy: 73.4375] [G loss: 1.064359188079834]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7564 [D loss: 0.5370097160339355 | D accuracy: 75.0] [G loss: 1.06480073928833]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7565 [D loss: 0.5514417290687561 | D accuracy: 68.75] [G loss: 1.0409135818481445]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7566 [D loss: 0.5865766406059265 | D accuracy: 67.1875] [G loss: 1.1554388999938965]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7567 [D loss: 0.5829933881759644 | D accuracy: 68.75] [G loss: 1.0875606536865234]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7568 [D loss: 0.6029444932937622 | D accuracy: 68.75] [G loss: 1.081122875213623]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7569 [D loss: 0.6146203577518463 | D accuracy: 67.1875] [G loss: 1.0822670459747314]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7570 [D loss: 0.526402935385704 | D accuracy: 73.4375] [G loss: 1.1373140811920166]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7571 [D loss: 0.5002797991037369 | D accuracy: 85.9375] [G loss: 1.0347416400909424]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7572 [D loss: 0.5242254137992859 | D accuracy: 73.4375] [G loss: 1.058282732963562]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7573 [D loss: 0.7020387947559357 | D accuracy: 54.6875] [G loss: 1.0864135026931763]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7574 [D loss: 0.5972030162811279 | D accuracy: 64.0625] [G loss: 0.9010619521141052]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7575 [D loss: 0.5223051905632019 | D accuracy: 78.125] [G loss: 0.9467996954917908]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7576 [D loss: 0.48407623171806335 | D accuracy: 75.0] [G loss: 1.136589765548706]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7577 [D loss: 0.5433959364891052 | D accuracy: 68.75] [G loss: 1.2185486555099487]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7578 [D loss: 0.5705822706222534 | D accuracy: 65.625] [G loss: 1.074314832687378]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7579 [D loss: 0.6180289387702942 | D accuracy: 57.8125] [G loss: 1.0758676528930664]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7580 [D loss: 0.6022273898124695 | D accuracy: 65.625] [G loss: 0.9604729413986206]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7581 [D loss: 0.5955699384212494 | D accuracy: 73.4375] [G loss: 0.9893209338188171]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7582 [D loss: 0.5178700685501099 | D accuracy: 78.125] [G loss: 1.1431198120117188]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7583 [D loss: 0.5996549725532532 | D accuracy: 62.5] [G loss: 1.1457602977752686]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7584 [D loss: 0.5145230740308762 | D accuracy: 73.4375] [G loss: 1.0550341606140137]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7585 [D loss: 0.548742413520813 | D accuracy: 67.1875] [G loss: 1.214434027671814]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7586 [D loss: 0.5655466020107269 | D accuracy: 59.375] [G loss: 1.1524484157562256]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7587 [D loss: 0.6119639575481415 | D accuracy: 62.5] [G loss: 1.079211950302124]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7588 [D loss: 0.5647580623626709 | D accuracy: 68.75] [G loss: 1.2252963781356812]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7589 [D loss: 0.5651409327983856 | D accuracy: 70.3125] [G loss: 1.1959335803985596]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7590 [D loss: 0.48784464597702026 | D accuracy: 78.125] [G loss: 1.2903635501861572]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7591 [D loss: 0.6261860728263855 | D accuracy: 64.0625] [G loss: 1.1436169147491455]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7592 [D loss: 0.5998612940311432 | D accuracy: 67.1875] [G loss: 1.1599586009979248]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7593 [D loss: 0.5143569856882095 | D accuracy: 78.125] [G loss: 1.1569108963012695]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7594 [D loss: 0.4824700951576233 | D accuracy: 76.5625] [G loss: 1.1128642559051514]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7595 [D loss: 0.5994060039520264 | D accuracy: 67.1875] [G loss: 1.1143901348114014]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7596 [D loss: 0.5432555079460144 | D accuracy: 68.75] [G loss: 1.054694414138794]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7597 [D loss: 0.5387800335884094 | D accuracy: 73.4375] [G loss: 1.0850262641906738]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7598 [D loss: 0.632878303527832 | D accuracy: 62.5] [G loss: 0.9707014560699463]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7599 [D loss: 0.6372771561145782 | D accuracy: 53.125] [G loss: 1.1686739921569824]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7600 [D loss: 0.6408905684947968 | D accuracy: 65.625] [G loss: 1.07236647605896]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7601 [D loss: 0.638242244720459 | D accuracy: 64.0625] [G loss: 1.1004345417022705]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7602 [D loss: 0.6101756691932678 | D accuracy: 67.1875] [G loss: 1.095100998878479]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7603 [D loss: 0.5137317031621933 | D accuracy: 71.875] [G loss: 1.040644884109497]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7604 [D loss: 0.5424337983131409 | D accuracy: 75.0] [G loss: 1.1118440628051758]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7605 [D loss: 0.5447255969047546 | D accuracy: 75.0] [G loss: 1.0164010524749756]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7606 [D loss: 0.5906272530555725 | D accuracy: 73.4375] [G loss: 1.0932122468948364]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7607 [D loss: 0.5885195434093475 | D accuracy: 68.75] [G loss: 0.9907345771789551]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7608 [D loss: 0.5662219226360321 | D accuracy: 67.1875] [G loss: 1.0587865114212036]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7609 [D loss: 0.7294249832630157 | D accuracy: 57.8125] [G loss: 1.135334849357605]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7610 [D loss: 0.5235553979873657 | D accuracy: 76.5625] [G loss: 1.1469759941101074]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7611 [D loss: 0.5744894742965698 | D accuracy: 68.75] [G loss: 1.1319788694381714]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7612 [D loss: 0.5743438005447388 | D accuracy: 67.1875] [G loss: 1.143747329711914]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7613 [D loss: 0.5496594607830048 | D accuracy: 71.875] [G loss: 1.0718088150024414]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7614 [D loss: 0.5133641064167023 | D accuracy: 73.4375] [G loss: 1.1979093551635742]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7615 [D loss: 0.6214077174663544 | D accuracy: 68.75] [G loss: 1.0981558561325073]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7616 [D loss: 0.5893941521644592 | D accuracy: 70.3125] [G loss: 1.0347739458084106]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "7617 [D loss: 0.5179875195026398 | D accuracy: 75.0] [G loss: 1.159312129020691]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7618 [D loss: 0.5492771863937378 | D accuracy: 73.4375] [G loss: 1.1767297983169556]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7619 [D loss: 0.6189514398574829 | D accuracy: 62.5] [G loss: 1.0453877449035645]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7620 [D loss: 0.5953860133886337 | D accuracy: 65.625] [G loss: 1.0087804794311523]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7621 [D loss: 0.6170333325862885 | D accuracy: 62.5] [G loss: 1.0761475563049316]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7622 [D loss: 0.5301895439624786 | D accuracy: 73.4375] [G loss: 1.179317831993103]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7623 [D loss: 0.54693603515625 | D accuracy: 76.5625] [G loss: 1.0820178985595703]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7624 [D loss: 0.6730015277862549 | D accuracy: 56.25] [G loss: 1.1087052822113037]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "7625 [D loss: 0.5650693774223328 | D accuracy: 71.875] [G loss: 1.0869789123535156]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "7626 [D loss: 0.555816262960434 | D accuracy: 67.1875] [G loss: 1.1566061973571777]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7627 [D loss: 0.5528374314308167 | D accuracy: 70.3125] [G loss: 1.0841318368911743]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7628 [D loss: 0.5923895835876465 | D accuracy: 73.4375] [G loss: 1.0763273239135742]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7629 [D loss: 0.5421472191810608 | D accuracy: 71.875] [G loss: 1.097853183746338]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7630 [D loss: 0.5631368160247803 | D accuracy: 70.3125] [G loss: 1.0909056663513184]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7631 [D loss: 0.49176904559135437 | D accuracy: 73.4375] [G loss: 0.9255015850067139]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7632 [D loss: 0.642541229724884 | D accuracy: 64.0625] [G loss: 1.1340373754501343]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7633 [D loss: 0.5483912229537964 | D accuracy: 71.875] [G loss: 1.0435855388641357]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7634 [D loss: 0.6180897951126099 | D accuracy: 62.5] [G loss: 1.0691105127334595]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7635 [D loss: 0.6175624132156372 | D accuracy: 65.625] [G loss: 1.0640076398849487]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7636 [D loss: 0.6710605025291443 | D accuracy: 57.8125] [G loss: 1.1894338130950928]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7637 [D loss: 0.566327765583992 | D accuracy: 64.0625] [G loss: 1.1388368606567383]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7638 [D loss: 0.5915610194206238 | D accuracy: 67.1875] [G loss: 1.008298397064209]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7639 [D loss: 0.5873174667358398 | D accuracy: 67.1875] [G loss: 1.178680658340454]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7640 [D loss: 0.6318897008895874 | D accuracy: 57.8125] [G loss: 1.03280508518219]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7641 [D loss: 0.571885883808136 | D accuracy: 67.1875] [G loss: 1.0820614099502563]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7642 [D loss: 0.6637692451477051 | D accuracy: 59.375] [G loss: 1.0784251689910889]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7643 [D loss: 0.5504858493804932 | D accuracy: 76.5625] [G loss: 1.0683598518371582]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7644 [D loss: 0.6404314637184143 | D accuracy: 60.9375] [G loss: 1.0365742444992065]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7645 [D loss: 0.5874203145503998 | D accuracy: 71.875] [G loss: 1.0829367637634277]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7646 [D loss: 0.547185093164444 | D accuracy: 73.4375] [G loss: 1.0438721179962158]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7647 [D loss: 0.5759494304656982 | D accuracy: 70.3125] [G loss: 0.984982430934906]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7648 [D loss: 0.6052451431751251 | D accuracy: 60.9375] [G loss: 1.111014485359192]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7649 [D loss: 0.4717940390110016 | D accuracy: 81.25] [G loss: 1.1891101598739624]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7650 [D loss: 0.6023270189762115 | D accuracy: 62.5] [G loss: 1.0649898052215576]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7651 [D loss: 0.5386126637458801 | D accuracy: 78.125] [G loss: 1.1283369064331055]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7652 [D loss: 0.5065142512321472 | D accuracy: 81.25] [G loss: 1.2188525199890137]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7653 [D loss: 0.6353538036346436 | D accuracy: 57.8125] [G loss: 1.1521811485290527]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7654 [D loss: 0.6885814368724823 | D accuracy: 64.0625] [G loss: 1.1517105102539062]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7655 [D loss: 0.6064484417438507 | D accuracy: 64.0625] [G loss: 1.1896166801452637]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7656 [D loss: 0.640021950006485 | D accuracy: 67.1875] [G loss: 1.0589163303375244]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7657 [D loss: 0.6197940707206726 | D accuracy: 70.3125] [G loss: 1.0424892902374268]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7658 [D loss: 0.6225792169570923 | D accuracy: 65.625] [G loss: 1.1059491634368896]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7659 [D loss: 0.5663845241069794 | D accuracy: 68.75] [G loss: 1.11313796043396]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7660 [D loss: 0.5758269429206848 | D accuracy: 71.875] [G loss: 1.0323346853256226]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7661 [D loss: 0.576627790927887 | D accuracy: 75.0] [G loss: 1.0051000118255615]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7662 [D loss: 0.6046071946620941 | D accuracy: 70.3125] [G loss: 1.0852222442626953]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7663 [D loss: 0.591741681098938 | D accuracy: 65.625] [G loss: 1.0046555995941162]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7664 [D loss: 0.5935730934143066 | D accuracy: 64.0625] [G loss: 1.0554075241088867]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7665 [D loss: 0.6085376739501953 | D accuracy: 67.1875] [G loss: 0.9674878120422363]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7666 [D loss: 0.5888004004955292 | D accuracy: 70.3125] [G loss: 1.1529624462127686]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7667 [D loss: 0.5995336174964905 | D accuracy: 62.5] [G loss: 1.0808656215667725]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7668 [D loss: 0.489999920129776 | D accuracy: 79.6875] [G loss: 1.1456050872802734]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7669 [D loss: 0.567562997341156 | D accuracy: 71.875] [G loss: 1.1266593933105469]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7670 [D loss: 0.6642136871814728 | D accuracy: 59.375] [G loss: 1.1412419080734253]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7671 [D loss: 0.6634414196014404 | D accuracy: 65.625] [G loss: 1.1424453258514404]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7672 [D loss: 0.5661890208721161 | D accuracy: 70.3125] [G loss: 1.1351432800292969]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7673 [D loss: 0.5446512699127197 | D accuracy: 65.625] [G loss: 1.0592622756958008]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7674 [D loss: 0.51042740046978 | D accuracy: 75.0] [G loss: 1.0948083400726318]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7675 [D loss: 0.5859565436840057 | D accuracy: 71.875] [G loss: 1.1436593532562256]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7676 [D loss: 0.5716816484928131 | D accuracy: 68.75] [G loss: 1.0766944885253906]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7677 [D loss: 0.5397590696811676 | D accuracy: 75.0] [G loss: 1.0564230680465698]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7678 [D loss: 0.5883910655975342 | D accuracy: 71.875] [G loss: 1.0577037334442139]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7679 [D loss: 0.5770167708396912 | D accuracy: 64.0625] [G loss: 1.0971646308898926]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7680 [D loss: 0.6250467002391815 | D accuracy: 62.5] [G loss: 1.0420260429382324]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7681 [D loss: 0.5141623020172119 | D accuracy: 78.125] [G loss: 1.0957950353622437]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7682 [D loss: 0.5333566963672638 | D accuracy: 76.5625] [G loss: 0.9982302784919739]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7683 [D loss: 0.6288153529167175 | D accuracy: 60.9375] [G loss: 1.1120952367782593]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7684 [D loss: 0.5791381001472473 | D accuracy: 67.1875] [G loss: 1.1333510875701904]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7685 [D loss: 0.5631888806819916 | D accuracy: 64.0625] [G loss: 0.9927076101303101]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7686 [D loss: 0.6197482943534851 | D accuracy: 64.0625] [G loss: 1.015727162361145]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7687 [D loss: 0.5550265610218048 | D accuracy: 71.875] [G loss: 1.0942189693450928]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7688 [D loss: 0.5568545162677765 | D accuracy: 71.875] [G loss: 1.0347102880477905]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7689 [D loss: 0.5530853271484375 | D accuracy: 71.875] [G loss: 1.0412771701812744]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "7690 [D loss: 0.5684870183467865 | D accuracy: 70.3125] [G loss: 1.089774489402771]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "7691 [D loss: 0.5263716280460358 | D accuracy: 76.5625] [G loss: 1.0519468784332275]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "7692 [D loss: 0.5708668231964111 | D accuracy: 71.875] [G loss: 1.0577555894851685]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "7693 [D loss: 0.5249730944633484 | D accuracy: 71.875] [G loss: 1.1237313747406006]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7694 [D loss: 0.5901820957660675 | D accuracy: 60.9375] [G loss: 1.2148860692977905]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "7695 [D loss: 0.5812478065490723 | D accuracy: 67.1875] [G loss: 1.273806095123291]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "7696 [D loss: 0.6630246639251709 | D accuracy: 60.9375] [G loss: 1.2126933336257935]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7697 [D loss: 0.5498398244380951 | D accuracy: 71.875] [G loss: 1.1803537607192993]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "7698 [D loss: 0.5945591032505035 | D accuracy: 64.0625] [G loss: 1.2604904174804688]\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "7699 [D loss: 0.5681308209896088 | D accuracy: 65.625] [G loss: 0.9998360276222229]\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "7700 [D loss: 0.5102536976337433 | D accuracy: 78.125] [G loss: 1.0432913303375244]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7701 [D loss: 0.5198107957839966 | D accuracy: 79.6875] [G loss: 1.0611931085586548]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7702 [D loss: 0.5469214916229248 | D accuracy: 67.1875] [G loss: 1.079660415649414]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7703 [D loss: 0.6551647186279297 | D accuracy: 64.0625] [G loss: 1.1917564868927002]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7704 [D loss: 0.6204922497272491 | D accuracy: 57.8125] [G loss: 1.1909875869750977]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7705 [D loss: 0.5587646067142487 | D accuracy: 76.5625] [G loss: 1.2025597095489502]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7706 [D loss: 0.630389541387558 | D accuracy: 71.875] [G loss: 1.13037109375]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7707 [D loss: 0.4931825250387192 | D accuracy: 78.125] [G loss: 1.0562769174575806]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7708 [D loss: 0.6622498333454132 | D accuracy: 60.9375] [G loss: 1.1176010370254517]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7709 [D loss: 0.530171275138855 | D accuracy: 73.4375] [G loss: 1.037410020828247]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7710 [D loss: 0.5552715063095093 | D accuracy: 70.3125] [G loss: 1.1020721197128296]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7711 [D loss: 0.5492314845323563 | D accuracy: 70.3125] [G loss: 1.0855653285980225]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7712 [D loss: 0.6328655779361725 | D accuracy: 64.0625] [G loss: 1.0991584062576294]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7713 [D loss: 0.656605064868927 | D accuracy: 56.25] [G loss: 0.958347737789154]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7714 [D loss: 0.5971314311027527 | D accuracy: 68.75] [G loss: 0.9600646495819092]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7715 [D loss: 0.5276888906955719 | D accuracy: 75.0] [G loss: 1.2157385349273682]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7716 [D loss: 0.6344956755638123 | D accuracy: 64.0625] [G loss: 0.9605686664581299]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7717 [D loss: 0.5244914293289185 | D accuracy: 68.75] [G loss: 1.204089641571045]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7718 [D loss: 0.5793676376342773 | D accuracy: 60.9375] [G loss: 1.1155946254730225]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7719 [D loss: 0.5435943752527237 | D accuracy: 71.875] [G loss: 1.139088749885559]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7720 [D loss: 0.6614267826080322 | D accuracy: 59.375] [G loss: 1.102295160293579]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7721 [D loss: 0.6249369382858276 | D accuracy: 62.5] [G loss: 1.098116159439087]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7722 [D loss: 0.5678343772888184 | D accuracy: 65.625] [G loss: 1.143121361732483]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7723 [D loss: 0.5991280972957611 | D accuracy: 65.625] [G loss: 1.0012671947479248]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7724 [D loss: 0.6368452906608582 | D accuracy: 59.375] [G loss: 1.1317178010940552]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7725 [D loss: 0.6163966655731201 | D accuracy: 60.9375] [G loss: 1.0316641330718994]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7726 [D loss: 0.6207848787307739 | D accuracy: 62.5] [G loss: 1.1791960000991821]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7727 [D loss: 0.6067120730876923 | D accuracy: 62.5] [G loss: 1.027955174446106]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7728 [D loss: 0.6263578534126282 | D accuracy: 64.0625] [G loss: 1.056986927986145]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7729 [D loss: 0.6316212713718414 | D accuracy: 62.5] [G loss: 1.040642261505127]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7730 [D loss: 0.5290620923042297 | D accuracy: 82.8125] [G loss: 1.0180437564849854]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7731 [D loss: 0.5712739825248718 | D accuracy: 64.0625] [G loss: 1.0585194826126099]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7732 [D loss: 0.4752788841724396 | D accuracy: 82.8125] [G loss: 1.1510926485061646]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7733 [D loss: 0.573670506477356 | D accuracy: 67.1875] [G loss: 1.1179993152618408]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7734 [D loss: 0.5807870626449585 | D accuracy: 70.3125] [G loss: 1.0782701969146729]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7735 [D loss: 0.4830055683851242 | D accuracy: 79.6875] [G loss: 1.1040027141571045]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7736 [D loss: 0.574819952249527 | D accuracy: 75.0] [G loss: 1.09716796875]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7737 [D loss: 0.6467176675796509 | D accuracy: 60.9375] [G loss: 1.0790894031524658]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7738 [D loss: 0.5113915503025055 | D accuracy: 73.4375] [G loss: 1.088444709777832]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7739 [D loss: 0.6310220956802368 | D accuracy: 64.0625] [G loss: 1.1163296699523926]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7740 [D loss: 0.5358084142208099 | D accuracy: 76.5625] [G loss: 1.0675214529037476]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7741 [D loss: 0.4384068697690964 | D accuracy: 79.6875] [G loss: 1.201775074005127]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7742 [D loss: 0.5609623789787292 | D accuracy: 71.875] [G loss: 1.1083009243011475]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7743 [D loss: 0.5892473459243774 | D accuracy: 62.5] [G loss: 1.1002707481384277]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7744 [D loss: 0.5367608219385147 | D accuracy: 71.875] [G loss: 1.0202866792678833]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7745 [D loss: 0.5314929187297821 | D accuracy: 75.0] [G loss: 1.0370934009552002]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7746 [D loss: 0.6178189814090729 | D accuracy: 73.4375] [G loss: 1.0434093475341797]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7747 [D loss: 0.5216714888811111 | D accuracy: 76.5625] [G loss: 1.1932649612426758]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7748 [D loss: 0.605388879776001 | D accuracy: 59.375] [G loss: 1.159782886505127]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7749 [D loss: 0.6546235382556915 | D accuracy: 57.8125] [G loss: 0.9992177486419678]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7750 [D loss: 0.6268216967582703 | D accuracy: 57.8125] [G loss: 1.1777724027633667]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7751 [D loss: 0.6065969467163086 | D accuracy: 65.625] [G loss: 1.1734607219696045]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7752 [D loss: 0.5626899898052216 | D accuracy: 64.0625] [G loss: 1.0992803573608398]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7753 [D loss: 0.6051000654697418 | D accuracy: 64.0625] [G loss: 1.0064399242401123]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7754 [D loss: 0.4987431615591049 | D accuracy: 76.5625] [G loss: 1.1475913524627686]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7755 [D loss: 0.5021974444389343 | D accuracy: 81.25] [G loss: 1.0884990692138672]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7756 [D loss: 0.4951990842819214 | D accuracy: 78.125] [G loss: 1.3160394430160522]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7757 [D loss: 0.6583499312400818 | D accuracy: 59.375] [G loss: 1.1667847633361816]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7758 [D loss: 0.5137965977191925 | D accuracy: 71.875] [G loss: 1.2061699628829956]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7759 [D loss: 0.6521475315093994 | D accuracy: 64.0625] [G loss: 1.1066327095031738]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7760 [D loss: 0.5521461963653564 | D accuracy: 68.75] [G loss: 1.1561331748962402]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7761 [D loss: 0.5761792659759521 | D accuracy: 75.0] [G loss: 1.226117730140686]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7762 [D loss: 0.5504398345947266 | D accuracy: 70.3125] [G loss: 1.0948889255523682]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7763 [D loss: 0.5675835609436035 | D accuracy: 67.1875] [G loss: 1.1719491481781006]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7764 [D loss: 0.5777426064014435 | D accuracy: 73.4375] [G loss: 1.0275187492370605]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "7765 [D loss: 0.6574802994728088 | D accuracy: 56.25] [G loss: 1.0554561614990234]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7766 [D loss: 0.5427274405956268 | D accuracy: 78.125] [G loss: 1.155031442642212]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7767 [D loss: 0.5893195867538452 | D accuracy: 64.0625] [G loss: 0.997126042842865]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "7768 [D loss: 0.6176834404468536 | D accuracy: 68.75] [G loss: 1.0185320377349854]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7769 [D loss: 0.5224972069263458 | D accuracy: 71.875] [G loss: 0.9782750606536865]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "7770 [D loss: 0.6611347198486328 | D accuracy: 62.5] [G loss: 1.0922695398330688]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "7771 [D loss: 0.5450010895729065 | D accuracy: 75.0] [G loss: 1.0534578561782837]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7772 [D loss: 0.6405099630355835 | D accuracy: 67.1875] [G loss: 0.9706733822822571]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "7773 [D loss: 0.5160927027463913 | D accuracy: 75.0] [G loss: 1.047571063041687]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7774 [D loss: 0.6578373312950134 | D accuracy: 59.375] [G loss: 1.056107759475708]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "7775 [D loss: 0.6473506093025208 | D accuracy: 62.5] [G loss: 1.0679899454116821]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "7776 [D loss: 0.5262058824300766 | D accuracy: 73.4375] [G loss: 1.1912412643432617]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "7777 [D loss: 0.5243077576160431 | D accuracy: 71.875] [G loss: 1.08091402053833]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7778 [D loss: 0.7476299107074738 | D accuracy: 50.0] [G loss: 1.084836483001709]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7779 [D loss: 0.5859351754188538 | D accuracy: 65.625] [G loss: 1.0794776678085327]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7780 [D loss: 0.6365616917610168 | D accuracy: 62.5] [G loss: 1.156877875328064]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7781 [D loss: 0.48398303985595703 | D accuracy: 82.8125] [G loss: 1.2398910522460938]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7782 [D loss: 0.5488132238388062 | D accuracy: 68.75] [G loss: 1.0993232727050781]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7783 [D loss: 0.47159478068351746 | D accuracy: 78.125] [G loss: 1.1922309398651123]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7784 [D loss: 0.569650799036026 | D accuracy: 68.75] [G loss: 1.0882488489151]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7785 [D loss: 0.5117930918931961 | D accuracy: 81.25] [G loss: 1.190363883972168]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7786 [D loss: 0.7011224031448364 | D accuracy: 59.375] [G loss: 0.999642014503479]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7787 [D loss: 0.5495114922523499 | D accuracy: 68.75] [G loss: 1.1973955631256104]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7788 [D loss: 0.5074840784072876 | D accuracy: 76.5625] [G loss: 1.1119295358657837]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7789 [D loss: 0.5796261727809906 | D accuracy: 67.1875] [G loss: 1.1571507453918457]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7790 [D loss: 0.6856809258460999 | D accuracy: 50.0] [G loss: 1.1630874872207642]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7791 [D loss: 0.5927819609642029 | D accuracy: 68.75] [G loss: 1.1696081161499023]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7792 [D loss: 0.6473509073257446 | D accuracy: 65.625] [G loss: 1.028989315032959]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7793 [D loss: 0.687140166759491 | D accuracy: 62.5] [G loss: 1.091158390045166]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7794 [D loss: 0.567190945148468 | D accuracy: 73.4375] [G loss: 1.2010371685028076]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7795 [D loss: 0.5338665246963501 | D accuracy: 70.3125] [G loss: 1.2993149757385254]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7796 [D loss: 0.5851207077503204 | D accuracy: 68.75] [G loss: 1.1791208982467651]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7797 [D loss: 0.5599417984485626 | D accuracy: 67.1875] [G loss: 1.129856824874878]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7798 [D loss: 0.5735837519168854 | D accuracy: 67.1875] [G loss: 1.0648295879364014]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7799 [D loss: 0.5534020066261292 | D accuracy: 75.0] [G loss: 1.0235364437103271]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7800 [D loss: 0.6518681347370148 | D accuracy: 59.375] [G loss: 1.071221113204956]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7801 [D loss: 0.6565834283828735 | D accuracy: 65.625] [G loss: 1.0150482654571533]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7802 [D loss: 0.5146118998527527 | D accuracy: 78.125] [G loss: 1.0308268070220947]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7803 [D loss: 0.6077606678009033 | D accuracy: 67.1875] [G loss: 0.955868124961853]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7804 [D loss: 0.5080097317695618 | D accuracy: 76.5625] [G loss: 1.1098555326461792]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7805 [D loss: 0.5659766495227814 | D accuracy: 73.4375] [G loss: 0.9382177591323853]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7806 [D loss: 0.5619199573993683 | D accuracy: 70.3125] [G loss: 1.0284568071365356]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7807 [D loss: 0.6198869049549103 | D accuracy: 64.0625] [G loss: 1.0177338123321533]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7808 [D loss: 0.5107038021087646 | D accuracy: 75.0] [G loss: 0.9991475343704224]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7809 [D loss: 0.5252137929201126 | D accuracy: 76.5625] [G loss: 1.1287274360656738]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7810 [D loss: 0.5386303663253784 | D accuracy: 75.0] [G loss: 1.1473352909088135]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7811 [D loss: 0.5924157500267029 | D accuracy: 68.75] [G loss: 1.1590080261230469]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7812 [D loss: 0.6212399303913116 | D accuracy: 62.5] [G loss: 1.1802711486816406]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7813 [D loss: 0.5598360896110535 | D accuracy: 75.0] [G loss: 1.1061739921569824]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7814 [D loss: 0.5872717797756195 | D accuracy: 68.75] [G loss: 1.1427443027496338]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7815 [D loss: 0.7069415152072906 | D accuracy: 60.9375] [G loss: 1.0086534023284912]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7816 [D loss: 0.6071249544620514 | D accuracy: 67.1875] [G loss: 1.178533911705017]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7817 [D loss: 0.5325789451599121 | D accuracy: 70.3125] [G loss: 1.1052095890045166]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7818 [D loss: 0.6178489923477173 | D accuracy: 62.5] [G loss: 1.0339140892028809]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7819 [D loss: 0.5663147270679474 | D accuracy: 64.0625] [G loss: 1.087982416152954]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7820 [D loss: 0.58611661195755 | D accuracy: 70.3125] [G loss: 1.0755033493041992]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7821 [D loss: 0.5504109859466553 | D accuracy: 75.0] [G loss: 1.1358559131622314]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7822 [D loss: 0.5976596474647522 | D accuracy: 70.3125] [G loss: 1.0913583040237427]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7823 [D loss: 0.4863969385623932 | D accuracy: 75.0] [G loss: 1.0806384086608887]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7824 [D loss: 0.5867757797241211 | D accuracy: 68.75] [G loss: 1.133025884628296]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7825 [D loss: 0.6142970323562622 | D accuracy: 64.0625] [G loss: 1.020408034324646]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7826 [D loss: 0.5666606426239014 | D accuracy: 65.625] [G loss: 0.9605570435523987]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7827 [D loss: 0.5264039635658264 | D accuracy: 73.4375] [G loss: 1.0991878509521484]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7828 [D loss: 0.5426353514194489 | D accuracy: 64.0625] [G loss: 1.0774203538894653]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7829 [D loss: 0.5709834098815918 | D accuracy: 73.4375] [G loss: 1.09900963306427]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7830 [D loss: 0.6346133053302765 | D accuracy: 62.5] [G loss: 0.9872854351997375]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7831 [D loss: 0.5862736701965332 | D accuracy: 71.875] [G loss: 1.0470316410064697]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7832 [D loss: 0.6081173419952393 | D accuracy: 59.375] [G loss: 1.1801483631134033]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7833 [D loss: 0.6616171896457672 | D accuracy: 57.8125] [G loss: 1.173471212387085]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7834 [D loss: 0.534006729722023 | D accuracy: 75.0] [G loss: 1.0928287506103516]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7835 [D loss: 0.6273311376571655 | D accuracy: 59.375] [G loss: 1.1380584239959717]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7836 [D loss: 0.504778653383255 | D accuracy: 76.5625] [G loss: 1.0737789869308472]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7837 [D loss: 0.5960689187049866 | D accuracy: 59.375] [G loss: 1.076711654663086]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7838 [D loss: 0.5335772037506104 | D accuracy: 71.875] [G loss: 1.1922695636749268]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7839 [D loss: 0.5799447298049927 | D accuracy: 65.625] [G loss: 1.1239666938781738]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7840 [D loss: 0.6216859817504883 | D accuracy: 67.1875] [G loss: 1.1060423851013184]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7841 [D loss: 0.6531482934951782 | D accuracy: 57.8125] [G loss: 1.0779658555984497]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "7842 [D loss: 0.551607295870781 | D accuracy: 71.875] [G loss: 1.0661590099334717]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7843 [D loss: 0.5277048051357269 | D accuracy: 75.0] [G loss: 1.0743153095245361]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "7844 [D loss: 0.5627314448356628 | D accuracy: 76.5625] [G loss: 0.9886313676834106]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7845 [D loss: 0.5229460000991821 | D accuracy: 78.125] [G loss: 1.0551079511642456]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7846 [D loss: 0.5153854638338089 | D accuracy: 75.0] [G loss: 1.0566827058792114]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "7847 [D loss: 0.5372567176818848 | D accuracy: 68.75] [G loss: 1.1415197849273682]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "7848 [D loss: 0.45979681611061096 | D accuracy: 81.25] [G loss: 1.213952898979187]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7849 [D loss: 0.5840705633163452 | D accuracy: 67.1875] [G loss: 1.0340490341186523]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7850 [D loss: 0.5253753364086151 | D accuracy: 73.4375] [G loss: 1.171636700630188]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7851 [D loss: 0.5861131548881531 | D accuracy: 67.1875] [G loss: 1.0109295845031738]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7852 [D loss: 0.627251386642456 | D accuracy: 65.625] [G loss: 1.086600422859192]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7853 [D loss: 0.5976318717002869 | D accuracy: 67.1875] [G loss: 1.0511856079101562]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7854 [D loss: 0.5226000547409058 | D accuracy: 68.75] [G loss: 1.2385308742523193]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7855 [D loss: 0.5967212319374084 | D accuracy: 67.1875] [G loss: 1.2103899717330933]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7856 [D loss: 0.5255024582147598 | D accuracy: 70.3125] [G loss: 1.0892319679260254]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7857 [D loss: 0.5768682062625885 | D accuracy: 68.75] [G loss: 1.0993938446044922]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "7858 [D loss: 0.5271613895893097 | D accuracy: 71.875] [G loss: 0.957886815071106]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7859 [D loss: 0.5288748890161514 | D accuracy: 78.125] [G loss: 1.015751838684082]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7860 [D loss: 0.531383216381073 | D accuracy: 71.875] [G loss: 1.0799850225448608]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7861 [D loss: 0.6005823910236359 | D accuracy: 68.75] [G loss: 1.1965160369873047]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7862 [D loss: 0.4917510002851486 | D accuracy: 76.5625] [G loss: 1.1730953454971313]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7863 [D loss: 0.6241467893123627 | D accuracy: 67.1875] [G loss: 1.1286827325820923]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7864 [D loss: 0.5650681853294373 | D accuracy: 64.0625] [G loss: 1.0997085571289062]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7865 [D loss: 0.58486507833004 | D accuracy: 71.875] [G loss: 1.1580488681793213]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7866 [D loss: 0.6331749856472015 | D accuracy: 62.5] [G loss: 0.9902780652046204]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7867 [D loss: 0.5567412674427032 | D accuracy: 73.4375] [G loss: 1.0149540901184082]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7868 [D loss: 0.49201348423957825 | D accuracy: 75.0] [G loss: 1.2041198015213013]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7869 [D loss: 0.5659587979316711 | D accuracy: 67.1875] [G loss: 1.0210232734680176]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7870 [D loss: 0.599806934595108 | D accuracy: 65.625] [G loss: 1.1309807300567627]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7871 [D loss: 0.5135287195444107 | D accuracy: 71.875] [G loss: 1.0218385457992554]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7872 [D loss: 0.5504671633243561 | D accuracy: 65.625] [G loss: 1.0507080554962158]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7873 [D loss: 0.6399961113929749 | D accuracy: 56.25] [G loss: 1.2363446950912476]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7874 [D loss: 0.6388252973556519 | D accuracy: 57.8125] [G loss: 1.1230045557022095]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7875 [D loss: 0.6056146025657654 | D accuracy: 62.5] [G loss: 1.2553069591522217]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7876 [D loss: 0.5612073838710785 | D accuracy: 75.0] [G loss: 1.151512622833252]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7877 [D loss: 0.5787781476974487 | D accuracy: 65.625] [G loss: 1.1248530149459839]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7878 [D loss: 0.5187596380710602 | D accuracy: 75.0] [G loss: 1.1079738140106201]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7879 [D loss: 0.528520405292511 | D accuracy: 78.125] [G loss: 1.0721921920776367]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7880 [D loss: 0.5956292152404785 | D accuracy: 73.4375] [G loss: 1.0923190116882324]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7881 [D loss: 0.5599677264690399 | D accuracy: 75.0] [G loss: 1.1352618932724]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7882 [D loss: 0.6307092308998108 | D accuracy: 60.9375] [G loss: 1.0524970293045044]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7883 [D loss: 0.6515567004680634 | D accuracy: 59.375] [G loss: 1.0469496250152588]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7884 [D loss: 0.6782735288143158 | D accuracy: 53.125] [G loss: 1.1478594541549683]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7885 [D loss: 0.6407443284988403 | D accuracy: 54.6875] [G loss: 1.139033555984497]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7886 [D loss: 0.6060858368873596 | D accuracy: 62.5] [G loss: 1.25315523147583]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7887 [D loss: 0.585084080696106 | D accuracy: 64.0625] [G loss: 1.0997601747512817]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7888 [D loss: 0.6227158606052399 | D accuracy: 67.1875] [G loss: 1.0567166805267334]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7889 [D loss: 0.5941558629274368 | D accuracy: 70.3125] [G loss: 0.9301356077194214]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7890 [D loss: 0.6135703325271606 | D accuracy: 64.0625] [G loss: 0.9800344109535217]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7891 [D loss: 0.5561339259147644 | D accuracy: 67.1875] [G loss: 0.9897873401641846]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7892 [D loss: 0.5851344764232635 | D accuracy: 70.3125] [G loss: 1.077029824256897]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7893 [D loss: 0.5456058382987976 | D accuracy: 68.75] [G loss: 0.9824192523956299]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7894 [D loss: 0.6610898077487946 | D accuracy: 62.5] [G loss: 0.9851987361907959]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7895 [D loss: 0.5792748034000397 | D accuracy: 67.1875] [G loss: 1.1559720039367676]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7896 [D loss: 0.636696070432663 | D accuracy: 65.625] [G loss: 1.277047872543335]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7897 [D loss: 0.5332166850566864 | D accuracy: 76.5625] [G loss: 1.256455421447754]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7898 [D loss: 0.5675150156021118 | D accuracy: 73.4375] [G loss: 1.1772618293762207]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7899 [D loss: 0.560444176197052 | D accuracy: 71.875] [G loss: 1.289294719696045]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7900 [D loss: 0.629056304693222 | D accuracy: 62.5] [G loss: 1.18755042552948]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7901 [D loss: 0.4729619473218918 | D accuracy: 78.125] [G loss: 1.0364015102386475]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7902 [D loss: 0.5230048596858978 | D accuracy: 76.5625] [G loss: 1.185899019241333]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7903 [D loss: 0.6178757548332214 | D accuracy: 57.8125] [G loss: 1.0936545133590698]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7904 [D loss: 0.6151069104671478 | D accuracy: 62.5] [G loss: 1.140460729598999]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7905 [D loss: 0.5717771351337433 | D accuracy: 70.3125] [G loss: 1.1590735912322998]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7906 [D loss: 0.6485534608364105 | D accuracy: 54.6875] [G loss: 1.0933055877685547]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7907 [D loss: 0.5123565793037415 | D accuracy: 75.0] [G loss: 1.042827844619751]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7908 [D loss: 0.5385704636573792 | D accuracy: 73.4375] [G loss: 1.0727872848510742]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7909 [D loss: 0.48514819145202637 | D accuracy: 79.6875] [G loss: 1.1401125192642212]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7910 [D loss: 0.5493717193603516 | D accuracy: 75.0] [G loss: 1.0405223369598389]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7911 [D loss: 0.5954318940639496 | D accuracy: 73.4375] [G loss: 0.9590467214584351]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7912 [D loss: 0.5722113251686096 | D accuracy: 71.875] [G loss: 0.9660384058952332]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7913 [D loss: 0.5473883152008057 | D accuracy: 73.4375] [G loss: 1.117114782333374]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7914 [D loss: 0.5302556753158569 | D accuracy: 78.125] [G loss: 1.149951696395874]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7915 [D loss: 0.5860118567943573 | D accuracy: 64.0625] [G loss: 1.0160959959030151]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7916 [D loss: 0.5195521116256714 | D accuracy: 76.5625] [G loss: 1.0073966979980469]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7917 [D loss: 0.5474088788032532 | D accuracy: 68.75] [G loss: 0.987002432346344]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7918 [D loss: 0.5772735327482224 | D accuracy: 65.625] [G loss: 1.0628845691680908]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7919 [D loss: 0.5567958950996399 | D accuracy: 75.0] [G loss: 1.0427221059799194]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "7920 [D loss: 0.4588591605424881 | D accuracy: 82.8125] [G loss: 1.1442056894302368]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "7921 [D loss: 0.6124555468559265 | D accuracy: 60.9375] [G loss: 1.2380561828613281]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7922 [D loss: 0.5458642542362213 | D accuracy: 68.75] [G loss: 1.1509604454040527]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7923 [D loss: 0.56073859333992 | D accuracy: 68.75] [G loss: 1.1943461894989014]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "7924 [D loss: 0.524415522813797 | D accuracy: 73.4375] [G loss: 1.1086976528167725]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7925 [D loss: 0.5568177402019501 | D accuracy: 73.4375] [G loss: 1.1861271858215332]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7926 [D loss: 0.5100799947977066 | D accuracy: 78.125] [G loss: 1.0108494758605957]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "7927 [D loss: 0.5035727918148041 | D accuracy: 78.125] [G loss: 1.0368797779083252]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "7928 [D loss: 0.585066020488739 | D accuracy: 70.3125] [G loss: 1.1608753204345703]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7929 [D loss: 0.5729323625564575 | D accuracy: 71.875] [G loss: 1.0756330490112305]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7930 [D loss: 0.6474975347518921 | D accuracy: 62.5] [G loss: 1.1480262279510498]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7931 [D loss: 0.525618851184845 | D accuracy: 75.0] [G loss: 1.1647939682006836]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7932 [D loss: 0.5113082528114319 | D accuracy: 75.0] [G loss: 1.0989360809326172]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7933 [D loss: 0.6323208212852478 | D accuracy: 60.9375] [G loss: 1.1520543098449707]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7934 [D loss: 0.514569416642189 | D accuracy: 75.0] [G loss: 1.1029582023620605]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7935 [D loss: 0.5695849657058716 | D accuracy: 68.75] [G loss: 1.1779744625091553]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7936 [D loss: 0.5529054999351501 | D accuracy: 65.625] [G loss: 1.164221167564392]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7937 [D loss: 0.5226364433765411 | D accuracy: 76.5625] [G loss: 1.1478726863861084]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7938 [D loss: 0.5866858661174774 | D accuracy: 64.0625] [G loss: 1.1077585220336914]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7939 [D loss: 0.6466464400291443 | D accuracy: 59.375] [G loss: 0.9216629266738892]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7940 [D loss: 0.5749730169773102 | D accuracy: 71.875] [G loss: 1.0794613361358643]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7941 [D loss: 0.5903927981853485 | D accuracy: 70.3125] [G loss: 1.0555906295776367]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7942 [D loss: 0.6438265144824982 | D accuracy: 51.5625] [G loss: 1.0809481143951416]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7943 [D loss: 0.5999579429626465 | D accuracy: 62.5] [G loss: 1.1690313816070557]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7944 [D loss: 0.5015787184238434 | D accuracy: 71.875] [G loss: 1.048525333404541]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7945 [D loss: 0.5505131483078003 | D accuracy: 71.875] [G loss: 1.0402259826660156]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7946 [D loss: 0.5356034934520721 | D accuracy: 71.875] [G loss: 1.05361807346344]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7947 [D loss: 0.563959151506424 | D accuracy: 68.75] [G loss: 1.1828923225402832]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7948 [D loss: 0.5313327312469482 | D accuracy: 71.875] [G loss: 1.2726716995239258]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7949 [D loss: 0.571908712387085 | D accuracy: 68.75] [G loss: 1.1724727153778076]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7950 [D loss: 0.5919928848743439 | D accuracy: 65.625] [G loss: 1.0682199001312256]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7951 [D loss: 0.6070022284984589 | D accuracy: 65.625] [G loss: 1.0912303924560547]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7952 [D loss: 0.5148729979991913 | D accuracy: 71.875] [G loss: 1.176098108291626]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7953 [D loss: 0.4918936938047409 | D accuracy: 75.0] [G loss: 1.2566015720367432]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "7954 [D loss: 0.6073989272117615 | D accuracy: 68.75] [G loss: 1.075103521347046]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7955 [D loss: 0.5205236077308655 | D accuracy: 73.4375] [G loss: 1.0811262130737305]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7956 [D loss: 0.6521168947219849 | D accuracy: 65.625] [G loss: 1.0268843173980713]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "7957 [D loss: 0.7064794301986694 | D accuracy: 54.6875] [G loss: 1.334844946861267]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7958 [D loss: 0.5599953532218933 | D accuracy: 76.5625] [G loss: 1.2708909511566162]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7959 [D loss: 0.501621663570404 | D accuracy: 79.6875] [G loss: 1.1089459657669067]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7960 [D loss: 0.6355715692043304 | D accuracy: 57.8125] [G loss: 1.2640920877456665]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7961 [D loss: 0.5739238560199738 | D accuracy: 71.875] [G loss: 1.2121878862380981]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7962 [D loss: 0.6365604102611542 | D accuracy: 65.625] [G loss: 1.2188676595687866]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7963 [D loss: 0.5771048963069916 | D accuracy: 67.1875] [G loss: 1.0729196071624756]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7964 [D loss: 0.5872992277145386 | D accuracy: 68.75] [G loss: 1.1059370040893555]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7965 [D loss: 0.5277884602546692 | D accuracy: 68.75] [G loss: 1.2375320196151733]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7966 [D loss: 0.7069782018661499 | D accuracy: 51.5625] [G loss: 1.223894715309143]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "7967 [D loss: 0.530745267868042 | D accuracy: 76.5625] [G loss: 1.0412744283676147]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "7968 [D loss: 0.5446225106716156 | D accuracy: 75.0] [G loss: 1.245870590209961]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7969 [D loss: 0.5731967389583588 | D accuracy: 68.75] [G loss: 1.1710777282714844]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7970 [D loss: 0.5217211842536926 | D accuracy: 75.0] [G loss: 1.2149455547332764]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7971 [D loss: 0.6847888231277466 | D accuracy: 60.9375] [G loss: 1.3066824674606323]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "7972 [D loss: 0.555810272693634 | D accuracy: 67.1875] [G loss: 1.1181950569152832]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7973 [D loss: 0.514416515827179 | D accuracy: 73.4375] [G loss: 1.1094624996185303]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7974 [D loss: 0.606687605381012 | D accuracy: 65.625] [G loss: 1.1157200336456299]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "7975 [D loss: 0.6148226857185364 | D accuracy: 56.25] [G loss: 1.195542335510254]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7976 [D loss: 0.6278161406517029 | D accuracy: 62.5] [G loss: 1.0539685487747192]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "7977 [D loss: 0.5173386186361313 | D accuracy: 81.25] [G loss: 1.1344125270843506]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "7978 [D loss: 0.5992844998836517 | D accuracy: 68.75] [G loss: 1.1222392320632935]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7979 [D loss: 0.5779292583465576 | D accuracy: 68.75] [G loss: 1.0530089139938354]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7980 [D loss: 0.5368041843175888 | D accuracy: 73.4375] [G loss: 1.140028953552246]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7981 [D loss: 0.6080285012722015 | D accuracy: 70.3125] [G loss: 1.0349864959716797]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7982 [D loss: 0.5239518284797668 | D accuracy: 73.4375] [G loss: 1.0574160814285278]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7983 [D loss: 0.628234326839447 | D accuracy: 60.9375] [G loss: 1.1372733116149902]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "7984 [D loss: 0.6003687977790833 | D accuracy: 65.625] [G loss: 1.036912202835083]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7985 [D loss: 0.5956244766712189 | D accuracy: 64.0625] [G loss: 0.9415362477302551]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7986 [D loss: 0.694233775138855 | D accuracy: 57.8125] [G loss: 0.9343215227127075]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "7987 [D loss: 0.5462404489517212 | D accuracy: 70.3125] [G loss: 0.9453370571136475]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7988 [D loss: 0.5618084669113159 | D accuracy: 70.3125] [G loss: 1.103722333908081]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7989 [D loss: 0.5610029995441437 | D accuracy: 70.3125] [G loss: 1.1929638385772705]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "7990 [D loss: 0.6101318001747131 | D accuracy: 57.8125] [G loss: 1.2363648414611816]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "7991 [D loss: 0.5315785109996796 | D accuracy: 73.4375] [G loss: 1.101738691329956]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "7992 [D loss: 0.6266025006771088 | D accuracy: 67.1875] [G loss: 1.145732045173645]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "7993 [D loss: 0.6495205163955688 | D accuracy: 60.9375] [G loss: 1.141862154006958]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "7994 [D loss: 0.5753113031387329 | D accuracy: 67.1875] [G loss: 1.1623876094818115]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "7995 [D loss: 0.5799822807312012 | D accuracy: 70.3125] [G loss: 1.246496558189392]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "7996 [D loss: 0.5394928455352783 | D accuracy: 78.125] [G loss: 1.1119701862335205]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "7997 [D loss: 0.6820192039012909 | D accuracy: 64.0625] [G loss: 1.1730749607086182]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "7998 [D loss: 0.5535210371017456 | D accuracy: 73.4375] [G loss: 1.181775450706482]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "7999 [D loss: 0.506102442741394 | D accuracy: 75.0] [G loss: 0.9825640916824341]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "8000 [D loss: 0.5895954072475433 | D accuracy: 68.75] [G loss: 1.0963854789733887]\n",
            "1/1 [==============================] - 0s 47ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "8001 [D loss: 0.5930418074131012 | D accuracy: 70.3125] [G loss: 1.0718010663986206]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8002 [D loss: 0.5981960892677307 | D accuracy: 70.3125] [G loss: 1.0803459882736206]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8003 [D loss: 0.5543470084667206 | D accuracy: 75.0] [G loss: 1.0722053050994873]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8004 [D loss: 0.45842142403125763 | D accuracy: 81.25] [G loss: 1.169593095779419]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8005 [D loss: 0.5666197538375854 | D accuracy: 71.875] [G loss: 1.1975347995758057]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8006 [D loss: 0.6588528156280518 | D accuracy: 73.4375] [G loss: 1.2024391889572144]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8007 [D loss: 0.5380474030971527 | D accuracy: 70.3125] [G loss: 1.215895652770996]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8008 [D loss: 0.6070540249347687 | D accuracy: 65.625] [G loss: 1.1060060262680054]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8009 [D loss: 0.5737600922584534 | D accuracy: 70.3125] [G loss: 1.0970317125320435]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8010 [D loss: 0.5648634135723114 | D accuracy: 67.1875] [G loss: 1.1521954536437988]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8011 [D loss: 0.5463442504405975 | D accuracy: 78.125] [G loss: 1.0897209644317627]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8012 [D loss: 0.49077020585536957 | D accuracy: 84.375] [G loss: 1.0437679290771484]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8013 [D loss: 0.4924085736274719 | D accuracy: 78.125] [G loss: 1.1627302169799805]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8014 [D loss: 0.5484879612922668 | D accuracy: 73.4375] [G loss: 1.127610683441162]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8015 [D loss: 0.478030189871788 | D accuracy: 75.0] [G loss: 1.1592706441879272]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8016 [D loss: 0.5670556724071503 | D accuracy: 75.0] [G loss: 1.1134713888168335]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8017 [D loss: 0.6288717985153198 | D accuracy: 57.8125] [G loss: 1.0209226608276367]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8018 [D loss: 0.5407841205596924 | D accuracy: 71.875] [G loss: 1.0981382131576538]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8019 [D loss: 0.5680620074272156 | D accuracy: 76.5625] [G loss: 1.1680471897125244]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8020 [D loss: 0.4972482919692993 | D accuracy: 79.6875] [G loss: 0.9772713780403137]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8021 [D loss: 0.6043965816497803 | D accuracy: 70.3125] [G loss: 1.1130056381225586]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8022 [D loss: 0.5042205154895782 | D accuracy: 71.875] [G loss: 1.1782982349395752]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8023 [D loss: 0.6922709941864014 | D accuracy: 57.8125] [G loss: 1.0159558057785034]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8024 [D loss: 0.6307676136493683 | D accuracy: 65.625] [G loss: 1.1371294260025024]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8025 [D loss: 0.4856652170419693 | D accuracy: 75.0] [G loss: 1.14188551902771]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8026 [D loss: 0.6125186681747437 | D accuracy: 65.625] [G loss: 1.1159429550170898]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8027 [D loss: 0.541174054145813 | D accuracy: 68.75] [G loss: 1.0762596130371094]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8028 [D loss: 0.6003503799438477 | D accuracy: 73.4375] [G loss: 1.0678112506866455]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8029 [D loss: 0.4881509840488434 | D accuracy: 81.25] [G loss: 1.099138617515564]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8030 [D loss: 0.5402876734733582 | D accuracy: 71.875] [G loss: 1.1706652641296387]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8031 [D loss: 0.541336327791214 | D accuracy: 76.5625] [G loss: 1.0570988655090332]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8032 [D loss: 0.6060806214809418 | D accuracy: 65.625] [G loss: 1.193173885345459]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8033 [D loss: 0.6072145402431488 | D accuracy: 67.1875] [G loss: 1.0654646158218384]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8034 [D loss: 0.6157941520214081 | D accuracy: 60.9375] [G loss: 1.0788694620132446]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8035 [D loss: 0.5423927903175354 | D accuracy: 75.0] [G loss: 1.0962092876434326]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8036 [D loss: 0.5473127365112305 | D accuracy: 73.4375] [G loss: 1.3000142574310303]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8037 [D loss: 0.538204699754715 | D accuracy: 67.1875] [G loss: 1.2034225463867188]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8038 [D loss: 0.5114448666572571 | D accuracy: 81.25] [G loss: 1.212629795074463]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8039 [D loss: 0.5891380608081818 | D accuracy: 70.3125] [G loss: 1.1005854606628418]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8040 [D loss: 0.4362117648124695 | D accuracy: 82.8125] [G loss: 1.1914997100830078]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8041 [D loss: 0.5822312235832214 | D accuracy: 65.625] [G loss: 1.1812961101531982]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8042 [D loss: 0.6196498572826385 | D accuracy: 62.5] [G loss: 1.1587834358215332]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8043 [D loss: 0.5536597371101379 | D accuracy: 73.4375] [G loss: 1.1290452480316162]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8044 [D loss: 0.6007134914398193 | D accuracy: 59.375] [G loss: 1.1442265510559082]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8045 [D loss: 0.5227315723896027 | D accuracy: 79.6875] [G loss: 1.112807273864746]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8046 [D loss: 0.5684851855039597 | D accuracy: 65.625] [G loss: 1.1768819093704224]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8047 [D loss: 0.6073868274688721 | D accuracy: 67.1875] [G loss: 1.0973267555236816]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8048 [D loss: 0.5587218403816223 | D accuracy: 71.875] [G loss: 1.1411128044128418]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8049 [D loss: 0.5428031980991364 | D accuracy: 70.3125] [G loss: 1.1655972003936768]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8050 [D loss: 0.5666390359401703 | D accuracy: 71.875] [G loss: 1.0710878372192383]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8051 [D loss: 0.5214177370071411 | D accuracy: 76.5625] [G loss: 1.2245876789093018]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8052 [D loss: 0.545898824930191 | D accuracy: 70.3125] [G loss: 1.2310214042663574]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8053 [D loss: 0.6000621020793915 | D accuracy: 60.9375] [G loss: 1.1286582946777344]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8054 [D loss: 0.6376375555992126 | D accuracy: 59.375] [G loss: 1.3413251638412476]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8055 [D loss: 0.6229044497013092 | D accuracy: 62.5] [G loss: 1.2215285301208496]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8056 [D loss: 0.5516591370105743 | D accuracy: 70.3125] [G loss: 1.0627999305725098]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8057 [D loss: 0.4980487674474716 | D accuracy: 71.875] [G loss: 1.1155455112457275]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8058 [D loss: 0.5141887366771698 | D accuracy: 73.4375] [G loss: 1.0385856628417969]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8059 [D loss: 0.4931519031524658 | D accuracy: 78.125] [G loss: 1.1532087326049805]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8060 [D loss: 0.5666317641735077 | D accuracy: 65.625] [G loss: 1.1021888256072998]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8061 [D loss: 0.5296725034713745 | D accuracy: 71.875] [G loss: 1.073215126991272]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8062 [D loss: 0.5886568129062653 | D accuracy: 64.0625] [G loss: 1.0360291004180908]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8063 [D loss: 0.5294916480779648 | D accuracy: 68.75] [G loss: 1.0872633457183838]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8064 [D loss: 0.6423306167125702 | D accuracy: 59.375] [G loss: 0.8745995759963989]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8065 [D loss: 0.48882344365119934 | D accuracy: 76.5625] [G loss: 1.1369366645812988]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8066 [D loss: 0.6589921116828918 | D accuracy: 62.5] [G loss: 0.9726123809814453]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8067 [D loss: 0.5556577146053314 | D accuracy: 73.4375] [G loss: 1.0866566896438599]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8068 [D loss: 0.5919103026390076 | D accuracy: 68.75] [G loss: 1.1080918312072754]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8069 [D loss: 0.5084337592124939 | D accuracy: 75.0] [G loss: 1.1472132205963135]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8070 [D loss: 0.5273139625787735 | D accuracy: 68.75] [G loss: 1.2039821147918701]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8071 [D loss: 0.569857656955719 | D accuracy: 71.875] [G loss: 1.1503456830978394]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8072 [D loss: 0.47260263562202454 | D accuracy: 76.5625] [G loss: 1.1491225957870483]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8073 [D loss: 0.5338065922260284 | D accuracy: 73.4375] [G loss: 1.0902595520019531]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8074 [D loss: 0.5546103119850159 | D accuracy: 62.5] [G loss: 1.1374051570892334]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8075 [D loss: 0.4692523330450058 | D accuracy: 76.5625] [G loss: 1.1431032419204712]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8076 [D loss: 0.5240060091018677 | D accuracy: 76.5625] [G loss: 1.1517739295959473]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8077 [D loss: 0.5569237470626831 | D accuracy: 68.75] [G loss: 1.1381901502609253]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8078 [D loss: 0.507939487695694 | D accuracy: 78.125] [G loss: 1.138988971710205]\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "8079 [D loss: 0.5840088725090027 | D accuracy: 65.625] [G loss: 1.1598141193389893]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8080 [D loss: 0.5483760833740234 | D accuracy: 78.125] [G loss: 1.1279752254486084]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "8081 [D loss: 0.6271597743034363 | D accuracy: 59.375] [G loss: 1.1762371063232422]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8082 [D loss: 0.5209217071533203 | D accuracy: 78.125] [G loss: 1.103496789932251]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8083 [D loss: 0.5436677038669586 | D accuracy: 67.1875] [G loss: 1.1796321868896484]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8084 [D loss: 0.5782451331615448 | D accuracy: 67.1875] [G loss: 1.1004135608673096]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8085 [D loss: 0.5086208134889603 | D accuracy: 76.5625] [G loss: 1.0769891738891602]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8086 [D loss: 0.6030755639076233 | D accuracy: 64.0625] [G loss: 1.1615151166915894]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8087 [D loss: 0.5636737644672394 | D accuracy: 70.3125] [G loss: 1.1456735134124756]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8088 [D loss: 0.5242042243480682 | D accuracy: 73.4375] [G loss: 1.1796932220458984]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8089 [D loss: 0.6007132530212402 | D accuracy: 70.3125] [G loss: 1.199772596359253]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8090 [D loss: 0.5561852008104324 | D accuracy: 68.75] [G loss: 1.2102420330047607]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8091 [D loss: 0.5833049714565277 | D accuracy: 64.0625] [G loss: 1.075234293937683]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8092 [D loss: 0.5617625117301941 | D accuracy: 70.3125] [G loss: 1.0907920598983765]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8093 [D loss: 0.58572918176651 | D accuracy: 64.0625] [G loss: 1.1451964378356934]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8094 [D loss: 0.6499203145503998 | D accuracy: 64.0625] [G loss: 1.099244475364685]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8095 [D loss: 0.6217658817768097 | D accuracy: 67.1875] [G loss: 0.981843113899231]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8096 [D loss: 0.5397290885448456 | D accuracy: 71.875] [G loss: 1.0757664442062378]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8097 [D loss: 0.5544969141483307 | D accuracy: 70.3125] [G loss: 1.0405259132385254]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8098 [D loss: 0.6158143281936646 | D accuracy: 62.5] [G loss: 1.0202419757843018]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8099 [D loss: 0.5494662523269653 | D accuracy: 65.625] [G loss: 1.106289267539978]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8100 [D loss: 0.605163186788559 | D accuracy: 68.75] [G loss: 1.1646008491516113]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8101 [D loss: 0.5837571620941162 | D accuracy: 71.875] [G loss: 1.1684727668762207]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8102 [D loss: 0.6484272181987762 | D accuracy: 60.9375] [G loss: 1.1517897844314575]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8103 [D loss: 0.6052832305431366 | D accuracy: 67.1875] [G loss: 1.117315649986267]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8104 [D loss: 0.5716484189033508 | D accuracy: 70.3125] [G loss: 1.2035478353500366]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8105 [D loss: 0.6052797734737396 | D accuracy: 67.1875] [G loss: 1.1119569540023804]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8106 [D loss: 0.597099781036377 | D accuracy: 60.9375] [G loss: 1.1648149490356445]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8107 [D loss: 0.6162881255149841 | D accuracy: 64.0625] [G loss: 1.2724313735961914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8108 [D loss: 0.5320270955562592 | D accuracy: 71.875] [G loss: 1.1752476692199707]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8109 [D loss: 0.5876125693321228 | D accuracy: 67.1875] [G loss: 1.233829379081726]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8110 [D loss: 0.6041991114616394 | D accuracy: 68.75] [G loss: 1.197852373123169]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8111 [D loss: 0.5606713742017746 | D accuracy: 71.875] [G loss: 1.1088035106658936]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8112 [D loss: 0.571675032377243 | D accuracy: 71.875] [G loss: 1.073166012763977]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8113 [D loss: 0.5816195160150528 | D accuracy: 67.1875] [G loss: 1.1287329196929932]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8114 [D loss: 0.5337591469287872 | D accuracy: 75.0] [G loss: 1.109034538269043]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8115 [D loss: 0.4902840405702591 | D accuracy: 82.8125] [G loss: 1.159471035003662]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8116 [D loss: 0.615938663482666 | D accuracy: 67.1875] [G loss: 1.0208406448364258]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8117 [D loss: 0.6228536367416382 | D accuracy: 60.9375] [G loss: 1.0943233966827393]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8118 [D loss: 0.5491128116846085 | D accuracy: 62.5] [G loss: 1.2253919839859009]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8119 [D loss: 0.6095501780509949 | D accuracy: 70.3125] [G loss: 1.2221978902816772]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8120 [D loss: 0.5084125250577927 | D accuracy: 68.75] [G loss: 1.1816836595535278]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8121 [D loss: 0.6027554571628571 | D accuracy: 71.875] [G loss: 1.0971460342407227]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8122 [D loss: 0.5229634940624237 | D accuracy: 75.0] [G loss: 1.1932586431503296]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8123 [D loss: 0.6313242316246033 | D accuracy: 59.375] [G loss: 1.0431926250457764]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8124 [D loss: 0.5931690633296967 | D accuracy: 68.75] [G loss: 1.1210575103759766]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8125 [D loss: 0.534407377243042 | D accuracy: 70.3125] [G loss: 1.162853717803955]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8126 [D loss: 0.6153202503919601 | D accuracy: 59.375] [G loss: 1.0740371942520142]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8127 [D loss: 0.6102531850337982 | D accuracy: 62.5] [G loss: 1.0390288829803467]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8128 [D loss: 0.5885545313358307 | D accuracy: 68.75] [G loss: 1.0231651067733765]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8129 [D loss: 0.5277210474014282 | D accuracy: 75.0] [G loss: 1.1048009395599365]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8130 [D loss: 0.6572999060153961 | D accuracy: 67.1875] [G loss: 1.0622730255126953]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8131 [D loss: 0.5731412768363953 | D accuracy: 70.3125] [G loss: 1.1781939268112183]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8132 [D loss: 0.5476818978786469 | D accuracy: 70.3125] [G loss: 1.0824230909347534]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8133 [D loss: 0.5411013960838318 | D accuracy: 70.3125] [G loss: 1.1678637266159058]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8134 [D loss: 0.4975374639034271 | D accuracy: 76.5625] [G loss: 1.0495002269744873]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8135 [D loss: 0.5862570703029633 | D accuracy: 68.75] [G loss: 1.077559232711792]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8136 [D loss: 0.5701074302196503 | D accuracy: 73.4375] [G loss: 1.0372624397277832]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8137 [D loss: 0.44913463294506073 | D accuracy: 85.9375] [G loss: 1.0864646434783936]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8138 [D loss: 0.5648134350776672 | D accuracy: 68.75] [G loss: 0.9907419681549072]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8139 [D loss: 0.5536554753780365 | D accuracy: 75.0] [G loss: 1.11240553855896]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8140 [D loss: 0.5071364939212799 | D accuracy: 70.3125] [G loss: 1.056821346282959]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8141 [D loss: 0.4907712936401367 | D accuracy: 78.125] [G loss: 1.1087666749954224]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8142 [D loss: 0.492125540971756 | D accuracy: 76.5625] [G loss: 1.0475068092346191]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8143 [D loss: 0.5705548822879791 | D accuracy: 67.1875] [G loss: 1.1383140087127686]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8144 [D loss: 0.5456957221031189 | D accuracy: 73.4375] [G loss: 1.0735057592391968]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8145 [D loss: 0.6182381510734558 | D accuracy: 65.625] [G loss: 1.116109013557434]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8146 [D loss: 0.5521251261234283 | D accuracy: 71.875] [G loss: 1.1639125347137451]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8147 [D loss: 0.5538682341575623 | D accuracy: 68.75] [G loss: 1.2097406387329102]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8148 [D loss: 0.5560694187879562 | D accuracy: 71.875] [G loss: 1.154207468032837]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8149 [D loss: 0.5066781938076019 | D accuracy: 75.0] [G loss: 1.057113766670227]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8150 [D loss: 0.5998066663742065 | D accuracy: 70.3125] [G loss: 1.0669658184051514]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8151 [D loss: 0.6408050358295441 | D accuracy: 65.625] [G loss: 1.0898914337158203]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8152 [D loss: 0.5274014621973038 | D accuracy: 70.3125] [G loss: 1.02644681930542]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8153 [D loss: 0.47255584597587585 | D accuracy: 82.8125] [G loss: 1.0796730518341064]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8154 [D loss: 0.5358644723892212 | D accuracy: 73.4375] [G loss: 1.065315842628479]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8155 [D loss: 0.5573379695415497 | D accuracy: 68.75] [G loss: 1.0060523748397827]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8156 [D loss: 0.5003448277711868 | D accuracy: 68.75] [G loss: 1.117680311203003]\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "8157 [D loss: 0.5328500270843506 | D accuracy: 76.5625] [G loss: 1.1550912857055664]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "8158 [D loss: 0.49072137475013733 | D accuracy: 75.0] [G loss: 1.0848324298858643]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8159 [D loss: 0.5842205286026001 | D accuracy: 65.625] [G loss: 1.146310806274414]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8160 [D loss: 0.5424036681652069 | D accuracy: 75.0] [G loss: 1.139754295349121]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8161 [D loss: 0.5021032840013504 | D accuracy: 76.5625] [G loss: 1.104670524597168]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8162 [D loss: 0.5547803640365601 | D accuracy: 70.3125] [G loss: 1.1786810159683228]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8163 [D loss: 0.638447493314743 | D accuracy: 54.6875] [G loss: 1.1018222570419312]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8164 [D loss: 0.6178708672523499 | D accuracy: 64.0625] [G loss: 1.2678813934326172]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8165 [D loss: 0.5664293169975281 | D accuracy: 67.1875] [G loss: 1.0247586965560913]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8166 [D loss: 0.598961740732193 | D accuracy: 62.5] [G loss: 0.9799373149871826]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8167 [D loss: 0.5842849314212799 | D accuracy: 70.3125] [G loss: 1.1165159940719604]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8168 [D loss: 0.602301687002182 | D accuracy: 70.3125] [G loss: 1.2608582973480225]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8169 [D loss: 0.5346896052360535 | D accuracy: 75.0] [G loss: 1.2517235279083252]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8170 [D loss: 0.558233231306076 | D accuracy: 65.625] [G loss: 1.1292667388916016]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8171 [D loss: 0.5007102191448212 | D accuracy: 76.5625] [G loss: 1.1166102886199951]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8172 [D loss: 0.5461311638355255 | D accuracy: 70.3125] [G loss: 1.0565685033798218]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8173 [D loss: 0.5603724420070648 | D accuracy: 59.375] [G loss: 1.1877505779266357]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8174 [D loss: 0.543569952249527 | D accuracy: 68.75] [G loss: 1.1496996879577637]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8175 [D loss: 0.6036587953567505 | D accuracy: 68.75] [G loss: 1.240828037261963]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8176 [D loss: 0.5527949929237366 | D accuracy: 75.0] [G loss: 1.203977346420288]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8177 [D loss: 0.6165355443954468 | D accuracy: 65.625] [G loss: 1.1889023780822754]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8178 [D loss: 0.5386742353439331 | D accuracy: 68.75] [G loss: 1.2201462984085083]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8179 [D loss: 0.5937864035367966 | D accuracy: 70.3125] [G loss: 1.2244229316711426]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8180 [D loss: 0.6067095994949341 | D accuracy: 67.1875] [G loss: 1.082788109779358]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8181 [D loss: 0.5345213711261749 | D accuracy: 73.4375] [G loss: 1.1355547904968262]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8182 [D loss: 0.559671014547348 | D accuracy: 67.1875] [G loss: 1.0559861660003662]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8183 [D loss: 0.5703484416007996 | D accuracy: 67.1875] [G loss: 1.0928382873535156]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8184 [D loss: 0.5172463357448578 | D accuracy: 76.5625] [G loss: 1.2372030019760132]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8185 [D loss: 0.5981995761394501 | D accuracy: 75.0] [G loss: 1.1035343408584595]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8186 [D loss: 0.6395120620727539 | D accuracy: 53.125] [G loss: 1.0935099124908447]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8187 [D loss: 0.550900012254715 | D accuracy: 68.75] [G loss: 1.1945635080337524]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8188 [D loss: 0.44708251953125 | D accuracy: 82.8125] [G loss: 1.2378010749816895]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8189 [D loss: 0.5199381113052368 | D accuracy: 73.4375] [G loss: 1.3385854959487915]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8190 [D loss: 0.5698098242282867 | D accuracy: 65.625] [G loss: 1.0685176849365234]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8191 [D loss: 0.5867354869842529 | D accuracy: 70.3125] [G loss: 1.1751759052276611]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8192 [D loss: 0.4795040786266327 | D accuracy: 76.5625] [G loss: 1.2325360774993896]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8193 [D loss: 0.5645302534103394 | D accuracy: 70.3125] [G loss: 1.0976849794387817]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8194 [D loss: 0.5407274663448334 | D accuracy: 71.875] [G loss: 1.138566255569458]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8195 [D loss: 0.5890685617923737 | D accuracy: 65.625] [G loss: 1.0280511379241943]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8196 [D loss: 0.5641749203205109 | D accuracy: 65.625] [G loss: 1.0919272899627686]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8197 [D loss: 0.576175183057785 | D accuracy: 67.1875] [G loss: 1.1428368091583252]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8198 [D loss: 0.5495539307594299 | D accuracy: 75.0] [G loss: 1.155576229095459]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8199 [D loss: 0.5605760812759399 | D accuracy: 68.75] [G loss: 1.0573019981384277]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8200 [D loss: 0.5081157386302948 | D accuracy: 76.5625] [G loss: 1.2438397407531738]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8201 [D loss: 0.6055362820625305 | D accuracy: 65.625] [G loss: 1.0537322759628296]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8202 [D loss: 0.6278561949729919 | D accuracy: 68.75] [G loss: 1.0537338256835938]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8203 [D loss: 0.5706021785736084 | D accuracy: 75.0] [G loss: 1.0643365383148193]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8204 [D loss: 0.5285971462726593 | D accuracy: 71.875] [G loss: 1.1342822313308716]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8205 [D loss: 0.5376612395048141 | D accuracy: 75.0] [G loss: 1.1478933095932007]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8206 [D loss: 0.4806067645549774 | D accuracy: 75.0] [G loss: 1.1662755012512207]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8207 [D loss: 0.5177289992570877 | D accuracy: 71.875] [G loss: 1.0485271215438843]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8208 [D loss: 0.5775358080863953 | D accuracy: 65.625] [G loss: 1.0748136043548584]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8209 [D loss: 0.5741493701934814 | D accuracy: 70.3125] [G loss: 0.8984233140945435]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8210 [D loss: 0.513398677110672 | D accuracy: 70.3125] [G loss: 1.093543529510498]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8211 [D loss: 0.5794770419597626 | D accuracy: 81.25] [G loss: 1.107677936553955]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8212 [D loss: 0.5433466732501984 | D accuracy: 70.3125] [G loss: 1.1070464849472046]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8213 [D loss: 0.6029581725597382 | D accuracy: 67.1875] [G loss: 1.1579008102416992]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8214 [D loss: 0.5392797589302063 | D accuracy: 71.875] [G loss: 1.1077710390090942]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8215 [D loss: 0.5742987394332886 | D accuracy: 73.4375] [G loss: 1.1641993522644043]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8216 [D loss: 0.5876593291759491 | D accuracy: 70.3125] [G loss: 1.1840951442718506]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8217 [D loss: 0.5934344977140427 | D accuracy: 62.5] [G loss: 1.0866453647613525]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8218 [D loss: 0.652635395526886 | D accuracy: 59.375] [G loss: 1.1158030033111572]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8219 [D loss: 0.5495880246162415 | D accuracy: 68.75] [G loss: 1.284914493560791]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8220 [D loss: 0.5420747399330139 | D accuracy: 68.75] [G loss: 1.1154136657714844]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8221 [D loss: 0.6234695315361023 | D accuracy: 62.5] [G loss: 1.0608655214309692]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8222 [D loss: 0.5642312169075012 | D accuracy: 71.875] [G loss: 1.186468243598938]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8223 [D loss: 0.5312988460063934 | D accuracy: 68.75] [G loss: 1.1081914901733398]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8224 [D loss: 0.6812966465950012 | D accuracy: 60.9375] [G loss: 1.2005906105041504]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8225 [D loss: 0.5500514507293701 | D accuracy: 68.75] [G loss: 1.0534119606018066]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8226 [D loss: 0.5043468475341797 | D accuracy: 75.0] [G loss: 0.9983529448509216]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8227 [D loss: 0.524726927280426 | D accuracy: 70.3125] [G loss: 1.087209701538086]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8228 [D loss: 0.555205225944519 | D accuracy: 73.4375] [G loss: 1.0458695888519287]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8229 [D loss: 0.5571873188018799 | D accuracy: 67.1875] [G loss: 1.1675504446029663]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8230 [D loss: 0.48368003964424133 | D accuracy: 81.25] [G loss: 1.1854417324066162]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8231 [D loss: 0.5268540680408478 | D accuracy: 71.875] [G loss: 1.1060800552368164]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8232 [D loss: 0.498513400554657 | D accuracy: 81.25] [G loss: 1.1101129055023193]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8233 [D loss: 0.5717886388301849 | D accuracy: 68.75] [G loss: 1.0503363609313965]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8234 [D loss: 0.5195794105529785 | D accuracy: 79.6875] [G loss: 1.0795118808746338]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "8235 [D loss: 0.5668895244598389 | D accuracy: 78.125] [G loss: 1.1309808492660522]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8236 [D loss: 0.5667759776115417 | D accuracy: 67.1875] [G loss: 1.1238017082214355]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8237 [D loss: 0.7148517966270447 | D accuracy: 43.75] [G loss: 1.207993984222412]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8238 [D loss: 0.554469108581543 | D accuracy: 71.875] [G loss: 1.089136004447937]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8239 [D loss: 0.5693564713001251 | D accuracy: 67.1875] [G loss: 1.1255015134811401]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8240 [D loss: 0.6788242757320404 | D accuracy: 62.5] [G loss: 1.1489222049713135]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8241 [D loss: 0.6112448573112488 | D accuracy: 65.625] [G loss: 1.2483298778533936]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8242 [D loss: 0.45825281739234924 | D accuracy: 82.8125] [G loss: 1.1426502466201782]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8243 [D loss: 0.5224208831787109 | D accuracy: 76.5625] [G loss: 1.1360076665878296]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8244 [D loss: 0.5020575821399689 | D accuracy: 76.5625] [G loss: 1.284759521484375]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8245 [D loss: 0.6041969060897827 | D accuracy: 70.3125] [G loss: 1.1637310981750488]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8246 [D loss: 0.5393992364406586 | D accuracy: 71.875] [G loss: 1.287400484085083]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8247 [D loss: 0.6585085391998291 | D accuracy: 65.625] [G loss: 1.2064223289489746]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8248 [D loss: 0.5961506366729736 | D accuracy: 64.0625] [G loss: 1.2522683143615723]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8249 [D loss: 0.5857992768287659 | D accuracy: 67.1875] [G loss: 1.0942960977554321]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8250 [D loss: 0.6647190451622009 | D accuracy: 60.9375] [G loss: 1.1754090785980225]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8251 [D loss: 0.5533234775066376 | D accuracy: 73.4375] [G loss: 1.1650086641311646]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8252 [D loss: 0.5125775039196014 | D accuracy: 78.125] [G loss: 1.079092264175415]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8253 [D loss: 0.4720691442489624 | D accuracy: 78.125] [G loss: 1.1735917329788208]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8254 [D loss: 0.6787920296192169 | D accuracy: 54.6875] [G loss: 1.1177542209625244]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8255 [D loss: 0.5468469858169556 | D accuracy: 71.875] [G loss: 1.118058204650879]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8256 [D loss: 0.5344175100326538 | D accuracy: 71.875] [G loss: 1.1911859512329102]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8257 [D loss: 0.5817258059978485 | D accuracy: 68.75] [G loss: 1.083479642868042]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8258 [D loss: 0.5756575465202332 | D accuracy: 71.875] [G loss: 1.2186484336853027]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8259 [D loss: 0.5829160809516907 | D accuracy: 65.625] [G loss: 1.20745849609375]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8260 [D loss: 0.5745352506637573 | D accuracy: 62.5] [G loss: 1.247215986251831]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8261 [D loss: 0.5799368619918823 | D accuracy: 68.75] [G loss: 1.104710578918457]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8262 [D loss: 0.5199913084506989 | D accuracy: 73.4375] [G loss: 1.1448251008987427]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8263 [D loss: 0.5169448852539062 | D accuracy: 73.4375] [G loss: 1.2162315845489502]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8264 [D loss: 0.5798269510269165 | D accuracy: 68.75] [G loss: 1.2646117210388184]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8265 [D loss: 0.5823366641998291 | D accuracy: 65.625] [G loss: 1.1198275089263916]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8266 [D loss: 0.5902052521705627 | D accuracy: 65.625] [G loss: 1.0669801235198975]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8267 [D loss: 0.6058120727539062 | D accuracy: 67.1875] [G loss: 1.0723004341125488]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8268 [D loss: 0.5862750262022018 | D accuracy: 67.1875] [G loss: 1.1332283020019531]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8269 [D loss: 0.6730097830295563 | D accuracy: 60.9375] [G loss: 1.0260814428329468]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8270 [D loss: 0.5706932842731476 | D accuracy: 67.1875] [G loss: 1.1628941297531128]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8271 [D loss: 0.5309716463088989 | D accuracy: 75.0] [G loss: 1.1895380020141602]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8272 [D loss: 0.5777606666088104 | D accuracy: 70.3125] [G loss: 1.224410057067871]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8273 [D loss: 0.5468988716602325 | D accuracy: 68.75] [G loss: 1.1936875581741333]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8274 [D loss: 0.5964131057262421 | D accuracy: 67.1875] [G loss: 1.159363031387329]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8275 [D loss: 0.5842650234699249 | D accuracy: 65.625] [G loss: 1.1215558052062988]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8276 [D loss: 0.5672764182090759 | D accuracy: 71.875] [G loss: 1.166755199432373]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8277 [D loss: 0.5821657180786133 | D accuracy: 60.9375] [G loss: 1.2029459476470947]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8278 [D loss: 0.5750768482685089 | D accuracy: 64.0625] [G loss: 1.0976722240447998]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8279 [D loss: 0.5333682149648666 | D accuracy: 73.4375] [G loss: 1.1365033388137817]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8280 [D loss: 0.5569031536579132 | D accuracy: 73.4375] [G loss: 1.0211933851242065]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8281 [D loss: 0.45249468088150024 | D accuracy: 82.8125] [G loss: 1.1767414808273315]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8282 [D loss: 0.5567569434642792 | D accuracy: 78.125] [G loss: 1.125093698501587]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8283 [D loss: 0.5893811583518982 | D accuracy: 67.1875] [G loss: 1.1638436317443848]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8284 [D loss: 0.5553907155990601 | D accuracy: 76.5625] [G loss: 1.2844958305358887]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8285 [D loss: 0.5380515158176422 | D accuracy: 64.0625] [G loss: 1.2881057262420654]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8286 [D loss: 0.576148509979248 | D accuracy: 68.75] [G loss: 1.18235182762146]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8287 [D loss: 0.5785208344459534 | D accuracy: 67.1875] [G loss: 1.21904718875885]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8288 [D loss: 0.5628554821014404 | D accuracy: 65.625] [G loss: 0.9837678670883179]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8289 [D loss: 0.5550723075866699 | D accuracy: 68.75] [G loss: 1.0871858596801758]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8290 [D loss: 0.5628583878278732 | D accuracy: 68.75] [G loss: 1.2246623039245605]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8291 [D loss: 0.5827719867229462 | D accuracy: 68.75] [G loss: 1.140186071395874]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8292 [D loss: 0.49569468200206757 | D accuracy: 79.6875] [G loss: 1.2025949954986572]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8293 [D loss: 0.613797128200531 | D accuracy: 70.3125] [G loss: 1.1163262128829956]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8294 [D loss: 0.545979768037796 | D accuracy: 70.3125] [G loss: 1.198195457458496]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8295 [D loss: 0.6240858435630798 | D accuracy: 62.5] [G loss: 1.0439062118530273]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8296 [D loss: 0.6761182248592377 | D accuracy: 53.125] [G loss: 1.0606539249420166]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8297 [D loss: 0.4965968579053879 | D accuracy: 75.0] [G loss: 1.205927848815918]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8298 [D loss: 0.5613169968128204 | D accuracy: 70.3125] [G loss: 1.0574774742126465]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8299 [D loss: 0.6116619110107422 | D accuracy: 62.5] [G loss: 0.9808667302131653]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8300 [D loss: 0.5628102123737335 | D accuracy: 73.4375] [G loss: 1.0564889907836914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8301 [D loss: 0.6072423458099365 | D accuracy: 64.0625] [G loss: 1.1003844738006592]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8302 [D loss: 0.6001201868057251 | D accuracy: 65.625] [G loss: 1.290689468383789]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8303 [D loss: 0.530839204788208 | D accuracy: 76.5625] [G loss: 1.2021090984344482]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8304 [D loss: 0.6677449941635132 | D accuracy: 60.9375] [G loss: 1.274261236190796]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8305 [D loss: 0.5699634850025177 | D accuracy: 60.9375] [G loss: 1.1600341796875]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8306 [D loss: 0.5680288374423981 | D accuracy: 71.875] [G loss: 1.1032636165618896]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8307 [D loss: 0.6018464863300323 | D accuracy: 62.5] [G loss: 1.0304782390594482]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8308 [D loss: 0.6508395075798035 | D accuracy: 57.8125] [G loss: 1.0363695621490479]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8309 [D loss: 0.6293917596340179 | D accuracy: 56.25] [G loss: 1.2071030139923096]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8310 [D loss: 0.5970804989337921 | D accuracy: 68.75] [G loss: 1.2958447933197021]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8311 [D loss: 0.6001291871070862 | D accuracy: 68.75] [G loss: 1.1824036836624146]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8312 [D loss: 0.634456604719162 | D accuracy: 62.5] [G loss: 1.0695512294769287]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8313 [D loss: 0.5297503173351288 | D accuracy: 70.3125] [G loss: 1.1321196556091309]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "8314 [D loss: 0.5667193830013275 | D accuracy: 73.4375] [G loss: 1.2054669857025146]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "8315 [D loss: 0.6147971451282501 | D accuracy: 67.1875] [G loss: 1.2503130435943604]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8316 [D loss: 0.5678776502609253 | D accuracy: 70.3125] [G loss: 1.161027193069458]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8317 [D loss: 0.6548314690589905 | D accuracy: 57.8125] [G loss: 1.0894323587417603]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "8318 [D loss: 0.6102499961853027 | D accuracy: 67.1875] [G loss: 1.0534050464630127]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8319 [D loss: 0.5326774418354034 | D accuracy: 71.875] [G loss: 1.1128474473953247]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8320 [D loss: 0.5343703925609589 | D accuracy: 71.875] [G loss: 1.189484715461731]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8321 [D loss: 0.6039971709251404 | D accuracy: 68.75] [G loss: 1.185979962348938]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8322 [D loss: 0.5330176204442978 | D accuracy: 76.5625] [G loss: 1.2094230651855469]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8323 [D loss: 0.583739697933197 | D accuracy: 68.75] [G loss: 1.1876554489135742]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8324 [D loss: 0.48703280091285706 | D accuracy: 71.875] [G loss: 1.0747888088226318]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8325 [D loss: 0.5072702020406723 | D accuracy: 78.125] [G loss: 1.1160252094268799]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8326 [D loss: 0.5450446307659149 | D accuracy: 67.1875] [G loss: 1.2532119750976562]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8327 [D loss: 0.5638839602470398 | D accuracy: 71.875] [G loss: 1.001816749572754]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8328 [D loss: 0.5293629467487335 | D accuracy: 76.5625] [G loss: 1.061396598815918]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8329 [D loss: 0.5340723395347595 | D accuracy: 73.4375] [G loss: 1.0805755853652954]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8330 [D loss: 0.6089886426925659 | D accuracy: 68.75] [G loss: 1.089702844619751]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8331 [D loss: 0.6159718036651611 | D accuracy: 65.625] [G loss: 1.1508158445358276]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8332 [D loss: 0.5583908557891846 | D accuracy: 75.0] [G loss: 1.1545741558074951]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8333 [D loss: 0.5371517986059189 | D accuracy: 70.3125] [G loss: 1.1825366020202637]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8334 [D loss: 0.5757920145988464 | D accuracy: 64.0625] [G loss: 1.2169616222381592]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8335 [D loss: 0.49298034608364105 | D accuracy: 79.6875] [G loss: 1.1784363985061646]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8336 [D loss: 0.5950277149677277 | D accuracy: 62.5] [G loss: 1.0848846435546875]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8337 [D loss: 0.6387351155281067 | D accuracy: 56.25] [G loss: 1.213428258895874]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8338 [D loss: 0.5661457777023315 | D accuracy: 70.3125] [G loss: 1.1483709812164307]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8339 [D loss: 0.4842085838317871 | D accuracy: 76.5625] [G loss: 1.2603811025619507]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8340 [D loss: 0.5761170536279678 | D accuracy: 64.0625] [G loss: 1.08302903175354]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8341 [D loss: 0.5856923460960388 | D accuracy: 64.0625] [G loss: 1.1175340414047241]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8342 [D loss: 0.5235595107078552 | D accuracy: 75.0] [G loss: 1.017111897468567]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8343 [D loss: 0.5914245545864105 | D accuracy: 64.0625] [G loss: 1.0553004741668701]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8344 [D loss: 0.6428439021110535 | D accuracy: 64.0625] [G loss: 1.0989015102386475]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8345 [D loss: 0.640948623418808 | D accuracy: 71.875] [G loss: 1.204601526260376]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8346 [D loss: 0.5069346725940704 | D accuracy: 76.5625] [G loss: 1.1335785388946533]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8347 [D loss: 0.5240755379199982 | D accuracy: 78.125] [G loss: 1.1022672653198242]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8348 [D loss: 0.5726570785045624 | D accuracy: 73.4375] [G loss: 1.2299184799194336]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8349 [D loss: 0.5204308032989502 | D accuracy: 70.3125] [G loss: 1.2535319328308105]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8350 [D loss: 0.5909496545791626 | D accuracy: 71.875] [G loss: 1.218562364578247]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8351 [D loss: 0.5906894505023956 | D accuracy: 62.5] [G loss: 1.10581374168396]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8352 [D loss: 0.5356748104095459 | D accuracy: 73.4375] [G loss: 1.1322402954101562]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8353 [D loss: 0.5710663199424744 | D accuracy: 67.1875] [G loss: 1.1303679943084717]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8354 [D loss: 0.5055665671825409 | D accuracy: 75.0] [G loss: 1.1315042972564697]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8355 [D loss: 0.5884757339954376 | D accuracy: 65.625] [G loss: 1.174734115600586]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8356 [D loss: 0.6247235238552094 | D accuracy: 64.0625] [G loss: 1.1490814685821533]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8357 [D loss: 0.523303747177124 | D accuracy: 78.125] [G loss: 1.2224297523498535]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8358 [D loss: 0.6508006155490875 | D accuracy: 65.625] [G loss: 1.2522902488708496]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8359 [D loss: 0.6493199467658997 | D accuracy: 64.0625] [G loss: 1.1977243423461914]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8360 [D loss: 0.5223751664161682 | D accuracy: 82.8125] [G loss: 1.1343542337417603]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8361 [D loss: 0.5399439930915833 | D accuracy: 71.875] [G loss: 1.2172250747680664]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8362 [D loss: 0.5036157667636871 | D accuracy: 81.25] [G loss: 1.1042492389678955]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8363 [D loss: 0.490416944026947 | D accuracy: 75.0] [G loss: 1.1526157855987549]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8364 [D loss: 0.530889630317688 | D accuracy: 71.875] [G loss: 1.1271251440048218]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8365 [D loss: 0.5164725184440613 | D accuracy: 71.875] [G loss: 1.0722968578338623]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8366 [D loss: 0.5999558568000793 | D accuracy: 60.9375] [G loss: 1.1752140522003174]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8367 [D loss: 0.547376424074173 | D accuracy: 67.1875] [G loss: 1.1586387157440186]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8368 [D loss: 0.5508933961391449 | D accuracy: 70.3125] [G loss: 1.124908447265625]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8369 [D loss: 0.5433815866708755 | D accuracy: 73.4375] [G loss: 1.1241226196289062]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8370 [D loss: 0.5497015714645386 | D accuracy: 68.75] [G loss: 1.182988166809082]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8371 [D loss: 0.5151893943548203 | D accuracy: 73.4375] [G loss: 1.1306794881820679]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8372 [D loss: 0.6022999286651611 | D accuracy: 68.75] [G loss: 1.1723825931549072]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8373 [D loss: 0.5871706008911133 | D accuracy: 65.625] [G loss: 1.2729239463806152]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8374 [D loss: 0.5565318167209625 | D accuracy: 70.3125] [G loss: 1.1242516040802002]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8375 [D loss: 0.5880901664495468 | D accuracy: 68.75] [G loss: 1.1104118824005127]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8376 [D loss: 0.5597767531871796 | D accuracy: 67.1875] [G loss: 1.0911391973495483]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8377 [D loss: 0.5328153669834137 | D accuracy: 78.125] [G loss: 1.0413204431533813]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8378 [D loss: 0.516851007938385 | D accuracy: 79.6875] [G loss: 1.2680943012237549]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8379 [D loss: 0.5598000288009644 | D accuracy: 75.0] [G loss: 1.1740303039550781]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8380 [D loss: 0.5018364042043686 | D accuracy: 79.6875] [G loss: 1.2092235088348389]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8381 [D loss: 0.483494833111763 | D accuracy: 81.25] [G loss: 1.251825213432312]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8382 [D loss: 0.5684531927108765 | D accuracy: 70.3125] [G loss: 1.313524842262268]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8383 [D loss: 0.5543522536754608 | D accuracy: 76.5625] [G loss: 1.157994031906128]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "8384 [D loss: 0.5923943817615509 | D accuracy: 70.3125] [G loss: 1.1033236980438232]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8385 [D loss: 0.5281762182712555 | D accuracy: 78.125] [G loss: 1.2173435688018799]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8386 [D loss: 0.5045446157455444 | D accuracy: 70.3125] [G loss: 1.0745973587036133]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8387 [D loss: 0.5290064811706543 | D accuracy: 70.3125] [G loss: 1.1382718086242676]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8388 [D loss: 0.5368673801422119 | D accuracy: 78.125] [G loss: 1.144897699356079]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "8389 [D loss: 0.5765653848648071 | D accuracy: 71.875] [G loss: 1.248626470565796]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8390 [D loss: 0.5858908593654633 | D accuracy: 65.625] [G loss: 1.2122268676757812]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8391 [D loss: 0.6930041909217834 | D accuracy: 57.8125] [G loss: 1.1210098266601562]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "8392 [D loss: 0.5429355204105377 | D accuracy: 73.4375] [G loss: 1.1009577512741089]\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "8393 [D loss: 0.6643504798412323 | D accuracy: 64.0625] [G loss: 1.2062809467315674]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8394 [D loss: 0.5991342663764954 | D accuracy: 65.625] [G loss: 1.1222797632217407]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8395 [D loss: 0.5138260722160339 | D accuracy: 78.125] [G loss: 1.173746943473816]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8396 [D loss: 0.5186941623687744 | D accuracy: 78.125] [G loss: 1.1992886066436768]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8397 [D loss: 0.5322944521903992 | D accuracy: 73.4375] [G loss: 1.206736445426941]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8398 [D loss: 0.6092102527618408 | D accuracy: 68.75] [G loss: 1.1855177879333496]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8399 [D loss: 0.6100181341171265 | D accuracy: 67.1875] [G loss: 1.0844627618789673]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8400 [D loss: 0.508443221449852 | D accuracy: 71.875] [G loss: 1.13424551486969]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8401 [D loss: 0.48295867443084717 | D accuracy: 79.6875] [G loss: 1.2486991882324219]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8402 [D loss: 0.5774530470371246 | D accuracy: 62.5] [G loss: 1.2986583709716797]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8403 [D loss: 0.5463477969169617 | D accuracy: 67.1875] [G loss: 1.1785707473754883]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8404 [D loss: 0.531602680683136 | D accuracy: 71.875] [G loss: 1.1607434749603271]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8405 [D loss: 0.5278192758560181 | D accuracy: 76.5625] [G loss: 0.9533095359802246]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8406 [D loss: 0.5528953969478607 | D accuracy: 67.1875] [G loss: 1.1271857023239136]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8407 [D loss: 0.58330437541008 | D accuracy: 64.0625] [G loss: 1.1716997623443604]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8408 [D loss: 0.5015200674533844 | D accuracy: 79.6875] [G loss: 1.0717957019805908]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8409 [D loss: 0.5271651744842529 | D accuracy: 70.3125] [G loss: 1.2628719806671143]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8410 [D loss: 0.5842728912830353 | D accuracy: 64.0625] [G loss: 1.16724693775177]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8411 [D loss: 0.5298527777194977 | D accuracy: 70.3125] [G loss: 1.2299251556396484]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8412 [D loss: 0.624894767999649 | D accuracy: 67.1875] [G loss: 1.1701865196228027]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8413 [D loss: 0.6135738492012024 | D accuracy: 67.1875] [G loss: 1.3273108005523682]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8414 [D loss: 0.5945758521556854 | D accuracy: 67.1875] [G loss: 1.3499913215637207]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8415 [D loss: 0.5702759921550751 | D accuracy: 67.1875] [G loss: 1.1784358024597168]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8416 [D loss: 0.5319959223270416 | D accuracy: 71.875] [G loss: 1.0357742309570312]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8417 [D loss: 0.5760725736618042 | D accuracy: 67.1875] [G loss: 1.2047268152236938]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8418 [D loss: 0.5112413614988327 | D accuracy: 76.5625] [G loss: 1.1232541799545288]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8419 [D loss: 0.4576658755540848 | D accuracy: 75.0] [G loss: 0.9786329865455627]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8420 [D loss: 0.5462419092655182 | D accuracy: 68.75] [G loss: 0.9999312162399292]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8421 [D loss: 0.5129855573177338 | D accuracy: 70.3125] [G loss: 1.179487943649292]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8422 [D loss: 0.6560719311237335 | D accuracy: 59.375] [G loss: 1.0433545112609863]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8423 [D loss: 0.5745974779129028 | D accuracy: 64.0625] [G loss: 1.182685375213623]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8424 [D loss: 0.5949169993400574 | D accuracy: 64.0625] [G loss: 1.2426536083221436]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8425 [D loss: 0.5199384987354279 | D accuracy: 71.875] [G loss: 1.3207035064697266]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8426 [D loss: 0.6033571660518646 | D accuracy: 71.875] [G loss: 1.078831672668457]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8427 [D loss: 0.7701211273670197 | D accuracy: 59.375] [G loss: 1.0931427478790283]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8428 [D loss: 0.5594284236431122 | D accuracy: 71.875] [G loss: 1.3047552108764648]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8429 [D loss: 0.5485109090805054 | D accuracy: 71.875] [G loss: 1.177981972694397]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8430 [D loss: 0.5633155107498169 | D accuracy: 62.5] [G loss: 1.1362000703811646]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8431 [D loss: 0.5100867450237274 | D accuracy: 71.875] [G loss: 1.0294253826141357]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8432 [D loss: 0.5533477365970612 | D accuracy: 70.3125] [G loss: 1.0858794450759888]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8433 [D loss: 0.49810387194156647 | D accuracy: 79.6875] [G loss: 1.0833358764648438]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8434 [D loss: 0.5625743865966797 | D accuracy: 73.4375] [G loss: 1.1551846265792847]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8435 [D loss: 0.5350919961929321 | D accuracy: 75.0] [G loss: 1.1525263786315918]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8436 [D loss: 0.4773925542831421 | D accuracy: 82.8125] [G loss: 1.1285698413848877]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8437 [D loss: 0.5251347422599792 | D accuracy: 71.875] [G loss: 1.1801061630249023]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8438 [D loss: 0.5909150540828705 | D accuracy: 64.0625] [G loss: 1.1222865581512451]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8439 [D loss: 0.6223172545433044 | D accuracy: 64.0625] [G loss: 1.0553431510925293]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8440 [D loss: 0.5889152586460114 | D accuracy: 62.5] [G loss: 1.0675681829452515]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8441 [D loss: 0.5381996631622314 | D accuracy: 73.4375] [G loss: 1.1769635677337646]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8442 [D loss: 0.5977270603179932 | D accuracy: 67.1875] [G loss: 1.1597193479537964]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8443 [D loss: 0.6297352612018585 | D accuracy: 60.9375] [G loss: 1.179674744606018]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8444 [D loss: 0.5276591181755066 | D accuracy: 68.75] [G loss: 1.2526590824127197]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8445 [D loss: 0.6151237487792969 | D accuracy: 60.9375] [G loss: 1.0155233144760132]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8446 [D loss: 0.5669702291488647 | D accuracy: 67.1875] [G loss: 1.1085124015808105]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8447 [D loss: 0.606936901807785 | D accuracy: 60.9375] [G loss: 1.0393532514572144]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8448 [D loss: 0.5898224115371704 | D accuracy: 78.125] [G loss: 1.0470359325408936]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8449 [D loss: 0.5926179885864258 | D accuracy: 67.1875] [G loss: 1.066141963005066]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8450 [D loss: 0.4740114212036133 | D accuracy: 84.375] [G loss: 1.2036347389221191]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8451 [D loss: 0.546461284160614 | D accuracy: 68.75] [G loss: 1.1441328525543213]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8452 [D loss: 0.5866588652133942 | D accuracy: 70.3125] [G loss: 1.1405742168426514]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8453 [D loss: 0.5920731425285339 | D accuracy: 64.0625] [G loss: 1.171486735343933]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8454 [D loss: 0.5421053767204285 | D accuracy: 71.875] [G loss: 1.2683130502700806]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8455 [D loss: 0.5117112994194031 | D accuracy: 75.0] [G loss: 1.1896216869354248]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8456 [D loss: 0.62508824467659 | D accuracy: 62.5] [G loss: 1.0927424430847168]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "8457 [D loss: 0.7170607447624207 | D accuracy: 56.25] [G loss: 1.2078354358673096]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8458 [D loss: 0.5615765750408173 | D accuracy: 73.4375] [G loss: 1.1977190971374512]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "8459 [D loss: 0.5572665631771088 | D accuracy: 71.875] [G loss: 1.1035144329071045]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "8460 [D loss: 0.5226914584636688 | D accuracy: 71.875] [G loss: 1.0370346307754517]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8461 [D loss: 0.520540863275528 | D accuracy: 71.875] [G loss: 1.1568129062652588]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "8462 [D loss: 0.5272623598575592 | D accuracy: 68.75] [G loss: 1.1460402011871338]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8463 [D loss: 0.536012202501297 | D accuracy: 71.875] [G loss: 1.2126803398132324]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8464 [D loss: 0.6104031205177307 | D accuracy: 62.5] [G loss: 1.1656479835510254]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8465 [D loss: 0.5534379482269287 | D accuracy: 68.75] [G loss: 1.1651861667633057]\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "8466 [D loss: 0.5367868840694427 | D accuracy: 75.0] [G loss: 1.2292875051498413]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8467 [D loss: 0.49279458820819855 | D accuracy: 78.125] [G loss: 1.2251355648040771]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8468 [D loss: 0.5380991101264954 | D accuracy: 73.4375] [G loss: 1.3910846710205078]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8469 [D loss: 0.5086285173892975 | D accuracy: 73.4375] [G loss: 1.2234842777252197]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8470 [D loss: 0.5310362577438354 | D accuracy: 73.4375] [G loss: 1.3369786739349365]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8471 [D loss: 0.5970811992883682 | D accuracy: 68.75] [G loss: 1.389331340789795]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8472 [D loss: 0.6256289482116699 | D accuracy: 59.375] [G loss: 1.2387272119522095]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8473 [D loss: 0.5379460155963898 | D accuracy: 76.5625] [G loss: 1.1935312747955322]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8474 [D loss: 0.6279463768005371 | D accuracy: 60.9375] [G loss: 1.2791374921798706]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8475 [D loss: 0.6011792719364166 | D accuracy: 59.375] [G loss: 1.050599217414856]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8476 [D loss: 0.7035176157951355 | D accuracy: 56.25] [G loss: 1.0989954471588135]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8477 [D loss: 0.5229531526565552 | D accuracy: 73.4375] [G loss: 1.0623761415481567]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8478 [D loss: 0.6918799579143524 | D accuracy: 54.6875] [G loss: 1.044825553894043]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8479 [D loss: 0.4862096905708313 | D accuracy: 76.5625] [G loss: 1.177391767501831]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8480 [D loss: 0.5622657239437103 | D accuracy: 68.75] [G loss: 1.2230148315429688]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8481 [D loss: 0.6119886636734009 | D accuracy: 68.75] [G loss: 1.073958158493042]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8482 [D loss: 0.5402222573757172 | D accuracy: 73.4375] [G loss: 1.0872455835342407]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8483 [D loss: 0.5216474533081055 | D accuracy: 75.0] [G loss: 1.1799204349517822]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8484 [D loss: 0.5472832918167114 | D accuracy: 68.75] [G loss: 1.0618095397949219]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8485 [D loss: 0.603296548128128 | D accuracy: 65.625] [G loss: 1.0334532260894775]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8486 [D loss: 0.5815618634223938 | D accuracy: 64.0625] [G loss: 1.217020869255066]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8487 [D loss: 0.5583182275295258 | D accuracy: 70.3125] [G loss: 1.2468502521514893]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8488 [D loss: 0.5673964023590088 | D accuracy: 73.4375] [G loss: 1.1076269149780273]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8489 [D loss: 0.5574308633804321 | D accuracy: 67.1875] [G loss: 1.1982860565185547]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8490 [D loss: 0.6137300133705139 | D accuracy: 67.1875] [G loss: 1.150346040725708]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8491 [D loss: 0.5859415680170059 | D accuracy: 65.625] [G loss: 1.0390610694885254]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8492 [D loss: 0.48872560262680054 | D accuracy: 76.5625] [G loss: 1.051746129989624]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8493 [D loss: 0.5763194859027863 | D accuracy: 73.4375] [G loss: 1.1433134078979492]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8494 [D loss: 0.5632489919662476 | D accuracy: 73.4375] [G loss: 1.1072511672973633]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8495 [D loss: 0.5873833298683167 | D accuracy: 67.1875] [G loss: 1.2850441932678223]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8496 [D loss: 0.65506911277771 | D accuracy: 59.375] [G loss: 1.1662826538085938]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8497 [D loss: 0.555597573518753 | D accuracy: 68.75] [G loss: 1.2531962394714355]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8498 [D loss: 0.5261893272399902 | D accuracy: 68.75] [G loss: 1.131533145904541]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8499 [D loss: 0.5145323723554611 | D accuracy: 78.125] [G loss: 1.1701209545135498]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "8500 [D loss: 0.639342188835144 | D accuracy: 60.9375] [G loss: 1.1022344827651978]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8501 [D loss: 0.5690008997917175 | D accuracy: 65.625] [G loss: 1.1720800399780273]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8502 [D loss: 0.5657030940055847 | D accuracy: 68.75] [G loss: 1.2017807960510254]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8503 [D loss: 0.47132790088653564 | D accuracy: 81.25] [G loss: 1.2037782669067383]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8504 [D loss: 0.5209363698959351 | D accuracy: 75.0] [G loss: 1.1485395431518555]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8505 [D loss: 0.5526354312896729 | D accuracy: 68.75] [G loss: 1.1188360452651978]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8506 [D loss: 0.5399854183197021 | D accuracy: 70.3125] [G loss: 1.1286990642547607]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8507 [D loss: 0.5342899560928345 | D accuracy: 68.75] [G loss: 1.032500982284546]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8508 [D loss: 0.45228758454322815 | D accuracy: 85.9375] [G loss: 1.0589221715927124]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8509 [D loss: 0.6549707055091858 | D accuracy: 64.0625] [G loss: 1.1328420639038086]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8510 [D loss: 0.677609384059906 | D accuracy: 60.9375] [G loss: 1.2028493881225586]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8511 [D loss: 0.6596157550811768 | D accuracy: 59.375] [G loss: 1.0799016952514648]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8512 [D loss: 0.4857386350631714 | D accuracy: 79.6875] [G loss: 1.1484804153442383]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8513 [D loss: 0.5985343158245087 | D accuracy: 65.625] [G loss: 1.1315484046936035]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8514 [D loss: 0.5997785925865173 | D accuracy: 60.9375] [G loss: 1.1155874729156494]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8515 [D loss: 0.6341945230960846 | D accuracy: 62.5] [G loss: 1.2398221492767334]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8516 [D loss: 0.5225485563278198 | D accuracy: 65.625] [G loss: 1.2636750936508179]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8517 [D loss: 0.5733705163002014 | D accuracy: 60.9375] [G loss: 1.1033072471618652]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8518 [D loss: 0.5714558064937592 | D accuracy: 75.0] [G loss: 1.0756607055664062]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8519 [D loss: 0.5782236158847809 | D accuracy: 64.0625] [G loss: 1.1213574409484863]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8520 [D loss: 0.5301908254623413 | D accuracy: 70.3125] [G loss: 1.1487689018249512]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8521 [D loss: 0.5989502668380737 | D accuracy: 68.75] [G loss: 1.020092487335205]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8522 [D loss: 0.4933367669582367 | D accuracy: 78.125] [G loss: 1.1378693580627441]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8523 [D loss: 0.6292831897735596 | D accuracy: 59.375] [G loss: 1.1782512664794922]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8524 [D loss: 0.573710024356842 | D accuracy: 70.3125] [G loss: 1.10475754737854]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8525 [D loss: 0.5456642210483551 | D accuracy: 73.4375] [G loss: 1.0262068510055542]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8526 [D loss: 0.5202864706516266 | D accuracy: 75.0] [G loss: 1.0709426403045654]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8527 [D loss: 0.6011117696762085 | D accuracy: 65.625] [G loss: 1.1126614809036255]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8528 [D loss: 0.5898911356925964 | D accuracy: 73.4375] [G loss: 1.2293870449066162]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8529 [D loss: 0.5882722735404968 | D accuracy: 67.1875] [G loss: 0.9643391370773315]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8530 [D loss: 0.5447035133838654 | D accuracy: 65.625] [G loss: 1.059434175491333]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8531 [D loss: 0.588642030954361 | D accuracy: 62.5] [G loss: 1.1394753456115723]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8532 [D loss: 0.6065129935741425 | D accuracy: 60.9375] [G loss: 1.1578198671340942]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8533 [D loss: 0.6463266611099243 | D accuracy: 64.0625] [G loss: 1.0994868278503418]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8534 [D loss: 0.5062438398599625 | D accuracy: 78.125] [G loss: 1.1974210739135742]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8535 [D loss: 0.6625151634216309 | D accuracy: 64.0625] [G loss: 0.9587314128875732]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8536 [D loss: 0.5325976014137268 | D accuracy: 70.3125] [G loss: 1.1838374137878418]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8537 [D loss: 0.5112985372543335 | D accuracy: 75.0] [G loss: 1.146176815032959]\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "8538 [D loss: 0.7018386423587799 | D accuracy: 60.9375] [G loss: 1.256004810333252]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "8539 [D loss: 0.6213497519493103 | D accuracy: 67.1875] [G loss: 1.294154167175293]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8540 [D loss: 0.4913943111896515 | D accuracy: 81.25] [G loss: 1.2949092388153076]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8541 [D loss: 0.6108412742614746 | D accuracy: 62.5] [G loss: 1.21436607837677]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8542 [D loss: 0.5608375668525696 | D accuracy: 78.125] [G loss: 1.1586458683013916]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "8543 [D loss: 0.5780823826789856 | D accuracy: 70.3125] [G loss: 1.0875961780548096]\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "8544 [D loss: 0.5195596814155579 | D accuracy: 70.3125] [G loss: 1.1856085062026978]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8545 [D loss: 0.5931923687458038 | D accuracy: 67.1875] [G loss: 1.0481133460998535]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8546 [D loss: 0.4740933030843735 | D accuracy: 75.0] [G loss: 1.219636082649231]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8547 [D loss: 0.405124768614769 | D accuracy: 87.5] [G loss: 1.1482393741607666]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8548 [D loss: 0.5220493674278259 | D accuracy: 68.75] [G loss: 1.1547596454620361]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8549 [D loss: 0.6547467410564423 | D accuracy: 62.5] [G loss: 1.2752981185913086]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8550 [D loss: 0.6157320439815521 | D accuracy: 65.625] [G loss: 1.1987333297729492]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8551 [D loss: 0.4906080514192581 | D accuracy: 81.25] [G loss: 1.1822274923324585]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8552 [D loss: 0.5049039125442505 | D accuracy: 73.4375] [G loss: 1.1954423189163208]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8553 [D loss: 0.569808840751648 | D accuracy: 67.1875] [G loss: 1.1167590618133545]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8554 [D loss: 0.5417228937149048 | D accuracy: 73.4375] [G loss: 1.122299075126648]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8555 [D loss: 0.5119194388389587 | D accuracy: 76.5625] [G loss: 1.0926148891448975]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8556 [D loss: 0.6178571879863739 | D accuracy: 64.0625] [G loss: 0.9223625659942627]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8557 [D loss: 0.5776388347148895 | D accuracy: 71.875] [G loss: 1.1025207042694092]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8558 [D loss: 0.5261321067810059 | D accuracy: 76.5625] [G loss: 1.1138309240341187]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8559 [D loss: 0.5895235538482666 | D accuracy: 64.0625] [G loss: 1.032684564590454]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8560 [D loss: 0.6459737420082092 | D accuracy: 65.625] [G loss: 1.191425085067749]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8561 [D loss: 0.5100418031215668 | D accuracy: 75.0] [G loss: 1.150313377380371]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8562 [D loss: 0.5504887104034424 | D accuracy: 68.75] [G loss: 1.114027976989746]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8563 [D loss: 0.4957738220691681 | D accuracy: 75.0] [G loss: 1.1316547393798828]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8564 [D loss: 0.5536482632160187 | D accuracy: 68.75] [G loss: 1.1872005462646484]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8565 [D loss: 0.52753546833992 | D accuracy: 75.0] [G loss: 1.101283073425293]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8566 [D loss: 0.5749142169952393 | D accuracy: 68.75] [G loss: 1.0808628797531128]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8567 [D loss: 0.5743201971054077 | D accuracy: 73.4375] [G loss: 1.2618473768234253]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8568 [D loss: 0.5440236628055573 | D accuracy: 71.875] [G loss: 1.2481703758239746]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8569 [D loss: 0.5538887977600098 | D accuracy: 67.1875] [G loss: 1.2611773014068604]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8570 [D loss: 0.6646457016468048 | D accuracy: 62.5] [G loss: 1.1383724212646484]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8571 [D loss: 0.6101542115211487 | D accuracy: 65.625] [G loss: 1.1007401943206787]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8572 [D loss: 0.4948810935020447 | D accuracy: 78.125] [G loss: 1.1344664096832275]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8573 [D loss: 0.5858531892299652 | D accuracy: 64.0625] [G loss: 1.1005226373672485]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8574 [D loss: 0.5948216319084167 | D accuracy: 70.3125] [G loss: 1.2001856565475464]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8575 [D loss: 0.5291773080825806 | D accuracy: 75.0] [G loss: 1.140275001525879]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8576 [D loss: 0.5316073894500732 | D accuracy: 64.0625] [G loss: 1.132869005203247]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8577 [D loss: 0.55731001496315 | D accuracy: 70.3125] [G loss: 1.02678382396698]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8578 [D loss: 0.5340636670589447 | D accuracy: 68.75] [G loss: 1.1026349067687988]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8579 [D loss: 0.5554617047309875 | D accuracy: 68.75] [G loss: 1.0621349811553955]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8580 [D loss: 0.5476917326450348 | D accuracy: 73.4375] [G loss: 1.1090271472930908]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8581 [D loss: 0.643050879240036 | D accuracy: 65.625] [G loss: 1.1241018772125244]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8582 [D loss: 0.6358702778816223 | D accuracy: 67.1875] [G loss: 1.0388256311416626]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8583 [D loss: 0.5524121075868607 | D accuracy: 70.3125] [G loss: 1.067875623703003]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8584 [D loss: 0.5085038840770721 | D accuracy: 73.4375] [G loss: 0.9880330562591553]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8585 [D loss: 0.5696133971214294 | D accuracy: 73.4375] [G loss: 1.0881309509277344]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8586 [D loss: 0.5226937681436539 | D accuracy: 71.875] [G loss: 1.2086982727050781]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8587 [D loss: 0.48617760837078094 | D accuracy: 85.9375] [G loss: 1.2187868356704712]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8588 [D loss: 0.5551952719688416 | D accuracy: 65.625] [G loss: 1.0385096073150635]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8589 [D loss: 0.519041121006012 | D accuracy: 78.125] [G loss: 1.1927305459976196]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8590 [D loss: 0.6251694560050964 | D accuracy: 64.0625] [G loss: 1.4443557262420654]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8591 [D loss: 0.514118880033493 | D accuracy: 78.125] [G loss: 1.2289791107177734]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8592 [D loss: 0.5238712430000305 | D accuracy: 73.4375] [G loss: 1.171091914176941]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8593 [D loss: 0.4664241671562195 | D accuracy: 81.25] [G loss: 1.1297985315322876]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8594 [D loss: 0.5889362990856171 | D accuracy: 70.3125] [G loss: 1.148254632949829]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8595 [D loss: 0.6134264767169952 | D accuracy: 64.0625] [G loss: 1.1124346256256104]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8596 [D loss: 0.5823242664337158 | D accuracy: 68.75] [G loss: 1.0273346900939941]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8597 [D loss: 0.5729061961174011 | D accuracy: 67.1875] [G loss: 1.1555712223052979]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8598 [D loss: 0.521484300494194 | D accuracy: 73.4375] [G loss: 1.1119277477264404]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8599 [D loss: 0.4813135117292404 | D accuracy: 73.4375] [G loss: 1.205486536026001]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8600 [D loss: 0.44141389429569244 | D accuracy: 81.25] [G loss: 1.2872848510742188]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8601 [D loss: 0.5145584940910339 | D accuracy: 75.0] [G loss: 1.3153455257415771]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8602 [D loss: 0.47940593957901 | D accuracy: 78.125] [G loss: 1.2838335037231445]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8603 [D loss: 0.4887189567089081 | D accuracy: 75.0] [G loss: 1.2949122190475464]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8604 [D loss: 0.5648771971464157 | D accuracy: 71.875] [G loss: 1.2466886043548584]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8605 [D loss: 0.5788173377513885 | D accuracy: 59.375] [G loss: 1.0888293981552124]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8606 [D loss: 0.5804841816425323 | D accuracy: 71.875] [G loss: 1.1513365507125854]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "8607 [D loss: 0.5962755680084229 | D accuracy: 59.375] [G loss: 1.1406738758087158]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8608 [D loss: 0.6137495636940002 | D accuracy: 60.9375] [G loss: 0.935899019241333]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8609 [D loss: 0.6370622217655182 | D accuracy: 59.375] [G loss: 1.1666877269744873]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8610 [D loss: 0.5921136736869812 | D accuracy: 71.875] [G loss: 1.1578136682510376]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "8611 [D loss: 0.6286425590515137 | D accuracy: 64.0625] [G loss: 1.1852924823760986]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "8612 [D loss: 0.4940999150276184 | D accuracy: 71.875] [G loss: 1.1657063961029053]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8613 [D loss: 0.5707626044750214 | D accuracy: 68.75] [G loss: 1.209730625152588]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "8614 [D loss: 0.6407151222229004 | D accuracy: 57.8125] [G loss: 1.0971617698669434]\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "8615 [D loss: 0.5745404362678528 | D accuracy: 65.625] [G loss: 1.1802207231521606]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8616 [D loss: 0.5895878374576569 | D accuracy: 71.875] [G loss: 1.1590065956115723]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8617 [D loss: 0.5547398626804352 | D accuracy: 67.1875] [G loss: 1.1735928058624268]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8618 [D loss: 0.5685394108295441 | D accuracy: 75.0] [G loss: 1.0511237382888794]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8619 [D loss: 0.4964967966079712 | D accuracy: 71.875] [G loss: 1.1216050386428833]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8620 [D loss: 0.5445756763219833 | D accuracy: 71.875] [G loss: 1.2218884229660034]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8621 [D loss: 0.49241118133068085 | D accuracy: 75.0] [G loss: 1.2618342638015747]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "8622 [D loss: 0.6221562027931213 | D accuracy: 67.1875] [G loss: 1.1506757736206055]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8623 [D loss: 0.5574871897697449 | D accuracy: 73.4375] [G loss: 1.2929863929748535]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8624 [D loss: 0.44362524151802063 | D accuracy: 78.125] [G loss: 1.237187385559082]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8625 [D loss: 0.4456350803375244 | D accuracy: 81.25] [G loss: 1.2344120740890503]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8626 [D loss: 0.6265969574451447 | D accuracy: 64.0625] [G loss: 1.2046406269073486]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8627 [D loss: 0.6394342482089996 | D accuracy: 67.1875] [G loss: 1.1264290809631348]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8628 [D loss: 0.5515371561050415 | D accuracy: 67.1875] [G loss: 1.1151996850967407]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8629 [D loss: 0.570075273513794 | D accuracy: 73.4375] [G loss: 1.0757399797439575]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8630 [D loss: 0.5072938352823257 | D accuracy: 76.5625] [G loss: 1.163649082183838]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8631 [D loss: 0.5428469479084015 | D accuracy: 70.3125] [G loss: 1.094334602355957]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8632 [D loss: 0.6021966338157654 | D accuracy: 71.875] [G loss: 1.1377010345458984]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8633 [D loss: 0.538435161113739 | D accuracy: 75.0] [G loss: 1.1399266719818115]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8634 [D loss: 0.49477261304855347 | D accuracy: 76.5625] [G loss: 1.0500640869140625]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8635 [D loss: 0.4986037313938141 | D accuracy: 73.4375] [G loss: 0.9853971600532532]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8636 [D loss: 0.5048501342535019 | D accuracy: 75.0] [G loss: 1.0529686212539673]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8637 [D loss: 0.5296817719936371 | D accuracy: 73.4375] [G loss: 1.2233110666275024]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8638 [D loss: 0.5156891047954559 | D accuracy: 75.0] [G loss: 1.1738169193267822]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8639 [D loss: 0.5686834752559662 | D accuracy: 67.1875] [G loss: 1.1198468208312988]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8640 [D loss: 0.5147068500518799 | D accuracy: 76.5625] [G loss: 1.2434337139129639]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8641 [D loss: 0.638874888420105 | D accuracy: 64.0625] [G loss: 1.3669432401657104]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8642 [D loss: 0.6421549022197723 | D accuracy: 62.5] [G loss: 1.2953176498413086]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8643 [D loss: 0.6064885258674622 | D accuracy: 64.0625] [G loss: 1.0877878665924072]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8644 [D loss: 0.48393693566322327 | D accuracy: 84.375] [G loss: 1.0872907638549805]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8645 [D loss: 0.5329448580741882 | D accuracy: 71.875] [G loss: 1.2079399824142456]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8646 [D loss: 0.6833657920360565 | D accuracy: 64.0625] [G loss: 1.1250027418136597]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8647 [D loss: 0.6541243195533752 | D accuracy: 64.0625] [G loss: 1.218074083328247]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8648 [D loss: 0.5123254060745239 | D accuracy: 71.875] [G loss: 1.1080905199050903]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8649 [D loss: 0.5684885680675507 | D accuracy: 68.75] [G loss: 1.1713225841522217]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8650 [D loss: 0.6366490721702576 | D accuracy: 65.625] [G loss: 1.025813341140747]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8651 [D loss: 0.5494508147239685 | D accuracy: 68.75] [G loss: 1.030569076538086]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8652 [D loss: 0.4741821140050888 | D accuracy: 79.6875] [G loss: 1.0724194049835205]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8653 [D loss: 0.5428556054830551 | D accuracy: 73.4375] [G loss: 1.144366979598999]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8654 [D loss: 0.4131292253732681 | D accuracy: 84.375] [G loss: 1.0723378658294678]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8655 [D loss: 0.49401454627513885 | D accuracy: 73.4375] [G loss: 1.2526309490203857]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8656 [D loss: 0.5756865739822388 | D accuracy: 65.625] [G loss: 1.260071039199829]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8657 [D loss: 0.5075735449790955 | D accuracy: 75.0] [G loss: 1.2938332557678223]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8658 [D loss: 0.48308804631233215 | D accuracy: 76.5625] [G loss: 1.2238094806671143]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8659 [D loss: 0.4449264407157898 | D accuracy: 84.375] [G loss: 1.1047844886779785]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8660 [D loss: 0.5954169034957886 | D accuracy: 68.75] [G loss: 1.22646164894104]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8661 [D loss: 0.6168168783187866 | D accuracy: 70.3125] [G loss: 1.186384916305542]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8662 [D loss: 0.5900743007659912 | D accuracy: 65.625] [G loss: 1.083841323852539]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8663 [D loss: 0.5973829627037048 | D accuracy: 71.875] [G loss: 1.1685855388641357]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8664 [D loss: 0.5321225821971893 | D accuracy: 76.5625] [G loss: 1.1520731449127197]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8665 [D loss: 0.45145875215530396 | D accuracy: 84.375] [G loss: 1.2048394680023193]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8666 [D loss: 0.5386533737182617 | D accuracy: 75.0] [G loss: 1.1676158905029297]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8667 [D loss: 0.5379202961921692 | D accuracy: 70.3125] [G loss: 1.1680843830108643]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8668 [D loss: 0.6573383510112762 | D accuracy: 59.375] [G loss: 1.0481288433074951]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8669 [D loss: 0.5503867566585541 | D accuracy: 67.1875] [G loss: 1.1127557754516602]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8670 [D loss: 0.39779242873191833 | D accuracy: 92.1875] [G loss: 1.0727996826171875]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8671 [D loss: 0.5423802137374878 | D accuracy: 73.4375] [G loss: 1.226724624633789]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8672 [D loss: 0.5803630948066711 | D accuracy: 65.625] [G loss: 1.075852394104004]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8673 [D loss: 0.45850853621959686 | D accuracy: 81.25] [G loss: 1.187121033668518]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8674 [D loss: 0.4822486639022827 | D accuracy: 78.125] [G loss: 1.114302158355713]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8675 [D loss: 0.544173002243042 | D accuracy: 75.0] [G loss: 1.2910685539245605]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8676 [D loss: 0.5753636062145233 | D accuracy: 71.875] [G loss: 1.1613656282424927]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8677 [D loss: 0.48184388875961304 | D accuracy: 76.5625] [G loss: 1.1610982418060303]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8678 [D loss: 0.568782389163971 | D accuracy: 67.1875] [G loss: 1.1589970588684082]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8679 [D loss: 0.531965970993042 | D accuracy: 68.75] [G loss: 1.2034834623336792]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8680 [D loss: 0.552442729473114 | D accuracy: 67.1875] [G loss: 0.994605302810669]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8681 [D loss: 0.5587072521448135 | D accuracy: 68.75] [G loss: 1.0658763647079468]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8682 [D loss: 0.5963349044322968 | D accuracy: 65.625] [G loss: 1.0577324628829956]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8683 [D loss: 0.5703613460063934 | D accuracy: 70.3125] [G loss: 1.127582311630249]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8684 [D loss: 0.5513801276683807 | D accuracy: 70.3125] [G loss: 1.1894779205322266]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8685 [D loss: 0.5911016762256622 | D accuracy: 68.75] [G loss: 1.1686474084854126]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8686 [D loss: 0.5042399019002914 | D accuracy: 70.3125] [G loss: 1.1564257144927979]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "8687 [D loss: 0.5517994165420532 | D accuracy: 73.4375] [G loss: 1.2033672332763672]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8688 [D loss: 0.5820126235485077 | D accuracy: 64.0625] [G loss: 0.9952336549758911]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8689 [D loss: 0.4800177216529846 | D accuracy: 78.125] [G loss: 1.094313621520996]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8690 [D loss: 0.46684977412223816 | D accuracy: 75.0] [G loss: 1.2299342155456543]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8691 [D loss: 0.586554765701294 | D accuracy: 71.875] [G loss: 1.3197910785675049]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "8692 [D loss: 0.45774517953395844 | D accuracy: 81.25] [G loss: 1.4105397462844849]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8693 [D loss: 0.5315942019224167 | D accuracy: 73.4375] [G loss: 1.2600525617599487]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "8694 [D loss: 0.5319487154483795 | D accuracy: 75.0] [G loss: 1.250558614730835]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8695 [D loss: 0.5371018499135971 | D accuracy: 78.125] [G loss: 1.312721848487854]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8696 [D loss: 0.5527632236480713 | D accuracy: 65.625] [G loss: 1.1432825326919556]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8697 [D loss: 0.5387783646583557 | D accuracy: 75.0] [G loss: 1.1090863943099976]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8698 [D loss: 0.554465115070343 | D accuracy: 73.4375] [G loss: 1.1092283725738525]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8699 [D loss: 0.6716640591621399 | D accuracy: 59.375] [G loss: 1.1555882692337036]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8700 [D loss: 0.6087583303451538 | D accuracy: 67.1875] [G loss: 1.2351484298706055]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8701 [D loss: 0.5146855115890503 | D accuracy: 68.75] [G loss: 1.2070543766021729]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8702 [D loss: 0.5460107177495956 | D accuracy: 71.875] [G loss: 1.2672098875045776]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8703 [D loss: 0.553150862455368 | D accuracy: 73.4375] [G loss: 1.3841382265090942]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8704 [D loss: 0.6756882071495056 | D accuracy: 62.5] [G loss: 1.314166784286499]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8705 [D loss: 0.5247279405593872 | D accuracy: 73.4375] [G loss: 1.2270842790603638]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8706 [D loss: 0.40093353390693665 | D accuracy: 87.5] [G loss: 1.1892650127410889]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8707 [D loss: 0.496719092130661 | D accuracy: 71.875] [G loss: 1.2616963386535645]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8708 [D loss: 0.5603122115135193 | D accuracy: 73.4375] [G loss: 1.2167390584945679]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8709 [D loss: 0.643598347902298 | D accuracy: 62.5] [G loss: 1.1199079751968384]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8710 [D loss: 0.54903244972229 | D accuracy: 75.0] [G loss: 1.2202823162078857]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8711 [D loss: 0.5776102244853973 | D accuracy: 67.1875] [G loss: 1.1050304174423218]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8712 [D loss: 0.5607871413230896 | D accuracy: 68.75] [G loss: 1.3287347555160522]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8713 [D loss: 0.5388556271791458 | D accuracy: 68.75] [G loss: 1.1500957012176514]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8714 [D loss: 0.5700422823429108 | D accuracy: 68.75] [G loss: 1.212270736694336]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8715 [D loss: 0.545819029211998 | D accuracy: 67.1875] [G loss: 1.108436107635498]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8716 [D loss: 0.5572331249713898 | D accuracy: 65.625] [G loss: 1.09504234790802]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8717 [D loss: 0.5715287327766418 | D accuracy: 68.75] [G loss: 1.0670740604400635]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8718 [D loss: 0.5487156510353088 | D accuracy: 73.4375] [G loss: 1.1231329441070557]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8719 [D loss: 0.5339579880237579 | D accuracy: 68.75] [G loss: 1.0066630840301514]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8720 [D loss: 0.6279744803905487 | D accuracy: 62.5] [G loss: 1.1248135566711426]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8721 [D loss: 0.4624375104904175 | D accuracy: 81.25] [G loss: 1.2622830867767334]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8722 [D loss: 0.6205833256244659 | D accuracy: 68.75] [G loss: 1.1157169342041016]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8723 [D loss: 0.5832602083683014 | D accuracy: 70.3125] [G loss: 1.093214988708496]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8724 [D loss: 0.5871240794658661 | D accuracy: 62.5] [G loss: 1.2904081344604492]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8725 [D loss: 0.5750640034675598 | D accuracy: 70.3125] [G loss: 1.2660796642303467]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8726 [D loss: 0.4716098755598068 | D accuracy: 76.5625] [G loss: 1.1239254474639893]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8727 [D loss: 0.5068950206041336 | D accuracy: 78.125] [G loss: 1.2303080558776855]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8728 [D loss: 0.48851168155670166 | D accuracy: 76.5625] [G loss: 1.1732525825500488]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8729 [D loss: 0.502438023686409 | D accuracy: 79.6875] [G loss: 1.2606972455978394]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8730 [D loss: 0.6064935922622681 | D accuracy: 67.1875] [G loss: 1.1513292789459229]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8731 [D loss: 0.5563745200634003 | D accuracy: 70.3125] [G loss: 1.12057363986969]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8732 [D loss: 0.5628345608711243 | D accuracy: 70.3125] [G loss: 1.1488041877746582]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8733 [D loss: 0.6257801651954651 | D accuracy: 57.8125] [G loss: 1.1781959533691406]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8734 [D loss: 0.5578502118587494 | D accuracy: 75.0] [G loss: 1.2015591859817505]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8735 [D loss: 0.6190682053565979 | D accuracy: 67.1875] [G loss: 1.3018667697906494]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8736 [D loss: 0.48566973209381104 | D accuracy: 76.5625] [G loss: 1.2903081178665161]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8737 [D loss: 0.6163796186447144 | D accuracy: 65.625] [G loss: 1.1118521690368652]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8738 [D loss: 0.5247926563024521 | D accuracy: 78.125] [G loss: 1.2573230266571045]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8739 [D loss: 0.492525115609169 | D accuracy: 71.875] [G loss: 1.2082583904266357]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8740 [D loss: 0.5791968405246735 | D accuracy: 65.625] [G loss: 1.1389809846878052]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8741 [D loss: 0.5710332691669464 | D accuracy: 64.0625] [G loss: 1.1707212924957275]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8742 [D loss: 0.5037473142147064 | D accuracy: 81.25] [G loss: 1.105853796005249]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8743 [D loss: 0.7087819278240204 | D accuracy: 54.6875] [G loss: 1.16371750831604]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8744 [D loss: 0.5717300772666931 | D accuracy: 71.875] [G loss: 1.1110188961029053]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8745 [D loss: 0.590937465429306 | D accuracy: 57.8125] [G loss: 1.2063968181610107]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8746 [D loss: 0.6036441028118134 | D accuracy: 68.75] [G loss: 1.0759713649749756]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8747 [D loss: 0.4968266487121582 | D accuracy: 79.6875] [G loss: 1.175955057144165]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8748 [D loss: 0.5879735946655273 | D accuracy: 59.375] [G loss: 1.2393492460250854]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8749 [D loss: 0.4835393726825714 | D accuracy: 78.125] [G loss: 1.3103950023651123]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8750 [D loss: 0.48484601080417633 | D accuracy: 79.6875] [G loss: 1.2994396686553955]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8751 [D loss: 0.6121050119400024 | D accuracy: 59.375] [G loss: 1.2308380603790283]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8752 [D loss: 0.5798142552375793 | D accuracy: 68.75] [G loss: 1.007401466369629]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8753 [D loss: 0.5773611962795258 | D accuracy: 70.3125] [G loss: 1.0719772577285767]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8754 [D loss: 0.48792290687561035 | D accuracy: 78.125] [G loss: 1.108083724975586]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8755 [D loss: 0.5493623614311218 | D accuracy: 70.3125] [G loss: 1.2902663946151733]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8756 [D loss: 0.5580697059631348 | D accuracy: 71.875] [G loss: 1.27079439163208]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8757 [D loss: 0.6097257733345032 | D accuracy: 62.5] [G loss: 1.2685821056365967]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8758 [D loss: 0.5291917324066162 | D accuracy: 73.4375] [G loss: 1.259953260421753]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8759 [D loss: 0.5247472822666168 | D accuracy: 75.0] [G loss: 1.331478476524353]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8760 [D loss: 0.49691128730773926 | D accuracy: 71.875] [G loss: 1.3123204708099365]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8761 [D loss: 0.6522158086299896 | D accuracy: 60.9375] [G loss: 1.2553831338882446]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "8762 [D loss: 0.5404198318719864 | D accuracy: 71.875] [G loss: 1.164137840270996]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8763 [D loss: 0.5346918702125549 | D accuracy: 70.3125] [G loss: 1.1406012773513794]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8764 [D loss: 0.6031374037265778 | D accuracy: 64.0625] [G loss: 1.0489161014556885]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8765 [D loss: 0.5406952351331711 | D accuracy: 78.125] [G loss: 1.0944185256958008]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8766 [D loss: 0.5310189574956894 | D accuracy: 82.8125] [G loss: 1.0942754745483398]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8767 [D loss: 0.5370933711528778 | D accuracy: 75.0] [G loss: 1.14829683303833]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "8768 [D loss: 0.4660807251930237 | D accuracy: 84.375] [G loss: 1.0785267353057861]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8769 [D loss: 0.5026184767484665 | D accuracy: 78.125] [G loss: 1.1485282182693481]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "8770 [D loss: 0.6036814153194427 | D accuracy: 68.75] [G loss: 1.1685924530029297]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8771 [D loss: 0.6520158648490906 | D accuracy: 68.75] [G loss: 1.131062388420105]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8772 [D loss: 0.5797736346721649 | D accuracy: 68.75] [G loss: 1.1803075075149536]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8773 [D loss: 0.6141000986099243 | D accuracy: 65.625] [G loss: 1.2310757637023926]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8774 [D loss: 0.5287371873855591 | D accuracy: 65.625] [G loss: 1.163877010345459]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8775 [D loss: 0.6550945341587067 | D accuracy: 70.3125] [G loss: 1.1018092632293701]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8776 [D loss: 0.547042191028595 | D accuracy: 65.625] [G loss: 1.0722516775131226]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8777 [D loss: 0.49183517694473267 | D accuracy: 75.0] [G loss: 0.9583967924118042]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8778 [D loss: 0.49240750074386597 | D accuracy: 81.25] [G loss: 1.0918095111846924]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8779 [D loss: 0.4826211929321289 | D accuracy: 79.6875] [G loss: 1.1474566459655762]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8780 [D loss: 0.6781123578548431 | D accuracy: 57.8125] [G loss: 1.1393682956695557]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8781 [D loss: 0.6220080852508545 | D accuracy: 67.1875] [G loss: 1.163158893585205]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8782 [D loss: 0.5624092817306519 | D accuracy: 67.1875] [G loss: 1.1743218898773193]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8783 [D loss: 0.5532491505146027 | D accuracy: 70.3125] [G loss: 1.1714385747909546]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8784 [D loss: 0.5659068524837494 | D accuracy: 70.3125] [G loss: 1.223949670791626]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8785 [D loss: 0.4735327959060669 | D accuracy: 76.5625] [G loss: 1.2643252611160278]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8786 [D loss: 0.66182541847229 | D accuracy: 59.375] [G loss: 1.1515127420425415]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8787 [D loss: 0.5478744804859161 | D accuracy: 76.5625] [G loss: 1.300887107849121]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8788 [D loss: 0.6264715194702148 | D accuracy: 62.5] [G loss: 1.0862786769866943]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8789 [D loss: 0.5235966742038727 | D accuracy: 73.4375] [G loss: 1.0421797037124634]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8790 [D loss: 0.5917463302612305 | D accuracy: 71.875] [G loss: 1.1567575931549072]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8791 [D loss: 0.5476531386375427 | D accuracy: 65.625] [G loss: 1.2787158489227295]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8792 [D loss: 0.4369488060474396 | D accuracy: 79.6875] [G loss: 1.2767863273620605]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8793 [D loss: 0.5177045464515686 | D accuracy: 71.875] [G loss: 1.1713417768478394]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8794 [D loss: 0.5185906887054443 | D accuracy: 70.3125] [G loss: 1.2308253049850464]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8795 [D loss: 0.5327751040458679 | D accuracy: 75.0] [G loss: 1.2414376735687256]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8796 [D loss: 0.5851379930973053 | D accuracy: 65.625] [G loss: 1.2114930152893066]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8797 [D loss: 0.4891309142112732 | D accuracy: 70.3125] [G loss: 1.208974003791809]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8798 [D loss: 0.6072722673416138 | D accuracy: 60.9375] [G loss: 1.1570155620574951]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8799 [D loss: 0.5402983725070953 | D accuracy: 73.4375] [G loss: 1.1733214855194092]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8800 [D loss: 0.5776253640651703 | D accuracy: 68.75] [G loss: 1.1311415433883667]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8801 [D loss: 0.509957492351532 | D accuracy: 79.6875] [G loss: 1.150862455368042]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8802 [D loss: 0.5289438366889954 | D accuracy: 71.875] [G loss: 1.2690236568450928]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8803 [D loss: 0.569842666387558 | D accuracy: 73.4375] [G loss: 1.1812199354171753]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8804 [D loss: 0.6015348434448242 | D accuracy: 65.625] [G loss: 1.2274410724639893]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8805 [D loss: 0.44402699172496796 | D accuracy: 76.5625] [G loss: 1.2123212814331055]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8806 [D loss: 0.4730665981769562 | D accuracy: 81.25] [G loss: 0.990197479724884]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8807 [D loss: 0.6506586074829102 | D accuracy: 57.8125] [G loss: 1.169893503189087]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8808 [D loss: 0.5558459758758545 | D accuracy: 70.3125] [G loss: 1.2435362339019775]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8809 [D loss: 0.5320022106170654 | D accuracy: 68.75] [G loss: 1.2198190689086914]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8810 [D loss: 0.4954984039068222 | D accuracy: 73.4375] [G loss: 1.3257296085357666]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8811 [D loss: 0.5272872447967529 | D accuracy: 81.25] [G loss: 1.1167120933532715]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8812 [D loss: 0.5525351166725159 | D accuracy: 68.75] [G loss: 1.19586980342865]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8813 [D loss: 0.49252189695835114 | D accuracy: 81.25] [G loss: 1.15434992313385]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8814 [D loss: 0.5523575842380524 | D accuracy: 70.3125] [G loss: 1.287178874015808]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8815 [D loss: 0.5795730650424957 | D accuracy: 70.3125] [G loss: 1.2257423400878906]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8816 [D loss: 0.5052266418933868 | D accuracy: 75.0] [G loss: 1.2129881381988525]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8817 [D loss: 0.4826029986143112 | D accuracy: 82.8125] [G loss: 1.3088815212249756]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8818 [D loss: 0.6300613880157471 | D accuracy: 60.9375] [G loss: 1.2570877075195312]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8819 [D loss: 0.6319313049316406 | D accuracy: 60.9375] [G loss: 1.0888230800628662]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8820 [D loss: 0.5573557317256927 | D accuracy: 70.3125] [G loss: 1.151191234588623]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8821 [D loss: 0.5371348261833191 | D accuracy: 75.0] [G loss: 1.2495765686035156]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8822 [D loss: 0.5882520079612732 | D accuracy: 68.75] [G loss: 1.2599732875823975]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8823 [D loss: 0.6445962190628052 | D accuracy: 62.5] [G loss: 1.1329340934753418]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8824 [D loss: 0.5578906238079071 | D accuracy: 65.625] [G loss: 1.190568447113037]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8825 [D loss: 0.4526836574077606 | D accuracy: 81.25] [G loss: 1.087353229522705]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8826 [D loss: 0.5358462333679199 | D accuracy: 75.0] [G loss: 1.197858452796936]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8827 [D loss: 0.5743051767349243 | D accuracy: 70.3125] [G loss: 1.0127962827682495]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8828 [D loss: 0.49624103307724 | D accuracy: 73.4375] [G loss: 1.111090064048767]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8829 [D loss: 0.4878118485212326 | D accuracy: 82.8125] [G loss: 1.1334009170532227]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8830 [D loss: 0.5471159815788269 | D accuracy: 76.5625] [G loss: 1.124351143836975]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8831 [D loss: 0.583842933177948 | D accuracy: 62.5] [G loss: 1.0652412176132202]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8832 [D loss: 0.5462884902954102 | D accuracy: 68.75] [G loss: 1.1568350791931152]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8833 [D loss: 0.5236421525478363 | D accuracy: 76.5625] [G loss: 1.2631731033325195]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8834 [D loss: 0.6570033431053162 | D accuracy: 65.625] [G loss: 1.2013392448425293]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8835 [D loss: 0.5754134058952332 | D accuracy: 67.1875] [G loss: 1.1527128219604492]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8836 [D loss: 0.5554735362529755 | D accuracy: 65.625] [G loss: 1.114721417427063]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8837 [D loss: 0.5878322124481201 | D accuracy: 71.875] [G loss: 1.1851999759674072]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8838 [D loss: 0.615822434425354 | D accuracy: 65.625] [G loss: 1.1065586805343628]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8839 [D loss: 0.5997986495494843 | D accuracy: 65.625] [G loss: 1.056422233581543]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "8840 [D loss: 0.4817051589488983 | D accuracy: 73.4375] [G loss: 1.278648853302002]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8841 [D loss: 0.5338860303163528 | D accuracy: 75.0] [G loss: 1.2494391202926636]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8842 [D loss: 0.5588020980358124 | D accuracy: 67.1875] [G loss: 1.2733136415481567]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8843 [D loss: 0.5087509751319885 | D accuracy: 75.0] [G loss: 1.0542891025543213]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8844 [D loss: 0.5075312703847885 | D accuracy: 71.875] [G loss: 1.2225723266601562]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8845 [D loss: 0.5601612627506256 | D accuracy: 67.1875] [G loss: 1.3320562839508057]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8846 [D loss: 0.5438262224197388 | D accuracy: 73.4375] [G loss: 1.2728838920593262]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8847 [D loss: 0.47405315935611725 | D accuracy: 78.125] [G loss: 1.2782948017120361]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8848 [D loss: 0.6769264042377472 | D accuracy: 53.125] [G loss: 1.243505835533142]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8849 [D loss: 0.5609784722328186 | D accuracy: 75.0] [G loss: 1.2175108194351196]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "8850 [D loss: 0.5879725217819214 | D accuracy: 62.5] [G loss: 1.3416765928268433]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "8851 [D loss: 0.5841492414474487 | D accuracy: 68.75] [G loss: 1.3499040603637695]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8852 [D loss: 0.5161994695663452 | D accuracy: 79.6875] [G loss: 1.3038928508758545]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8853 [D loss: 0.5654861927032471 | D accuracy: 75.0] [G loss: 1.3094902038574219]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8854 [D loss: 0.5467312335968018 | D accuracy: 73.4375] [G loss: 1.2104227542877197]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8855 [D loss: 0.6225047409534454 | D accuracy: 65.625] [G loss: 1.1008250713348389]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8856 [D loss: 0.5304119884967804 | D accuracy: 71.875] [G loss: 1.1561048030853271]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8857 [D loss: 0.624260663986206 | D accuracy: 71.875] [G loss: 1.194016695022583]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8858 [D loss: 0.5068554282188416 | D accuracy: 78.125] [G loss: 1.175915241241455]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8859 [D loss: 0.640561431646347 | D accuracy: 67.1875] [G loss: 1.1694884300231934]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8860 [D loss: 0.5076275020837784 | D accuracy: 70.3125] [G loss: 1.2936902046203613]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8861 [D loss: 0.5373217910528183 | D accuracy: 75.0] [G loss: 1.1395879983901978]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8862 [D loss: 0.5344418585300446 | D accuracy: 73.4375] [G loss: 1.1827201843261719]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8863 [D loss: 0.4646507650613785 | D accuracy: 78.125] [G loss: 1.1270365715026855]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8864 [D loss: 0.5329260677099228 | D accuracy: 65.625] [G loss: 1.2381973266601562]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8865 [D loss: 0.5466032028198242 | D accuracy: 70.3125] [G loss: 1.2407467365264893]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8866 [D loss: 0.48911207914352417 | D accuracy: 79.6875] [G loss: 1.0915801525115967]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8867 [D loss: 0.5412522256374359 | D accuracy: 78.125] [G loss: 0.9875451326370239]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8868 [D loss: 0.5742745697498322 | D accuracy: 70.3125] [G loss: 1.054198980331421]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8869 [D loss: 0.4776518791913986 | D accuracy: 78.125] [G loss: 1.1575132608413696]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8870 [D loss: 0.5275703966617584 | D accuracy: 79.6875] [G loss: 1.267980694770813]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8871 [D loss: 0.5848927795886993 | D accuracy: 60.9375] [G loss: 1.170332670211792]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8872 [D loss: 0.6219905018806458 | D accuracy: 59.375] [G loss: 1.2816253900527954]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8873 [D loss: 0.48490872979164124 | D accuracy: 75.0] [G loss: 1.192444086074829]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8874 [D loss: 0.6346745193004608 | D accuracy: 64.0625] [G loss: 1.1818509101867676]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8875 [D loss: 0.6145713627338409 | D accuracy: 65.625] [G loss: 1.1917119026184082]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8876 [D loss: 0.5593248903751373 | D accuracy: 67.1875] [G loss: 1.2787355184555054]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8877 [D loss: 0.5059602111577988 | D accuracy: 78.125] [G loss: 1.0905730724334717]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8878 [D loss: 0.6012254953384399 | D accuracy: 65.625] [G loss: 1.312296748161316]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8879 [D loss: 0.5419295132160187 | D accuracy: 73.4375] [G loss: 1.290334701538086]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8880 [D loss: 0.5031952857971191 | D accuracy: 79.6875] [G loss: 1.2841567993164062]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8881 [D loss: 0.5498001575469971 | D accuracy: 68.75] [G loss: 1.2464077472686768]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8882 [D loss: 0.5511562824249268 | D accuracy: 65.625] [G loss: 1.2818353176116943]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8883 [D loss: 0.5264406949281693 | D accuracy: 70.3125] [G loss: 1.2584943771362305]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8884 [D loss: 0.5505401492118835 | D accuracy: 71.875] [G loss: 1.2049334049224854]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8885 [D loss: 0.6574553847312927 | D accuracy: 65.625] [G loss: 1.1694415807724]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8886 [D loss: 0.5974154472351074 | D accuracy: 68.75] [G loss: 1.1628596782684326]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8887 [D loss: 0.44789251685142517 | D accuracy: 73.4375] [G loss: 1.1062750816345215]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8888 [D loss: 0.5853880494832993 | D accuracy: 65.625] [G loss: 1.0881023406982422]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "8889 [D loss: 0.5060333013534546 | D accuracy: 71.875] [G loss: 1.135029911994934]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8890 [D loss: 0.5052724331617355 | D accuracy: 79.6875] [G loss: 1.1392570734024048]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8891 [D loss: 0.53114053606987 | D accuracy: 73.4375] [G loss: 1.0994431972503662]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8892 [D loss: 0.4766264855861664 | D accuracy: 78.125] [G loss: 1.2483761310577393]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8893 [D loss: 0.5042183846235275 | D accuracy: 70.3125] [G loss: 1.1360399723052979]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8894 [D loss: 0.6087223589420319 | D accuracy: 62.5] [G loss: 1.0194346904754639]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8895 [D loss: 0.5635853707790375 | D accuracy: 65.625] [G loss: 1.1799564361572266]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8896 [D loss: 0.5692522823810577 | D accuracy: 67.1875] [G loss: 1.0894651412963867]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8897 [D loss: 0.517493486404419 | D accuracy: 79.6875] [G loss: 1.2324782609939575]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "8898 [D loss: 0.5877306759357452 | D accuracy: 70.3125] [G loss: 1.0543879270553589]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8899 [D loss: 0.5743580460548401 | D accuracy: 68.75] [G loss: 1.1480729579925537]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8900 [D loss: 0.5384058058261871 | D accuracy: 70.3125] [G loss: 1.176171898841858]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8901 [D loss: 0.643379807472229 | D accuracy: 57.8125] [G loss: 1.2941778898239136]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8902 [D loss: 0.5100643634796143 | D accuracy: 75.0] [G loss: 1.2833186388015747]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8903 [D loss: 0.5875074863433838 | D accuracy: 67.1875] [G loss: 1.1675751209259033]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8904 [D loss: 0.5534184277057648 | D accuracy: 68.75] [G loss: 1.0672845840454102]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8905 [D loss: 0.5909697711467743 | D accuracy: 65.625] [G loss: 1.2579443454742432]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8906 [D loss: 0.5617843568325043 | D accuracy: 68.75] [G loss: 1.2769701480865479]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8907 [D loss: 0.5809187889099121 | D accuracy: 67.1875] [G loss: 1.153116226196289]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8908 [D loss: 0.5122972130775452 | D accuracy: 73.4375] [G loss: 1.1779605150222778]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8909 [D loss: 0.5471857190132141 | D accuracy: 73.4375] [G loss: 1.23375403881073]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8910 [D loss: 0.5745233595371246 | D accuracy: 71.875] [G loss: 1.270364761352539]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8911 [D loss: 0.5288159549236298 | D accuracy: 73.4375] [G loss: 1.1307094097137451]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8912 [D loss: 0.507728099822998 | D accuracy: 71.875] [G loss: 1.1898318529129028]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8913 [D loss: 0.5184615850448608 | D accuracy: 71.875] [G loss: 1.1903676986694336]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8914 [D loss: 0.5693147629499435 | D accuracy: 76.5625] [G loss: 1.093712329864502]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8915 [D loss: 0.5222351849079132 | D accuracy: 71.875] [G loss: 1.1742181777954102]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8916 [D loss: 0.5289202630519867 | D accuracy: 73.4375] [G loss: 1.2192106246948242]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8917 [D loss: 0.5690684914588928 | D accuracy: 71.875] [G loss: 1.150315284729004]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "8918 [D loss: 0.6106480062007904 | D accuracy: 68.75] [G loss: 1.1963105201721191]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8919 [D loss: 0.49590522050857544 | D accuracy: 76.5625] [G loss: 1.1959718465805054]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8920 [D loss: 0.6517026722431183 | D accuracy: 62.5] [G loss: 1.0420539379119873]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "8921 [D loss: 0.6445702612400055 | D accuracy: 62.5] [G loss: 0.9966240525245667]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "8922 [D loss: 0.5259754508733749 | D accuracy: 70.3125] [G loss: 1.1416034698486328]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8923 [D loss: 0.6003320217132568 | D accuracy: 68.75] [G loss: 1.1576828956604004]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8924 [D loss: 0.6441780924797058 | D accuracy: 60.9375] [G loss: 1.1260828971862793]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "8925 [D loss: 0.5771087408065796 | D accuracy: 67.1875] [G loss: 1.2068560123443604]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "8926 [D loss: 0.5575268864631653 | D accuracy: 73.4375] [G loss: 1.1746406555175781]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "8927 [D loss: 0.5571569502353668 | D accuracy: 65.625] [G loss: 1.2034499645233154]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "8928 [D loss: 0.6282035708427429 | D accuracy: 57.8125] [G loss: 1.17551589012146]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "8929 [D loss: 0.5368265211582184 | D accuracy: 76.5625] [G loss: 1.1203455924987793]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "8930 [D loss: 0.5465162098407745 | D accuracy: 67.1875] [G loss: 1.125291109085083]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "8931 [D loss: 0.5501073598861694 | D accuracy: 68.75] [G loss: 1.0965588092803955]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "8932 [D loss: 0.509287565946579 | D accuracy: 67.1875] [G loss: 1.2856018543243408]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8933 [D loss: 0.5326265245676041 | D accuracy: 71.875] [G loss: 1.1552525758743286]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8934 [D loss: 0.4946536123752594 | D accuracy: 78.125] [G loss: 1.1900315284729004]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8935 [D loss: 0.48927174508571625 | D accuracy: 75.0] [G loss: 1.2022017240524292]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8936 [D loss: 0.5021153837442398 | D accuracy: 76.5625] [G loss: 1.1321849822998047]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8937 [D loss: 0.5538617670536041 | D accuracy: 71.875] [G loss: 1.1635980606079102]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8938 [D loss: 0.5796672999858856 | D accuracy: 70.3125] [G loss: 1.3181049823760986]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8939 [D loss: 0.6472772061824799 | D accuracy: 65.625] [G loss: 1.3608795404434204]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8940 [D loss: 0.5578216016292572 | D accuracy: 75.0] [G loss: 1.204759955406189]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "8941 [D loss: 0.5671574771404266 | D accuracy: 68.75] [G loss: 1.2912112474441528]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8942 [D loss: 0.5020916014909744 | D accuracy: 75.0] [G loss: 1.194746971130371]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8943 [D loss: 0.4836502969264984 | D accuracy: 76.5625] [G loss: 1.1577855348587036]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8944 [D loss: 0.5443311631679535 | D accuracy: 73.4375] [G loss: 1.2132453918457031]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8945 [D loss: 0.558544397354126 | D accuracy: 71.875] [G loss: 1.2091556787490845]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8946 [D loss: 0.47614702582359314 | D accuracy: 75.0] [G loss: 1.1278010606765747]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8947 [D loss: 0.5620148777961731 | D accuracy: 65.625] [G loss: 1.1205071210861206]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8948 [D loss: 0.5627371072769165 | D accuracy: 73.4375] [G loss: 1.138418436050415]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "8949 [D loss: 0.5066054165363312 | D accuracy: 76.5625] [G loss: 1.289015293121338]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8950 [D loss: 0.6066092252731323 | D accuracy: 64.0625] [G loss: 1.1868181228637695]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8951 [D loss: 0.5790987312793732 | D accuracy: 68.75] [G loss: 1.0457700490951538]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8952 [D loss: 0.5701987147331238 | D accuracy: 76.5625] [G loss: 1.131718635559082]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8953 [D loss: 0.5335248410701752 | D accuracy: 70.3125] [G loss: 1.159523844718933]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8954 [D loss: 0.4859361797571182 | D accuracy: 73.4375] [G loss: 1.086836576461792]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8955 [D loss: 0.47948671877384186 | D accuracy: 78.125] [G loss: 1.1707987785339355]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8956 [D loss: 0.6747968792915344 | D accuracy: 62.5] [G loss: 1.2009146213531494]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8957 [D loss: 0.5350993573665619 | D accuracy: 67.1875] [G loss: 1.1820939779281616]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8958 [D loss: 0.6098227500915527 | D accuracy: 67.1875] [G loss: 1.2662372589111328]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8959 [D loss: 0.5564319789409637 | D accuracy: 70.3125] [G loss: 1.1623709201812744]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8960 [D loss: 0.5419182330369949 | D accuracy: 70.3125] [G loss: 1.2465898990631104]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8961 [D loss: 0.5360767245292664 | D accuracy: 73.4375] [G loss: 1.258068323135376]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8962 [D loss: 0.5241678953170776 | D accuracy: 73.4375] [G loss: 1.131847620010376]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "8963 [D loss: 0.5769204497337341 | D accuracy: 73.4375] [G loss: 1.1077914237976074]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8964 [D loss: 0.592501163482666 | D accuracy: 68.75] [G loss: 1.1209263801574707]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8965 [D loss: 0.5776588916778564 | D accuracy: 64.0625] [G loss: 1.1869523525238037]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8966 [D loss: 0.49729710817337036 | D accuracy: 75.0] [G loss: 1.1881601810455322]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8967 [D loss: 0.5393452346324921 | D accuracy: 73.4375] [G loss: 1.2220699787139893]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8968 [D loss: 0.5258132219314575 | D accuracy: 65.625] [G loss: 1.1598533391952515]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8969 [D loss: 0.5264289379119873 | D accuracy: 71.875] [G loss: 1.2370175123214722]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8970 [D loss: 0.5097076594829559 | D accuracy: 73.4375] [G loss: 1.224758267402649]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8971 [D loss: 0.6344323456287384 | D accuracy: 62.5] [G loss: 1.3231419324874878]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8972 [D loss: 0.5219107568264008 | D accuracy: 70.3125] [G loss: 1.2191815376281738]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8973 [D loss: 0.6131078004837036 | D accuracy: 65.625] [G loss: 1.2351253032684326]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8974 [D loss: 0.5307112336158752 | D accuracy: 73.4375] [G loss: 1.1583731174468994]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8975 [D loss: 0.5861505568027496 | D accuracy: 64.0625] [G loss: 1.332038402557373]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8976 [D loss: 0.5555975139141083 | D accuracy: 70.3125] [G loss: 1.1555147171020508]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8977 [D loss: 0.5838494896888733 | D accuracy: 65.625] [G loss: 1.2060664892196655]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "8978 [D loss: 0.48956744372844696 | D accuracy: 75.0] [G loss: 1.2457932233810425]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "8979 [D loss: 0.5956960916519165 | D accuracy: 62.5] [G loss: 1.1278917789459229]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8980 [D loss: 0.5362385213375092 | D accuracy: 70.3125] [G loss: 1.1480050086975098]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8981 [D loss: 0.5168492496013641 | D accuracy: 71.875] [G loss: 1.2251205444335938]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8982 [D loss: 0.5987297892570496 | D accuracy: 64.0625] [G loss: 1.1713593006134033]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8983 [D loss: 0.4408430755138397 | D accuracy: 78.125] [G loss: 1.275033950805664]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8984 [D loss: 0.5765748023986816 | D accuracy: 71.875] [G loss: 1.1284035444259644]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8985 [D loss: 0.5265985131263733 | D accuracy: 67.1875] [G loss: 1.1745200157165527]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "8986 [D loss: 0.582425594329834 | D accuracy: 70.3125] [G loss: 1.1706243753433228]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8987 [D loss: 0.6463038325309753 | D accuracy: 62.5] [G loss: 1.2253961563110352]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "8988 [D loss: 0.5991533398628235 | D accuracy: 60.9375] [G loss: 1.1044459342956543]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "8989 [D loss: 0.489535853266716 | D accuracy: 75.0] [G loss: 1.1495983600616455]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8990 [D loss: 0.40299856662750244 | D accuracy: 81.25] [G loss: 1.213382601737976]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "8991 [D loss: 0.5878225266933441 | D accuracy: 62.5] [G loss: 1.132746934890747]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8992 [D loss: 0.5833489298820496 | D accuracy: 64.0625] [G loss: 1.224367380142212]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "8993 [D loss: 0.5098202377557755 | D accuracy: 71.875] [G loss: 1.2133691310882568]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8994 [D loss: 0.5858226716518402 | D accuracy: 70.3125] [G loss: 1.2881872653961182]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "8995 [D loss: 0.5002620816230774 | D accuracy: 76.5625] [G loss: 1.1516528129577637]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "8996 [D loss: 0.4178641140460968 | D accuracy: 79.6875] [G loss: 1.2063257694244385]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8997 [D loss: 0.5007024109363556 | D accuracy: 73.4375] [G loss: 1.2313255071640015]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "8998 [D loss: 0.589015007019043 | D accuracy: 60.9375] [G loss: 1.1727573871612549]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "8999 [D loss: 0.5908560752868652 | D accuracy: 65.625] [G loss: 1.139206886291504]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9000 [D loss: 0.549209326505661 | D accuracy: 73.4375] [G loss: 1.2431310415267944]\n",
            "1/1 [==============================] - 0s 33ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "9001 [D loss: 0.5115512311458588 | D accuracy: 79.6875] [G loss: 1.0900466442108154]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9002 [D loss: 0.593209981918335 | D accuracy: 71.875] [G loss: 1.1861969232559204]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9003 [D loss: 0.49945735931396484 | D accuracy: 76.5625] [G loss: 1.1942391395568848]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9004 [D loss: 0.5282626152038574 | D accuracy: 78.125] [G loss: 1.1074442863464355]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9005 [D loss: 0.5556091666221619 | D accuracy: 71.875] [G loss: 1.3082001209259033]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9006 [D loss: 0.510313093662262 | D accuracy: 73.4375] [G loss: 1.1861555576324463]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9007 [D loss: 0.5743692517280579 | D accuracy: 64.0625] [G loss: 1.2281136512756348]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "9008 [D loss: 0.49132823944091797 | D accuracy: 73.4375] [G loss: 1.3092069625854492]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "9009 [D loss: 0.5464767813682556 | D accuracy: 70.3125] [G loss: 1.2596051692962646]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9010 [D loss: 0.5752516090869904 | D accuracy: 65.625] [G loss: 1.1486098766326904]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9011 [D loss: 0.4975973069667816 | D accuracy: 78.125] [G loss: 1.1834664344787598]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9012 [D loss: 0.5643668472766876 | D accuracy: 71.875] [G loss: 1.1925268173217773]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9013 [D loss: 0.6190169304609299 | D accuracy: 64.0625] [G loss: 1.1690254211425781]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9014 [D loss: 0.549712210893631 | D accuracy: 75.0] [G loss: 1.248753547668457]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9015 [D loss: 0.419020414352417 | D accuracy: 87.5] [G loss: 1.1572601795196533]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9016 [D loss: 0.5879123210906982 | D accuracy: 68.75] [G loss: 1.2621971368789673]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9017 [D loss: 0.6089860796928406 | D accuracy: 62.5] [G loss: 1.166707992553711]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9018 [D loss: 0.6275583803653717 | D accuracy: 67.1875] [G loss: 1.2379275560379028]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9019 [D loss: 0.5767847895622253 | D accuracy: 68.75] [G loss: 1.4076311588287354]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9020 [D loss: 0.6046362519264221 | D accuracy: 67.1875] [G loss: 1.2823126316070557]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9021 [D loss: 0.6004031300544739 | D accuracy: 64.0625] [G loss: 1.243165135383606]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9022 [D loss: 0.5189360082149506 | D accuracy: 71.875] [G loss: 1.3134489059448242]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9023 [D loss: 0.5309851467609406 | D accuracy: 73.4375] [G loss: 1.2419610023498535]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9024 [D loss: 0.5585958361625671 | D accuracy: 73.4375] [G loss: 1.1285465955734253]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9025 [D loss: 0.6008865535259247 | D accuracy: 62.5] [G loss: 1.1420361995697021]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9026 [D loss: 0.5121715813875198 | D accuracy: 70.3125] [G loss: 1.0342929363250732]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9027 [D loss: 0.5620316863059998 | D accuracy: 68.75] [G loss: 1.17185640335083]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9028 [D loss: 0.5914001166820526 | D accuracy: 68.75] [G loss: 1.2447798252105713]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9029 [D loss: 0.5187760442495346 | D accuracy: 71.875] [G loss: 1.1239852905273438]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9030 [D loss: 0.5645242929458618 | D accuracy: 65.625] [G loss: 1.1723251342773438]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9031 [D loss: 0.47472311556339264 | D accuracy: 82.8125] [G loss: 1.072152853012085]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9032 [D loss: 0.5522556751966476 | D accuracy: 71.875] [G loss: 1.2061512470245361]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9033 [D loss: 0.5601847767829895 | D accuracy: 73.4375] [G loss: 1.2089614868164062]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9034 [D loss: 0.45042678713798523 | D accuracy: 81.25] [G loss: 1.2045338153839111]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9035 [D loss: 0.4579717516899109 | D accuracy: 79.6875] [G loss: 1.3266786336898804]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9036 [D loss: 0.5137408971786499 | D accuracy: 79.6875] [G loss: 1.4350521564483643]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9037 [D loss: 0.5027076005935669 | D accuracy: 76.5625] [G loss: 1.3051133155822754]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9038 [D loss: 0.6193550229072571 | D accuracy: 62.5] [G loss: 1.3642172813415527]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9039 [D loss: 0.6632683575153351 | D accuracy: 67.1875] [G loss: 1.1693663597106934]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9040 [D loss: 0.468634232878685 | D accuracy: 81.25] [G loss: 1.251847267150879]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9041 [D loss: 0.6266874074935913 | D accuracy: 68.75] [G loss: 1.095455527305603]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9042 [D loss: 0.5219255983829498 | D accuracy: 78.125] [G loss: 1.3574095964431763]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9043 [D loss: 0.576239824295044 | D accuracy: 70.3125] [G loss: 1.1692687273025513]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9044 [D loss: 0.5258445590734482 | D accuracy: 70.3125] [G loss: 1.159267783164978]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9045 [D loss: 0.5156126022338867 | D accuracy: 70.3125] [G loss: 1.2955043315887451]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9046 [D loss: 0.5610429048538208 | D accuracy: 75.0] [G loss: 1.1884971857070923]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9047 [D loss: 0.5132340341806412 | D accuracy: 71.875] [G loss: 1.3198115825653076]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9048 [D loss: 0.5591303706169128 | D accuracy: 65.625] [G loss: 1.1865323781967163]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9049 [D loss: 0.46797406673431396 | D accuracy: 81.25] [G loss: 1.085631251335144]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9050 [D loss: 0.5261602699756622 | D accuracy: 71.875] [G loss: 1.2056094408035278]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9051 [D loss: 0.5538206398487091 | D accuracy: 64.0625] [G loss: 1.228017807006836]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9052 [D loss: 0.5365724712610245 | D accuracy: 73.4375] [G loss: 1.2908680438995361]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9053 [D loss: 0.5929639339447021 | D accuracy: 71.875] [G loss: 1.2401014566421509]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9054 [D loss: 0.5016146600246429 | D accuracy: 76.5625] [G loss: 1.3040578365325928]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9055 [D loss: 0.47426241636276245 | D accuracy: 82.8125] [G loss: 1.1606558561325073]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9056 [D loss: 0.6139664053916931 | D accuracy: 62.5] [G loss: 1.1159950494766235]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9057 [D loss: 0.6480399668216705 | D accuracy: 67.1875] [G loss: 1.188942313194275]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9058 [D loss: 0.4899315685033798 | D accuracy: 82.8125] [G loss: 1.2568128108978271]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9059 [D loss: 0.6235682368278503 | D accuracy: 67.1875] [G loss: 1.433618187904358]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9060 [D loss: 0.6190134882926941 | D accuracy: 62.5] [G loss: 1.2280683517456055]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9061 [D loss: 0.6629337668418884 | D accuracy: 57.8125] [G loss: 1.1758311986923218]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9062 [D loss: 0.5189120471477509 | D accuracy: 70.3125] [G loss: 1.0701303482055664]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9063 [D loss: 0.5415486991405487 | D accuracy: 67.1875] [G loss: 1.245807409286499]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9064 [D loss: 0.5549821555614471 | D accuracy: 70.3125] [G loss: 1.2013461589813232]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9065 [D loss: 0.5491825640201569 | D accuracy: 70.3125] [G loss: 1.1499890089035034]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9066 [D loss: 0.5388071686029434 | D accuracy: 76.5625] [G loss: 1.2068133354187012]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9067 [D loss: 0.5494508147239685 | D accuracy: 67.1875] [G loss: 1.1793920993804932]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9068 [D loss: 0.5656235814094543 | D accuracy: 76.5625] [G loss: 1.3284848928451538]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9069 [D loss: 0.5205802023410797 | D accuracy: 70.3125] [G loss: 1.2658368349075317]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9070 [D loss: 0.48764678835868835 | D accuracy: 70.3125] [G loss: 1.2902026176452637]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9071 [D loss: 0.5771323144435883 | D accuracy: 70.3125] [G loss: 1.2673577070236206]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9072 [D loss: 0.5436992794275284 | D accuracy: 71.875] [G loss: 1.3779010772705078]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9073 [D loss: 0.5404586791992188 | D accuracy: 71.875] [G loss: 1.2914950847625732]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9074 [D loss: 0.5717247128486633 | D accuracy: 70.3125] [G loss: 1.296044111251831]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9075 [D loss: 0.5519459992647171 | D accuracy: 71.875] [G loss: 1.16787850856781]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9076 [D loss: 0.4570775628089905 | D accuracy: 76.5625] [G loss: 1.1711316108703613]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9077 [D loss: 0.4841427356004715 | D accuracy: 79.6875] [G loss: 1.0882935523986816]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9078 [D loss: 0.5533252954483032 | D accuracy: 70.3125] [G loss: 1.1069765090942383]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9079 [D loss: 0.5314457416534424 | D accuracy: 75.0] [G loss: 1.1353260278701782]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9080 [D loss: 0.5302038192749023 | D accuracy: 73.4375] [G loss: 1.2544445991516113]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9081 [D loss: 0.5430188328027725 | D accuracy: 75.0] [G loss: 1.1442530155181885]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9082 [D loss: 0.528131902217865 | D accuracy: 68.75] [G loss: 1.0336241722106934]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9083 [D loss: 0.5608947724103928 | D accuracy: 64.0625] [G loss: 1.3000965118408203]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9084 [D loss: 0.5089983344078064 | D accuracy: 73.4375] [G loss: 1.1679391860961914]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9085 [D loss: 0.5165683329105377 | D accuracy: 73.4375] [G loss: 1.2033779621124268]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9086 [D loss: 0.5391740798950195 | D accuracy: 65.625] [G loss: 1.1082744598388672]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9087 [D loss: 0.48259569704532623 | D accuracy: 79.6875] [G loss: 1.2390060424804688]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9088 [D loss: 0.5530673861503601 | D accuracy: 70.3125] [G loss: 1.200949788093567]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9089 [D loss: 0.5213296115398407 | D accuracy: 76.5625] [G loss: 1.0841847658157349]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9090 [D loss: 0.5523403584957123 | D accuracy: 70.3125] [G loss: 1.1878000497817993]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9091 [D loss: 0.4947405308485031 | D accuracy: 78.125] [G loss: 1.183696985244751]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9092 [D loss: 0.4892105609178543 | D accuracy: 75.0] [G loss: 1.3507189750671387]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9093 [D loss: 0.49072423577308655 | D accuracy: 76.5625] [G loss: 1.2527409791946411]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9094 [D loss: 0.44021032750606537 | D accuracy: 82.8125] [G loss: 1.2078384160995483]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9095 [D loss: 0.5835663378238678 | D accuracy: 64.0625] [G loss: 1.2466932535171509]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9096 [D loss: 0.5664209127426147 | D accuracy: 71.875] [G loss: 1.2228913307189941]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9097 [D loss: 0.48402830958366394 | D accuracy: 79.6875] [G loss: 1.282834529876709]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9098 [D loss: 0.4751565754413605 | D accuracy: 79.6875] [G loss: 1.269737720489502]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9099 [D loss: 0.48657627403736115 | D accuracy: 76.5625] [G loss: 1.4312994480133057]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9100 [D loss: 0.5101619213819504 | D accuracy: 75.0] [G loss: 1.2029073238372803]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9101 [D loss: 0.5809198468923569 | D accuracy: 59.375] [G loss: 1.2037779092788696]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9102 [D loss: 0.6931900382041931 | D accuracy: 48.4375] [G loss: 1.0397553443908691]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9103 [D loss: 0.5303637683391571 | D accuracy: 71.875] [G loss: 1.2898801565170288]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9104 [D loss: 0.5151385366916656 | D accuracy: 79.6875] [G loss: 1.1883747577667236]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9105 [D loss: 0.49219825863838196 | D accuracy: 81.25] [G loss: 1.2763125896453857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9106 [D loss: 0.5330116897821426 | D accuracy: 71.875] [G loss: 1.1662778854370117]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9107 [D loss: 0.5967331230640411 | D accuracy: 68.75] [G loss: 1.280290961265564]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9108 [D loss: 0.5576537400484085 | D accuracy: 68.75] [G loss: 1.2343535423278809]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9109 [D loss: 0.5695893168449402 | D accuracy: 70.3125] [G loss: 1.3257992267608643]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9110 [D loss: 0.5303585827350616 | D accuracy: 67.1875] [G loss: 1.2035717964172363]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "9111 [D loss: 0.5229357331991196 | D accuracy: 70.3125] [G loss: 1.189234733581543]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9112 [D loss: 0.5857935547828674 | D accuracy: 71.875] [G loss: 1.381752371788025]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9113 [D loss: 0.5835752785205841 | D accuracy: 71.875] [G loss: 1.276425838470459]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9114 [D loss: 0.6128449440002441 | D accuracy: 68.75] [G loss: 1.0804965496063232]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9115 [D loss: 0.52436164021492 | D accuracy: 78.125] [G loss: 1.1903979778289795]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9116 [D loss: 0.5377084612846375 | D accuracy: 68.75] [G loss: 1.072871446609497]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9117 [D loss: 0.5462467074394226 | D accuracy: 68.75] [G loss: 1.1254215240478516]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9118 [D loss: 0.512552946805954 | D accuracy: 76.5625] [G loss: 1.2367331981658936]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9119 [D loss: 0.47880901396274567 | D accuracy: 81.25] [G loss: 1.295941948890686]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9120 [D loss: 0.4873128682374954 | D accuracy: 79.6875] [G loss: 1.222337007522583]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9121 [D loss: 0.5925504565238953 | D accuracy: 70.3125] [G loss: 1.198585033416748]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9122 [D loss: 0.5690945684909821 | D accuracy: 67.1875] [G loss: 1.239100694656372]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9123 [D loss: 0.606856644153595 | D accuracy: 67.1875] [G loss: 1.0893902778625488]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "9124 [D loss: 0.5844862163066864 | D accuracy: 65.625] [G loss: 1.0078105926513672]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9125 [D loss: 0.5449396520853043 | D accuracy: 70.3125] [G loss: 1.1159054040908813]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9126 [D loss: 0.48979561030864716 | D accuracy: 75.0] [G loss: 1.0983206033706665]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9127 [D loss: 0.47069382667541504 | D accuracy: 84.375] [G loss: 1.0820834636688232]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9128 [D loss: 0.5031274855136871 | D accuracy: 78.125] [G loss: 1.159691572189331]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9129 [D loss: 0.612116128206253 | D accuracy: 60.9375] [G loss: 1.0877704620361328]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9130 [D loss: 0.5197781920433044 | D accuracy: 71.875] [G loss: 1.1245959997177124]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9131 [D loss: 0.5167304575443268 | D accuracy: 67.1875] [G loss: 1.3248991966247559]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9132 [D loss: 0.558999627828598 | D accuracy: 65.625] [G loss: 1.1450603008270264]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9133 [D loss: 0.4853407144546509 | D accuracy: 76.5625] [G loss: 1.3595695495605469]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9134 [D loss: 0.5032510459423065 | D accuracy: 79.6875] [G loss: 1.236757755279541]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9135 [D loss: 0.4898515045642853 | D accuracy: 78.125] [G loss: 1.2308498620986938]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9136 [D loss: 0.5717930495738983 | D accuracy: 67.1875] [G loss: 1.310316801071167]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9137 [D loss: 0.5934119373559952 | D accuracy: 65.625] [G loss: 1.2839014530181885]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9138 [D loss: 0.5627278983592987 | D accuracy: 73.4375] [G loss: 1.2136123180389404]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9139 [D loss: 0.6200177073478699 | D accuracy: 60.9375] [G loss: 1.1354682445526123]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9140 [D loss: 0.5244417488574982 | D accuracy: 75.0] [G loss: 1.0920655727386475]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9141 [D loss: 0.6252458691596985 | D accuracy: 64.0625] [G loss: 1.0073312520980835]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9142 [D loss: 0.5788875669240952 | D accuracy: 68.75] [G loss: 0.9994655847549438]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9143 [D loss: 0.4633819907903671 | D accuracy: 81.25] [G loss: 1.2731209993362427]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9144 [D loss: 0.5432846248149872 | D accuracy: 70.3125] [G loss: 1.2142058610916138]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9145 [D loss: 0.5738426744937897 | D accuracy: 68.75] [G loss: 1.1608340740203857]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9146 [D loss: 0.49320873618125916 | D accuracy: 75.0] [G loss: 1.128795862197876]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9147 [D loss: 0.5604090690612793 | D accuracy: 67.1875] [G loss: 1.1614105701446533]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9148 [D loss: 0.5748787820339203 | D accuracy: 67.1875] [G loss: 1.2039191722869873]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9149 [D loss: 0.6196267902851105 | D accuracy: 65.625] [G loss: 1.0307424068450928]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9150 [D loss: 0.5401306450366974 | D accuracy: 73.4375] [G loss: 1.2470452785491943]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9151 [D loss: 0.5594356060028076 | D accuracy: 67.1875] [G loss: 1.0723251104354858]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9152 [D loss: 0.4774593710899353 | D accuracy: 75.0] [G loss: 1.2061822414398193]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9153 [D loss: 0.41963276267051697 | D accuracy: 84.375] [G loss: 1.2529860734939575]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9154 [D loss: 0.5560777634382248 | D accuracy: 73.4375] [G loss: 1.1923720836639404]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9155 [D loss: 0.5287643671035767 | D accuracy: 68.75] [G loss: 1.16365385055542]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9156 [D loss: 0.5650418400764465 | D accuracy: 70.3125] [G loss: 1.2126976251602173]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9157 [D loss: 0.5062208771705627 | D accuracy: 73.4375] [G loss: 1.450103759765625]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9158 [D loss: 0.5266219675540924 | D accuracy: 68.75] [G loss: 1.2612923383712769]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9159 [D loss: 0.5258556753396988 | D accuracy: 73.4375] [G loss: 1.2331037521362305]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9160 [D loss: 0.5146158039569855 | D accuracy: 71.875] [G loss: 1.225829839706421]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9161 [D loss: 0.5758780837059021 | D accuracy: 64.0625] [G loss: 1.1966997385025024]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "9162 [D loss: 0.5131695568561554 | D accuracy: 79.6875] [G loss: 1.3195226192474365]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9163 [D loss: 0.5190531015396118 | D accuracy: 70.3125] [G loss: 1.2740286588668823]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "9164 [D loss: 0.5673589110374451 | D accuracy: 68.75] [G loss: 1.1669443845748901]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "9165 [D loss: 0.5697369277477264 | D accuracy: 65.625] [G loss: 1.3020877838134766]\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "9166 [D loss: 0.6124608814716339 | D accuracy: 68.75] [G loss: 1.221718430519104]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "9167 [D loss: 0.6103968322277069 | D accuracy: 62.5] [G loss: 1.1708333492279053]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9168 [D loss: 0.5935293436050415 | D accuracy: 68.75] [G loss: 1.1569944620132446]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9169 [D loss: 0.5199309587478638 | D accuracy: 68.75] [G loss: 1.2089788913726807]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9170 [D loss: 0.47353847324848175 | D accuracy: 84.375] [G loss: 1.298356533050537]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9171 [D loss: 0.5411422103643417 | D accuracy: 73.4375] [G loss: 1.1285667419433594]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9172 [D loss: 0.5479805767536163 | D accuracy: 70.3125] [G loss: 1.1445095539093018]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9173 [D loss: 0.5774753987789154 | D accuracy: 71.875] [G loss: 1.0419998168945312]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9174 [D loss: 0.4227704703807831 | D accuracy: 81.25] [G loss: 1.2630877494812012]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9175 [D loss: 0.4868296980857849 | D accuracy: 78.125] [G loss: 1.2746286392211914]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9176 [D loss: 0.612665057182312 | D accuracy: 68.75] [G loss: 1.2674179077148438]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9177 [D loss: 0.5323695242404938 | D accuracy: 68.75] [G loss: 1.2552211284637451]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9178 [D loss: 0.4657650887966156 | D accuracy: 78.125] [G loss: 1.3654975891113281]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9179 [D loss: 0.6590797007083893 | D accuracy: 60.9375] [G loss: 1.3480437994003296]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9180 [D loss: 0.5988884270191193 | D accuracy: 68.75] [G loss: 1.4105807542800903]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9181 [D loss: 0.5342551618814468 | D accuracy: 65.625] [G loss: 1.3769021034240723]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9182 [D loss: 0.5109235346317291 | D accuracy: 68.75] [G loss: 1.3049503564834595]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9183 [D loss: 0.6502611041069031 | D accuracy: 67.1875] [G loss: 1.245549201965332]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9184 [D loss: 0.6144404411315918 | D accuracy: 62.5] [G loss: 1.2481014728546143]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9185 [D loss: 0.4610946476459503 | D accuracy: 81.25] [G loss: 1.3333933353424072]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9186 [D loss: 0.6382088363170624 | D accuracy: 65.625] [G loss: 1.3863539695739746]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9187 [D loss: 0.5352841764688492 | D accuracy: 70.3125] [G loss: 1.147332787513733]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9188 [D loss: 0.5320961177349091 | D accuracy: 67.1875] [G loss: 1.2603379487991333]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9189 [D loss: 0.5255905091762543 | D accuracy: 71.875] [G loss: 1.2839913368225098]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9190 [D loss: 0.5096418261528015 | D accuracy: 76.5625] [G loss: 1.3039785623550415]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9191 [D loss: 0.44450898468494415 | D accuracy: 79.6875] [G loss: 1.4032485485076904]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9192 [D loss: 0.41485199332237244 | D accuracy: 85.9375] [G loss: 1.2333861589431763]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9193 [D loss: 0.46524642407894135 | D accuracy: 71.875] [G loss: 1.2913235425949097]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9194 [D loss: 0.590359091758728 | D accuracy: 70.3125] [G loss: 1.2118306159973145]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9195 [D loss: 0.42852193117141724 | D accuracy: 82.8125] [G loss: 1.1839087009429932]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9196 [D loss: 0.5797594487667084 | D accuracy: 71.875] [G loss: 1.3399896621704102]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9197 [D loss: 0.5320191234350204 | D accuracy: 70.3125] [G loss: 1.2872674465179443]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9198 [D loss: 0.5602014660835266 | D accuracy: 65.625] [G loss: 1.1356559991836548]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9199 [D loss: 0.5659191012382507 | D accuracy: 71.875] [G loss: 1.3199987411499023]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9200 [D loss: 0.5817432403564453 | D accuracy: 59.375] [G loss: 1.2627952098846436]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9201 [D loss: 0.4889390617609024 | D accuracy: 75.0] [G loss: 1.2092077732086182]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9202 [D loss: 0.5225003361701965 | D accuracy: 67.1875] [G loss: 1.2252452373504639]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "9203 [D loss: 0.48799246549606323 | D accuracy: 71.875] [G loss: 1.2470238208770752]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9204 [D loss: 0.5359023362398148 | D accuracy: 71.875] [G loss: 1.2380040884017944]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9205 [D loss: 0.5241343379020691 | D accuracy: 70.3125] [G loss: 1.250321388244629]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9206 [D loss: 0.4827452600002289 | D accuracy: 81.25] [G loss: 1.1381700038909912]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9207 [D loss: 0.4872835576534271 | D accuracy: 76.5625] [G loss: 1.1176661252975464]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9208 [D loss: 0.580262690782547 | D accuracy: 65.625] [G loss: 1.3015754222869873]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9209 [D loss: 0.5200311839580536 | D accuracy: 71.875] [G loss: 1.105614423751831]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9210 [D loss: 0.6350506842136383 | D accuracy: 59.375] [G loss: 1.1854095458984375]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9211 [D loss: 0.5651014745235443 | D accuracy: 70.3125] [G loss: 1.2873601913452148]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9212 [D loss: 0.4672339856624603 | D accuracy: 75.0] [G loss: 1.215417504310608]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9213 [D loss: 0.4759353697299957 | D accuracy: 79.6875] [G loss: 1.364120364189148]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9214 [D loss: 0.5600971281528473 | D accuracy: 70.3125] [G loss: 1.214688777923584]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9215 [D loss: 0.5162756741046906 | D accuracy: 70.3125] [G loss: 1.1244573593139648]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9216 [D loss: 0.5127622485160828 | D accuracy: 71.875] [G loss: 1.1708637475967407]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9217 [D loss: 0.5060147345066071 | D accuracy: 81.25] [G loss: 1.240569829940796]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9218 [D loss: 0.6140031218528748 | D accuracy: 60.9375] [G loss: 1.2464268207550049]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9219 [D loss: 0.452967569231987 | D accuracy: 79.6875] [G loss: 1.3580982685089111]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9220 [D loss: 0.5029371678829193 | D accuracy: 67.1875] [G loss: 1.2942787408828735]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9221 [D loss: 0.5760420560836792 | D accuracy: 71.875] [G loss: 1.2164729833602905]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9222 [D loss: 0.5222424566745758 | D accuracy: 68.75] [G loss: 1.4015603065490723]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9223 [D loss: 0.6057368516921997 | D accuracy: 64.0625] [G loss: 1.2920420169830322]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9224 [D loss: 0.5025671422481537 | D accuracy: 73.4375] [G loss: 1.348123550415039]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9225 [D loss: 0.6007054150104523 | D accuracy: 70.3125] [G loss: 1.3412147760391235]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9226 [D loss: 0.5215860307216644 | D accuracy: 82.8125] [G loss: 1.1845307350158691]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9227 [D loss: 0.5360473394393921 | D accuracy: 75.0] [G loss: 1.1712802648544312]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9228 [D loss: 0.5265378952026367 | D accuracy: 67.1875] [G loss: 1.4632699489593506]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9229 [D loss: 0.46593326330184937 | D accuracy: 79.6875] [G loss: 1.192809820175171]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9230 [D loss: 0.6167896091938019 | D accuracy: 64.0625] [G loss: 1.1463186740875244]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9231 [D loss: 0.5959767401218414 | D accuracy: 73.4375] [G loss: 1.1919978857040405]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9232 [D loss: 0.5079693496227264 | D accuracy: 79.6875] [G loss: 1.18694007396698]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9233 [D loss: 0.5547491014003754 | D accuracy: 67.1875] [G loss: 1.3108437061309814]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9234 [D loss: 0.5588527321815491 | D accuracy: 73.4375] [G loss: 1.3097419738769531]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "9235 [D loss: 0.5660848021507263 | D accuracy: 67.1875] [G loss: 1.374021291732788]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9236 [D loss: 0.611942708492279 | D accuracy: 64.0625] [G loss: 1.2961769104003906]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9237 [D loss: 0.5247841775417328 | D accuracy: 79.6875] [G loss: 1.2248296737670898]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "9238 [D loss: 0.5065881609916687 | D accuracy: 71.875] [G loss: 1.2862679958343506]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9239 [D loss: 0.6644635200500488 | D accuracy: 60.9375] [G loss: 1.183387041091919]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9240 [D loss: 0.5232152938842773 | D accuracy: 73.4375] [G loss: 1.2528412342071533]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9241 [D loss: 0.5006168484687805 | D accuracy: 75.0] [G loss: 1.2438727617263794]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9242 [D loss: 0.5915118753910065 | D accuracy: 67.1875] [G loss: 1.3746354579925537]\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "9243 [D loss: 0.4338103234767914 | D accuracy: 82.8125] [G loss: 1.2698938846588135]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9244 [D loss: 0.6637110114097595 | D accuracy: 59.375] [G loss: 1.1872578859329224]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9245 [D loss: 0.5264894962310791 | D accuracy: 71.875] [G loss: 1.1839101314544678]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "9246 [D loss: 0.4782251864671707 | D accuracy: 82.8125] [G loss: 1.1917567253112793]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9247 [D loss: 0.5682592689990997 | D accuracy: 65.625] [G loss: 1.1024627685546875]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9248 [D loss: 0.5238909125328064 | D accuracy: 68.75] [G loss: 1.1157760620117188]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9249 [D loss: 0.5903173685073853 | D accuracy: 64.0625] [G loss: 1.1774441003799438]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9250 [D loss: 0.5237170159816742 | D accuracy: 78.125] [G loss: 1.1727595329284668]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9251 [D loss: 0.5280417650938034 | D accuracy: 75.0] [G loss: 1.1429443359375]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9252 [D loss: 0.6831209659576416 | D accuracy: 60.9375] [G loss: 1.2003273963928223]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9253 [D loss: 0.43593502044677734 | D accuracy: 89.0625] [G loss: 1.1260244846343994]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9254 [D loss: 0.5168524831533432 | D accuracy: 67.1875] [G loss: 1.1319289207458496]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9255 [D loss: 0.6670243442058563 | D accuracy: 57.8125] [G loss: 1.271199345588684]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9256 [D loss: 0.6263965964317322 | D accuracy: 59.375] [G loss: 1.2023169994354248]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9257 [D loss: 0.5890567898750305 | D accuracy: 64.0625] [G loss: 1.1186306476593018]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9258 [D loss: 0.582853764295578 | D accuracy: 65.625] [G loss: 1.1626543998718262]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9259 [D loss: 0.5106310695409775 | D accuracy: 76.5625] [G loss: 1.0908699035644531]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9260 [D loss: 0.6267120838165283 | D accuracy: 65.625] [G loss: 1.0485544204711914]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9261 [D loss: 0.4755455553531647 | D accuracy: 81.25] [G loss: 1.0974702835083008]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9262 [D loss: 0.6025145053863525 | D accuracy: 62.5] [G loss: 1.2861851453781128]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9263 [D loss: 0.5676982700824738 | D accuracy: 70.3125] [G loss: 1.3015105724334717]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9264 [D loss: 0.5833820402622223 | D accuracy: 65.625] [G loss: 1.2393158674240112]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9265 [D loss: 0.5648331046104431 | D accuracy: 70.3125] [G loss: 1.1679723262786865]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9266 [D loss: 0.6392652988433838 | D accuracy: 65.625] [G loss: 1.2727999687194824]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9267 [D loss: 0.5836851596832275 | D accuracy: 70.3125] [G loss: 1.1543872356414795]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9268 [D loss: 0.6493464112281799 | D accuracy: 65.625] [G loss: 1.3931818008422852]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9269 [D loss: 0.5537786185741425 | D accuracy: 71.875] [G loss: 1.2571481466293335]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9270 [D loss: 0.5329530239105225 | D accuracy: 73.4375] [G loss: 1.2646905183792114]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9271 [D loss: 0.5994155406951904 | D accuracy: 65.625] [G loss: 1.1684324741363525]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9272 [D loss: 0.44334423542022705 | D accuracy: 76.5625] [G loss: 1.28562331199646]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9273 [D loss: 0.553955614566803 | D accuracy: 68.75] [G loss: 1.1342623233795166]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9274 [D loss: 0.5084863305091858 | D accuracy: 73.4375] [G loss: 1.1762373447418213]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9275 [D loss: 0.5199828445911407 | D accuracy: 75.0] [G loss: 1.1961572170257568]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9276 [D loss: 0.5713990330696106 | D accuracy: 73.4375] [G loss: 1.0936968326568604]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9277 [D loss: 0.532047837972641 | D accuracy: 67.1875] [G loss: 1.0788781642913818]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9278 [D loss: 0.5259539484977722 | D accuracy: 70.3125] [G loss: 1.4075710773468018]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9279 [D loss: 0.5700636506080627 | D accuracy: 73.4375] [G loss: 1.3509865999221802]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9280 [D loss: 0.46713635325431824 | D accuracy: 75.0] [G loss: 1.2449357509613037]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9281 [D loss: 0.5332087278366089 | D accuracy: 71.875] [G loss: 1.2735569477081299]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9282 [D loss: 0.6073945164680481 | D accuracy: 64.0625] [G loss: 1.2582299709320068]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9283 [D loss: 0.5846667587757111 | D accuracy: 67.1875] [G loss: 1.1757519245147705]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9284 [D loss: 0.5400634706020355 | D accuracy: 73.4375] [G loss: 1.2283210754394531]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9285 [D loss: 0.4692430794239044 | D accuracy: 76.5625] [G loss: 1.333076000213623]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9286 [D loss: 0.49708670377731323 | D accuracy: 75.0] [G loss: 1.2133748531341553]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9287 [D loss: 0.5273631811141968 | D accuracy: 70.3125] [G loss: 1.3104126453399658]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9288 [D loss: 0.5608331263065338 | D accuracy: 65.625] [G loss: 1.1850471496582031]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9289 [D loss: 0.4784049987792969 | D accuracy: 78.125] [G loss: 1.1691731214523315]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9290 [D loss: 0.6329028308391571 | D accuracy: 67.1875] [G loss: 1.2389016151428223]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9291 [D loss: 0.6370251476764679 | D accuracy: 60.9375] [G loss: 1.043025016784668]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9292 [D loss: 0.5427424609661102 | D accuracy: 67.1875] [G loss: 1.028247356414795]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9293 [D loss: 0.6002963185310364 | D accuracy: 59.375] [G loss: 1.1867821216583252]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9294 [D loss: 0.6015585362911224 | D accuracy: 59.375] [G loss: 1.1482279300689697]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9295 [D loss: 0.4925037622451782 | D accuracy: 78.125] [G loss: 1.1312897205352783]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9296 [D loss: 0.5762791782617569 | D accuracy: 70.3125] [G loss: 1.1771785020828247]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9297 [D loss: 0.48875923454761505 | D accuracy: 79.6875] [G loss: 1.0922133922576904]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9298 [D loss: 0.5580377578735352 | D accuracy: 70.3125] [G loss: 1.12659752368927]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9299 [D loss: 0.4949379861354828 | D accuracy: 76.5625] [G loss: 1.2948447465896606]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9300 [D loss: 0.6723225712776184 | D accuracy: 60.9375] [G loss: 1.2568082809448242]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9301 [D loss: 0.5893394351005554 | D accuracy: 71.875] [G loss: 1.3090237379074097]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9302 [D loss: 0.5566474199295044 | D accuracy: 71.875] [G loss: 1.309992790222168]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9303 [D loss: 0.608373761177063 | D accuracy: 56.25] [G loss: 1.2413406372070312]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9304 [D loss: 0.5277027189731598 | D accuracy: 78.125] [G loss: 1.1228389739990234]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9305 [D loss: 0.4765303283929825 | D accuracy: 75.0] [G loss: 1.0501788854599]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9306 [D loss: 0.5541256666183472 | D accuracy: 65.625] [G loss: 1.1706212759017944]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9307 [D loss: 0.6175388395786285 | D accuracy: 64.0625] [G loss: 1.1962120532989502]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9308 [D loss: 0.5150669366121292 | D accuracy: 71.875] [G loss: 1.2489986419677734]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9309 [D loss: 0.5573665499687195 | D accuracy: 64.0625] [G loss: 1.1473548412322998]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9310 [D loss: 0.49129022657871246 | D accuracy: 79.6875] [G loss: 1.1907739639282227]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9311 [D loss: 0.5351714491844177 | D accuracy: 75.0] [G loss: 1.2036116123199463]\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "9312 [D loss: 0.6395039260387421 | D accuracy: 70.3125] [G loss: 1.2356271743774414]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9313 [D loss: 0.4797634333372116 | D accuracy: 76.5625] [G loss: 1.3693939447402954]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9314 [D loss: 0.5432949066162109 | D accuracy: 70.3125] [G loss: 1.305311679840088]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9315 [D loss: 0.5455929636955261 | D accuracy: 71.875] [G loss: 1.1931049823760986]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "9316 [D loss: 0.6077733039855957 | D accuracy: 75.0] [G loss: 1.253173828125]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "9317 [D loss: 0.668543666601181 | D accuracy: 67.1875] [G loss: 1.0465896129608154]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9318 [D loss: 0.5578276962041855 | D accuracy: 68.75] [G loss: 1.1726675033569336]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "9319 [D loss: 0.5046835690736771 | D accuracy: 75.0] [G loss: 1.1209449768066406]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9320 [D loss: 0.4916432648897171 | D accuracy: 71.875] [G loss: 1.3802094459533691]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9321 [D loss: 0.5238868296146393 | D accuracy: 71.875] [G loss: 1.2274365425109863]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9322 [D loss: 0.6181758642196655 | D accuracy: 67.1875] [G loss: 1.3591854572296143]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9323 [D loss: 0.5267298966646194 | D accuracy: 73.4375] [G loss: 1.3048920631408691]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9324 [D loss: 0.5550466775894165 | D accuracy: 67.1875] [G loss: 1.2723532915115356]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "9325 [D loss: 0.5570657551288605 | D accuracy: 70.3125] [G loss: 1.289886713027954]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9326 [D loss: 0.5855402648448944 | D accuracy: 71.875] [G loss: 1.194307565689087]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9327 [D loss: 0.4397518187761307 | D accuracy: 85.9375] [G loss: 1.2324650287628174]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9328 [D loss: 0.611213356256485 | D accuracy: 64.0625] [G loss: 1.2252370119094849]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9329 [D loss: 0.4914206713438034 | D accuracy: 78.125] [G loss: 1.1646513938903809]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9330 [D loss: 0.5016961097717285 | D accuracy: 71.875] [G loss: 1.2999393939971924]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9331 [D loss: 0.5004352927207947 | D accuracy: 84.375] [G loss: 1.1734957695007324]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9332 [D loss: 0.560149073600769 | D accuracy: 70.3125] [G loss: 1.1206706762313843]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9333 [D loss: 0.5990584492683411 | D accuracy: 70.3125] [G loss: 1.1527225971221924]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9334 [D loss: 0.5610343366861343 | D accuracy: 71.875] [G loss: 1.1515439748764038]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9335 [D loss: 0.5108164399862289 | D accuracy: 75.0] [G loss: 1.2100056409835815]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9336 [D loss: 0.48719142377376556 | D accuracy: 82.8125] [G loss: 1.2602076530456543]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9337 [D loss: 0.5310402810573578 | D accuracy: 76.5625] [G loss: 1.2147843837738037]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9338 [D loss: 0.601829469203949 | D accuracy: 60.9375] [G loss: 1.2996777296066284]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9339 [D loss: 0.4476749449968338 | D accuracy: 82.8125] [G loss: 1.2855671644210815]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9340 [D loss: 0.5147252678871155 | D accuracy: 75.0] [G loss: 1.314814567565918]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9341 [D loss: 0.5593990683555603 | D accuracy: 71.875] [G loss: 1.1440210342407227]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9342 [D loss: 0.48970048129558563 | D accuracy: 78.125] [G loss: 1.2691541910171509]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9343 [D loss: 0.4769303500652313 | D accuracy: 75.0] [G loss: 1.2999249696731567]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9344 [D loss: 0.5673375427722931 | D accuracy: 67.1875] [G loss: 1.353200912475586]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9345 [D loss: 0.5232623219490051 | D accuracy: 73.4375] [G loss: 1.2541663646697998]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9346 [D loss: 0.6147622466087341 | D accuracy: 64.0625] [G loss: 1.278898000717163]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9347 [D loss: 0.5652951300144196 | D accuracy: 67.1875] [G loss: 1.147341251373291]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9348 [D loss: 0.530811071395874 | D accuracy: 68.75] [G loss: 1.164857268333435]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9349 [D loss: 0.561447411775589 | D accuracy: 67.1875] [G loss: 1.0780863761901855]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9350 [D loss: 0.5062755644321442 | D accuracy: 75.0] [G loss: 1.1186915636062622]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9351 [D loss: 0.5077444314956665 | D accuracy: 73.4375] [G loss: 1.0379068851470947]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9352 [D loss: 0.6417541801929474 | D accuracy: 60.9375] [G loss: 1.2094645500183105]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9353 [D loss: 0.5377033352851868 | D accuracy: 73.4375] [G loss: 1.148021936416626]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9354 [D loss: 0.5044340044260025 | D accuracy: 73.4375] [G loss: 1.112853765487671]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9355 [D loss: 0.49415820837020874 | D accuracy: 73.4375] [G loss: 1.3263907432556152]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9356 [D loss: 0.5418882369995117 | D accuracy: 70.3125] [G loss: 1.231161117553711]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9357 [D loss: 0.5346614420413971 | D accuracy: 67.1875] [G loss: 1.2334799766540527]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9358 [D loss: 0.5232488363981247 | D accuracy: 68.75] [G loss: 1.152130126953125]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9359 [D loss: 0.5527235269546509 | D accuracy: 70.3125] [G loss: 1.2198461294174194]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9360 [D loss: 0.602480411529541 | D accuracy: 57.8125] [G loss: 1.180069923400879]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9361 [D loss: 0.5044036507606506 | D accuracy: 71.875] [G loss: 1.2668622732162476]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9362 [D loss: 0.5941553711891174 | D accuracy: 70.3125] [G loss: 1.221924066543579]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9363 [D loss: 0.6697297096252441 | D accuracy: 56.25] [G loss: 1.204567790031433]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9364 [D loss: 0.56627357006073 | D accuracy: 70.3125] [G loss: 1.1011238098144531]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9365 [D loss: 0.6417911946773529 | D accuracy: 59.375] [G loss: 1.159733772277832]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9366 [D loss: 0.5722691416740417 | D accuracy: 67.1875] [G loss: 1.1110175848007202]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9367 [D loss: 0.5742451846599579 | D accuracy: 71.875] [G loss: 1.2430799007415771]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9368 [D loss: 0.5843521952629089 | D accuracy: 60.9375] [G loss: 1.2072384357452393]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9369 [D loss: 0.5561228692531586 | D accuracy: 68.75] [G loss: 1.3227918148040771]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9370 [D loss: 0.4516727328300476 | D accuracy: 79.6875] [G loss: 1.2645013332366943]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9371 [D loss: 0.49718646705150604 | D accuracy: 75.0] [G loss: 1.1561830043792725]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9372 [D loss: 0.5541135966777802 | D accuracy: 68.75] [G loss: 1.302408218383789]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9373 [D loss: 0.6202954947948456 | D accuracy: 65.625] [G loss: 1.4308242797851562]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9374 [D loss: 0.5388847291469574 | D accuracy: 73.4375] [G loss: 1.258538842201233]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9375 [D loss: 0.6441076099872589 | D accuracy: 64.0625] [G loss: 1.225350260734558]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9376 [D loss: 0.583524227142334 | D accuracy: 68.75] [G loss: 1.1377630233764648]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9377 [D loss: 0.5657682418823242 | D accuracy: 70.3125] [G loss: 1.28169846534729]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9378 [D loss: 0.6258437931537628 | D accuracy: 64.0625] [G loss: 1.3832216262817383]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9379 [D loss: 0.5531589388847351 | D accuracy: 65.625] [G loss: 1.4495761394500732]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9380 [D loss: 0.5488331764936447 | D accuracy: 78.125] [G loss: 1.2371933460235596]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9381 [D loss: 0.5084971934556961 | D accuracy: 68.75] [G loss: 1.2202074527740479]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9382 [D loss: 0.5538540482521057 | D accuracy: 67.1875] [G loss: 1.317297101020813]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9383 [D loss: 0.49641698598861694 | D accuracy: 73.4375] [G loss: 1.3092701435089111]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9384 [D loss: 0.687724381685257 | D accuracy: 57.8125] [G loss: 1.1113697290420532]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9385 [D loss: 0.541458010673523 | D accuracy: 73.4375] [G loss: 1.218893051147461]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9386 [D loss: 0.40946514904499054 | D accuracy: 85.9375] [G loss: 1.2081859111785889]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9387 [D loss: 0.5573096573352814 | D accuracy: 67.1875] [G loss: 1.1375651359558105]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9388 [D loss: 0.5439161658287048 | D accuracy: 75.0] [G loss: 1.0729830265045166]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9389 [D loss: 0.5245733857154846 | D accuracy: 73.4375] [G loss: 1.1849865913391113]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9390 [D loss: 0.5571730434894562 | D accuracy: 70.3125] [G loss: 1.089547872543335]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "9391 [D loss: 0.5436649918556213 | D accuracy: 65.625] [G loss: 1.2458527088165283]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9392 [D loss: 0.46064700186252594 | D accuracy: 78.125] [G loss: 1.2242889404296875]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9393 [D loss: 0.5191471576690674 | D accuracy: 73.4375] [G loss: 1.376593828201294]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9394 [D loss: 0.610393762588501 | D accuracy: 59.375] [G loss: 1.266076683998108]\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "9395 [D loss: 0.5074744522571564 | D accuracy: 78.125] [G loss: 1.1465177536010742]\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "9396 [D loss: 0.6051713228225708 | D accuracy: 70.3125] [G loss: 1.1473020315170288]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9397 [D loss: 0.5889630019664764 | D accuracy: 68.75] [G loss: 1.1603033542633057]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "9398 [D loss: 0.5816823542118073 | D accuracy: 68.75] [G loss: 1.204951524734497]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9399 [D loss: 0.45966836810112 | D accuracy: 73.4375] [G loss: 1.3987581729888916]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9400 [D loss: 0.6030917763710022 | D accuracy: 60.9375] [G loss: 1.3779256343841553]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9401 [D loss: 0.5564001202583313 | D accuracy: 68.75] [G loss: 1.2351866960525513]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9402 [D loss: 0.5162173062562943 | D accuracy: 76.5625] [G loss: 1.3095117807388306]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9403 [D loss: 0.5990933477878571 | D accuracy: 67.1875] [G loss: 1.1443268060684204]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9404 [D loss: 0.5022145658731461 | D accuracy: 75.0] [G loss: 1.2532429695129395]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9405 [D loss: 0.4630148559808731 | D accuracy: 78.125] [G loss: 1.0441304445266724]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9406 [D loss: 0.5120644271373749 | D accuracy: 68.75] [G loss: 1.0689640045166016]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9407 [D loss: 0.48439325392246246 | D accuracy: 76.5625] [G loss: 1.1966432332992554]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9408 [D loss: 0.5652386546134949 | D accuracy: 67.1875] [G loss: 1.3980164527893066]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9409 [D loss: 0.4885675460100174 | D accuracy: 76.5625] [G loss: 1.3207820653915405]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9410 [D loss: 0.4664442837238312 | D accuracy: 76.5625] [G loss: 1.1638128757476807]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9411 [D loss: 0.540075033903122 | D accuracy: 65.625] [G loss: 1.2864019870758057]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9412 [D loss: 0.5045587718486786 | D accuracy: 78.125] [G loss: 1.437696933746338]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9413 [D loss: 0.5267637372016907 | D accuracy: 70.3125] [G loss: 1.3076473474502563]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9414 [D loss: 0.5491759777069092 | D accuracy: 64.0625] [G loss: 1.2970314025878906]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9415 [D loss: 0.5128065943717957 | D accuracy: 68.75] [G loss: 1.2665760517120361]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9416 [D loss: 0.5245045125484467 | D accuracy: 73.4375] [G loss: 1.163741946220398]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9417 [D loss: 0.5316789746284485 | D accuracy: 71.875] [G loss: 1.2333849668502808]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9418 [D loss: 0.594430685043335 | D accuracy: 67.1875] [G loss: 1.3881645202636719]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9419 [D loss: 0.5779310613870621 | D accuracy: 65.625] [G loss: 1.2324321269989014]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9420 [D loss: 0.47592830657958984 | D accuracy: 78.125] [G loss: 1.1834447383880615]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9421 [D loss: 0.6944608092308044 | D accuracy: 60.9375] [G loss: 1.2917168140411377]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9422 [D loss: 0.5650055706501007 | D accuracy: 68.75] [G loss: 1.2139692306518555]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9423 [D loss: 0.5357094407081604 | D accuracy: 73.4375] [G loss: 1.1752771139144897]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9424 [D loss: 0.4630822092294693 | D accuracy: 84.375] [G loss: 1.264632225036621]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9425 [D loss: 0.6071054637432098 | D accuracy: 68.75] [G loss: 1.3036085367202759]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9426 [D loss: 0.5220425128936768 | D accuracy: 73.4375] [G loss: 1.211289405822754]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9427 [D loss: 0.57826367020607 | D accuracy: 59.375] [G loss: 1.2147570848464966]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9428 [D loss: 0.500842422246933 | D accuracy: 73.4375] [G loss: 1.2145776748657227]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9429 [D loss: 0.5275612771511078 | D accuracy: 75.0] [G loss: 1.1393961906433105]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9430 [D loss: 0.5563011765480042 | D accuracy: 76.5625] [G loss: 1.2553057670593262]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9431 [D loss: 0.5551740229129791 | D accuracy: 67.1875] [G loss: 1.1490696668624878]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9432 [D loss: 0.6156256198883057 | D accuracy: 65.625] [G loss: 1.191960334777832]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9433 [D loss: 0.538240373134613 | D accuracy: 73.4375] [G loss: 1.2414460182189941]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9434 [D loss: 0.583301454782486 | D accuracy: 68.75] [G loss: 1.236055612564087]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9435 [D loss: 0.45463553071022034 | D accuracy: 78.125] [G loss: 1.1130467653274536]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9436 [D loss: 0.5888877213001251 | D accuracy: 75.0] [G loss: 1.1597950458526611]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9437 [D loss: 0.5536409020423889 | D accuracy: 68.75] [G loss: 1.0911264419555664]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9438 [D loss: 0.6546979248523712 | D accuracy: 59.375] [G loss: 1.3279762268066406]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9439 [D loss: 0.4939752370119095 | D accuracy: 78.125] [G loss: 1.160656452178955]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9440 [D loss: 0.6167643666267395 | D accuracy: 70.3125] [G loss: 1.231303334236145]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9441 [D loss: 0.5224380493164062 | D accuracy: 71.875] [G loss: 1.106611728668213]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9442 [D loss: 0.4674241691827774 | D accuracy: 79.6875] [G loss: 1.256605863571167]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9443 [D loss: 0.5382608473300934 | D accuracy: 73.4375] [G loss: 1.2411367893218994]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9444 [D loss: 0.5206993222236633 | D accuracy: 67.1875] [G loss: 1.260444164276123]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9445 [D loss: 0.602767825126648 | D accuracy: 65.625] [G loss: 1.2639825344085693]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9446 [D loss: 0.57439985871315 | D accuracy: 62.5] [G loss: 1.2929056882858276]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9447 [D loss: 0.5443251132965088 | D accuracy: 73.4375] [G loss: 1.3820760250091553]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9448 [D loss: 0.6201659440994263 | D accuracy: 64.0625] [G loss: 1.2718355655670166]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9449 [D loss: 0.5688430666923523 | D accuracy: 65.625] [G loss: 1.1888092756271362]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9450 [D loss: 0.4005977511405945 | D accuracy: 85.9375] [G loss: 1.3361607789993286]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9451 [D loss: 0.5443446934223175 | D accuracy: 68.75] [G loss: 1.2126309871673584]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9452 [D loss: 0.6160277128219604 | D accuracy: 62.5] [G loss: 1.2757835388183594]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9453 [D loss: 0.5172691643238068 | D accuracy: 75.0] [G loss: 1.1087124347686768]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9454 [D loss: 0.6030405759811401 | D accuracy: 64.0625] [G loss: 1.0294899940490723]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9455 [D loss: 0.5031412541866302 | D accuracy: 76.5625] [G loss: 1.1060889959335327]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9456 [D loss: 0.5122980624437332 | D accuracy: 76.5625] [G loss: 1.1243281364440918]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9457 [D loss: 0.48584239184856415 | D accuracy: 76.5625] [G loss: 1.2474277019500732]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9458 [D loss: 0.4865128695964813 | D accuracy: 78.125] [G loss: 1.2919927835464478]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9459 [D loss: 0.5563591569662094 | D accuracy: 71.875] [G loss: 1.2290265560150146]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9460 [D loss: 0.610831081867218 | D accuracy: 65.625] [G loss: 1.2390046119689941]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9461 [D loss: 0.6130377352237701 | D accuracy: 65.625] [G loss: 1.2069417238235474]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9462 [D loss: 0.4560834765434265 | D accuracy: 78.125] [G loss: 1.1594126224517822]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9463 [D loss: 0.5613500773906708 | D accuracy: 67.1875] [G loss: 1.1203020811080933]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9464 [D loss: 0.5104926526546478 | D accuracy: 73.4375] [G loss: 1.1966238021850586]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9465 [D loss: 0.51335608959198 | D accuracy: 73.4375] [G loss: 1.156737208366394]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9466 [D loss: 0.619194507598877 | D accuracy: 60.9375] [G loss: 1.206725835800171]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9467 [D loss: 0.5224992632865906 | D accuracy: 75.0] [G loss: 1.2285399436950684]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9468 [D loss: 0.5729215443134308 | D accuracy: 67.1875] [G loss: 1.2187726497650146]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9469 [D loss: 0.5045326948165894 | D accuracy: 76.5625] [G loss: 1.096641182899475]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9470 [D loss: 0.6263336837291718 | D accuracy: 59.375] [G loss: 1.3599133491516113]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9471 [D loss: 0.4990028738975525 | D accuracy: 79.6875] [G loss: 1.3980977535247803]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9472 [D loss: 0.596317708492279 | D accuracy: 65.625] [G loss: 1.1227655410766602]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9473 [D loss: 0.5114824771881104 | D accuracy: 78.125] [G loss: 1.1645604372024536]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "9474 [D loss: 0.6005758345127106 | D accuracy: 65.625] [G loss: 1.2568519115447998]\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "9475 [D loss: 0.5192157030105591 | D accuracy: 73.4375] [G loss: 1.3373643159866333]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9476 [D loss: 0.4479586184024811 | D accuracy: 82.8125] [G loss: 1.3526002168655396]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9477 [D loss: 0.45004698634147644 | D accuracy: 78.125] [G loss: 1.2204821109771729]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9478 [D loss: 0.51747265458107 | D accuracy: 71.875] [G loss: 1.3583276271820068]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9479 [D loss: 0.5873227417469025 | D accuracy: 68.75] [G loss: 1.2530622482299805]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9480 [D loss: 0.5363519936800003 | D accuracy: 70.3125] [G loss: 1.1737229824066162]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9481 [D loss: 0.5014500916004181 | D accuracy: 71.875] [G loss: 1.3418972492218018]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9482 [D loss: 0.4973054975271225 | D accuracy: 75.0] [G loss: 1.172471284866333]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9483 [D loss: 0.4094300866127014 | D accuracy: 78.125] [G loss: 1.4337509870529175]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9484 [D loss: 0.6205744743347168 | D accuracy: 68.75] [G loss: 1.2858829498291016]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9485 [D loss: 0.5324590653181076 | D accuracy: 76.5625] [G loss: 1.2515039443969727]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9486 [D loss: 0.6029373705387115 | D accuracy: 62.5] [G loss: 1.2702683210372925]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9487 [D loss: 0.5394587218761444 | D accuracy: 73.4375] [G loss: 1.3930633068084717]\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "9488 [D loss: 0.6114920973777771 | D accuracy: 62.5] [G loss: 1.2427810430526733]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9489 [D loss: 0.41087280213832855 | D accuracy: 84.375] [G loss: 1.2820641994476318]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9490 [D loss: 0.5185795426368713 | D accuracy: 70.3125] [G loss: 1.1966265439987183]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9491 [D loss: 0.5333993136882782 | D accuracy: 70.3125] [G loss: 1.1350798606872559]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9492 [D loss: 0.6676005721092224 | D accuracy: 60.9375] [G loss: 1.2647778987884521]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9493 [D loss: 0.5073327571153641 | D accuracy: 73.4375] [G loss: 1.4794554710388184]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9494 [D loss: 0.4944451004266739 | D accuracy: 71.875] [G loss: 1.2284088134765625]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9495 [D loss: 0.5011795908212662 | D accuracy: 76.5625] [G loss: 1.12802255153656]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9496 [D loss: 0.5834630727767944 | D accuracy: 70.3125] [G loss: 1.2126144170761108]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9497 [D loss: 0.4954753816127777 | D accuracy: 71.875] [G loss: 1.215897798538208]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9498 [D loss: 0.6148736774921417 | D accuracy: 62.5] [G loss: 1.1132359504699707]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9499 [D loss: 0.5271537601947784 | D accuracy: 76.5625] [G loss: 1.2125606536865234]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9500 [D loss: 0.5572503805160522 | D accuracy: 64.0625] [G loss: 1.235528826713562]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9501 [D loss: 0.46777670085430145 | D accuracy: 84.375] [G loss: 1.155239224433899]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9502 [D loss: 0.6021382212638855 | D accuracy: 64.0625] [G loss: 1.1364014148712158]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9503 [D loss: 0.5369023382663727 | D accuracy: 71.875] [G loss: 1.25228750705719]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9504 [D loss: 0.45276427268981934 | D accuracy: 84.375] [G loss: 1.306136965751648]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9505 [D loss: 0.5209082961082458 | D accuracy: 76.5625] [G loss: 1.110346794128418]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9506 [D loss: 0.5657526254653931 | D accuracy: 67.1875] [G loss: 1.1423218250274658]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9507 [D loss: 0.5192320346832275 | D accuracy: 76.5625] [G loss: 1.1858177185058594]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9508 [D loss: 0.5130607932806015 | D accuracy: 75.0] [G loss: 1.306782841682434]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9509 [D loss: 0.5009596049785614 | D accuracy: 71.875] [G loss: 1.2502353191375732]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9510 [D loss: 0.5027443170547485 | D accuracy: 75.0] [G loss: 1.2283271551132202]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9511 [D loss: 0.562402218580246 | D accuracy: 71.875] [G loss: 1.2932223081588745]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9512 [D loss: 0.5384518504142761 | D accuracy: 76.5625] [G loss: 1.20737886428833]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9513 [D loss: 0.653863936662674 | D accuracy: 64.0625] [G loss: 1.1117196083068848]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9514 [D loss: 0.5011222958564758 | D accuracy: 73.4375] [G loss: 1.2143070697784424]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9515 [D loss: 0.5078303813934326 | D accuracy: 73.4375] [G loss: 1.1474123001098633]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9516 [D loss: 0.4562070071697235 | D accuracy: 79.6875] [G loss: 1.3677761554718018]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9517 [D loss: 0.5384051501750946 | D accuracy: 70.3125] [G loss: 1.285027027130127]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9518 [D loss: 0.5290423929691315 | D accuracy: 75.0] [G loss: 1.1037919521331787]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9519 [D loss: 0.5604896545410156 | D accuracy: 67.1875] [G loss: 1.3142657279968262]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9520 [D loss: 0.5198841094970703 | D accuracy: 75.0] [G loss: 1.081594467163086]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9521 [D loss: 0.5606786906719208 | D accuracy: 71.875] [G loss: 1.1935410499572754]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9522 [D loss: 0.5998518466949463 | D accuracy: 70.3125] [G loss: 1.3212549686431885]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9523 [D loss: 0.5204707682132721 | D accuracy: 75.0] [G loss: 1.3004169464111328]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9524 [D loss: 0.5600508153438568 | D accuracy: 68.75] [G loss: 1.2630388736724854]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9525 [D loss: 0.513454407453537 | D accuracy: 75.0] [G loss: 1.164319634437561]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9526 [D loss: 0.6136431694030762 | D accuracy: 64.0625] [G loss: 1.118517518043518]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9527 [D loss: 0.5236435681581497 | D accuracy: 70.3125] [G loss: 1.2235345840454102]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9528 [D loss: 0.5791763663291931 | D accuracy: 67.1875] [G loss: 1.167435646057129]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9529 [D loss: 0.5307463109493256 | D accuracy: 71.875] [G loss: 1.429488182067871]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9530 [D loss: 0.5078212171792984 | D accuracy: 75.0] [G loss: 1.434516429901123]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9531 [D loss: 0.6577660739421844 | D accuracy: 62.5] [G loss: 1.3594162464141846]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9532 [D loss: 0.6249804198741913 | D accuracy: 59.375] [G loss: 1.2768505811691284]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9533 [D loss: 0.7190068066120148 | D accuracy: 56.25] [G loss: 1.2504668235778809]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9534 [D loss: 0.5737423896789551 | D accuracy: 65.625] [G loss: 1.284433364868164]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "9535 [D loss: 0.5850772857666016 | D accuracy: 68.75] [G loss: 1.3180317878723145]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9536 [D loss: 0.5557307302951813 | D accuracy: 75.0] [G loss: 1.2184890508651733]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9537 [D loss: 0.48504599928855896 | D accuracy: 81.25] [G loss: 1.1502289772033691]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9538 [D loss: 0.43017643690109253 | D accuracy: 79.6875] [G loss: 1.2819476127624512]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9539 [D loss: 0.49213647842407227 | D accuracy: 76.5625] [G loss: 1.347240686416626]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9540 [D loss: 0.47691553831100464 | D accuracy: 84.375] [G loss: 1.2593199014663696]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9541 [D loss: 0.5642352253198624 | D accuracy: 73.4375] [G loss: 1.3173292875289917]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9542 [D loss: 0.581449031829834 | D accuracy: 67.1875] [G loss: 1.1697947978973389]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9543 [D loss: 0.4410254806280136 | D accuracy: 82.8125] [G loss: 1.1733067035675049]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9544 [D loss: 0.5456949174404144 | D accuracy: 76.5625] [G loss: 1.1111116409301758]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9545 [D loss: 0.46036219596862793 | D accuracy: 78.125] [G loss: 1.2386733293533325]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9546 [D loss: 0.5258496105670929 | D accuracy: 71.875] [G loss: 1.3087897300720215]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9547 [D loss: 0.5150475800037384 | D accuracy: 73.4375] [G loss: 1.3929404020309448]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9548 [D loss: 0.6592125296592712 | D accuracy: 64.0625] [G loss: 1.2170360088348389]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9549 [D loss: 0.4500836730003357 | D accuracy: 82.8125] [G loss: 1.1067824363708496]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9550 [D loss: 0.5316244959831238 | D accuracy: 71.875] [G loss: 1.3607079982757568]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9551 [D loss: 0.5965370833873749 | D accuracy: 64.0625] [G loss: 1.2771416902542114]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9552 [D loss: 0.5220800936222076 | D accuracy: 75.0] [G loss: 1.1667643785476685]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9553 [D loss: 0.5623098015785217 | D accuracy: 71.875] [G loss: 1.3657937049865723]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9554 [D loss: 0.49030838906764984 | D accuracy: 76.5625] [G loss: 1.2769558429718018]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9555 [D loss: 0.5916767120361328 | D accuracy: 60.9375] [G loss: 1.2305879592895508]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9556 [D loss: 0.5091284662485123 | D accuracy: 75.0] [G loss: 1.347367525100708]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9557 [D loss: 0.6349549293518066 | D accuracy: 65.625] [G loss: 1.2377183437347412]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9558 [D loss: 0.5346299707889557 | D accuracy: 71.875] [G loss: 1.2322064638137817]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9559 [D loss: 0.5164376199245453 | D accuracy: 71.875] [G loss: 1.167937994003296]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9560 [D loss: 0.6016887426376343 | D accuracy: 64.0625] [G loss: 1.264897108078003]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9561 [D loss: 0.41037124395370483 | D accuracy: 84.375] [G loss: 1.2057411670684814]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9562 [D loss: 0.5665696561336517 | D accuracy: 65.625] [G loss: 1.2429349422454834]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9563 [D loss: 0.6279489994049072 | D accuracy: 65.625] [G loss: 1.2219901084899902]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9564 [D loss: 0.5817583501338959 | D accuracy: 73.4375] [G loss: 1.2422040700912476]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9565 [D loss: 0.6047861576080322 | D accuracy: 67.1875] [G loss: 1.2273098230361938]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9566 [D loss: 0.5286374390125275 | D accuracy: 73.4375] [G loss: 1.1912133693695068]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9567 [D loss: 0.5165718644857407 | D accuracy: 79.6875] [G loss: 1.1749762296676636]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "9568 [D loss: 0.5018156468868256 | D accuracy: 71.875] [G loss: 1.2336788177490234]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9569 [D loss: 0.39954061806201935 | D accuracy: 81.25] [G loss: 1.1216057538986206]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9570 [D loss: 0.5899994969367981 | D accuracy: 67.1875] [G loss: 1.277885913848877]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9571 [D loss: 0.4405490458011627 | D accuracy: 79.6875] [G loss: 1.3357012271881104]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9572 [D loss: 0.4983639121055603 | D accuracy: 73.4375] [G loss: 1.141720175743103]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9573 [D loss: 0.5033370554447174 | D accuracy: 75.0] [G loss: 1.315630316734314]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9574 [D loss: 0.5827855616807938 | D accuracy: 71.875] [G loss: 1.3285412788391113]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9575 [D loss: 0.5790790319442749 | D accuracy: 67.1875] [G loss: 1.1954705715179443]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9576 [D loss: 0.4244468957185745 | D accuracy: 87.5] [G loss: 1.3047045469284058]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9577 [D loss: 0.5107031911611557 | D accuracy: 73.4375] [G loss: 1.235358715057373]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9578 [D loss: 0.6248812675476074 | D accuracy: 54.6875] [G loss: 1.1889728307724]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9579 [D loss: 0.5746256709098816 | D accuracy: 70.3125] [G loss: 1.196847915649414]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9580 [D loss: 0.4838051199913025 | D accuracy: 71.875] [G loss: 1.2935092449188232]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9581 [D loss: 0.5866104364395142 | D accuracy: 70.3125] [G loss: 1.2244964838027954]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9582 [D loss: 0.536402702331543 | D accuracy: 76.5625] [G loss: 1.1686675548553467]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9583 [D loss: 0.6148581206798553 | D accuracy: 65.625] [G loss: 1.1122002601623535]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9584 [D loss: 0.5030955076217651 | D accuracy: 78.125] [G loss: 1.0894718170166016]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9585 [D loss: 0.5123304128646851 | D accuracy: 75.0] [G loss: 1.2886494398117065]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9586 [D loss: 0.5222074091434479 | D accuracy: 71.875] [G loss: 1.2447173595428467]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9587 [D loss: 0.5670693218708038 | D accuracy: 71.875] [G loss: 1.3184230327606201]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9588 [D loss: 0.6517809629440308 | D accuracy: 65.625] [G loss: 1.288515329360962]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9589 [D loss: 0.4851112514734268 | D accuracy: 68.75] [G loss: 1.2637312412261963]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9590 [D loss: 0.4601142704486847 | D accuracy: 79.6875] [G loss: 1.3313930034637451]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9591 [D loss: 0.6321313679218292 | D accuracy: 60.9375] [G loss: 1.3309658765792847]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9592 [D loss: 0.47535181045532227 | D accuracy: 71.875] [G loss: 1.1917729377746582]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9593 [D loss: 0.5716270208358765 | D accuracy: 68.75] [G loss: 1.1824884414672852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9594 [D loss: 0.5503814220428467 | D accuracy: 70.3125] [G loss: 1.2814791202545166]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9595 [D loss: 0.43723803758621216 | D accuracy: 79.6875] [G loss: 1.281095266342163]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9596 [D loss: 0.48589543998241425 | D accuracy: 75.0] [G loss: 1.384699821472168]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9597 [D loss: 0.519379585981369 | D accuracy: 68.75] [G loss: 1.2480854988098145]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9598 [D loss: 0.561208039522171 | D accuracy: 68.75] [G loss: 1.267927646636963]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9599 [D loss: 0.6738675832748413 | D accuracy: 59.375] [G loss: 1.2805595397949219]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9600 [D loss: 0.5347358286380768 | D accuracy: 67.1875] [G loss: 1.2606003284454346]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9601 [D loss: 0.4813704639673233 | D accuracy: 84.375] [G loss: 1.134368658065796]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9602 [D loss: 0.49157392978668213 | D accuracy: 71.875] [G loss: 1.319715976715088]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9603 [D loss: 0.5523073077201843 | D accuracy: 71.875] [G loss: 1.141067385673523]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9604 [D loss: 0.5132156908512115 | D accuracy: 76.5625] [G loss: 1.2088775634765625]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9605 [D loss: 0.5166219174861908 | D accuracy: 78.125] [G loss: 1.117782711982727]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9606 [D loss: 0.5250203013420105 | D accuracy: 68.75] [G loss: 1.161943793296814]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9607 [D loss: 0.5991623103618622 | D accuracy: 65.625] [G loss: 1.2205440998077393]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9608 [D loss: 0.5869638323783875 | D accuracy: 68.75] [G loss: 1.2465070486068726]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9609 [D loss: 0.49237194657325745 | D accuracy: 70.3125] [G loss: 1.2670490741729736]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9610 [D loss: 0.6396926045417786 | D accuracy: 59.375] [G loss: 1.2632588148117065]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9611 [D loss: 0.49824097752571106 | D accuracy: 71.875] [G loss: 1.3189897537231445]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9612 [D loss: 0.4489010274410248 | D accuracy: 81.25] [G loss: 1.263080358505249]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9613 [D loss: 0.5431448519229889 | D accuracy: 70.3125] [G loss: 1.324758529663086]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9614 [D loss: 0.5565139502286911 | D accuracy: 71.875] [G loss: 1.1018911600112915]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9615 [D loss: 0.592107355594635 | D accuracy: 67.1875] [G loss: 1.2186750173568726]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9616 [D loss: 0.566390186548233 | D accuracy: 68.75] [G loss: 1.20634126663208]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9617 [D loss: 0.5065114349126816 | D accuracy: 75.0] [G loss: 1.0405925512313843]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9618 [D loss: 0.5413617491722107 | D accuracy: 75.0] [G loss: 1.223069429397583]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9619 [D loss: 0.6253274977207184 | D accuracy: 59.375] [G loss: 1.1849044561386108]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9620 [D loss: 0.41487516462802887 | D accuracy: 85.9375] [G loss: 1.2726504802703857]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9621 [D loss: 0.5005058944225311 | D accuracy: 78.125] [G loss: 1.2714546918869019]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9622 [D loss: 0.5730141997337341 | D accuracy: 67.1875] [G loss: 1.1323950290679932]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9623 [D loss: 0.5402488708496094 | D accuracy: 73.4375] [G loss: 1.2169345617294312]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9624 [D loss: 0.5475335121154785 | D accuracy: 65.625] [G loss: 1.172386884689331]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9625 [D loss: 0.5322934687137604 | D accuracy: 70.3125] [G loss: 1.325076937675476]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9626 [D loss: 0.6267409026622772 | D accuracy: 62.5] [G loss: 1.211294174194336]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9627 [D loss: 0.47278672456741333 | D accuracy: 82.8125] [G loss: 1.4528061151504517]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9628 [D loss: 0.6563487350940704 | D accuracy: 64.0625] [G loss: 1.200083613395691]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9629 [D loss: 0.5687607526779175 | D accuracy: 67.1875] [G loss: 1.1472203731536865]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9630 [D loss: 0.5646674036979675 | D accuracy: 65.625] [G loss: 1.1448233127593994]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9631 [D loss: 0.5323650687932968 | D accuracy: 68.75] [G loss: 1.2716171741485596]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9632 [D loss: 0.5639825761318207 | D accuracy: 62.5] [G loss: 1.2905490398406982]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9633 [D loss: 0.5609359741210938 | D accuracy: 70.3125] [G loss: 1.227408528327942]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9634 [D loss: 0.4754965305328369 | D accuracy: 76.5625] [G loss: 1.2630774974822998]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9635 [D loss: 0.6352791786193848 | D accuracy: 70.3125] [G loss: 1.183225393295288]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9636 [D loss: 0.521327406167984 | D accuracy: 73.4375] [G loss: 1.25789213180542]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9637 [D loss: 0.5816861689090729 | D accuracy: 65.625] [G loss: 1.3468916416168213]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9638 [D loss: 0.5884942710399628 | D accuracy: 70.3125] [G loss: 1.1410809755325317]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9639 [D loss: 0.6066155433654785 | D accuracy: 68.75] [G loss: 1.0942884683609009]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9640 [D loss: 0.4462102800607681 | D accuracy: 81.25] [G loss: 1.2289237976074219]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9641 [D loss: 0.5174374282360077 | D accuracy: 71.875] [G loss: 1.2543601989746094]\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "9642 [D loss: 0.411783829331398 | D accuracy: 78.125] [G loss: 1.294112205505371]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9643 [D loss: 0.574969932436943 | D accuracy: 71.875] [G loss: 1.216789722442627]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9644 [D loss: 0.5669134259223938 | D accuracy: 73.4375] [G loss: 1.2856448888778687]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9645 [D loss: 0.5819894969463348 | D accuracy: 65.625] [G loss: 1.1713091135025024]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9646 [D loss: 0.49325205385684967 | D accuracy: 71.875] [G loss: 1.1329848766326904]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9647 [D loss: 0.5842728018760681 | D accuracy: 67.1875] [G loss: 1.0518958568572998]\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "9648 [D loss: 0.5522617250680923 | D accuracy: 68.75] [G loss: 1.2078495025634766]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9649 [D loss: 0.5077713578939438 | D accuracy: 73.4375] [G loss: 1.1296353340148926]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "9650 [D loss: 0.5927847325801849 | D accuracy: 65.625] [G loss: 1.3065941333770752]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9651 [D loss: 0.59825000166893 | D accuracy: 57.8125] [G loss: 1.2931482791900635]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9652 [D loss: 0.5704807341098785 | D accuracy: 67.1875] [G loss: 1.2507227659225464]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9653 [D loss: 0.5064929872751236 | D accuracy: 73.4375] [G loss: 1.3096652030944824]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9654 [D loss: 0.5909788608551025 | D accuracy: 67.1875] [G loss: 1.281895637512207]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9655 [D loss: 0.4864172637462616 | D accuracy: 75.0] [G loss: 1.123645544052124]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9656 [D loss: 0.5651290714740753 | D accuracy: 65.625] [G loss: 1.1388347148895264]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9657 [D loss: 0.5662013590335846 | D accuracy: 62.5] [G loss: 1.2223873138427734]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9658 [D loss: 0.5415753126144409 | D accuracy: 70.3125] [G loss: 1.2056043148040771]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9659 [D loss: 0.4722270220518112 | D accuracy: 75.0] [G loss: 1.319326400756836]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9660 [D loss: 0.5365184545516968 | D accuracy: 68.75] [G loss: 1.1575136184692383]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9661 [D loss: 0.5244736969470978 | D accuracy: 78.125] [G loss: 1.2000634670257568]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9662 [D loss: 0.5435232818126678 | D accuracy: 73.4375] [G loss: 1.208054542541504]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9663 [D loss: 0.4612530320882797 | D accuracy: 76.5625] [G loss: 1.313838243484497]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9664 [D loss: 0.46026335656642914 | D accuracy: 79.6875] [G loss: 1.3394500017166138]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9665 [D loss: 0.5487665683031082 | D accuracy: 73.4375] [G loss: 1.309689998626709]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9666 [D loss: 0.6811084747314453 | D accuracy: 64.0625] [G loss: 1.1425235271453857]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9667 [D loss: 0.43297797441482544 | D accuracy: 78.125] [G loss: 1.1933810710906982]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9668 [D loss: 0.4969176650047302 | D accuracy: 79.6875] [G loss: 1.0977699756622314]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9669 [D loss: 0.5090296715497971 | D accuracy: 70.3125] [G loss: 1.232703447341919]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9670 [D loss: 0.4902907907962799 | D accuracy: 73.4375] [G loss: 1.3019790649414062]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9671 [D loss: 0.5846414566040039 | D accuracy: 67.1875] [G loss: 1.2493412494659424]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9672 [D loss: 0.48290401697158813 | D accuracy: 76.5625] [G loss: 1.209431767463684]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9673 [D loss: 0.55338454246521 | D accuracy: 70.3125] [G loss: 1.2737929821014404]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9674 [D loss: 0.5136683434247971 | D accuracy: 68.75] [G loss: 1.1787022352218628]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9675 [D loss: 0.4986928105354309 | D accuracy: 79.6875] [G loss: 1.2877486944198608]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9676 [D loss: 0.5549986362457275 | D accuracy: 67.1875] [G loss: 1.22207772731781]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9677 [D loss: 0.44641630351543427 | D accuracy: 81.25] [G loss: 1.1409090757369995]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9678 [D loss: 0.5351980030536652 | D accuracy: 67.1875] [G loss: 1.1223468780517578]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9679 [D loss: 0.5333015024662018 | D accuracy: 75.0] [G loss: 1.1659189462661743]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9680 [D loss: 0.5795267224311829 | D accuracy: 73.4375] [G loss: 1.2957078218460083]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9681 [D loss: 0.4681500941514969 | D accuracy: 76.5625] [G loss: 1.2241885662078857]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9682 [D loss: 0.5180086493492126 | D accuracy: 76.5625] [G loss: 1.3155946731567383]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9683 [D loss: 0.5193642526865005 | D accuracy: 68.75] [G loss: 1.3624401092529297]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9684 [D loss: 0.5459771156311035 | D accuracy: 73.4375] [G loss: 1.2947204113006592]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9685 [D loss: 0.6677883267402649 | D accuracy: 60.9375] [G loss: 1.2773438692092896]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9686 [D loss: 0.5089583992958069 | D accuracy: 73.4375] [G loss: 1.3218493461608887]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9687 [D loss: 0.48456642031669617 | D accuracy: 79.6875] [G loss: 1.2602622509002686]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9688 [D loss: 0.5799179971218109 | D accuracy: 70.3125] [G loss: 1.1939146518707275]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9689 [D loss: 0.5040340274572372 | D accuracy: 73.4375] [G loss: 1.2711149454116821]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9690 [D loss: 0.5278852581977844 | D accuracy: 70.3125] [G loss: 1.1281390190124512]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9691 [D loss: 0.5502233505249023 | D accuracy: 73.4375] [G loss: 1.2240643501281738]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9692 [D loss: 0.460225909948349 | D accuracy: 79.6875] [G loss: 1.1950428485870361]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9693 [D loss: 0.4709133356809616 | D accuracy: 76.5625] [G loss: 1.1240170001983643]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9694 [D loss: 0.4849109947681427 | D accuracy: 71.875] [G loss: 1.2157477140426636]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9695 [D loss: 0.6150892227888107 | D accuracy: 70.3125] [G loss: 1.3268588781356812]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9696 [D loss: 0.581037849187851 | D accuracy: 68.75] [G loss: 1.5719184875488281]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9697 [D loss: 0.5210484117269516 | D accuracy: 68.75] [G loss: 1.3443843126296997]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9698 [D loss: 0.6219417154788971 | D accuracy: 73.4375] [G loss: 1.310905933380127]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9699 [D loss: 0.5910344421863556 | D accuracy: 65.625] [G loss: 1.0896310806274414]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9700 [D loss: 0.576975554227829 | D accuracy: 68.75] [G loss: 1.0840692520141602]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9701 [D loss: 0.48309603333473206 | D accuracy: 73.4375] [G loss: 1.2457373142242432]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9702 [D loss: 0.6053576469421387 | D accuracy: 64.0625] [G loss: 1.1399683952331543]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9703 [D loss: 0.5613612830638885 | D accuracy: 71.875] [G loss: 1.170117735862732]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9704 [D loss: 0.5201112329959869 | D accuracy: 73.4375] [G loss: 1.1994521617889404]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9705 [D loss: 0.46183787286281586 | D accuracy: 78.125] [G loss: 1.1988041400909424]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9706 [D loss: 0.5386423766613007 | D accuracy: 76.5625] [G loss: 1.3045600652694702]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9707 [D loss: 0.48069746792316437 | D accuracy: 76.5625] [G loss: 1.3691519498825073]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9708 [D loss: 0.5054923892021179 | D accuracy: 76.5625] [G loss: 1.232069492340088]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9709 [D loss: 0.4841681569814682 | D accuracy: 79.6875] [G loss: 1.23946213722229]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9710 [D loss: 0.564047634601593 | D accuracy: 67.1875] [G loss: 1.1596852540969849]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9711 [D loss: 0.5426478981971741 | D accuracy: 73.4375] [G loss: 1.2419103384017944]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9712 [D loss: 0.5904708504676819 | D accuracy: 71.875] [G loss: 1.1622016429901123]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9713 [D loss: 0.6071327328681946 | D accuracy: 67.1875] [G loss: 1.2584232091903687]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9714 [D loss: 0.5370417535305023 | D accuracy: 70.3125] [G loss: 1.2915581464767456]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9715 [D loss: 0.46634775400161743 | D accuracy: 75.0] [G loss: 1.131940245628357]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9716 [D loss: 0.5323260426521301 | D accuracy: 75.0] [G loss: 1.086318016052246]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9717 [D loss: 0.5578857660293579 | D accuracy: 70.3125] [G loss: 1.1368693113327026]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9718 [D loss: 0.5632427036762238 | D accuracy: 75.0] [G loss: 1.1967073678970337]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9719 [D loss: 0.6343730688095093 | D accuracy: 68.75] [G loss: 1.2421131134033203]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "9720 [D loss: 0.5061495751142502 | D accuracy: 73.4375] [G loss: 1.167402982711792]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9721 [D loss: 0.508500725030899 | D accuracy: 75.0] [G loss: 1.2278820276260376]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9722 [D loss: 0.5516257882118225 | D accuracy: 65.625] [G loss: 1.2019257545471191]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9723 [D loss: 0.5648358464241028 | D accuracy: 71.875] [G loss: 1.219197154045105]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9724 [D loss: 0.501435711979866 | D accuracy: 70.3125] [G loss: 1.1584081649780273]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9725 [D loss: 0.6591896712779999 | D accuracy: 53.125] [G loss: 1.1681928634643555]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9726 [D loss: 0.5349037647247314 | D accuracy: 70.3125] [G loss: 1.0984508991241455]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9727 [D loss: 0.587486058473587 | D accuracy: 64.0625] [G loss: 1.1707353591918945]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "9728 [D loss: 0.47326841950416565 | D accuracy: 76.5625] [G loss: 1.2890496253967285]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9729 [D loss: 0.5832438766956329 | D accuracy: 64.0625] [G loss: 1.2460941076278687]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9730 [D loss: 0.5216239392757416 | D accuracy: 71.875] [G loss: 1.1313843727111816]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9731 [D loss: 0.4622535705566406 | D accuracy: 75.0] [G loss: 1.211954116821289]\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "9732 [D loss: 0.48871323466300964 | D accuracy: 76.5625] [G loss: 1.249589443206787]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9733 [D loss: 0.5087362676858902 | D accuracy: 75.0] [G loss: 1.175736665725708]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9734 [D loss: 0.5896280407905579 | D accuracy: 65.625] [G loss: 1.1979975700378418]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9735 [D loss: 0.6060498356819153 | D accuracy: 64.0625] [G loss: 1.1114857196807861]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9736 [D loss: 0.5119000822305679 | D accuracy: 78.125] [G loss: 1.1375155448913574]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9737 [D loss: 0.4906511604785919 | D accuracy: 75.0] [G loss: 1.2070118188858032]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9738 [D loss: 0.5372495055198669 | D accuracy: 68.75] [G loss: 1.1902437210083008]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9739 [D loss: 0.587552934885025 | D accuracy: 67.1875] [G loss: 1.1874175071716309]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9740 [D loss: 0.518850177526474 | D accuracy: 75.0] [G loss: 1.0706253051757812]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9741 [D loss: 0.5089043080806732 | D accuracy: 78.125] [G loss: 1.1920067071914673]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9742 [D loss: 0.5093373656272888 | D accuracy: 70.3125] [G loss: 1.2115064859390259]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9743 [D loss: 0.49500253796577454 | D accuracy: 68.75] [G loss: 1.2624871730804443]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9744 [D loss: 0.4891005903482437 | D accuracy: 78.125] [G loss: 1.2860751152038574]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9745 [D loss: 0.5066836476325989 | D accuracy: 73.4375] [G loss: 1.3444223403930664]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9746 [D loss: 0.544039785861969 | D accuracy: 68.75] [G loss: 1.3249046802520752]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9747 [D loss: 0.636236846446991 | D accuracy: 59.375] [G loss: 1.3853561878204346]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9748 [D loss: 0.5502932369709015 | D accuracy: 71.875] [G loss: 1.155766248703003]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9749 [D loss: 0.5105268359184265 | D accuracy: 73.4375] [G loss: 1.216970443725586]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9750 [D loss: 0.48018912971019745 | D accuracy: 82.8125] [G loss: 1.3074538707733154]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9751 [D loss: 0.565286248922348 | D accuracy: 76.5625] [G loss: 1.2498962879180908]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9752 [D loss: 0.49303245544433594 | D accuracy: 76.5625] [G loss: 1.443567156791687]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9753 [D loss: 0.5735875368118286 | D accuracy: 65.625] [G loss: 1.1870046854019165]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9754 [D loss: 0.5014305859804153 | D accuracy: 76.5625] [G loss: 1.1576567888259888]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9755 [D loss: 0.6197049617767334 | D accuracy: 59.375] [G loss: 1.143718957901001]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9756 [D loss: 0.5183615386486053 | D accuracy: 78.125] [G loss: 1.253988265991211]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9757 [D loss: 0.5051350444555283 | D accuracy: 73.4375] [G loss: 1.1382145881652832]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9758 [D loss: 0.5089810788631439 | D accuracy: 78.125] [G loss: 1.183258056640625]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9759 [D loss: 0.510788157582283 | D accuracy: 75.0] [G loss: 1.2824256420135498]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9760 [D loss: 0.4978797435760498 | D accuracy: 71.875] [G loss: 1.2885384559631348]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9761 [D loss: 0.48018093407154083 | D accuracy: 73.4375] [G loss: 1.249369502067566]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9762 [D loss: 0.47818873822689056 | D accuracy: 75.0] [G loss: 1.3833296298980713]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9763 [D loss: 0.573800802230835 | D accuracy: 68.75] [G loss: 1.3289077281951904]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9764 [D loss: 0.4444689452648163 | D accuracy: 76.5625] [G loss: 1.2796902656555176]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9765 [D loss: 0.509553536772728 | D accuracy: 70.3125] [G loss: 1.5431854724884033]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9766 [D loss: 0.606448233127594 | D accuracy: 68.75] [G loss: 1.3744564056396484]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9767 [D loss: 0.5432376116514206 | D accuracy: 71.875] [G loss: 1.2813477516174316]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9768 [D loss: 0.5450966656208038 | D accuracy: 71.875] [G loss: 1.2251005172729492]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9769 [D loss: 0.5770933926105499 | D accuracy: 65.625] [G loss: 1.1225001811981201]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9770 [D loss: 0.5495933294296265 | D accuracy: 68.75] [G loss: 1.1423571109771729]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9771 [D loss: 0.5812192559242249 | D accuracy: 64.0625] [G loss: 1.4415099620819092]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9772 [D loss: 0.46483172476291656 | D accuracy: 75.0] [G loss: 1.40651535987854]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9773 [D loss: 0.517426609992981 | D accuracy: 73.4375] [G loss: 1.3319957256317139]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9774 [D loss: 0.515476256608963 | D accuracy: 71.875] [G loss: 1.3385913372039795]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9775 [D loss: 0.5371534824371338 | D accuracy: 71.875] [G loss: 1.2435674667358398]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9776 [D loss: 0.4962110072374344 | D accuracy: 75.0] [G loss: 1.249937891960144]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9777 [D loss: 0.5916523933410645 | D accuracy: 73.4375] [G loss: 1.1616417169570923]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9778 [D loss: 0.5572315901517868 | D accuracy: 65.625] [G loss: 1.338744878768921]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9779 [D loss: 0.5930486023426056 | D accuracy: 64.0625] [G loss: 1.296668291091919]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9780 [D loss: 0.5064201951026917 | D accuracy: 75.0] [G loss: 1.3501412868499756]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9781 [D loss: 0.5782587081193924 | D accuracy: 68.75] [G loss: 1.199540615081787]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9782 [D loss: 0.4957675337791443 | D accuracy: 76.5625] [G loss: 1.2661492824554443]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9783 [D loss: 0.5901025533676147 | D accuracy: 73.4375] [G loss: 1.306976079940796]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9784 [D loss: 0.6903040409088135 | D accuracy: 56.25] [G loss: 1.2991563081741333]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9785 [D loss: 0.6146738827228546 | D accuracy: 59.375] [G loss: 1.2507424354553223]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9786 [D loss: 0.5843763947486877 | D accuracy: 60.9375] [G loss: 1.2290065288543701]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9787 [D loss: 0.47990575432777405 | D accuracy: 82.8125] [G loss: 1.2386529445648193]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9788 [D loss: 0.4705829471349716 | D accuracy: 81.25] [G loss: 1.2785396575927734]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9789 [D loss: 0.5579088181257248 | D accuracy: 73.4375] [G loss: 1.1761244535446167]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9790 [D loss: 0.6255423128604889 | D accuracy: 60.9375] [G loss: 1.3326691389083862]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9791 [D loss: 0.4770725220441818 | D accuracy: 76.5625] [G loss: 1.2208914756774902]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9792 [D loss: 0.4843504726886749 | D accuracy: 84.375] [G loss: 1.2437065839767456]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9793 [D loss: 0.5534134954214096 | D accuracy: 68.75] [G loss: 1.3162109851837158]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9794 [D loss: 0.6309159696102142 | D accuracy: 68.75] [G loss: 1.3470382690429688]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9795 [D loss: 0.6020832061767578 | D accuracy: 71.875] [G loss: 1.1276628971099854]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9796 [D loss: 0.6011290848255157 | D accuracy: 67.1875] [G loss: 1.2753901481628418]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9797 [D loss: 0.5613877773284912 | D accuracy: 68.75] [G loss: 1.15321946144104]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9798 [D loss: 0.48728013038635254 | D accuracy: 70.3125] [G loss: 1.2702692747116089]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9799 [D loss: 0.5819077789783478 | D accuracy: 65.625] [G loss: 1.332045316696167]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9800 [D loss: 0.4888208210468292 | D accuracy: 76.5625] [G loss: 1.1845600605010986]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9801 [D loss: 0.5230168998241425 | D accuracy: 76.5625] [G loss: 1.3105192184448242]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9802 [D loss: 0.5487621426582336 | D accuracy: 76.5625] [G loss: 1.3143343925476074]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9803 [D loss: 0.5723122358322144 | D accuracy: 70.3125] [G loss: 1.3102645874023438]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9804 [D loss: 0.5666224360466003 | D accuracy: 75.0] [G loss: 1.2169525623321533]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9805 [D loss: 0.5630239397287369 | D accuracy: 78.125] [G loss: 1.1607036590576172]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9806 [D loss: 0.48346997797489166 | D accuracy: 73.4375] [G loss: 1.168134331703186]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9807 [D loss: 0.5092634558677673 | D accuracy: 73.4375] [G loss: 1.2675068378448486]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9808 [D loss: 0.5389940440654755 | D accuracy: 79.6875] [G loss: 1.0718464851379395]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9809 [D loss: 0.5824241936206818 | D accuracy: 65.625] [G loss: 1.1209728717803955]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9810 [D loss: 0.46228115260601044 | D accuracy: 81.25] [G loss: 1.307623028755188]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9811 [D loss: 0.5058796405792236 | D accuracy: 81.25] [G loss: 1.1235742568969727]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9812 [D loss: 0.5381893515586853 | D accuracy: 68.75] [G loss: 1.1584463119506836]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9813 [D loss: 0.582818865776062 | D accuracy: 67.1875] [G loss: 1.178030014038086]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9814 [D loss: 0.6256971061229706 | D accuracy: 59.375] [G loss: 1.175896406173706]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9815 [D loss: 0.5839232802391052 | D accuracy: 68.75] [G loss: 1.316490650177002]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9816 [D loss: 0.501251757144928 | D accuracy: 81.25] [G loss: 1.130771279335022]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9817 [D loss: 0.5647590160369873 | D accuracy: 68.75] [G loss: 1.1550019979476929]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9818 [D loss: 0.5631573498249054 | D accuracy: 68.75] [G loss: 1.3611202239990234]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9819 [D loss: 0.4947633445262909 | D accuracy: 76.5625] [G loss: 1.1830430030822754]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9820 [D loss: 0.5998669862747192 | D accuracy: 65.625] [G loss: 1.2327427864074707]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9821 [D loss: 0.42972853779792786 | D accuracy: 78.125] [G loss: 1.1853108406066895]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9822 [D loss: 0.5242110788822174 | D accuracy: 67.1875] [G loss: 1.2257832288742065]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9823 [D loss: 0.6419138610363007 | D accuracy: 57.8125] [G loss: 1.144766092300415]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9824 [D loss: 0.4985707104206085 | D accuracy: 78.125] [G loss: 1.271740436553955]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9825 [D loss: 0.543350338935852 | D accuracy: 70.3125] [G loss: 1.3099215030670166]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9826 [D loss: 0.5535760074853897 | D accuracy: 67.1875] [G loss: 1.3004214763641357]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9827 [D loss: 0.5617441236972809 | D accuracy: 70.3125] [G loss: 1.1405364274978638]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9828 [D loss: 0.5674374848604202 | D accuracy: 71.875] [G loss: 1.3522241115570068]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9829 [D loss: 0.49043868482112885 | D accuracy: 78.125] [G loss: 1.3328182697296143]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9830 [D loss: 0.5612204372882843 | D accuracy: 75.0] [G loss: 1.364973783493042]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9831 [D loss: 0.5197054445743561 | D accuracy: 73.4375] [G loss: 1.35165536403656]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9832 [D loss: 0.4748372435569763 | D accuracy: 79.6875] [G loss: 1.3705251216888428]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9833 [D loss: 0.5256919264793396 | D accuracy: 73.4375] [G loss: 1.1901012659072876]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9834 [D loss: 0.5031613707542419 | D accuracy: 75.0] [G loss: 1.3870689868927002]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9835 [D loss: 0.5761055648326874 | D accuracy: 68.75] [G loss: 1.3739709854125977]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9836 [D loss: 0.6368623375892639 | D accuracy: 64.0625] [G loss: 1.3968003988265991]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9837 [D loss: 0.5541658699512482 | D accuracy: 64.0625] [G loss: 1.1656016111373901]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9838 [D loss: 0.4600234478712082 | D accuracy: 85.9375] [G loss: 1.2306925058364868]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9839 [D loss: 0.5043689608573914 | D accuracy: 79.6875] [G loss: 1.3091673851013184]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9840 [D loss: 0.4901582598686218 | D accuracy: 79.6875] [G loss: 1.2333645820617676]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9841 [D loss: 0.5288258194923401 | D accuracy: 70.3125] [G loss: 1.2833811044692993]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9842 [D loss: 0.5218315869569778 | D accuracy: 73.4375] [G loss: 1.413069725036621]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9843 [D loss: 0.5082737058401108 | D accuracy: 75.0] [G loss: 1.3819929361343384]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9844 [D loss: 0.511839896440506 | D accuracy: 71.875] [G loss: 1.3921314477920532]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9845 [D loss: 0.5436718314886093 | D accuracy: 73.4375] [G loss: 1.2411991357803345]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9846 [D loss: 0.5597772151231766 | D accuracy: 68.75] [G loss: 1.246250867843628]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9847 [D loss: 0.507018119096756 | D accuracy: 64.0625] [G loss: 1.327711582183838]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9848 [D loss: 0.6367309987545013 | D accuracy: 71.875] [G loss: 1.3221427202224731]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9849 [D loss: 0.4484126716852188 | D accuracy: 79.6875] [G loss: 1.249572992324829]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9850 [D loss: 0.5290521383285522 | D accuracy: 78.125] [G loss: 1.295238733291626]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9851 [D loss: 0.617251843214035 | D accuracy: 65.625] [G loss: 1.2404953241348267]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9852 [D loss: 0.6074095964431763 | D accuracy: 65.625] [G loss: 1.3577948808670044]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9853 [D loss: 0.6689958274364471 | D accuracy: 56.25] [G loss: 1.180420160293579]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9854 [D loss: 0.4758980870246887 | D accuracy: 76.5625] [G loss: 1.194061517715454]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9855 [D loss: 0.49975134432315826 | D accuracy: 75.0] [G loss: 1.1401257514953613]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9856 [D loss: 0.5944815278053284 | D accuracy: 68.75] [G loss: 1.3455147743225098]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9857 [D loss: 0.4732877165079117 | D accuracy: 79.6875] [G loss: 1.3178114891052246]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9858 [D loss: 0.5442403554916382 | D accuracy: 73.4375] [G loss: 1.1171584129333496]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9859 [D loss: 0.5786151587963104 | D accuracy: 68.75] [G loss: 1.2431010007858276]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9860 [D loss: 0.5107553005218506 | D accuracy: 75.0] [G loss: 1.3228979110717773]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9861 [D loss: 0.5064429044723511 | D accuracy: 68.75] [G loss: 1.1531983613967896]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9862 [D loss: 0.486958846449852 | D accuracy: 78.125] [G loss: 1.204980731010437]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9863 [D loss: 0.5312824100255966 | D accuracy: 76.5625] [G loss: 1.192535638809204]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9864 [D loss: 0.5493888556957245 | D accuracy: 71.875] [G loss: 1.2466449737548828]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9865 [D loss: 0.5693487524986267 | D accuracy: 68.75] [G loss: 1.209945797920227]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9866 [D loss: 0.6537625193595886 | D accuracy: 60.9375] [G loss: 1.160565972328186]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9867 [D loss: 0.5753778219223022 | D accuracy: 67.1875] [G loss: 1.1707127094268799]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9868 [D loss: 0.567815363407135 | D accuracy: 67.1875] [G loss: 1.0721945762634277]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9869 [D loss: 0.49709226191043854 | D accuracy: 75.0] [G loss: 1.320360779762268]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9870 [D loss: 0.6432358026504517 | D accuracy: 64.0625] [G loss: 1.3418320417404175]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9871 [D loss: 0.6073864996433258 | D accuracy: 64.0625] [G loss: 1.2917250394821167]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9872 [D loss: 0.4679548442363739 | D accuracy: 73.4375] [G loss: 1.4001516103744507]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9873 [D loss: 0.4806465208530426 | D accuracy: 76.5625] [G loss: 1.251776099205017]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9874 [D loss: 0.5093809068202972 | D accuracy: 75.0] [G loss: 1.2175885438919067]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9875 [D loss: 0.5450878441333771 | D accuracy: 71.875] [G loss: 1.1542608737945557]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9876 [D loss: 0.5077282786369324 | D accuracy: 75.0] [G loss: 1.1265809535980225]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9877 [D loss: 0.5808267891407013 | D accuracy: 64.0625] [G loss: 1.1686562299728394]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9878 [D loss: 0.5015026181936264 | D accuracy: 76.5625] [G loss: 1.3894143104553223]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9879 [D loss: 0.5226887166500092 | D accuracy: 65.625] [G loss: 1.3292299509048462]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9880 [D loss: 0.6330157518386841 | D accuracy: 59.375] [G loss: 1.238938808441162]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9881 [D loss: 0.4822506159543991 | D accuracy: 73.4375] [G loss: 1.363268494606018]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9882 [D loss: 0.5047069489955902 | D accuracy: 75.0] [G loss: 1.2038729190826416]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9883 [D loss: 0.5109956860542297 | D accuracy: 76.5625] [G loss: 1.1801867485046387]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9884 [D loss: 0.5240793526172638 | D accuracy: 71.875] [G loss: 1.2688416242599487]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9885 [D loss: 0.428161084651947 | D accuracy: 81.25] [G loss: 1.3987083435058594]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "9886 [D loss: 0.6119197905063629 | D accuracy: 65.625] [G loss: 1.2996739149093628]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9887 [D loss: 0.5798444151878357 | D accuracy: 68.75] [G loss: 1.1303415298461914]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "9888 [D loss: 0.5641860663890839 | D accuracy: 64.0625] [G loss: 1.1750202178955078]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9889 [D loss: 0.5587740838527679 | D accuracy: 73.4375] [G loss: 1.1054201126098633]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9890 [D loss: 0.4953354299068451 | D accuracy: 79.6875] [G loss: 1.1057336330413818]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9891 [D loss: 0.5592258274555206 | D accuracy: 71.875] [G loss: 1.2720656394958496]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9892 [D loss: 0.5866947174072266 | D accuracy: 67.1875] [G loss: 1.2459633350372314]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "9893 [D loss: 0.530772864818573 | D accuracy: 75.0] [G loss: 1.2881410121917725]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9894 [D loss: 0.5458110570907593 | D accuracy: 71.875] [G loss: 1.1747032403945923]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9895 [D loss: 0.4453869163990021 | D accuracy: 79.6875] [G loss: 1.1816481351852417]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9896 [D loss: 0.4652027189731598 | D accuracy: 76.5625] [G loss: 1.2567553520202637]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9897 [D loss: 0.48240926861763 | D accuracy: 85.9375] [G loss: 1.3373048305511475]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9898 [D loss: 0.5092042237520218 | D accuracy: 71.875] [G loss: 1.2803635597229004]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9899 [D loss: 0.6289701163768768 | D accuracy: 62.5] [G loss: 1.1154409646987915]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9900 [D loss: 0.4234277755022049 | D accuracy: 84.375] [G loss: 1.2073124647140503]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9901 [D loss: 0.40770554542541504 | D accuracy: 87.5] [G loss: 1.3768945932388306]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9902 [D loss: 0.5657141208648682 | D accuracy: 67.1875] [G loss: 1.3966418504714966]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9903 [D loss: 0.5220552980899811 | D accuracy: 76.5625] [G loss: 1.4085204601287842]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9904 [D loss: 0.5199465304613113 | D accuracy: 78.125] [G loss: 1.3347938060760498]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9905 [D loss: 0.5816529095172882 | D accuracy: 67.1875] [G loss: 1.2919554710388184]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9906 [D loss: 0.4859251230955124 | D accuracy: 73.4375] [G loss: 1.1461987495422363]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9907 [D loss: 0.5949362814426422 | D accuracy: 64.0625] [G loss: 1.2128305435180664]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9908 [D loss: 0.5219010710716248 | D accuracy: 73.4375] [G loss: 1.2857131958007812]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9909 [D loss: 0.5248181223869324 | D accuracy: 70.3125] [G loss: 1.195380687713623]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9910 [D loss: 0.6377246379852295 | D accuracy: 56.25] [G loss: 1.1483142375946045]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9911 [D loss: 0.5447010397911072 | D accuracy: 68.75] [G loss: 1.1629830598831177]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9912 [D loss: 0.5249373912811279 | D accuracy: 71.875] [G loss: 1.2615423202514648]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9913 [D loss: 0.545876681804657 | D accuracy: 71.875] [G loss: 1.1948344707489014]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9914 [D loss: 0.5350552499294281 | D accuracy: 73.4375] [G loss: 1.150244951248169]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9915 [D loss: 0.43293847143650055 | D accuracy: 81.25] [G loss: 1.2105779647827148]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9916 [D loss: 0.5957441627979279 | D accuracy: 65.625] [G loss: 1.3855462074279785]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9917 [D loss: 0.5713054239749908 | D accuracy: 59.375] [G loss: 1.2598531246185303]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9918 [D loss: 0.4888617992401123 | D accuracy: 76.5625] [G loss: 1.322722315788269]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9919 [D loss: 0.577244371175766 | D accuracy: 70.3125] [G loss: 1.2472946643829346]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9920 [D loss: 0.5509617924690247 | D accuracy: 68.75] [G loss: 1.2282400131225586]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9921 [D loss: 0.5728908479213715 | D accuracy: 70.3125] [G loss: 1.1634948253631592]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9922 [D loss: 0.5777283906936646 | D accuracy: 65.625] [G loss: 1.1492462158203125]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9923 [D loss: 0.522785872220993 | D accuracy: 70.3125] [G loss: 1.3128547668457031]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9924 [D loss: 0.46386393904685974 | D accuracy: 79.6875] [G loss: 1.3494257926940918]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9925 [D loss: 0.5629390329122543 | D accuracy: 67.1875] [G loss: 1.307864785194397]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9926 [D loss: 0.5352253019809723 | D accuracy: 64.0625] [G loss: 1.2995940446853638]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9927 [D loss: 0.463639497756958 | D accuracy: 76.5625] [G loss: 1.2681924104690552]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "9928 [D loss: 0.5098682641983032 | D accuracy: 71.875] [G loss: 1.1871941089630127]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9929 [D loss: 0.522263690829277 | D accuracy: 65.625] [G loss: 1.251556634902954]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9930 [D loss: 0.515297070145607 | D accuracy: 75.0] [G loss: 1.169246792793274]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9931 [D loss: 0.46079501509666443 | D accuracy: 78.125] [G loss: 1.1100459098815918]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "9932 [D loss: 0.4542621523141861 | D accuracy: 85.9375] [G loss: 1.201721429824829]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9933 [D loss: 0.5167193710803986 | D accuracy: 75.0] [G loss: 1.2335646152496338]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9934 [D loss: 0.5218503624200821 | D accuracy: 79.6875] [G loss: 1.2549397945404053]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9935 [D loss: 0.44912882149219513 | D accuracy: 84.375] [G loss: 1.2409988641738892]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9936 [D loss: 0.595203161239624 | D accuracy: 64.0625] [G loss: 1.33282470703125]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9937 [D loss: 0.5939067900180817 | D accuracy: 70.3125] [G loss: 1.4451388120651245]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "9938 [D loss: 0.5620321333408356 | D accuracy: 60.9375] [G loss: 1.3604990243911743]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9939 [D loss: 0.5079630017280579 | D accuracy: 70.3125] [G loss: 1.3000364303588867]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "9940 [D loss: 0.46866363286972046 | D accuracy: 75.0] [G loss: 1.29152250289917]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9941 [D loss: 0.5018382519483566 | D accuracy: 75.0] [G loss: 1.3156249523162842]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9942 [D loss: 0.5134082138538361 | D accuracy: 76.5625] [G loss: 1.187574863433838]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9943 [D loss: 0.5186273008584976 | D accuracy: 71.875] [G loss: 1.230229139328003]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9944 [D loss: 0.5935230255126953 | D accuracy: 70.3125] [G loss: 1.1655213832855225]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9945 [D loss: 0.522876963019371 | D accuracy: 78.125] [G loss: 1.197251796722412]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9946 [D loss: 0.5483680367469788 | D accuracy: 71.875] [G loss: 1.2170782089233398]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9947 [D loss: 0.48675450682640076 | D accuracy: 76.5625] [G loss: 1.210382342338562]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9948 [D loss: 0.5645689368247986 | D accuracy: 67.1875] [G loss: 1.1745972633361816]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9949 [D loss: 0.4801909625530243 | D accuracy: 78.125] [G loss: 1.2261192798614502]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9950 [D loss: 0.5686562955379486 | D accuracy: 68.75] [G loss: 1.2126872539520264]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9951 [D loss: 0.5753265619277954 | D accuracy: 73.4375] [G loss: 1.1292545795440674]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9952 [D loss: 0.4345886707305908 | D accuracy: 79.6875] [G loss: 1.2860193252563477]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9953 [D loss: 0.5453868955373764 | D accuracy: 70.3125] [G loss: 1.314573049545288]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9954 [D loss: 0.487880602478981 | D accuracy: 76.5625] [G loss: 1.4173145294189453]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9955 [D loss: 0.5270647406578064 | D accuracy: 68.75] [G loss: 1.351349949836731]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9956 [D loss: 0.5403488129377365 | D accuracy: 68.75] [G loss: 1.2297770977020264]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9957 [D loss: 0.5510754287242889 | D accuracy: 70.3125] [G loss: 1.460533618927002]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9958 [D loss: 0.4829910546541214 | D accuracy: 76.5625] [G loss: 1.3386791944503784]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9959 [D loss: 0.5823871046304703 | D accuracy: 67.1875] [G loss: 1.0396714210510254]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9960 [D loss: 0.5006127208471298 | D accuracy: 75.0] [G loss: 1.1801412105560303]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9961 [D loss: 0.5622347295284271 | D accuracy: 71.875] [G loss: 1.0759721994400024]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9962 [D loss: 0.504232332110405 | D accuracy: 75.0] [G loss: 1.294893741607666]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9963 [D loss: 0.49192696809768677 | D accuracy: 82.8125] [G loss: 1.16654372215271]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9964 [D loss: 0.5024604201316833 | D accuracy: 71.875] [G loss: 1.4136631488800049]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9965 [D loss: 0.4974677711725235 | D accuracy: 73.4375] [G loss: 1.2766101360321045]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9966 [D loss: 0.5312028229236603 | D accuracy: 75.0] [G loss: 1.485432505607605]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9967 [D loss: 0.605425238609314 | D accuracy: 67.1875] [G loss: 1.3349027633666992]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9968 [D loss: 0.5729380249977112 | D accuracy: 73.4375] [G loss: 1.2169911861419678]\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "9969 [D loss: 0.607786625623703 | D accuracy: 60.9375] [G loss: 1.375913143157959]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9970 [D loss: 0.5404533743858337 | D accuracy: 68.75] [G loss: 1.1773779392242432]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9971 [D loss: 0.5952781140804291 | D accuracy: 65.625] [G loss: 1.2722175121307373]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9972 [D loss: 0.5612730085849762 | D accuracy: 75.0] [G loss: 1.231725811958313]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "9973 [D loss: 0.4779093712568283 | D accuracy: 79.6875] [G loss: 1.2666702270507812]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "9974 [D loss: 0.44625604152679443 | D accuracy: 84.375] [G loss: 1.3052501678466797]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "9975 [D loss: 0.5626594722270966 | D accuracy: 67.1875] [G loss: 1.3781585693359375]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9976 [D loss: 0.5719759166240692 | D accuracy: 62.5] [G loss: 1.4666748046875]\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9977 [D loss: 0.5457054376602173 | D accuracy: 70.3125] [G loss: 1.254276156425476]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9978 [D loss: 0.6522279679775238 | D accuracy: 65.625] [G loss: 1.345684289932251]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9979 [D loss: 0.5967411994934082 | D accuracy: 62.5] [G loss: 1.1256093978881836]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9980 [D loss: 0.5138506889343262 | D accuracy: 78.125] [G loss: 1.206861972808838]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "9981 [D loss: 0.5427549779415131 | D accuracy: 70.3125] [G loss: 1.2077829837799072]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9982 [D loss: 0.5137331187725067 | D accuracy: 67.1875] [G loss: 1.1422820091247559]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9983 [D loss: 0.5204969346523285 | D accuracy: 67.1875] [G loss: 1.2010338306427002]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "9984 [D loss: 0.4355800747871399 | D accuracy: 76.5625] [G loss: 1.2814381122589111]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9985 [D loss: 0.531930148601532 | D accuracy: 70.3125] [G loss: 1.3906844854354858]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9986 [D loss: 0.5939087271690369 | D accuracy: 67.1875] [G loss: 1.3433425426483154]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9987 [D loss: 0.5625881850719452 | D accuracy: 70.3125] [G loss: 1.3359968662261963]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9988 [D loss: 0.5002644062042236 | D accuracy: 78.125] [G loss: 1.2681403160095215]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "9989 [D loss: 0.4994190037250519 | D accuracy: 73.4375] [G loss: 1.2861285209655762]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9990 [D loss: 0.6285229921340942 | D accuracy: 67.1875] [G loss: 1.4345629215240479]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9991 [D loss: 0.5458329916000366 | D accuracy: 75.0] [G loss: 1.4178261756896973]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "9992 [D loss: 0.5484389662742615 | D accuracy: 71.875] [G loss: 1.2442259788513184]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9993 [D loss: 0.5418122112751007 | D accuracy: 65.625] [G loss: 1.1581653356552124]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9994 [D loss: 0.5732997953891754 | D accuracy: 67.1875] [G loss: 1.3242723941802979]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9995 [D loss: 0.5820403695106506 | D accuracy: 78.125] [G loss: 1.1972668170928955]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9996 [D loss: 0.4944568872451782 | D accuracy: 76.5625] [G loss: 1.435636281967163]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9997 [D loss: 0.5901122689247131 | D accuracy: 73.4375] [G loss: 1.472813367843628]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9998 [D loss: 0.5637006461620331 | D accuracy: 71.875] [G loss: 1.3019280433654785]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9999 [D loss: 0.5716351568698883 | D accuracy: 68.75] [G loss: 1.1772921085357666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_images(epoch='final')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "kFlvQpk0TkCy",
        "outputId": "57dc27f0-bc47-48cb-d481-e2c89496cb52"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_real_vs_fake():\n",
        "    r, c = 5, 5\n",
        "    real_imgs = x_test[:r * c]\n",
        "    real_labels = y_test[:r * c]\n",
        "\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    fake_imgs = generator.predict([noise, real_labels])\n",
        "\n",
        "    real_imgs = 0.5 * real_imgs + 0.5\n",
        "    fake_imgs = 0.5 * fake_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c, figsize=(10, 10))\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            if j % 2 == 0:\n",
        "                axs[i, j].imshow(real_imgs[i * c + j], cmap='gray')\n",
        "                axs[i, j].set_title(\"Real\")\n",
        "            else:\n",
        "                axs[i, j].imshow(fake_imgs[i * c + j], cmap='gray')\n",
        "                axs[i, j].set_title(\"Fake\")\n",
        "            axs[i, j].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize_real_vs_fake()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "bmkEl7U7TmI7",
        "outputId": "01307be7-cb23-4634-a36a-ee0f7ef24bc2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 265ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}