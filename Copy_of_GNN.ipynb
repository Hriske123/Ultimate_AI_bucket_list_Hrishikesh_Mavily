{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzlSq1rdQInP",
        "outputId": "231176eb-0588-47f7-9cfc-53534c823c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4daJZXWwQojl",
        "outputId": "c0324053-9171-4615-c39c-d57cc3971d62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/pyg_lib-0.4.0%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m947.1/947.1 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt23cu121 torch_cluster-1.6.3+pt23cu121 torch_scatter-2.1.2+pt23cu121 torch_sparse-0.6.18+pt23cu121 torch_spline_conv-1.2.2+pt23cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upyLy2NlQupd",
        "outputId": "95169679-fed9-4f12-ffdc-d6b4a45a8437"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.3-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wlZmLAeanv3",
        "outputId": "a1ef0fd3-08a6-4225-886c-a9335436f68a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepchem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARkongB2bFKG",
        "outputId": "be3f1dbf-e8b1-4f5a-fe06-79404adb1ad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.12.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.11.4)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2024.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (9.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
            "Installing collected packages: deepchem\n",
            "Successfully installed deepchem-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install scipy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4L0GnZwdAyz",
        "outputId": "983f0962-a5f8-480e-ccfa-030999144607"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem\n",
        "import os\n",
        "\n",
        "deepchem_dir = os.path.dirname(deepchem.__file__)\n",
        "print(deepchem_dir)\n",
        "import fileinput\n",
        "\n",
        "rdkit_descriptors_path = os.path.join(deepchem_dir, 'feat', 'molecule_featurizers', 'rdkit_descriptors.py')\n",
        "\n",
        "# Replace 'gilbrat' with 'gibrat' in the rdkit_descriptors.py file\n",
        "with fileinput.FileInput(rdkit_descriptors_path, inplace=True) as file:\n",
        "    for line in file:\n",
        "        print(line.replace(\"gilbrat\", \"gibrat\"), end='')\n",
        "\n",
        "# Now import deepchem as usual\n",
        "import deepchem as dc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjGMkXi2faEI",
        "outputId": "a76d0217-18a4-4037-e6c8-302154c16e57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deepchem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# URL of the dataset\n",
        "url = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/HIV.csv\"\n",
        "\n",
        "# Path where the file will be saved\n",
        "file_path = \"HIV.csv\"\n",
        "\n",
        "# Download the file\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0m_KCbmojdw",
        "outputId": "7012aa54-ef5b-4e08-e6f5-8209c4821eb8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('HIV.csv', <http.client.HTTPMessage at 0x7d8575aa3a60>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check the current directory\n",
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)\n",
        "\n",
        "# List files in the current directory\n",
        "files_in_dir = os.listdir(current_dir)\n",
        "print(\"Files in current directory:\", files_in_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi6FiYLV9RnN",
        "outputId": "ad52bb96-787d-441c-a270-527e131a481e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n",
            "Files in current directory: ['.config', 'HIV.csv', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path of the new directory\n",
        "new_dir_path = '/content/raw'\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(new_dir_path, exist_ok=True)\n",
        "\n",
        "# Verify that the directory has been created\n",
        "if os.path.exists(new_dir_path):\n",
        "    print(f\"Directory '{new_dir_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Failed to create directory '{new_dir_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgLmjV3i_390",
        "outputId": "350b65a2-0a7c-4c74-e6fd-4cc5021b3b3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/raw' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "source_file = '/content/HIV.csv'  # Adjust the source path as per your file location\n",
        "target_directory = '/content/raw'\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source_file, target_directory)\n",
        "\n",
        "# Verify that the file has been moved\n",
        "new_file_path = os.path.join(target_directory, 'HIV.csv')\n",
        "if os.path.exists(new_file_path):\n",
        "    print(f\"HIV.csv moved to '{target_directory}' successfully.\")\n",
        "else:\n",
        "    print(f\"Failed to move HIV.csv to '{target_directory}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_IruGaJAbyM",
        "outputId": "ffe230bf-8646-46a9-9788-256a7b0039c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIV.csv moved to '/content/raw' successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import deepchem as dc\n",
        "from rdkit import Chem\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
        "\n",
        "class MoleculeDataset(Dataset):\n",
        "    def __init__(self, root, filename, test=False, transform=None, pre_transform=None):\n",
        "        \"\"\"\n",
        "        root = Where the dataset should be stored. This folder is split\n",
        "        into raw_dir (downloaded dataset) and processed_dir (processed data).\n",
        "        \"\"\"\n",
        "        self.test = test\n",
        "        self.filename = filename\n",
        "        super(MoleculeDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
        "            (The download func. is not implemented here)\n",
        "        \"\"\"\n",
        "        return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "\n",
        "        if self.test:\n",
        "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
        "        else:\n",
        "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
        "\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
        "        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
        "        for index, row in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "            # Featurize molecule\n",
        "            mol = Chem.MolFromSmiles(row[\"smiles\"])\n",
        "            f = featurizer._featurize(mol)\n",
        "            data = f.to_pyg_graph()\n",
        "            data.y = self._get_label(row[\"HIV_active\"])\n",
        "            data.smiles = row[\"smiles\"]\n",
        "            if self.test:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{index}.pt'))\n",
        "            else:\n",
        "                torch.save(data,\n",
        "                    os.path.join(self.processed_dir,\n",
        "                                 f'data_{index}.pt'))\n",
        "\n",
        "\n",
        "    def _get_label(self, label):\n",
        "        label = np.asarray([label])\n",
        "        return torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "    def len(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def get(self, idx):\n",
        "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
        "            - Is not needed for PyG's InMemoryDataset\n",
        "        \"\"\"\n",
        "        if self.test:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_test_{idx}.pt'))\n",
        "        else:\n",
        "            data = torch.load(os.path.join(self.processed_dir,\n",
        "                                 f'data_{idx}.pt'))\n",
        "        return data\n",
        "dataset = MoleculeDataset(root=\"/content\",filename=\"HIV.csv\")\n",
        "print(dataset[0].edge_index.t())\n",
        "print(dataset[0].x)\n",
        "print(dataset[0].edge_attr)\n",
        "print(dataset[0].y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMOP7OFEaMJy",
        "outputId": "844b3681-e822-4514-904b-febc4dd7089d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.3.0+cu121\n",
            "Cuda available: False\n",
            "Torch geometric version: 2.5.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            " 85%|████████▌ | 35138/41127 [09:08<01:05, 91.75it/s][14:59:01] WARNING: not removing hydrogen atom without neighbors\n",
            "[14:59:01] WARNING: not removing hydrogen atom without neighbors\n",
            "100%|██████████| 41127/41127 [10:57<00:00, 62.55it/s]\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1],\n",
            "        [ 1,  0],\n",
            "        [ 1,  2],\n",
            "        [ 2,  1],\n",
            "        [ 2,  3],\n",
            "        [ 3,  2],\n",
            "        [ 3,  4],\n",
            "        [ 4,  3],\n",
            "        [ 4,  5],\n",
            "        [ 5,  4],\n",
            "        [ 5,  6],\n",
            "        [ 6,  5],\n",
            "        [ 6,  7],\n",
            "        [ 7,  6],\n",
            "        [ 7,  8],\n",
            "        [ 8,  7],\n",
            "        [ 6,  9],\n",
            "        [ 9,  6],\n",
            "        [ 4, 10],\n",
            "        [10,  4],\n",
            "        [10, 11],\n",
            "        [11, 10],\n",
            "        [11, 12],\n",
            "        [12, 11],\n",
            "        [12, 13],\n",
            "        [13, 12],\n",
            "        [11, 14],\n",
            "        [14, 11],\n",
            "        [14, 15],\n",
            "        [15, 14],\n",
            "        [15, 16],\n",
            "        [16, 15],\n",
            "        [16, 17],\n",
            "        [17, 16],\n",
            "        [15, 18],\n",
            "        [18, 15],\n",
            "        [ 9,  2],\n",
            "        [ 2,  9],\n",
            "        [18,  4],\n",
            "        [ 4, 18]])\n",
            "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -3.,  0.,  0.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
            "          0.,  0.],\n",
            "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
            "          0.,  0.],\n",
            "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
            "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
            "          0.,  0.]])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]])\n",
            "tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deepfindr/gnn-project\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqAe3BzAM5aU",
        "outputId": "562681ef-d8f8-459d-f94f-d8842a55eaba"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gnn-project'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 85 (delta 42), reused 59 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (85/85), 3.36 MiB | 3.65 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check the current directory\n",
        "current_dir = os.getcwd()\n",
        "print(\"Current directory:\", current_dir)\n",
        "\n",
        "# List files in the current directory\n",
        "files_in_dir = os.listdir(current_dir)\n",
        "print(\"Files in current directory:\", files_in_dir)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSoEaZl6NTvt",
        "outputId": "7332c32a-6339-48ff-f618-3b70b5e8cc9d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/gnn-project\n",
            "Files in current directory: ['utils.py', 'requirements.txt', 'dataset_featurizer.py', 'dashboard.py', 'model.py', 'oversample_data.py', 'data', 'README.md', '.gitignore', 'predict.py', '__pycache__', 'dataset.py', '.git', 'train.py', 'config.py']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNu8rHNoOhr3",
        "outputId": "d1bbe1a1-a003-4acd-edb7-ba7e73382e5f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.14.2-py3-none-any.whl (25.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow)\n",
            "  Downloading importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.31)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Collecting gunicorn<23 (from mlflow)\n",
            "  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<8,>=3.7.0 (from mlflow)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: aniso8601, smmap, querystring-parser, Mako, importlib-metadata, gunicorn, graphql-core, deprecated, opentelemetry-api, graphql-relay, gitdb, docker, alembic, opentelemetry-semantic-conventions, graphene, gitpython, opentelemetry-sdk, mlflow\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 aniso8601-9.0.1 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 importlib-metadata-7.1.0 mlflow-2.14.2 opentelemetry-api-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mango"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8U0xLSA3O2n3",
        "outputId": "09f1343f-4cde-4d3c-ec34-144ab0eb1c42"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mango\n",
            "  Downloading mango-0.2.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi<=2023.7.22 (from mango)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<=3.3.0 (from mango)\n",
            "  Downloading charset_normalizer-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile<=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mango) (1.1.0)\n",
            "Collecting fastjsonschema<=2.18.1 (from mango)\n",
            "  Downloading fastjsonschema-2.18.1-py3-none-any.whl (23 kB)\n",
            "Collecting idna<=3.4 (from mango)\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<=1.26.1 in /usr/local/lib/python3.10/dist-packages (from mango) (1.25.2)\n",
            "Collecting openpyxl<=3.1.2 (from mango)\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<=2.4.2 (from mango)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<=2.8.2 in /usr/local/lib/python3.10/dist-packages (from mango) (2.8.2)\n",
            "Collecting pytups<=0.86.2 (from mango)\n",
            "  Downloading pytups-0.86.2-py3-none-any.whl (14 kB)\n",
            "Collecting pytz<=2023.3.post1 (from mango)\n",
            "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<=2.31.0 in /usr/local/lib/python3.10/dist-packages (from mango) (2.31.0)\n",
            "Requirement already satisfied: six<=1.16.0 in /usr/local/lib/python3.10/dist-packages (from mango) (1.16.0)\n",
            "Collecting tqdm<=4.66.1 (from mango)\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<=2.0.7 in /usr/local/lib/python3.10/dist-packages (from mango) (2.0.7)\n",
            "Collecting XlsxWriter<=3.1.9 (from mango)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<=2.4.2->mango) (0.7.0)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic<=2.4.2->mango)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<=2.4.2->mango) (4.12.2)\n",
            "Installing collected packages: pytz, pytups, fastjsonschema, XlsxWriter, tqdm, pydantic-core, openpyxl, idna, charset-normalizer, certifi, pydantic, mango\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  Attempting uninstall: fastjsonschema\n",
            "    Found existing installation: fastjsonschema 2.20.0\n",
            "    Uninstalling fastjsonschema-2.20.0:\n",
            "      Successfully uninstalled fastjsonschema-2.20.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.20.0\n",
            "    Uninstalling pydantic_core-2.20.0:\n",
            "      Successfully uninstalled pydantic_core-2.20.0\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.1.5\n",
            "    Uninstalling openpyxl-3.1.5:\n",
            "      Successfully uninstalled openpyxl-3.1.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.6.2\n",
            "    Uninstalling certifi-2024.6.2:\n",
            "      Successfully uninstalled certifi-2024.6.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.8.0\n",
            "    Uninstalling pydantic-2.8.0:\n",
            "      Successfully uninstalled pydantic-2.8.0\n",
            "Successfully installed XlsxWriter-3.1.9 certifi-2023.7.22 charset-normalizer-3.3.0 fastjsonschema-2.18.1 idna-3.4 mango-0.2.2 openpyxl-3.1.2 pydantic-2.4.2 pydantic-core-2.10.1 pytups-0.86.2 pytz-2023.3.post1 tqdm-4.66.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "charset_normalizer",
                  "pytz",
                  "tqdm"
                ]
              },
              "id": "4509884b35884dc78eb2d0c13e2f05cd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JQMFTsERo_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mango import __init__\n",
        "dir(__init__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgwVHD05Pt-P",
        "outputId": "996e856c-4ec0-4af8-d636-62dc605be5a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__name__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__objclass__',\n",
              " '__qualname__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__self__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__text_signature__']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% imports\n",
        "import torch\n",
        "from torch_geometric.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
        "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "%cd /content/gnn-project\n",
        "from dataset_featurizer import MoleculeDataset\n",
        "from model import GNN\n",
        "from config import HYPERPARAMETERS, BEST_PARAMETERS, SIGNATURE\n",
        "import data\n",
        "%cd /content\n",
        "\n",
        "import mlflow.pytorch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Specify tracking server\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
        "    # Enumerate over the data\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    running_loss = 0.0\n",
        "    step = 0\n",
        "    for _, batch in enumerate(tqdm(train_loader)):\n",
        "        # Use GPU\n",
        "        batch.to(device)\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Passing the node features and the connection info\n",
        "        pred = model(batch.x.float(),\n",
        "                                batch.edge_attr.float(),\n",
        "                                batch.edge_index,\n",
        "                                batch.batch)\n",
        "        # Calculating the loss and gradients\n",
        "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking\n",
        "        running_loss += loss.item()\n",
        "        step += 1\n",
        "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
        "        all_labels.append(batch.y.cpu().detach().numpy())\n",
        "    all_preds = np.concatenate(all_preds).ravel()\n",
        "    all_labels = np.concatenate(all_labels).ravel()\n",
        "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
        "    return running_loss/step\n",
        "\n",
        "def test(epoch, model, test_loader, loss_fn):\n",
        "    all_preds = []\n",
        "    all_preds_raw = []\n",
        "    all_labels = []\n",
        "    running_loss = 0.0\n",
        "    step = 0\n",
        "    for batch in test_loader:\n",
        "        batch.to(device)\n",
        "        pred = model(batch.x.float(),\n",
        "                        batch.edge_attr.float(),\n",
        "                        batch.edge_index,\n",
        "                        batch.batch)\n",
        "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
        "\n",
        "         # Update tracking\n",
        "        running_loss += loss.item()\n",
        "        step += 1\n",
        "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
        "        all_preds_raw.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
        "        all_labels.append(batch.y.cpu().detach().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds).ravel()\n",
        "    all_labels = np.concatenate(all_labels).ravel()\n",
        "    print(all_preds_raw[0][:10])\n",
        "    print(all_preds[:10])\n",
        "    print(all_labels[:10])\n",
        "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
        "    log_conf_matrix(all_preds, all_labels, epoch)\n",
        "    return running_loss/step\n",
        "\n",
        "def log_conf_matrix(y_pred, y_true, epoch):\n",
        "    # Log confusion matrix as image\n",
        "    cm = confusion_matrix(y_pred, y_true)\n",
        "    classes = [\"0\", \"1\"]\n",
        "    df_cfm = pd.DataFrame(cm, index = classes, columns = classes)\n",
        "    plt.figure(figsize = (10,7))\n",
        "    cfm_plot = sns.heatmap(df_cfm, annot=True, cmap='Blues', fmt='g')\n",
        "    cfm_plot.figure.savefig(f'data/images/cm_{epoch}.png')\n",
        "    mlflow.log_artifact(f\"data/images/cm_{epoch}.png\")\n",
        "\n",
        "def calculate_metrics(y_pred, y_true, epoch, type):\n",
        "    print(f\"\\n Confusion matrix: \\n {confusion_matrix(y_pred, y_true)}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred)}\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    print(f\"Precision: {prec}\")\n",
        "    print(f\"Recall: {rec}\")\n",
        "    mlflow.log_metric(key=f\"Precision-{type}\", value=float(prec), step=epoch)\n",
        "    mlflow.log_metric(key=f\"Recall-{type}\", value=float(rec), step=epoch)\n",
        "    try:\n",
        "        roc = roc_auc_score(y_true, y_pred)\n",
        "        print(f\"ROC AUC: {roc}\")\n",
        "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
        "    except:\n",
        "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(0), step=epoch)\n",
        "        print(f\"ROC AUC: notdefined\")\n",
        "\n",
        "\n",
        "# %% Run the training\n",
        "from mango import Tuner,scheduler\n",
        "\n",
        "def run_one_training(params):\n",
        "    params = params[0]\n",
        "    with mlflow.start_run() as run:\n",
        "        # Log parameters used in this experiment\n",
        "        for key in params.keys():\n",
        "            mlflow.log_param(key, params[key])\n",
        "\n",
        "        # Loading the dataset\n",
        "        print(\"Loading dataset...\")\n",
        "        train_dataset = MoleculeDataset(root=\"data/\", filename=\"HIV_train_oversampled.csv\")\n",
        "        test_dataset = MoleculeDataset(root=\"data/\", filename=\"HIV_test.csv\", test=True)\n",
        "        params[\"model_edge_dim\"] = train_dataset[0].edge_attr.shape[1]\n",
        "\n",
        "        # Prepare training\n",
        "        train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "\n",
        "        # Loading the model\n",
        "        print(\"Loading model...\")\n",
        "        model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}\n",
        "        model = GNN(feature_size=train_dataset[0].x.shape[1], model_params=model_params)\n",
        "        model = model.to(device)\n",
        "        print(f\"Number of parameters: {count_parameters(model)}\")\n",
        "        mlflow.log_param(\"num_params\", count_parameters(model))\n",
        "\n",
        "        # < 1 increases precision, > 1 recall\n",
        "        weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
        "        loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
        "        optimizer = torch.optim.SGD(model.parameters(),\n",
        "                                    lr=params[\"learning_rate\"],\n",
        "                                    momentum=params[\"sgd_momentum\"],\n",
        "                                    weight_decay=params[\"weight_decay\"])\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=params[\"scheduler_gamma\"])\n",
        "\n",
        "        # Start training\n",
        "        best_loss = 1000\n",
        "        early_stopping_counter = 0\n",
        "        for epoch in range(300):\n",
        "            if early_stopping_counter <= 10: # = x * 5\n",
        "                # Training\n",
        "                model.train()\n",
        "                loss = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
        "                print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
        "                mlflow.log_metric(key=\"Train loss\", value=float(loss), step=epoch)\n",
        "\n",
        "                # Testing\n",
        "                model.eval()\n",
        "                if epoch % 5 == 0:\n",
        "                    loss = test(epoch, model, test_loader, loss_fn)\n",
        "                    print(f\"Epoch {epoch} | Test Loss {loss}\")\n",
        "                    mlflow.log_metric(key=\"Test loss\", value=float(loss), step=epoch)\n",
        "\n",
        "                    # Update best loss\n",
        "                    if float(loss) < best_loss:\n",
        "                        best_loss = loss\n",
        "                        # Save the currently best model\n",
        "                        mlflow.pytorch.log_model(model, \"model\", signature=SIGNATURE)\n",
        "                        early_stopping_counter = 0\n",
        "                    else:\n",
        "                        early_stopping_counter += 1\n",
        "\n",
        "                scheduler.step()\n",
        "            else:\n",
        "                print(\"Early stopping due to no improvement.\")\n",
        "                return [best_loss]\n",
        "    print(f\"Finishing training with best test loss: {best_loss}\")\n",
        "    return [best_loss]\n",
        "\n",
        "# %% Hyperparameter search\n",
        "print(\"Running hyperparameter search...\")\n",
        "config = dict()\n",
        "config[\"optimizer\"] = \"Bayesian\"\n",
        "config[\"num_iteration\"] = 100\n",
        "\n",
        "tuner = Tuner(HYPERPARAMETERS,\n",
        "              objective=run_one_training,\n",
        "              conf_dict=config)\n",
        "results = tuner.minimize()"
      ],
      "metadata": {
        "id": "4RZYewVre_-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "66334fd8-77b2-46d2-9f05-46fe74248813"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gnn-project\n",
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Tuner' from 'mango' (/usr/local/lib/python3.10/dist-packages/mango/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-eba532d324ba>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m# %% Run the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmango\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_one_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tuner' from 'mango' (/usr/local/lib/python3.10/dist-packages/mango/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}